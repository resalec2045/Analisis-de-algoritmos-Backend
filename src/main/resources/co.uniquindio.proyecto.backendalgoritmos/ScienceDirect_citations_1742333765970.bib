@article{LEHRER200039,
title = {Developing Model-Based Reasoning in Mathematics and Science},
journal = {Journal of Applied Developmental Psychology},
volume = {21},
number = {1},
pages = {39-48},
year = {2000},
issn = {0193-3973},
doi = {https://doi.org/10.1016/S0193-3973(99)00049-0},
url = {https://www.sciencedirect.com/science/article/pii/S0193397399000490},
author = {Richard Lehrer and Leona Schauble},
abstract = {It is essential to base instruction on a foundation of understanding of children's thinking, but it is equally important to adopt the longer-term view that is needed to stretch these early competencies into forms of thinking that are complex, multifaceted, and subject to development over years, rather than weeks or months. We pursue this topic through our studies of model-based reasoning. We have identified four forms of models and related modeling practices that show promise for developing model-based reasoning. Models have the fortuitous feature of making forms of student reasoning public and inspectable—not only among the community of modelers, but also to teachers. Modeling provides feedback about student thinking that can guide teaching decisions, an important dividend for improving professional practice.}
}
@incollection{PERKINS2002187,
title = {Standard logic as a model of reasoning: The empirical critique},
editor = {Dov M. Gabbay and Ralph H. Johnson and Hans Jürgen Ohlbach and John Woods},
series = {Studies in Logic and Practical Reasoning},
publisher = {Elsevier},
volume = {1},
pages = {187-223},
year = {2002},
booktitle = {Handbook of the Logic of Argument and Inference},
issn = {1570-2464},
doi = {https://doi.org/10.1016/S1570-2464(02)80007-6},
url = {https://www.sciencedirect.com/science/article/pii/S1570246402800076},
author = {David N. Perkins},
abstract = {Publisher Summary
This chapter describes standard logic as a model of reasoning. The notion of formal logic has figured centrally in conceptions of human reasoning, rationality, and adaptiveness. The chapter reviews the evidence, appraises its weight, and offers a summative judgment of the place of logic in human thinking. "Standard logic," includes the canons of formal deduction, the special case of disconfirming hypotheses by finding counterevidence for their implications, and also the principles of probabilistic and statistical inference developed by mathematicians over the past couple of hundred years. It also examines deliberate or reflexive reasoning. The chapter argues that standard logic or subsets of it can be implemented in quite different ways and that human cognition incorporates more than one implementation. In addition, almost all the research on the role of standard logic in human thinking concerns deliberate rather than reflexive reasoning. Accordingly, the present analysis focuses on deliberate reasoning and the place of standard logic in it.}
}
@article{SOSA201656,
title = {Visual divergence in humans and computers},
journal = {Design Studies},
volume = {42},
pages = {56-85},
year = {2016},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000836},
author = {Ricardo Sosa and Nicolas Rojas and John S. Gero and Qinqi Xu},
keywords = {creativity, sketching, computer models, solution space},
abstract = {Studies of design creativity have underlined the importance of divergent reasoning and visual reasoning in idea generation. Connecting these two key design skills, this paper presents a model of divergent visual reasoning for the study of creativity. A visual divergence task called ShapeStorm is demonstrated for the study of creative ideation that can be applied to humans as well as computational systems. The model is examined in a study with human subjects, a computational stochastic generator, and a geometrical analysis of the solution space. The main significance of this task is that it offers a straightforward means to define a simple design task that can be used across research studies. Several scenarios for the application of ShapeStorm for the study of creativity are advanced.}
}
@article{COOK201895,
title = {An investigation of an undergraduate student’s reasoning with zero-divisors and the zero-product property},
journal = {The Journal of Mathematical Behavior},
volume = {49},
pages = {95-115},
year = {2018},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2017.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312317301748},
author = {John Paul Cook},
keywords = {Abstract algebra, Zero-product property, Zero-divisors, Equation solving, Student thinking, Realistic Mathematics Education},
abstract = {The zero-product property (ZPP), often stated as ‘if ab = 0, then a = 0 or b = 0,’ is an important concept in secondary algebra (as a tool for solving equations) and abstract algebra (as a property of integral domains). This study analyzes results from a teaching experiment to investigate how an undergraduate mathematics major might intuitively reason with zero-divisors and the ZPP. There are two primary findings. First, a procedurally embodied view of equation solving might preclude students’ attention to the algebraic properties (including the ZPP) that justify the equivalence of two equations. Second, students might not carefully attend to zero-divisors because they are employing the converse of the ZPP instead of the ZPP itself. These findings advance a hypothesis about why students might view abstract algebra as a different subject than school algebra and also affirm the utility of the student-centered theoretical perspective that guided the instructional design and analysis of student activity.}
}
@article{KASHYAPKASHYAP2021395,
title = {The universal language: mathematics or music?},
journal = {Journal for Multicultural Education},
volume = {15},
number = {4},
pages = {395-415},
year = {2021},
issn = {2053-535X},
doi = {https://doi.org/10.1108/JME-05-2021-0064},
url = {https://www.sciencedirect.com/science/article/pii/S2053535X21000197},
author = {RaviRavi KashyapKashyap},
keywords = {Mathematics, Multicultural, Music, Education policy, Artistic encoding of knowledge, Universal language},
abstract = {Purpose
Music could be a challenger for mathematics and a potential candidate for the title “The Universal Language.” This paper aims to discuss the primary objectives of engaging with music, including the therapeutic benefits. Similarities, between mathematics and music and how studying one might enhance one’s abilities of the other are pointed out.
Design/methodology/approach
A formal definition for a universal language is given. A qualitative approach, supplemented with rigorous reasoning, is adopted. The narrative relies on the author’s experiences, teaching mathematical concepts and musical interactions, with students from several countries. A vast amount of literature is reviewed and the corresponding findings are connected toward the arguments made.
Findings
The paper demonstrates that one day, once we understand both mathematics and music better, we might see both of them as the same language. Until then, it is essential to supplement mathematics with music. The educational implications, for all fields, are to ensure that the future creators of knowledge are equally adept at both music and mathematics. The wider policy connotations are to create a blueprint for a society with a vibrant musical and artistic environment.
Originality/value
This study illuminates new ways of thinking about music and mathematics. The possibility that many seemingly complex entities (including our universe, virtual computer worlds, mathematical operations, etc.), are made up of combinations of much simpler building blocks is hinted at. Familiarity with any intricate element of life, without getting flustered, is bound to produce remarkable results in other such endeavors.}
}
@article{VONRICHTHOFEN2018573,
title = {The ‘Urban Elements’ method for teaching parametric urban design to professionals},
journal = {Frontiers of Architectural Research},
volume = {7},
number = {4},
pages = {573-587},
year = {2018},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2018.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S209526351830044X},
author = {Aurel {von Richthofen} and Katja Knecht and Yufan Miao and Reinhard König},
keywords = {Urban design education, Parametric urban design, Singapore, Urban Elements},
abstract = {The article proposes a method for teaching advanced urban design to working professionals in Singapore. The article aims to expand the discourse on parametric urban design education by introducing ‘Urban Elements’ as conceptual urban design instruments with an inherent rule-based logic, which can help to bridge gaps in teaching parametric urban design thinking. As case study we present a course developed for and delivered to the Urban Redevelopment Authority (URA) in Singapore in 2017 by the Future Cities Laboratory at the Singapore-ETH Centre. The article reports on the pedagogical method, course results and course feedback. The main difficulties of teaching professionals in parametric urban design are described and possible reasons and improvements are discussed. The results show that participants using the ‘Urban Elements’ method successfully linked theoretical input to urban design problems, applied evidence-based urban design strategies to these problems, and developed parametric definitions to explore the solution spaces of these urban design challenges. The teaching methodology presented opens up a new research field for urban design pedagogy at the intersection of explicating urban design intent, integrating multidisciplinary knowledge and exploring new software driven tools.}
}
@article{BIALEK19901227,
title = {Temporal filtering in retinal bipolar cells. Elements of an optimal computation?},
journal = {Biophysical Journal},
volume = {58},
number = {5},
pages = {1227-1233},
year = {1990},
issn = {0006-3495},
doi = {https://doi.org/10.1016/S0006-3495(90)82463-2},
url = {https://www.sciencedirect.com/science/article/pii/S0006349590824632},
author = {W. Bialek and W.G. Owen},
abstract = {Recent experiments indicate that the dark-adapted vertebrate visual system can count photons with a reliability limited by dark noise in the rod photoreceptors themselves. This suggests that subsequent layers of the retina, responsible for signal processing, add little if any excess noise and extract all the available information. Given the signal and noise characteristics of the photoreceptors, what is the structure of such an optimal processor? We show that optimal estimates of time-varying light intensity can be accomplished by a two-stage filter, and we suggest that the first stage should be identified with the filtering which occurs at the first anatomical stage in retinal signal processing, signal transfer from the rod photoreceptor to the bipolar cell. This leads to parameter-free predictions of the bipolar cell response, which are in excellent agreement with experiments comparing rod and bipolar cell dynamics in the same retina. As far as we know this is the first case in which the computationally significant dynamics of a neuron could be predicted rather than modeled.}
}
@article{CUI2024101074,
title = {AI-enhanced collective intelligence},
journal = {Patterns},
volume = {5},
number = {11},
pages = {101074},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.101074},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924002332},
author = {Hao Cui and Taha Yasseri},
keywords = {AI, collective intelligence, hybrid intelligence, multi-agent systems, human-machine networks, human-machine intelligence},
abstract = {Summary
Current societal challenges exceed the capacity of humans operating either alone or collectively. As AI evolves, its role within human collectives will vary from an assistive tool to a participatory member. Humans and AI possess complementary capabilities that, together, can surpass the collective intelligence of either humans or AI in isolation. However, the interactions in human-AI systems are inherently complex, involving intricate processes and interdependencies. This review incorporates perspectives from complex network science to conceptualize a multilayer representation of human-AI collective intelligence, comprising cognition, physical, and information layers. Within this multilayer network, humans and AI agents exhibit varying characteristics; humans differ in diversity from surface-level to deep-level attributes, while AI agents range in degrees of functionality and anthropomorphism. We explore how agents’ diversity and interactions influence the system’s collective intelligence and analyze real-world instances of AI-enhanced collective intelligence. We conclude by considering potential challenges and future developments in this field.}
}
@article{INIGUEZLOMELI2024105106,
title = {A hardware architecture for single and multiple ellipse detection using genetic algorithms and high-level synthesis tools},
journal = {Microprocessors and Microsystems},
volume = {111},
pages = {105106},
year = {2024},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2024.105106},
url = {https://www.sciencedirect.com/science/article/pii/S0141933124001017},
author = {Francisco J. Iñiguez-Lomeli and Carlos H. Garcia-Capulin and Horacio Rostro-Gonzalez},
keywords = {Ellipse detection, Genetic algorithm, System-on-a-Chip (SoC), High-level synthesis (HLS), Hardware implementation, FPGA},
abstract = {Ellipse detection techniques are often developed and validated in software environments, neglecting the critical consideration of computational efficiency and resource constraints prevalent in embedded systems. Furthermore, programmable logic devices, notably Field Programmable Gate Arrays (FPGAs), have emerged as indispensable assets for enhancing performance and expediting various processing applications. In the realm of computational efficiency, hardware implementations have the flexibility to tailor the required arithmetic for various applications using fixed-point representation. This approach enables faster computations while upholding adequate accuracy, resulting in reduced resource and energy consumption compared to software applications that rely on higher clock speeds, which often lead to increased resource and energy consumption. Additionally, hardware solutions provide portability and are suitable for resource-constrained and battery-powered applications. This study introduces a novel hardware architecture in the form of an intellectual property core that harnesses the capabilities of a genetic algorithm to detect single and multi ellipses in digital images. In general, genetic algorithms have been demonstrated to be an alternative that shows better results than those based on traditional methods such as the Hough Transform and Random Sample Consensus, particularly in terms of accuracy, flexibility, and robustness. Our genetic algorithm randomly takes five edge points as parameters from the image tested, creating an individual treated as a potential candidate ellipse. The fitness evaluation function determines whether the candidate ellipse truly exists in the image space. The core is designed using Vitis High-Level Synthesis (HLS), a powerful tool that converts C or C＋＋functions into Register-Transfer Level (RTL) code, including VHDL and Verilog. The implementation and testing of the ellipse detection system were carried out on the PYNQ-Z1, a cost-effective development board housing the Xilinx Zynq-7000 System-on-Chip (SoC). PYNQ, an open-source framework, seamlessly integrates programmable logic with a dual-core ARM Cortex-A9 processor, offering the flexibility of Python programming for the onboard SoC processor. The experimental results, based on synthetic and real images, some of them with the presence of noise processed by the developed ellipse detection system, highlight the intellectual property core’s exceptional suitability for resource-constrained embedded systems. Notably, it achieves remarkable performance and accuracy rates, consistently exceeding 99% in most cases. This research aims to contribute to the advancement of hardware-accelerated ellipse detection, catering to the demanding requirements of real-time applications while minimizing resource consumption.}
}
@article{YOSHIOKA2024114985,
title = {An escort replicator dynamic with a continuous action space and its application to resource management},
journal = {Chaos, Solitons & Fractals},
volume = {185},
pages = {114985},
year = {2024},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2024.114985},
url = {https://www.sciencedirect.com/science/article/pii/S096007792400537X},
author = {Hidekazu Yoshioka},
keywords = {Evolutionary game, Escort replicator dynamic, Kaniadakis escort function, Numerical computation, Application to sustainable resource management},
abstract = {The escort replicator dynamic (ERD) is a version of the replicator dynamic in evolutionary games where the utility-driven decision-making process is modulated due to the information costs to be paid by players. The escort function as a coefficient to distort the decision-making determines the behavior of solutions to the ERD, whereas its investigations are still not sufficient. Particularly, the ERD was investigated in finite-action settings in the previous studies, while that with a continuum of actions has not been studied well. In this paper, we formulate and analyze the ERD with a continuum of actions represented by a bounded interval. Our ERD is a partial integro-differential equation whose well-posedness is nontrivial because of specific nonlocal terms arising from the escort function. The Kaniadakis escort function is chosen as a major example of the escort function, with which we obtain the unique existence of solutions to the ERD. We also discuss cases with the other escort functions, such as the power and constant ones, and suggest that the growth and regularity behaviors of the escort function are crucial. Finally, we computationally apply the ERD to problems related to sustainable environmental and resource management.}
}
@article{PAMPLONA2020100189,
title = {An overview of air delay: A case study of the Brazilian scenario},
journal = {Transportation Research Interdisciplinary Perspectives},
volume = {7},
pages = {100189},
year = {2020},
issn = {2590-1982},
doi = {https://doi.org/10.1016/j.trip.2020.100189},
url = {https://www.sciencedirect.com/science/article/pii/S2590198220301007},
author = {Daniel Alberto Pamplona and Claudio Jorge Pinto Alves},
keywords = {Air delay, Air traffic flow, Problem-structuring method, Value-focused thinking},
abstract = {Delay is a key point in air transportation activity. As a performance metric, it affects common policy concerns. Delay impacts passenger satisfaction and imposes costs. The complexity that sets in for the air traffic manager is how to mitigate delay, especially in an environment with several stakeholders. The present article applied a problem-structuring method (PSM), named value-focused thinking (VFT), to structure the problem of the air traffic flow management arrival delay. The inflexibility of incorporating a flight operator's specific needs is considered one of the reasons for the limited success of air traffic flow management (ATFM) programs. PSM allows participants to clarify their dilemmas, converge on a mutually liable problem, or agree to the proposed solutions and compromise on what partially solves the issue. The problem is that most papers focus only on the applied solution for air delay mitigation. Before implementing operational research techniques, we investigated the nature and characteristics of air delay. Results showed that there were several stakeholders with distinctive requirements for their business and many of their objectives are interconnected. The use of VFT provided an objective map that can be used as a guide for future solutions.}
}
@article{LIU2022121968,
title = {Comparison of coal-to-ethanol product separation strategies},
journal = {Separation and Purification Technology},
volume = {301},
pages = {121968},
year = {2022},
issn = {1383-5866},
doi = {https://doi.org/10.1016/j.seppur.2022.121968},
url = {https://www.sciencedirect.com/science/article/pii/S1383586622015234},
author = {Daoyan Liu and Hao Lyu and Jiahao Wang and Chengtian Cui and Jinsheng Sun},
keywords = {Coal-to-ethanol, Separation strategy, Differential evolution algorithm, Parallel computation, Heat integration},
abstract = {Given China's energy structure and the limitations of bioethanol, the coal-to-ethanol (CTE) pathway, from dimethyl ether to ethanol (DMTE) via carbonylation and hydrogenation, is highly anticipated. Ethanol, methanol, methyl acetate, and ethyl acetate are the crude hydrogenation products that need to be purified, requiring at least an eight-column scheme. However, the optimization of the existing separation strategy with ethanol as the priority is unfavorable in the following aspects: it is usually plagued by tedious rules of thumb and, due to the large scale of the process, is prone to falling into local minima; pre-designed heat integration inevitably neglects the interaction of parameter optimization and heat integration; reports on alternative feasible distillation sequences are scarce in publications, let alone comparisons amongst these counterparts. Therefore, four viable separation strategies are proposed in this paper to compare with this faulted separation strategy. A self-adapting dynamic differential evolution (SADDE) algorithm, which is accelerated by parallel computation, is used to search for optimal column parameters of all the configuration options and facilitates simultaneous heat integration structure synthesis. Two strategies stand out after 3000 generations of evolution. Splitting methanol outperforms in specific steam consumption (SSC) of ethanol (1.8177), much better than the benchmark (2.4840), and splitting ethyl acetate with ethyl acetate priority has the most competitive total annual cost (TAC), 23.98% lower than the benchmark. In summary, this paper provides a reference for optimizing complex distillation systems like CTE product separation, or more specifically, the DMTE route, before the appearance of the most suitable separation strategy in demand. Furthermore, it will also serve for the CTE superstructure to further explore the optimal distillation sequence.}
}
@article{KANCHANATAWAN2018168,
title = {Affective symptoms in schizophrenia are strongly associated with neurocognitive deficits indicating disorders in executive functions, visual memory, attention and social cognition},
journal = {Progress in Neuro-Psychopharmacology and Biological Psychiatry},
volume = {80},
pages = {168-176},
year = {2018},
note = {Peripheral markers of inflammation, oxidative & nitrosative stress pathways and memory functions as a new target of pharmacotherapy in depression},
issn = {0278-5846},
doi = {https://doi.org/10.1016/j.pnpbp.2017.06.031},
url = {https://www.sciencedirect.com/science/article/pii/S027858461730129X},
author = {Buranee Kanchanatawan and Supaksorn Thika and George Anderson and Piotr Galecki and Michael Maes},
keywords = {Major depression, Bipolar, Anxiety, Schizophrenia, CANTAB, Cognition},
abstract = {The aim of this study was to assess the neurocognitive correlates of affective symptoms in schizophrenia. Towards this end, 40 healthy controls and 80 schizophrenia patients were investigated with six tests of the Cambridge Neuropsychological Test Automated Battery (CANTAB), assessing spatial working memory, paired-association learning, one touch stocking, rapid visual information (RVP), emotional recognition test and intra/extradimensional set shifting. The Hamilton Depression (HDRS) and Anxiety (HAMA) Rating Scales and the Calgary Depression Scale for Schizophrenia (CDSS) as well as the Positive and Negative Syndrome Scale (PANSS) were also used. There were highly significant associations between all 6 CANTAB tests and HDRS, HAMA and CDSS (except RVP) scores. The most significant items associating with neurocognitive impairments in schizophrenia were self-depreciation (CDSS), fatigue, psychomotor retardation and agitation, psychic and somatic anxiety (HDRS), fears, cognitive symptoms, somatic-muscular, genito-urinary and autonomic symptoms and anxious behavior (HAMA). The selected HDRS and HAMA symptoms indicate fatigue, fears, anxiety, agitation, retardation, somatization and subjective cognitive complaints (SCC) and are therefore labeled “FAARS”. Up to 28.8% of the variance in the 6 CANTAB measurements was explained by FAARS, which are better predictors of neurocognitive impairments than the PANSS negative subscale score. Neurocognitive deficits in schizophrenia are best predicted by FAARS combined with difficulties in abstract thinking. In conclusion, depression and anxiety symptoms accompanying the negative and positive symptoms of schizophrenia are associated with neurocognitive deficits indicating disorders in executive functions, attention, visual memory, and social cognition. Neurocognitive deficits in schizophrenia reflect difficulties in abstract thinking and FAARS, including subjective cognitive complaints.}
}
@article{CHILMON2020106870,
title = {Modelling and simulation considerations for an end-to-end supply chain system},
journal = {Computers & Industrial Engineering},
volume = {150},
pages = {106870},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2020.106870},
url = {https://www.sciencedirect.com/science/article/pii/S0360835220305659},
author = {Barbara Chilmon and Nicoleta S. Tipi},
keywords = {Simulation, End-to-end supply chain, Systematic literature review},
abstract = {The efforts of this review paper are twofold: to provide an insightful examination of various contributions to knowledge surrounding simulation methods within an end-to-end supply chain and to guide research agenda by indicating generic elements required to model such systems using simulation. The authors examined 255 publications from 21 peer-reviewed journals in the field of an end-to-end supply chain and simulation using a systematic literature review approach. Each publication was thoroughly reviewed to capture best practices and key characteristics relative to simulation modelling techniques used in the context of complex end-to-end supply chain systems. This allowed for identification of generic elements required to model such systems, which were grouped into Structural, Computational and System Organization pillars. This research contributes to the body of knowledge by defining generic aspects of simulation modelling techniques used to study properties and attributes of complex end-to-end supply chains. The paper advances the theoretical understanding of the simulation methods used and applicability of simulation methodology in modelling end-to-end supply chain systems. The research presents the key findings from the use of simulation in modelling end-to-end supply chains and the main ways in which this modelling technique has informed research and practise.}
}
@article{MUNEEPEERAKUL2012123,
title = {The effect of scaling and connection on the sustainability of a socio-economic resource system},
journal = {Ecological Economics},
volume = {77},
pages = {123-128},
year = {2012},
issn = {0921-8009},
doi = {https://doi.org/10.1016/j.ecolecon.2012.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S092180091200081X},
author = {Rachata Muneepeerakul and Murad R. Qubbaj},
keywords = {Sustainability, Scaling, Connection, Bifurcation, Population dynamics},
abstract = {Policy makers dealing with complex systems oftentimes rely on “linear thinking.” This is understandable due to the ease and convenience offered by the simplicity of such conceptualization. Although this line of thinking may help facilitate decision making processes, it is only as defensible as the degree at which the system under consideration behaves linearly. Recent work shows that diverse properties of cities exhibit power-law relationships with population size. Such relationships may invalidate the reliance on linear thinking. Furthermore, in the era of globalization, resources and people move virtually freely through bounds of any confines used to define a system. We incorporate into a simple resource-population model the power-law scaling behavior and the influence of import and immigration, and investigate their effects on sustainable growth of communities. We explore through bifurcation analysis the different scenarios of how an unsustainable system could be sustained. Import can be effective if: the import exceeds a critical level and a critical mass of people populates the system. In contrast, increasing immigration alone can rescue the intrinsically unsustainable system, both directly through people entering the system and indirectly by increasing its harvesting ability, although critical values exist that cause the population to sharply rise or shrink.}
}
@article{HARWOOD201610,
title = {Locking up passwords – for good},
journal = {Network Security},
volume = {2016},
number = {4},
pages = {10-13},
year = {2016},
issn = {1353-4858},
doi = {https://doi.org/10.1016/S1353-4858(16)30037-X},
url = {https://www.sciencedirect.com/science/article/pii/S135348581630037X},
author = {Will Harwood},
abstract = {It's clear that bulk identity thefts – that is, the mass stealing of passwords or other personally identifiable information (PII) – are among the most harmful types of cyber-attack faced by businesses. They're a huge problem, not only in terms of the damage each attack causes, but also the volume of attacks overall. A cursory glance over the business headlines for the past few years announces huge password or PII thefts from organisations ranging from Sony PlayStation to eBay and Facebook to JP Morgan. We were barely a week into 2016 when it was revealed that email passwords for up to 320,000 users had been stolen from Time Warner. Bulk identity thefts are among the most harmful types of cyber-attack faced by businesses today and part of the problem is that businesses, security firms and cyber-criminals all share the same playing field. Thinking beyond standard computing architectures is the only solution to the ongoing arms race between hackers and security vendors. In a battle against cyber-criminality, in which businesses are always playing catch-up, this is a way of getting on the front foot and beginning to operate in a world beyond the attackers' reach, says Dr Will Harwood of Silicon:SAFE.}
}
@incollection{AKAL202471,
title = {Chapter Four - AI methods in microbial metabolite determination},
editor = {Akanksha Srivastava and Vaibhav Mishra},
series = {Methods in Microbiology},
publisher = {Academic Press},
volume = {55},
pages = {71-85},
year = {2024},
booktitle = {Artificial Intelligence in Microbiology: Scope and Challenges Volume 1},
issn = {0580-9517},
doi = {https://doi.org/10.1016/bs.mim.2024.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0580951724000023},
author = {H. Ceren Akal and Rumeysa Nur Kara-Aktaş and Sebnem Ozturkoglu-Budak},
keywords = {Metabolite, Microorganism-derived, Computational, Artificial intelligence},
abstract = {The multitude of microorganism species and the amount of data requiring examination is increasing day by day, which has made it very difficult to make informative determinations and analysis to be conducted by human labour. Artificial intelligence (AI) applications are crucial in mitigating these difficulties. AI is a multidisciplinary field that tries to imitate human-like abilities through learning, analysing, problem-solving and interpretation via digital systems. It can take part in many fields where human labour is required. It is widely used in various scientific disciplines and industries, including biotechnology, microbiology, medicine, etc. Machine learning, a subbranch of AI, is one of the most frequently used auxiliary methods. Critical topics are examined rapidly and meaningfully via machine-learning such as drug production, microbial detection, antimicrobial resistance, vaccine predictions, and disease diagnoses. The aim of this chapter is to highlight the relevance of computational methods for the determination of microbial metabolites which are mainly described in literatures. These computational methods are related with the advanced AI tools of data/genome mining, multivariate data analysis, molecular networking, mathematical modelling, and optimization. These novel methods create new perspectives to the isolation and/or determination of microbial metabolites which are unwanted or essential to human health.}
}
@article{THAGARD1986301,
title = {Parallel computation and the mind-body problem},
journal = {Cognitive Science},
volume = {10},
number = {3},
pages = {301-318},
year = {1986},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(86)80020-9},
url = {https://www.sciencedirect.com/science/article/pii/S0364021386800209},
author = {Paul Thagard},
abstract = {The position in the philosophy of mind called functionalism claims that mental states are to be understood in terms of their functional relationships to other mental states, not in terms of their material instantiation in any particular kind of hardware. But the argument that material instantiation is irrelevant to functional relationships is computationally naive. This paper uses recent work on parallel computation to argue that software and hardware are much more intertwined than the functionalists allow. Parallelism offers qualitative as well as quantitative advantages, leading to different styles of programming as well as increased speed. Hence hardware may well matter to the mental: only by further empirical investigations of the relation between the mind and brain and between artificial intelligence software and underlying hardware will we be able to achieve a defensible solution to the mind-body problem. The major disadvantage of parallel systems is the need to coordinate their subprocesses, but recent proposals that consciousness provides a serial control for parallel computation are implausible.}
}
@article{STEFIK1989241,
title = {Computation and cognition: Toward a foundation of cognitive science: Z.W. Pylyshyn, (MIT Press, Cambridge, MA, 1986); 292 pages, $33.75 (hardcover), $9.95 (paperback)},
journal = {Artificial Intelligence},
volume = {38},
number = {2},
pages = {241-247},
year = {1989},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(89)90061-1},
url = {https://www.sciencedirect.com/science/article/pii/0004370289900611},
author = {Mark Stefik}
}
@article{PADGETT1994185,
title = {Computational intelligence standards: motivation, current activities and progress},
journal = {Computer Standards & Interfaces},
volume = {16},
number = {3},
pages = {185-203},
year = {1994},
issn = {0920-5489},
doi = {https://doi.org/10.1016/0920-5489(94)90011-6},
url = {https://www.sciencedirect.com/science/article/pii/0920548994900116},
author = {Mary Lou Padgett and Walter J Karplus and Steve Deiss and Robert Shelton},
keywords = {Terminology, Artificial neural networks, Specification, Virtual reality},
abstract = {Computational Intelligence is an emerging technology of keen interest to the developers of computer standards and interfaces. Coherent communications among the diverse set of users of computational AI is necessary for the protection of all parties and can help further the serious development of artificial neural networks, fuzzy systems, evolutionary programming and virtual reality. Current activities of the IEEE Neural Networks Council Standards Committee encompass all these areas, emphasizing the development of glossaries and symbologies, performance measures and interface standards for these interrelated fields. Progress toward these goals is described in this paper.}
}
@article{BARNES2021,
title = {Gene Expression and Data Analysis Pipeline Using Cancer BioPortal in the Classroom},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2315},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000277},
author = {Chassidy N. Barnes and Blake P. Johnson and Stefanie W. Leacock and Ruben M. Ceballos and Lori L. Hensley and Nathan S. Reyna},
abstract = {At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis.
ABSTRACT
At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis. Cancer BioPortal (cBioPortal) is an open-access collective cancer research resource for storing and exploring clinical, genomic, proteomic, and transcriptomic data. cBioPortal eliminates the computational barrier of interpreting complex genomic data by providing easily understandable visualization that can be interpreted and translated into relevant biological insights. Because no prior computational knowledge is required, cBioPortal is an ideal educational tool for either in-person or distance learning environments. We developed a pedagogical approach, video tutorials, and data analysis workflows centered on using cBioPortal. Pedagogically, students develop an initial research outline that is continually updated and graded throughout the project. Progress during the project or course is assessed by a series of student presentations that are 5 to 15 min in length and are aimed at explaining the approach used in data acquisition, interpretation of the data, and relevance to the initial hypothesis. While cancer-specific, this analysis platform appeals to a wide range of classes and student interests. Further, the project has been successfully done both as an independent research experience and as part of a virtual class-based research project.}
}
@article{CASTROSCHEZ201465,
title = {Experience applying language processing techniques to develop educational software that allow active learning methodologies by advising students},
journal = {Journal of Network and Computer Applications},
volume = {41},
pages = {65-79},
year = {2014},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2013.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S1084804513002166},
author = {J.J. Castro-Schez and M.A. Redondo and F. Jurado and J. Albusac},
keywords = {Environment for active learning, Formal languages techniques, Automatic assessment},
abstract = {This paper is focused on those systems that allow students to build their own knowledge by providing them with feedback regarding their actions while performing a problem based learning activity or while making changes to problem statements, so that a higher order thinking skill can be achieved. This feedback is the consequence of an automatic assessment. Particularly, we propose a method that makes use of Language Processor techniques for developing these kinds of systems. This method could be applied in subjects in which problem statements and solutions can be formalized by mean of a formal language and the problems can be solved in an algorithmic way. The method has been used to develop a number of tools that are partially described in this paper. Thus, we show that our approach is applicable in addressing the development of the aforementioned systems. One of these tools (a virtual laboratory for language processing) has been in use for several years in order to support home assignments. The data collected for these years are presented and analyzed in this paper. The results of the analysis confirm that this tool is effective in facilitating the achievement of learning outcomes.}
}
@article{UBAN2021480,
title = {An emotion and cognitive based analysis of mental health disorders from social media data},
journal = {Future Generation Computer Systems},
volume = {124},
pages = {480-494},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.05.032},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21001825},
author = {Ana-Sabina Uban and Berta Chulvi and Paolo Rosso},
keywords = {Mental health disorders, Early risk prediction, Emotions, Cognitive styles, Deep learning, Social media},
abstract = {Mental disorders can severely affect quality of life, constitute a major predictive factor of suicide, and are usually underdiagnosed and undertreated. Early detection of signs of mental health problems is particularly important, since unattended, they can be life-threatening. This is why a deep understanding of the complex manifestations of mental disorder development is important. We present a study of mental disorders in social media, from different perspectives. We are interested in understanding whether monitoring language in social media could help with early detection of mental disorders, using computational methods. We developed deep learning models to learn linguistic markers of disorders, at different levels of the language (content, style, emotions), and further try to interpret the behavior of our models for a deeper understanding of mental disorder signs. We complement our prediction models with computational analyses grounded in theories from psychology related to cognitive styles and emotions, in order to understand to what extent it is possible to connect cognitive styles with the communication of emotions over time. The final goal is to distinguish between users diagnosed with a mental disorder and healthy users, in order to assist clinicians in diagnosing patients. We consider three different mental disorders, which we analyze separately and comparatively: depression, anorexia, and self-harm tendencies.}
}
@article{DUBEY2020118,
title = {Understanding exploration in humans and machines by formalizing the function of curiosity},
journal = {Current Opinion in Behavioral Sciences},
volume = {35},
pages = {118-124},
year = {2020},
note = {Curiosity (Explore vs Exploit)},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2020.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352154620301108},
author = {Rachit Dubey and Thomas L Griffiths},
abstract = {Recent work in machine learning has demonstrated the benefits of providing artificial agents with a sense of curiosity—a form of intrinsic reward that supports exploration. Two strategies have emerged for defining these rewards: favoring novelty and pursuing prediction errors. Psychological theories of curiosity have also emphasized these two factors. We show how these two literatures can be connected by understanding the function of curiosity, which requires thinking about the abstract computational problem that both humans and machines face as they explore their world.}
}
@article{CAMARGO2022496,
title = {Existence, Hypotheses and Categories in Knowledge Representation},
journal = {Procedia Computer Science},
volume = {213},
pages = {496-503},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.096},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922017872},
author = {Eduardo Camargo and Eduardo Yuji Sakabe and Ricardo Gudwin},
keywords = {Knowledge Representation, Cognitive Architecture, Cognitive Semiotics, Artificial Intelligent Agent},
abstract = {Cognitive architectures employ different means for knowledge representation. In this work, we describe how the Cognitive Systems Toolkit (CST), a toolkit for the construction of cognitive architectures addresses the issue of knowledge representation, by introducing the notion of a computational idea, as being an abstract and generic building block for representing multiple different pieces of knowledge. We particularly address how computational ideas can be used to represent both facts that really happened at an environment and just hypothesis that are not to be considered as being a part of existence, explaining how these are instances of general categories. At the end, we provide different examples to illustrate the subtle differences that are possible to be represented using this knowledge representation scheme.}
}
@article{MEICHENBAUM1969101,
title = {The effects of instructions and reinforcement on thinking and language behavior of schizophrenics},
journal = {Behaviour Research and Therapy},
volume = {7},
number = {1},
pages = {101-114},
year = {1969},
issn = {0005-7967},
doi = {https://doi.org/10.1016/0005-7967(69)90054-0},
url = {https://www.sciencedirect.com/science/article/pii/0005796769900540},
author = {Donald H. Meichenbaum},
abstract = {Six experimental groups and 2 control groups (N=48) were used to investigate the relative effectiveness of prolonged training of schizophrenics with contingent social and token reinforcement on (a) the level of abstraction as measured on a proverbs task, (b) the percentage of “sick talk” (% ST) emitted in a structured interview, (c) both verbal response classes of proverb abstraction and % ST. Prior to treatment, schizophrenic Ss compared with 20 nonpsychiatric hospitalized medical patients were significantly inferior on the proverbs task and emitted five times more ST in a structured interview. The results indicated that the experimental treatments were effective in decreasing % ST and increasing abstraction to proverbs with token reinforcement being most effective. Evidence for response and stimulus generalization was obtained.}
}
@article{MENG201851,
title = {Conducting highly principled data science: A statistician’s job and joy},
journal = {Statistics & Probability Letters},
volume = {136},
pages = {51-57},
year = {2018},
note = {The role of Statistics in the era of big data},
issn = {0167-7152},
doi = {https://doi.org/10.1016/j.spl.2018.02.053},
url = {https://www.sciencedirect.com/science/article/pii/S0167715218300981},
author = {Xiao-Li Meng},
keywords = {Astrostatistics, Computational efficiency, Principled corner cutting, Scientific justification},
abstract = {Highly Principled Data Science insists on methodologies that are: (1) scientifically justified; (2) statistically principled; and (3) computationally efficient. An astrostatistics collaboration, together with some reminiscences, illustrates the increased roles statisticians can and should play to ensure this trio, and to advance the science of data along the way.}
}
@article{VEGA2008255,
title = {The catwalk task: Reflections and synthesis: Part 2},
journal = {The Journal of Mathematical Behavior},
volume = {27},
number = {4},
pages = {255-263},
year = {2008},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2009.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312309000042},
author = {Emiliano Vega and Shawn Hicks},
keywords = {Modeling, Representation, Teacher learning, Task design},
abstract = {In this article we recount our experiences with a series of encounters with the catwalk task and reflect on the professional growth that these opportunities afforded. First, we individually reflect on our own mathematical work on the catwalk task. Second, we reflect on our experiences working with a group of community college students on the catwalk task and our interpretations of their mathematical thinking. In so doing we also detail a number of innovative and novel student-generated representations of the catwalk photos. Finally, we each individually reflect on the entire experience with the catwalk problem, as mathematics learners, as teachers, and as professionals.}
}
@article{1995146,
title = {95/02164 Sequential pressure-based Navier-Stokes algorithms on SIMD computers: Computational issues},
journal = {Fuel and Energy Abstracts},
volume = {36},
number = {2},
pages = {146},
year = {1995},
issn = {0140-6701},
doi = {https://doi.org/10.1016/0140-6701(95)93829-X},
url = {https://www.sciencedirect.com/science/article/pii/014067019593829X}
}
@incollection{STEEDMAN2011925,
title = {21 - Temporality},
editor = {Johan {van Benthem} and Alice {ter Meulen}},
booktitle = {Handbook of Logic and Language (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {London},
pages = {925-969},
year = {2011},
isbn = {978-0-444-53726-3},
doi = {https://doi.org/10.1016/B978-0-444-53726-3.00021-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780444537263000219},
author = {Mark Steedman},
keywords = {tense, aspect, natural language semantics, computational semantics, temporal semantics, aktionsarten, causality, evidentiality},
abstract = {Publisher Summary
In thinking about the logical and computational semantics of temporal categories in natural languages, issues of temporal ontology, or metaphysics, must be distinguished from issues of temporal relation. The first thing to observe about the temporal ontology implicit in natural languages is that it is not purely temporal. To take a simple example, the English perfect, when predicated of an event like losing a watch, says that some contextually retrievable consequences of the event in question hold at the time under discussion. Thus, conjoining such a perfect with a further clause denying those consequences is infelicitous. The claim that the semantics depends directly on the conceptual representation of action and contingency suggests that this semantics might be universal, despite considerable differences in its syntactic and morphological encoding across languages. The work described in this chapter suggests that such differences across languages are superficial. Ironically, the English tense/aspect system seems to be based on semantic primitives remarkably like those, which Whorf ascribed to Hopi. Matters of temporal sequence and temporal locality seem to be quite secondary to matters of perspective and contingency. This observation in turn suggests that the semantics of tense and aspect is profoundly shaped by concerns with goals, actions, and consequences, and that temporality in the narrow sense of the term is merely one facet of this system among many.}
}
@article{ZIA2022108066,
title = {SoFTNet: A concept-controlled deep learning architecture for interpretable image classification},
journal = {Knowledge-Based Systems},
volume = {240},
pages = {108066},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.108066},
url = {https://www.sciencedirect.com/science/article/pii/S095070512101145X},
author = {Tehseen Zia and Nauman Bashir and Mirza Ahsan Ullah and Shakeeb Murtaza},
keywords = {Interpretability, Concepts, KNN, Explanation satisfaction},
abstract = {Interpreting deep learning (DL)-based computer vision models is challenging due to the complexity of internal representations. Most recent techniques for rendering DL learning outcomes interpretable operate on low-level features rather than high-level concepts. Methods that explicitly incorporate high-level concepts do so through a determination of the relevancy of user-defined concepts or else concepts extracted directly from the data. However, they do not leverage the potential of concepts to explain model predictions. To overcome this challenge, we introduce a novel DL architecture – the Slow/Fast Thinking Network (SoFTNet) – enabling users to define/control high-level features and utilize them to perform image classification predicatively. We draw inspiration from the dual-process theory of human thought processes, decoupling low-level, fast & non-transparent processing from high-level, slow & transparent processing. SoFTNet hence uses a shallow convolutional neural network for low-level processing in conjunction with a memory network for high-level concept-based reasoning. We conduct experiments on the CUB-200-2011 and STL-10 datasets and also present a novel concept-based deep K-nearest neighbor approach for baseline comparisons. Our experiments show that SoFTNet achieves comparable performance to state-of-art non-interpretable models and outperforms comparable interpretative methods.}
}
@article{SCHINCKUS20094415,
title = {Economic uncertainty and econophysics},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {388},
number = {20},
pages = {4415-4423},
year = {2009},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2009.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0378437109005494},
author = {Christophe Schinckus},
keywords = {Econophysics, Uncertainty, Economics, Keynes, Knight, Hayek},
abstract = {The objective of this paper is to provide a methodological link between econophysics and economics. I will study a key notion of both fields: uncertainty and the ways of thinking about it developed by the two disciplines. After having presented the main economic theories of uncertainty (provided by Knight, Keynes and Hayek), I show how this notion is paradoxically excluded from the economic field. In economics, uncertainty is totally reduced by an a priori Gaussian framework—in contrast to econophysics, which does not use a priori models because it works directly on data. Uncertainty is then not shaped by a specific model, and is partially and temporally reduced as models improve. This way of thinking about uncertainty has echoes in the economic literature. By presenting econophysics as a Knightian method, and a complementary approach to a Hayekian framework, this paper shows that econophysics can be methodologically justified from an economic point of view.}
}
@article{KUNZE2024249,
title = {Bioinspired approaches for resource-efficient material flow in production – an innovative actuator concept for peristaltic-based transport},
journal = {Procedia CIRP},
volume = {125},
pages = {249-254},
year = {2024},
note = {CIRP BioM 2024},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.08.043},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124003974},
author = {Henriette Kunze and Marcel Lorenz},
keywords = {tensegrity, biotensegrity, assembly technologies},
abstract = {In automated material flow, in a wide variety of areas, the primary goal is usually to handle a wide spectrum of components as time- and cost-efficiently as possible. In view of the current and future challenges in industrial production, it is becoming apparent that ecological requirements are becoming increasingly important in automation solutions. For example, in form of resource efficiency, transformability and material efficiency. In this context, especially materials handling technology is subject of various optimization approaches, as no value is added to the part handled. The question: "How does material flow occur in nature?" thus offers biologically inspired approaches to thinking about transport in the industrial sector. This paper first presents a selection of concepts or existing mechanisms that are adaptable in materials- handling technology and have been developed based on a biological model. In the second part of this paper, a new concept is presented that is modeled on peristalsis as a transport mechanism. The approach presented here uses tensegrity-structures for assembly, which are characterized by their high material efficiency and flexibility. The transport movement is achieved by peristaltic typical contraction or relaxation of the respective structure parts.}
}
@article{BESHKOV2024109370,
title = {Topological structure of population activity in mouse visual cortex encodes densely sampled stimulus rotations},
journal = {iScience},
volume = {27},
number = {4},
pages = {109370},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.109370},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224005911},
author = {Kosio Beshkov and Marianne Fyhn and Torkel Hafting and Gaute T. Einevoll},
keywords = {Neuroscience, Sensory neuroscience, Cognitive neuroscience},
abstract = {Summary
The primary visual cortex is one of the most well understood regions supporting the processing involved in sensory computation. Following the popularization of high-density neural recordings, it has been observed that the activity of large neural populations is often constrained to low dimensional manifolds. In this work, we quantify the structure of such neural manifolds in the visual cortex. We do this by analyzing publicly available two-photon optical recordings of mouse primary visual cortex in response to visual stimuli with a densely sampled rotation angle. Using a geodesic metric along with persistent homology, we discover that population activity in response to such stimuli generates a circular manifold, encoding the angle of rotation. Furthermore, we observe that this circular manifold is expressed differently in subpopulations of neurons with differing orientation and direction selectivity. Finally, we discuss some of the obstacles to reliably retrieving the truthful topology generated by a neural population.}
}
@article{SPENCE2022100433,
title = {Gastrophysics: Getting creative with pairing flavours},
journal = {International Journal of Gastronomy and Food Science},
volume = {27},
pages = {100433},
year = {2022},
issn = {1878-450X},
doi = {https://doi.org/10.1016/j.ijgfs.2021.100433},
url = {https://www.sciencedirect.com/science/article/pii/S1878450X21001323},
author = {Charles Spence},
keywords = {Food pairing, Flavour pairing hypothesis, Sonic seasoning, Computational gastronomy, Data engineering, Gastrophysics},
abstract = {Traditionally, in the West, the decision about which flavours to pair in a tasting experience has been as much the personal choice of the chef or, more likely, the sommelier, as anything else. However, the last couple of decades have seen a rapid growth of research interest in the pairing of flavours. Nowadays, one can find examples of people pairing everything from beer with food, tea with cheese and chocolate, etc. As interest in the marketing potential of flavour pairing has risen, along with the growing public fascination in the topic, scientists have become increasingly interested in trying to understand the principles (both cognitive/intellectual and perceptual) underlying the successful pairing of flavours. In this narrative review, the relative strengths and weaknesses of the chemical, computational (gastronomy), and perceptual approaches to pairing flavours are highlighted. Thereafter, I show how the various principles of pairing (both perceptual and cognitive/intellectual) can be extended beyond the domain of pairing flavour with flavour to consider the rapidly growing are of sonic seasoning. The latter term refers to those situations in which specific pieces of music or soundscapes are matched, or paired, with particular tastes/flavours based on the crossmodal correspondences. The review ends by considering the future development of pairings flavours, and assessing novel means of establishing connections between flavours and other sensations.}
}
@article{BOSCH2017,
title = {Graduate Biomedical Science Education Needs a New Philosophy},
journal = {mBio},
volume = {8},
number = {6},
year = {2017},
issn = {2150-7511},
doi = {https://doi.org/10.1128/mbio.01539-17},
url = {https://www.sciencedirect.com/science/article/pii/S2161212917003111},
author = {Gundula Bosch and Arturo Casadevall},
keywords = {Ph.D., education, graduate},
abstract = {ABSTRACT
There is a growing realization that graduate education in the biomedical sciences is successful at teaching students how to conduct research but falls short in preparing them for a diverse job market, communicating with the public, and remaining versatile scientists throughout their careers. Major problems with graduate level education today include overspecialization in a narrow area of science without a proper grounding in essential critical thinking skills. Shortcomings in education may also contribute to some of the problems of the biomedical sciences, such as poor reproducibility, shoddy literature, and the rise in retracted publications. The challenge is to modify graduate programs such that they continue to generate individuals capable of conducting deep research while at the same time producing more broadly trained scientists without lengthening the time to a degree. Here we describe our first experiences at Johns Hopkins and propose a manifesto for reforming graduate science education.}
}
@article{JOO2024226,
title = {Teaching and Learning Model for Artificial Intelligence Education},
journal = {Procedia Computer Science},
volume = {239},
pages = {226-233},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.166},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924014091},
author = {Kil Hong Joo and Nam Hun Park},
keywords = {Artificial intelligence education, Lower grades in elementary school},
abstract = {AI education aims to nurture convergence talents equipped with various knowledge and AI capabilities. However, the educational programs developed so far are designed for less than 10 sessions. This is insufficient time for students to understand artificial intelligence algorithms, utilize the learned principles of artificial intelligence, and expand by converging with various knowledge. Since the developmental characteristics of students in the lower grades of elementary school are different, it is difficult to apply them as they are. Therefore, it is necessary to study the following AI education teaching and learning methods suitable for lower grade students. In this study, we develop a teaching system design model for artificial intelligence-based subject convergence education for elementary school students in the lower grades, and based on this, design and apply an artificial intelligence-based subject convergence education program. Experiments were conducted with 47 second-year elementary school students, and students’ responses were better in the AI-based convergence education program than in general subject classes in terms of interest, understanding, and expectations for classes.}
}
@article{DELLANNA2022105064,
title = {Evolving Fuzzy logic Systems for creative personalized Socially Assistive Robots},
journal = {Engineering Applications of Artificial Intelligence},
volume = {114},
pages = {105064},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.105064},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622002251},
author = {Davide Dell’Anna and Anahita Jamshidnejad},
keywords = {Evolving Fuzzy logic Systems, Personalized Socially Assistive Robots, Robot creativity},
abstract = {Socially Assistive Robots (SARs) are increasingly used in dementia and elderly care. In order to provide effective assistance, SARs need to be personalized to individual patients and account for stimulating their divergent thinking in creative ways. Rule-based fuzzy logic systems provide effective methods for automated decision-making of SARs. However, expanding and modifying the rules of fuzzy logic systems to account for the evolving needs, preferences, and medical conditions of patients can be tedious and costly. In this paper, we introduce EFS4SAR, a novel Evolving Fuzzy logic System for Socially Assistive Robots that supports autonomous evolution of the fuzzy rules that steer the behavior of the SAR. EFS4SAR combines traditional rule-based fuzzy logic systems with evolutionary algorithms, which model the process of evolution in nature and have shown to result in creative behaviors. We evaluate EFS4SAR via computer simulations on both synthetic and real-world data. The results show that the fuzzy rules evolved over time are not only personalized with respect to the personal preferences and therapeutic needs of the patients, but they also meet the following criteria for creativity of SARs: originality and effectiveness of the therapeutic tasks proposed to the patients. Compared to existing evolving fuzzy systems, EFS4SAR achieves similar effectiveness with higher degree of originality.}
}
@article{ALEXIOU2009623,
title = {Exploring the neurological basis of design cognition using brain imaging: some preliminary results},
journal = {Design Studies},
volume = {30},
number = {6},
pages = {623-647},
year = {2009},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2009.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X09000313},
author = {K. Alexiou and T. Zamenopoulos and J.H. Johnson and S.J. Gilbert},
keywords = {design cognition, problem solving, design problems, research methods, cognitive neuroscience},
abstract = {The paper presents a pilot interdisciplinary research study carried out as a step towards understanding the neurological basis of design thinking. The study involved functional magnetic resonance imaging (fMRI) of volunteers while performing design and problem-solving tasks. The findings suggest that design and problem solving involve distinct cognitive functions associated with distinct brain networks. The paper introduces the methodology, presents the findings, and discusses the potential role of brain imaging in design research.}
}
@article{KAMARI2017330,
title = {Sustainability focused decision-making in building renovation},
journal = {International Journal of Sustainable Built Environment},
volume = {6},
number = {2},
pages = {330-350},
year = {2017},
issn = {2212-6090},
doi = {https://doi.org/10.1016/j.ijsbe.2017.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S221260901730064X},
author = {Aliakbar Kamari and Rossella Corrao and Poul Henning Kirkegaard},
keywords = {Sustainability, Building renovation, Decision support, Knowledge management, Soft Systems Methodology (SSM), Value Focused Thinking (VFT)},
abstract = {An overview of recent research related to building renovation has revealed that efforts to date do not address sustainability issues comprehensively. The question then arises in regard to the holistic sustainability objectives within building renovation context. In order to deal with this question, the research adopts a multi-dimensional approach involving literature review, exploration of existing assessment methods and methodologies, individual and focus group interviews, and application of Soft Systems Methodologies (SSM) with Value Focused Thinking (VFT). In doing so, appropriate data about sustainability objectives have been collected and structured, and subsequently verified using a Delphi study. A sustainability framework was developed in cooperation with University of Palermo and Aarhus University to audit, develop and assess building renovation performance, and support decision-making during the project’s lifecycle. The paper represents the results of research aiming at addressing sustainability of the entire renovation effort including new categories, criteria, and indicators. The developed framework can be applied during different project stages and to assist in the consideration of the sustainability issues through support of decision-making and communication with relevant stakeholders. Early in a project, it can be used to identify key performance criteria, and later to evaluate/compare the pros and cons of alternative retrofitting solutions either during the design stage or upon the project completion. According to the procedure of the consensus-based process for the development of an effective sustainability decision-making framework which was employed in this study, the outcome can also be considered as an outset step intended for the establishment of a Decision Support Systems (DSS) and assessment tool suited to building renovation context.}
}
@article{BARNES2021,
title = {Gene Expression and Data Analysis Pipeline Using Cancer BioPortal in the Classroom},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2313},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000721},
author = {Chassidy N. Barnes and Blake P. Johnson and Stefanie W. Leacock and Ruben M. Ceballos and Lori L. Hensley and Nathan S. Reyna},
abstract = {At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis.
ABSTRACT
At institutions with an emphasis on authentic research experiences as an integral part of the biology curriculum, COVID created a huge challenge for course instructors whose learning objectives were designed for such experiences. Moving such laboratory experiences online when remote learning became necessary has resulted in a new model for CUREs that utilizes free online databases to provide not only a novel research experience for students, but also the opportunity to engage in big data analysis. Cancer BioPortal (cBioPortal) is an open-access collective cancer research resource for storing and exploring clinical, genomic, proteomic, and transcriptomic data. cBioPortal eliminates the computational barrier of interpreting complex genomic data by providing easily understandable visualization that can be interpreted and translated into relevant biological insights. Because no prior computational knowledge is required, cBioPortal is an ideal educational tool for either in-person or distance learning environments. We developed a pedagogical approach, video tutorials, and data analysis workflows centered on using cBioPortal. Pedagogically, students develop an initial research outline that is continually updated and graded throughout the project. Progress during the project or course is assessed by a series of student presentations that are 5 to 15 min in length and are aimed at explaining the approach used in data acquisition, interpretation of the data, and relevance to the initial hypothesis. While cancer-specific, this analysis platform appeals to a wide range of classes and student interests. Further, the project has been successfully done both as an independent research experience and as part of a virtual class-based research project.}
}
@article{DONALDSON1995301,
title = {Building object-oriented systems: An introduction from concepts to implementation in c++: R. E. Callan, Computational Mechanics Publications, Southampton, UK, 1994. ISBN 1-85312-340-4. 304 pp. £47.00},
journal = {Artificial Intelligence in Engineering},
volume = {9},
number = {4},
pages = {301},
year = {1995},
note = {Selected Papers from the 1994 Japan/Korea Joint Conference on Expert Systems},
issn = {0954-1810},
doi = {https://doi.org/10.1016/0954-1810(95)90016-0},
url = {https://www.sciencedirect.com/science/article/pii/0954181095900160},
author = {Iain Donaldson}
}
@article{ENE2016973,
title = {A genetic algorithm for minimizing energy consumption in warehouses},
journal = {Energy},
volume = {114},
pages = {973-980},
year = {2016},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2016.08.045},
url = {https://www.sciencedirect.com/science/article/pii/S0360544216311586},
author = {Seval Ene and İlker Küçükoğlu and Aslı Aksoy and Nursel Öztürk},
keywords = {Genetic algorithm, Green supply chain, Minimization of energy consumption, Warehouse management},
abstract = {Green supply chain management is generally defined as integration of green thinking and environmental issues into the whole supply chain operations like product design, manufacturing process, warehousing, distribution etc. Within this context green principles should be adopted in warehouse management to minimize negative impact on the environment. In warehouse operations, picking must be analyzed attentively which is widely studied in literature for minimizing service time levels because of its close relation to the higher costs. The efficiency of picking in warehouses mainly depends on storage assignment policy that directly affects picking performance in warehouses. In this paper, picking operation in warehouses is studied to minimize energy consumption with proper storage policy other than service time. Genetic algorithm (GA) is proposed to solve the problem and numerical examples are presented to demonstrate the performance of the GA. Results show that, the GA gives efficient solutions to the problem.}
}
@article{KIM2024110348,
title = {Hierarchical aerial offload computing algorithm based on the Stackelberg-evolutionary game model},
journal = {Computer Networks},
volume = {245},
pages = {110348},
year = {2024},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110348},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624001804},
author = {Sungwook Kim},
keywords = {Aerial access networks, High-altitude platforms, Unmanned aerial vehicles, Stackelberg-evolutionary game, Multi-objective bargaining solution},
abstract = {Aerial access networks have been envisioned as a promising 6 G technology to enhance the service experience in underserved areas where terrestrial base stations do not exist. In such scenarios, a hierarchical model of high-altitude platforms (HAPs) and unmanned aerial vehicles (UAVs) is considered to provide aerial computing services for ground Internet of Things (IoT) devices. In this study, we investigate a hierarchical aerial computing system to optimally orchestrate the limited computation resources in both HAPs and UAVs. For offloading services, we formulate a joint resource allocation problem to maximize service satisfaction for terrestrial IoT devices. To solve this problem, we employ the ideas of game theory with centralized decision and decentralized execution. Through the Stackelberg-evolutionary game model, the HAP works as a leader, and selects its price strategy based on the evolutionary learning process. As followers, individual UAVs make decisions to partially offload their computing tasks by considering different objectives. According to the interactive control paradigm, our proposed method can get reciprocal advantages for HAPs, UAVs, and ground IoT devices while adaptively handling dynamic aerial network conditions. Finally, extensive simulation results verify the efficiency of our proposed algorithm to increase the usability of edge servers’ computational resources. Compared with other existing state-of-the-art aerial network offloading protocols, we can improve the profits of system throughput, resource usability and UAV fairness up to 10 %, 10 %, and 15 %, respectively.}
}
@article{EARL2019303,
title = {Elusive optima: A process tracing analysis of procedural rationality in mobile phone connection plan choices},
journal = {Journal of Economic Behavior & Organization},
volume = {161},
pages = {303-322},
year = {2019},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2019.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167268119300988},
author = {Peter E. Earl and Lana Friesen and Christopher Shadforth},
keywords = {Consumer capabilities, Choice overload, Procedural rationality, Process tracing},
abstract = {This paper reports an experiment in which subjects were rewarded on the basis of how close they came to finding the cheapest mobile phone plan to serve a particular usage remit by searching freely in the Internet. During the task, subjects were required to ‘think aloud’ and recordings were made of what they said and what they did on their computer screens. Analysis of the screen-capture movie recordings revealed major shortfalls in procedural rationality, including poor strategic thinking about how to deal with choice overload, poor conceptual understanding of mobile phone plans and pricing systems, as well as cognitive and calculation errors. Our novel method leads to a very different policy focus from that implied by viewing the problem in terms of excess information per se and irrationality as driven by innate heuristics and biases.}
}
@article{HUANG201724,
title = {Energy and carbon performance evaluation for buildings and urban precincts: review and a new modelling concept},
journal = {Journal of Cleaner Production},
volume = {163},
pages = {24-35},
year = {2017},
note = {Achieving Low/no Fossil-carbon Economies based upon the Essential Transformations to Support them},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2015.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0959652615018235},
author = {Bin Huang and Ke Xing and Stephen Pullen},
keywords = {Buildings, Integrated modelling, Life cycle energy, Systems thinking, Urban precincts},
abstract = {With the accelerating pace of urbanisation around the world, the planning, development and operation of buildings and precincts have become increasingly important with respect to energy use and the associated carbon footprint of the modern built environment. Over recent decades, much effort, both in research and in practice, has been devoted to building construction and urban planning for the improvement of energy efficiency and greenhouse gas emissions. However, the accuracy of modelling and evaluation of energy and carbon performance for buildings and urban precincts remains limited, affected by inadequate energy intensity data and highly integrated building systems, as well as the complex interactions between buildings and the urban eco-system. This paper presents a critical review of current measures and models for representing and assessing life cycle energy as well as associated emissions profiles at both the building and the precinct levels. It also identifies influential factors and explores interactions among buildings, surrounding environment and user behaviours at the urban precinct level by taking a systems perspective. Based on such a review, this study maps out some key challenges for integrating energy and carbon metrics, and finally proposes a precinct-level system boundary definition and an integrated model following systems thinking. The proposed model can facilitate a critical thinking approach about the evaluations of global energy and emissions, and support the quantification of energy consumption and associated emissions for building precinct systems.}
}
@article{MOLNAR20152667,
title = {Three Dimensional Applications in Teaching and Learning Processes},
journal = {Procedia - Social and Behavioral Sciences},
volume = {191},
pages = {2667-2673},
year = {2015},
note = {The Proceedings of 6th World Conference on educational Sciences},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.04.600},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815028608},
author = {György Molnár and András Benedek},
keywords = {ICT, 3D interactive system, new learning potential, Leonar3Do ;},
abstract = {In the world of today's information society the torrent of information we are dailyfaced with has to be appropriately transformed and translated in order to yield representationswe are somehow capable of understanding. By extending 2D representations to three-dimensional ones, pictorialcontents become more lifelike, getting closer to practice, creating the basis for a new view ofpictorial thinking, giving rise to the emergence to a very effective method of dealing withinformation overload. To depict three-dimensionalreality onto a two-dimensional plane of course constitutes an age-old scientific problem, theprincipal aim of the technique sought after being the exact representation.We also present a general review of Hungarian and international experienceson ICT application and its environment that comply with current practice.}
}
@article{PEYRACHE2024255,
title = {A homothetic data generated technology},
journal = {European Journal of Operational Research},
volume = {316},
number = {1},
pages = {255-267},
year = {2024},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2024.01.031},
url = {https://www.sciencedirect.com/science/article/pii/S037722172400050X},
author = {Antonio Peyrache},
keywords = {Data envelopment analysis, Input homotheticity, Free disposal hull, Efficiency},
abstract = {I propose a method for constructing an enlargement of a variable returns to scale production technology that will satisfy homotheticity. The method can be used both with DEA and FDH single output (or single input) technologies and it is computationally fast. The method is constructed by adding a restriction to the axiomatically delineated homothetic reference technologies which requires these reference technologies to be subsets of the minimal reference technology that satisfies constant returns to scale. Within this set it is possible to identify a homothetic technology that satisfies the property of minimum extrapolation.}
}
@article{HAAS2024110900,
title = {Models vetted against prediction error and parameter sensitivity standards can credibly evaluate ecosystem management options},
journal = {Ecological Modelling},
volume = {498},
pages = {110900},
year = {2024},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2024.110900},
url = {https://www.sciencedirect.com/science/article/pii/S0304380024002886},
author = {Timothy C. Haas},
keywords = {Model vetting, Model credibility, Ecosystem management, Parameter sensitivity, Robust statistical estimators, High performance computing},
abstract = {A new standard for assessing model credibility is developed. This standard consists of parameter estimation, prediction error assessment, and a parameter sensitivity analysis that is driven by outside individuals who are skeptical of the model’s credibility (hereafter, skeptics). Ecological/environmental models that have a one-step-ahead prediction error rate that is better than naive forecasting — and are not excessively sensitive to small changes in their parameter values are said here to be vetted. A procedure is described that can perform this assessment on any model being evaluated for possible participation in an ecosystem management decision. Uncertainty surrounding the model’s ability to predict future values of its output variables and in the estimates of all of its parameters should be part of any effort to vett a model. The vetting procedure described herein, Prediction Error Rate-Deterministic Sensitivity Analysis (PER-DSA), incorporates these two aspects of model uncertainty. DSA in particular, requires participation by skeptics and is the reason why a successful DSA gives a model sufficient credibility to have a voice in ecosystem management decision making. But these models need to be stochastic and represent the mechanistic processes of the system being modeled. For such models, performing a PER-DSA can be computationally expensive. A cluster computing algorithm to speed-up these computations is described as one way to answer this challenge. This new standard is illustrated through a PER-DSA of a population dynamics model of South African rhinoceros (Ceratotherium simum simum).}
}
@article{SENANAYAKE2024104705,
title = {Agent-based simulation for pedestrian evacuation: A systematic literature review},
journal = {International Journal of Disaster Risk Reduction},
volume = {111},
pages = {104705},
year = {2024},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.104705},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924004679},
author = {Gayani P.D.P. Senanayake and Minh Kieu and Yang Zou and Kim Dirks},
keywords = {Pedestrian behaviour modelling, Agent-based modelling, Behavioural decision-making, Emergency evacuation},
abstract = {Agent-based models (ABMs) offer promise for realistically simulating human behaviours and interactions during emergency evacuations. This review aims to systematically assess the state of the art in ABM-based evacuation modelling with respect to methodologies, validation practices, and the associated challenges over the past decade. The review critically examines 134 studies from 2013 to 2023 that have applied ABMs for pedestrian evacuation simulation to synthesise current capabilities, limitations, and advancement pathways. Findings identify persistent challenges related to modeller bias, computational complexity, data scarcity for calibration and validation, and the predominance of simplistic rule-based decision-making models, while promise exists with the adoption of flexible behavioural frameworks, high-performance computing architectures, machine learning techniques for adaptive agent behaviours and surrogate modelling, and evolutionary computation methods for transparent rule generation. The findings underscore the importance of interdisciplinary collaboration among behavioural scientists, modellers, and emergency planners to enhance the realism and reliability of ABMs. By providing a critical synthesis of the state-of-the-art and proposing future research directions, this review aims to accelerate the development and application of ABMs that can meaningfully enhance the safety and resilience of communities facing emergencies.}
}
@article{CHAUHAN2023107757,
title = {Personalized optimal room temperature and illuminance for maximizing occupant's mental task performance using physiological data},
journal = {Journal of Building Engineering},
volume = {78},
pages = {107757},
year = {2023},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2023.107757},
url = {https://www.sciencedirect.com/science/article/pii/S235271022301937X},
author = {Hardik Chauhan and Youjin Jang and Surakshya Pradhan and Hyosoo Moon},
keywords = {Indoor environment quality, Physiological response, Occupant performance, Machine learning, Particle swarm optimization},
abstract = {Indoor room temperature and illuminance level are critical factors of indoor environment quality (IEQ), affecting human mental task performance. These effects are reflected in their physiological responses such as heart rate, electrodermal activity, and skin temperature. Occupants' individual preferences, sensitivity, and physiological responses to different combinations of room temperature and illuminance level can differ among individuals. Despite previous studies investigating the individual and combined effects of different IEQ parameters, the limited research on the cross-modal relationship between room temperature and illuminance level and its impact on mental task performance highlights its significance. Moreover, to achieve personalized insights, it is essential to incorporate individual physiological responses, and this necessitates the development of an optimization model to comprehensively examine their impact. To address these issues, this study proposes a personalized model that optimizes room temperature and illuminance levels to enhance mental task performance using occupants' physiological data. Having the random forest algorithm, this study first predicted mental task performance, which includes four mental abilities such as attention, perception, working memory, and thinking ability using the occupant's physiological data. Then, the particle swarm optimization algorithm was employed to optimize room temperature and illuminance level to maximize the predicted mental task performance. The results of the proposed model align with observed values of room temperature and illuminance level during experiments, validating the adoption of a personalized approach. The findings contribute to future insights and guidelines for the design and management of indoor environments to maximize occupants' performance.}
}
@incollection{STAUFFER2006i,
title = {Biology, Sociology, Geology by Computational Physicists},
editor = {D. Stauffer and S. Moss {de Oliveira} and P.M.C. {de Oliveira} and J.S. Sá Martins},
series = {Monograph Series on Nonlinear Science and Complexity},
publisher = {Elsevier},
volume = {1},
pages = {i-276},
year = {2006},
booktitle = {Biology, Sociology, Geology by Computational Physicists},
issn = {1574-6917},
doi = {https://doi.org/10.1016/S1574-6917(05)01001-9},
url = {https://www.sciencedirect.com/science/article/pii/S1574691705010019},
author = {D. Stauffer and S. Moss {de Oliveira} and P.M.C. {de Oliveira} and J.S. Sá Martins}
}
@article{PARR2025105984,
title = {Inferring when to move},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {169},
pages = {105984},
year = {2025},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105984},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424004536},
author = {Thomas Parr and Ashwini Oswal and Sanjay G. Manohar},
keywords = {Computational neuroscience, Generative, Bayesian, Active inference, Movement, Dynamical systems, Parkinson’s disease},
abstract = {Most of our movement consists of sequences of discrete actions at regular intervals—including speech, walking, playing music, or even chewing. Despite this, few models of the motor system address how the brain determines the interval at which to trigger actions. This paper offers a theoretical analysis of the problem of timing movements. We consider a scenario in which we must align an alternating movement with a regular external (auditory) stimulus. We assume that our brains employ generative world models that include internal clocks of various speeds. These allow us to associate a temporally regular sensory input with an internal clock, and actions with parts of that clock cycle. We treat this as process of inferring which clock best explains sensory input. This offers a way in which temporally discrete choices might emerge from a continuous process. This is not straightforward, particularly if each of those choices unfolds during a time that has a (possibly unknown) duration. We develop a route for translation to neurology, in the context of Parkinson’s disease—a disorder that characteristically slows down movements. The effects are often elicited in clinic by alternating movements. We find that it is possible to reproduce behavioural and electrophysiological features associated with parkinsonism by disrupting specific parameters—that determine the priors for inferences made by the brain. We observe three core features of Parkinson’s disease: amplitude decrement, festination, and breakdown of repetitive movements. Our simulations provide a mechanistic interpretation of how pathology and therapeutics might influence behaviour and neural activity.}
}
@article{YECKEL19971379,
title = {Parallel computation of incompressible flows in materials processing: Numerical experiments in diagonal preconditioning},
journal = {Parallel Computing},
volume = {23},
number = {9},
pages = {1379-1400},
year = {1997},
note = {Parallel computing methods in applied fluid mechanics},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(97)00059-8},
url = {https://www.sciencedirect.com/science/article/pii/S0167819197000598},
author = {Andrew Yeckel and Jeffrey J. Derby},
keywords = {Incompressible flow, Finite element method, Preconditioning, Iterative solution, Linear systems},
abstract = {Massively parallel computing is enabling dramatic advances in the simulation of three-dimensional flows in materials processing systems. This study focuses on the efficiency and robustness of parallel algorithms applied to such systems. Specifically, various diagonal preconditioning schemes are tested for the iterative solution of the linear equations arising from Newton's method applied to finite element discretizations. Two finite element discretizations are considered — the classical Galerkin and the Galerkin/least-squares method. Results show that the choice of preconditioning method can greatly influence the rate of convergence, but that no type worked uniformly well in all cases.}
}
@article{LOWENSTEIN20191237,
title = {Visual perception, cognition, and error in dermatologic diagnosis: Diagnosis and error},
journal = {Journal of the American Academy of Dermatology},
volume = {81},
number = {6},
pages = {1237-1245},
year = {2019},
issn = {0190-9622},
doi = {https://doi.org/10.1016/j.jaad.2018.12.072},
url = {https://www.sciencedirect.com/science/article/pii/S0190962219303251},
author = {Eve J. Lowenstein and Richard Sidlow and Christine J. Ko},
keywords = {cognitive error, diagnostic error, heuristic, metacognition, patient safety, visual intelligence},
abstract = {Diagnostic error in dermatology is a large practice gap that has received little attention. Diagnosis in dermatology relies heavily on a heuristic approach that is responsible for our perception of clinical findings. To improve our diagnostic accuracy, a better understanding of the strengths and limitations of heuristics (cognitive shortcuts) used in dermatology is essential. Numerous methods have been proposed to improve diagnostic accuracy, including brain training, reducing cognitive load, and getting feedback and second opinions. Becoming comfortable with the uncertainty intrinsic to medicine is essential. Ultimately, the practice of metacognition, or thinking about how we think, can offer corrective insights to improve accuracy in diagnosis.}
}
@article{SCHIFERL1997249,
title = {Evolution of plastic anisotropy for high-strain-rate computations},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {143},
number = {3},
pages = {249-270},
year = {1997},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(96)01159-0},
url = {https://www.sciencedirect.com/science/article/pii/S0045782596011590},
author = {Sheila K. Schiferl and Paul J. Maudlin},
abstract = {A model for anisotropic material strength, and for changes in the anisotropy due to plastic strain, is described. This model has been developed for use in high-rate, explicit, Lagrangian multidimensional continuum-mechanics codes. The model handles anisotropies, in single-phase materials, in particular the anisotropies due to crystallographic texture—preferred orientations of the single-crystal grains. Textural anisotropies, and the changes in these anisotropies, depend overwhelmingly on the crystal structure of the material and on the deformation history. The changes, particularly for complex deformations, are not amenable to simple analytical forms. To handle this problem, the material model described here includes a texture code, or micromechanical calculation, coupled to a continuum code. The texture code updates grain orientations as a function of tensor plastic strain, and calculates the yield strength in different directions. A yield function is fitted to these yield ‘points’. For each computational cell in the continuum simulation, the texture code tracks a particular set of grain orientations. The orientations will change due to the tensor strain history, and the yield function will change accordingly. Hence, the continuum code supplies a tensor strain to the texture code, and the texture code supplies an updated yield function to the continuum code. Since significant texture changes require relatively large strains—typically, a few percent or more—the texture code is not called very often, and the increase in computer time is not excessive. The model was implemented, using a finite-element continuum code and a texture code specialized for hexagonal-close-packed crystal structures. The results for several uniaxial stress problems and an explosive-forming problem are shown.}
}
@article{FATAHI2016272,
title = {A fuzzy cognitive map model to calculate a user's desirability based on personality in e-learning environments},
journal = {Computers in Human Behavior},
volume = {63},
pages = {272-281},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.05.041},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216303685},
author = {Somayeh Fatahi and Hadi Moradi},
keywords = {Personality, Emotion, User's status, Desirability, E-learning},
abstract = {The recent research in artificial intelligence shows an increasing interest in the modeling of human behavior factors such as personality, mood, and emotion for developing human-friendly systems. That is why there is an interest in developing models and algorithms to determine a human's emotions while interacting with a system to improve the quality of the interaction. In this paper, we propose a computational model to calculate a user's desirability based on personality in e-learning environments. The desirability is one of the most important variables in determining a user's emotions. The model receives several e-learning environmental events and predicts the desirability of the events based on the user's personality and his/her goals. The proposed model has been evaluated in a simulated and real e-learning environment. The results show that the model formulates the relationship between personality and emotions with high accuracy.}
}
@article{ZUO2010268,
title = {Integrating performance-based design in beginning interior design education: an interactive dialog between the built environment and its context},
journal = {Design Studies},
volume = {31},
number = {3},
pages = {268-287},
year = {2010},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2009.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X09000969},
author = {Qun Zuo and Wesley Leonard and Eileen E. MaloneBeach},
keywords = {performance-based design, interior design, design education, computer aided design, design process},
abstract = {This paper presents a new paradigm in interior design education in which building performance simulation was employed for decision making and design generation. Digital technology was intermixed with conventional paper-based media in the design process to explore formal, spatial and passive solar energy solutions. The intention of the study was to re-discover the value of computers in assisting design thinking and improving effective learning. The results indicated the Performance-Based Design approach resulted in an early awareness of sustainable energy for beginning interior design students. Further, it enhanced understanding of the mutual relationship between interior and exterior and between the built and natural environment. This paper acknowledged the achievements as well as limitations and future directions for the integration of Performance-Based Design into interior design curriculum.}
}
@incollection{COHEN20253,
title = {Chapter 1 - The evolution of machine learning: Past, present, and future},
editor = {Chhavi Chauhan and Stanley Cohen},
booktitle = {Artificial Intelligence in Pathology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {3-14},
year = {2025},
isbn = {978-0-323-95359-7},
doi = {https://doi.org/10.1016/B978-0-323-95359-7.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323953597000017},
author = {Stanley Cohen},
keywords = {Capsule, Core memory, Graphical, Instruction set, Neural networks, Neuromorphic computing, Probability, Statistics support vectors},
abstract = {The earliest computers were designed to perform complex calculations, and their architecture allowed for the storage of not only data but also instructions as to how to manipulate that data. This evolved to the point where the computer-processed data according to a structure model of the real world, expressible in mathematical terms. The computer did not learn but was merely following instructions. The next step was to create a set of instructions that would allow the computer to learn from experience, i.e., to extract its own rules from large amounts of data and use those rules for classification and prediction. This was the beginning of machine learning and has led to the field collectively defined as artificial intelligence (AI). A major breakthrough came with the implementation of algorithms that were loosely modeled on brain architecture, with multiple interconnecting units sharing weighted puts among them, organized in computational layers (deep learning). AI has already revolutionized many aspects of modern life and is finding application in biomedical research and clinical practice at an accelerating rate.}
}
@article{WU2023100739,
title = {The development of teacher feedback literacy in situ: EFL writing teachers’ endeavor to human-computer-AWE integral feedback innovation},
journal = {Assessing Writing},
volume = {57},
pages = {100739},
year = {2023},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2023.100739},
url = {https://www.sciencedirect.com/science/article/pii/S1075293523000478},
author = {Peisha Wu and Shulin Yu and Yanqi Luo},
keywords = {Teacher feedback literacy, Second language writing, Teacher feedback, Computer-mediated feedback, Writing assessment},
abstract = {While recent years have witnessed increasing theoretical and empirical elaboration on the construct of teacher feedback literacy in higher education and second language education, little research has investigated the development of teacher feedback literacy, especially when teachers collaborate in an attempt to improve feedback strategies with technology. To fill this gap, the present study examined two L2 writing teachers taking the initiative to create, update, and implement a human-computer-automatic writing evaluation (AWE) integral feedback platform, and how such a feedback innovation process impacted their feedback literacy development. The analysis of multiple sources of data, including semi-structured interviews, stimulated recalls, class observation, and artifacts, revealed that the two teachers approached the innovation by orchestrating mediating tools, interacting dialogically with social agents, reflecting critically, and crossing boundaries. Through this process, the development of teacher feedback literacy occurred at varying rates across different aspects. Specifically, positive changes were effected in the teachers’ feedback thinking as well as feedback giving and sharing practices. However, the teachers’ feedback literacy in classroom practice did not seem to have generated as salient a positive outcome. Possible reasons are discussed regarding the scope of the feedback innovation and contextual constraints, and implications are offered. The study underscored L2 writing teacher feedback literacy as a developmental phenomenon molded by situated social practice.}
}
@incollection{FAVERO2023509,
title = {Chapter 25 - Raster objects},
editor = {Luiz Paulo Fávero and Patrícia Belfiore and Rafael {de Freitas Souza}},
booktitle = {Data Science, Analytics and Machine Learning with R},
publisher = {Academic Press},
pages = {509-519},
year = {2023},
isbn = {978-0-12-824271-1},
doi = {https://doi.org/10.1016/B978-0-12-824271-1.00011-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128242711000111},
author = {Luiz Paulo Fávero and Patrícia Belfiore and Rafael {de Freitas Souza}},
keywords = {Spatial analysis, Maps, Raster objects, R},
abstract = {At the end of this chapter, you will be able to:•Understand what a raster object is;•Load and use raster objects;•Combine raster objects with shapefiles;•Manipulate and cut out raster objects;•Use the raster objects in such a way as to demand less computational time for the execution of tasks;•View raster objects in R language.}
}
@article{KROGER2013189,
title = {An ERP study of passive creative conceptual expansion using a modified alternate uses task},
journal = {Brain Research},
volume = {1527},
pages = {189-198},
year = {2013},
issn = {0006-8993},
doi = {https://doi.org/10.1016/j.brainres.2013.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0006899313009566},
author = {Sören Kröger and Barbara Rutter and Holger Hill and Sabine Windmann and Christiane Hermann and Anna Abraham},
keywords = {Creativity, ERP, N400, Conceptual expansion, Alternate uses task, Divergent thinking, Semantic cognition},
abstract = {A novel ERP paradigm was employed to investigate conceptual expansion, a central component of creative thinking. Participants were presented with word pairs, consisting of everyday objects and uses for these objects, which had to be judged based on the two defining criteria of creative products: unusualness and appropriateness. Three subject-determined trial types resulted from this judgement: high unusual and low appropriate (nonsensical uses), low unusual and high appropriate (common uses), and high unusual and high appropriate (creative uses). Word pairs of the creative uses type are held to passively induce conceptual expansion. The N400 component was not specifically modulated by conceptual expansion but was, instead, generally responsive as a function of unusualness or novelty of the stimuli (nonsense=creative>common). Explorative analyses in a later time window (500–900ms) revealed that ERP activity in this phase indexes appropriateness (nonsense>creative=common). In the discussion of these findings with reference to the literature on semantic cognition, both components are proposed as indexing processes relevant to conceptual expansion as they are selectively involved in the encoding and integration of a newly established semantic connection between two previously unrelated concepts.}
}
@article{HUANG2012250,
title = {The effectiveness of using procedural scaffoldings in a paper-plus-smartphone collaborative learning context},
journal = {Computers & Education},
volume = {59},
number = {2},
pages = {250-259},
year = {2012},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2012.01.015},
url = {https://www.sciencedirect.com/science/article/pii/S0360131512000310},
author = {Hui-Wen Huang and Chih-Wei Wu and Nian-Shing Chen},
keywords = {Cooperative/collaborative learning, Improving classroom teaching, Teaching/learning strategies},
abstract = {The purpose of this study was to evaluate the effectiveness of using procedural scaffoldings in fostering students’ group discourse levels and learning outcomes in a paper-plus-smartphone collaborative learning context. All participants used built-in camera smartphones to learn new knowledge by scanning Quick Response (QR) codes, a type of two-dimensional barcode, embedded in paper-based learning materials in this study. Sixty undergraduate and graduate students enrolled at a four-year university in southern Taiwan participated in this study. Participants were randomly assigned into two different groups, using procedural scaffoldings learning and non-procedural scaffoldings learning. The learning unit about the Long Tail, an important concept used in products sales, was the learning task that participants were expected to complete. During the experiment, pretest–posttest and the completed group worksheets were used to collect data. The researchers applied content analyses, chi-square test, t-test, and ANCOVA to answer research questions. The findings indicated that participants in the experimental group using procedural scaffoldings achieved better learning outcomes than their counterparts in the control group in terms of group discourse levels, group learning, and individual learning.}
}
@incollection{WANDELL2025360,
title = {Visual processing},
editor = {Jordan Henry Grafman},
booktitle = {Encyclopedia of the Human Brain (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {360-381},
year = {2025},
isbn = {978-0-12-820481-8},
doi = {https://doi.org/10.1016/B978-0-12-820480-1.00116-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204801001169},
author = {Brian A. Wandell and Jonathan Winawer},
keywords = {Physiological optics, Retinal circuits, Eye movements, Lateral geniculate nucleus, V1, Visual cortex, Functional specialization, Neural signaling, Visual field maps, Retinotopy, Receptive fields, Sparse representations, Asynchronous representation, Redundancy, Bayesian inference},
abstract = {The human visual system is a network of neural components that combine to create our perception of the world and guide our behavior. Deciphering the computational principles of this system is an important scientific challenge. We review measurements of these components, from the retinal encoding to cortical circuitry, and from molecules to circuits, focusing on measurements that are relevant to visual processing. We then delve into principles proposed to explain how this diverse collection of visual components enables us to interpret our surroundings.}
}
@article{RASTEIRO2009e9,
title = {LABVIRTUAL—A virtual platform to teach chemical processes},
journal = {Education for Chemical Engineers},
volume = {4},
number = {1},
pages = {e9-e19},
year = {2009},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2009.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772809000025},
author = {M.G. Rasteiro and L. Ferreira and J. Teixeira and F.P. Bernardo and M.G. Carvalho and A. Ferreira and R.Q. Ferreira and F. Garcia and C.M.S.G. Baptista and N. Oliveira and M. Quina and L. Santos and P.A. Saraiva and A. Mendes and F. Magalhães and A.S. Almeida and J. Granjo and M. Ascenso and R.M. Bastos and R. Borges},
keywords = {Chemical processes, E-learning, Virtual laboratories, Computational platform},
abstract = {The need to develop the capacity for autonomous and critical thinking in students and introduce practical approaches that complement the scientific background, have been acting as driving-forces that motivate engineering educators to develop new teaching methodologies. The Chemical Engineering Departments of both the Universities of Coimbra and Porto have been experimenting in this area and addressing these concerns. Recently, they have been engaged in a broader project, involving a large group of academics with complementary competencies. This project is aimed at developing a virtual platform directed towards the learning of Chemical Processes with a wide scope. From the functional point of view the platform is organized into four main areas: Chemical Engineering, Chemical Processes, Virtual Experiments and Simulators. The Chemical Processes area is further divided into four different sections: Unit Operations and Separations, Chemical Reaction, Process Systems Engineering and Biological Processes. These sections include simulators, applications and case studies to better understand the chemical/biochemical processes. The Virtual Experiments area considers both the laboratory visualization of the basic phenomena related to the processes in the other four sections, and the remote monitoring of laboratory experiments. This platform, constructed around a dynamic Web Portal, allows discussion forums and is also aimed at sharing experiences with other schools. This paper describes the different subjects included in the web platform, as well as the simulation strategies and the web methodologies used for its construction, and also presents examples of application in the classroom.}
}
@article{LEI2025110929,
title = {Fusion of heterogeneous industrial wireless networks: A survey},
journal = {Computer Networks},
volume = {257},
pages = {110929},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2024.110929},
url = {https://www.sciencedirect.com/science/article/pii/S1389128624007618},
author = {Jiale Lei and Piao Jiang and Linghe Kong and Chi Xu and Chenren Xu and Kai Lin and Yueping Cai and Yanzhao Su and Weiping Ding and Zhen Wang and Bangyu Li and Xiaoguang Chen and Feng Gao and Weibo Wang and Jiadi Yu},
keywords = {Industrial wireless networks, 5G-U, Network fusion, Industrial internet of things},
abstract = {With the surge of wireless communication technology in smart factories, competition between different signals for limited unauthorized spectrum has led to heavy network conflicts and congestion. New technologies such as 5G unlicensed (5G-U) join industrial wireless networks (IWN) to provide advanced network access properties, making the issue more troublesome. This paper explores the advantages of fusion thinking from a new perspective of integrating heterogeneous IWNs, and systematically analyzes the key technologies that support IWN fusion, filling the gap in existing literature on IWN fusion systems. The main contribution of this paper includes proposing a technical framework based on the classic IWN architecture, fully studying the technologies and extensive research work that contribute to achieving IWN fusion from a bottom-up perspective. Moreover, open issues and prospects are enumerated to inspire valuable research works. Our research not only provides substantial contributions to the integration of the latest technologies, but also has important potential impacts on the future development of smart factory network infrastructure.}
}
@incollection{MILLER2017103,
title = {6 - Graduate and postgraduate education at a crossroads},
editor = {Susan M. Miller and Walter H. Moos and Barbara H. Munk and Stephen A. Munk},
booktitle = {Managing the Drug Discovery Process},
publisher = {Woodhead Publishing},
address = {Boston},
pages = {103-128},
year = {2017},
isbn = {978-0-08-100625-2},
doi = {https://doi.org/10.1016/B978-0-08-100625-2.00006-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780081006252000064},
author = {Susan M. Miller and Walter H. Moos and Barbara H. Munk and Stephen A. Munk},
keywords = {Academia, Career, Critical thinking, Diversity, Education, Graduate school, Immigration, Industry, Jobs, Learn by doing, Medicinal chemistry, Online education, Organic chemistry, Postdoctoral, Postgraduate, Master's degree, Doctorate.},
abstract = {In this chapter we introduce the proverbial crossroads we have reached in graduate and postgraduate education and jobs. Many factors are at play, including an explosion of information, available now, at your fingertips, a move away from memorization toward critical thinking, the importance of learning by doing, and what has been called “the gathering storm.” Core drug discovery disciplines are discussed, such as medicinal and organic chemistry, especially in the context of academia–industry symbiosis. Challenges in making sure we continue to assemble the best and the brightest to tackle important biomedical problems are considered. Finally, we scratch the surface of how to navigate employers, employment, and careers.}
}
@article{HICKMAN1995153,
title = {Advanced computational methods for spatial information extraction},
journal = {Computers & Geosciences},
volume = {21},
number = {1},
pages = {153-173},
year = {1995},
issn = {0098-3004},
doi = {https://doi.org/10.1016/0098-3004(94)00063-Z},
url = {https://www.sciencedirect.com/science/article/pii/009830049400063Z},
author = {Betty L. Hickman and Michael P. Bishop and Michael V. Rescigno},
keywords = {Spatial feature extraction, Texture features, Parallel processing, Spatial task partitioning},
abstract = {A variety of mathematical approaches for spatial information extraction using digitized aerial photography and satellite imagery have been developed and implemented on serial computers. However, because of data volume and scale, the computational demands of spatial analysis procedures frequently exceed the capacity of available serial processing technologies. One way of addressing this problem is through parallel processing in which the power of multiple computing units can be used on a single problem. In this study we investigate the utility of parallel processing for spatial feature extraction. Our testing in the situation of texture feature extraction using a cooccurrence matrix indicates that dramatic reductions in execution time are possible—an image that required about 34 min to process using one processor was solved in under 2 min using nineteen processors. The availability of additional processors could result in smaller execution times. This speedup potential is a critical element in future studies focusing on more complex spatial analysis procedures.}
}
@article{NAKAKOJI2000451,
title = {Computational support for collective creativity},
journal = {Knowledge-Based Systems},
volume = {13},
number = {7},
pages = {451-458},
year = {2000},
issn = {0950-7051},
doi = {https://doi.org/10.1016/S0950-7051(00)00069-1},
url = {https://www.sciencedirect.com/science/article/pii/S0950705100000691},
author = {K Nakakoji and Y Yamamoto and M Ohira},
keywords = {Computer support for collective creativity, Human–computer interaction, Visual images in creative insight, Knowledge-based approaches, Visualization},
abstract = {The goal of our research is to develop computer systems that support designers’ collective creativity; such systems support individual creative aspects in design through the use of representations created by others in the community. We have developed two systems, IAM-eMMa and EVIDII, that both aim at supporting designers in finding visual images that would be useful for their creative design task. IAM-eMMa uses knowledge-based rules, which are constructed by other designers, to retrieve images related to a design task, and infers the underlying “rationale” when a designer chooses one of the images. EVIDII allows designers to associate affective words and images, and then shows several visual representations of the relationships among designers, images and words. By observing designers interacting with the two systems, we have identified that systems for supporting collective creativity need to be based on design knowledge that: (1) is contextualized; (2) is respectable and trustful; and (3) enables “appropriation” of a design task.}
}
@article{VAITESSWAR2024210,
title = {Machine learning based feature engineering for thermoelectric materials by design††Electronic supplementary information (ESI) available: Details on methodology, Box–Cox transformations, machine learning models, and inverse design. See DOI: https://doi.org/10.1039/d3dd00131h},
journal = {Digital Discovery},
volume = {3},
number = {1},
pages = {210-220},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00131h},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000305},
author = {U. S. Vaitesswar and Daniil Bash and Tan Huang and Jose Recatala-Gomez and Tianqi Deng and Shuo-Wang Yang and Xiaonan Wang and Kedar Hippalgaonkar},
abstract = {Availability of material datasets through high performance computing has enabled the use of machine learning to not only discover correlations and employ materials informatics to perform screening, but also to take the first steps towards materials by design. Computational materials databases are well-labelled and provide a fertile ground for predicting both ground-state and functional properties of materials. However, a clear design approach that allows prediction of materials with the desired functional performance does not yet exist. In this work, we train various machine learning models on a dataset curated from a combination of Materials Project as well as computationally calculated thermoelectric electronic power factor using a constant relaxation time Boltzmann transport equation (BoltzTrap). We show that simple random forest-based machine learning models outperform more complex neural network-based approaches on the moderately sized dataset and also allow for interpretability. In addition, when trained on only cubic material systems, the best performing machine learning model employs a perturbative scanning approach to find new candidates in Materials Project that it has never seen before, and automatically converges upon half-Heusler alloys as promising thermoelectric materials. We validate this prediction by performing density functional theory and BoltzTrap calculations to reveal accurate matching. One of those predicted to be a good material, NbFeSb, has been studied recently by the thermoelectric community; from this study, we propose four new half-Heusler compounds as promising thermoelectric materials – TiGePt, ZrInAu, ZrSiPd and ZrSiPt. Our approach is generalizable to extrapolate into previously unexplored material spaces and establishes an automated pipeline for the development of high-throughput functional materials.}
}
@article{WANG1996579,
title = {The IDS model of intelligent design system},
journal = {Computers & Structures},
volume = {61},
number = {3},
pages = {579-586},
year = {1996},
issn = {0045-7949},
doi = {https://doi.org/10.1016/0045-7949(96)00054-5},
url = {https://www.sciencedirect.com/science/article/pii/0045794996000545},
author = {Xiaotong Wang},
abstract = {Existing models of intelligent design system nowadays are generally logic-based, which solve only simple and small-scale design problems. In the author's opinion, these models which concentrate only on far-fetched use of logical inference and abstract knowledge deviate from designer's thinking and decision process; the crux of the deviation is the lack of imitating thinking with mental imagery ability. Considering the nature of design problems and imitating rational thinking with alternate use of pattern association and symbolic operation, a new intelligent design system (IDS) model and its implementation techniques are presented. Imitation of thinking with mental imagery which is also called pattern association in the IDS model is considered by applying artificial neural network (ANN) techniques. The pattern association in the IDS model imitates the rule of human thinking, “comprehending by analogy”, to some extent. Because of the robustness of the pattern-type knowledge used in pattern association, IDS provides a practical way in producing a design scheme using incomplete and/or undeterminate input data, which is very difficult to achieve in general expert design systems. According to the IDS model, an intelligent structural layout design system of wing (ISDW) is developed. ISDW realizes mapping from key parameters of design requirements and the environment of the wing to the layout design of wing structure in not only graphic form, but also in readable data form. After getting a layout of wing structure, the user will modify it interactively by Auto-CAD, and then return to the ISDW environment to produce FEM meshes by an intelligent meshing interface in order to do the preliminary static and dynamic structural analysis. The design schemes created by the system proved to be proper and usable, and this concludes that IDS model is practicable and practical.}
}
@incollection{MARKOVA2015443,
title = {Representations, Social Psychology of},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {443-449},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.24084-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868240841},
author = {Ivana Marková},
keywords = {Anchoring, Cognitive polyphasia, Common sense, Communication, Dialogicality, Ego–Alter–Object, Ethics, Figurative scheme, Imagination, Interactional epistemology, Intervention strategies, Language, Objectification, Social representations, Themata},
abstract = {The theory of social representations studies the formation and transformation of meanings and activities of complex social phenomena like health and illness, political problems or environmental issues in and through language and communication, history and culture. There are two mutually interdependent meanings of social representations. The first meaning concerns the theory of social representations as an interactional theory of knowledge. It refers to networks of concepts and figurative schemes that are generated in and through tradition, common sense, daily knowledge, and communication; these are shared by particular groups and communities. The main features of this theory are the Ego–Alter–Object, the field, the interdependence of asymmetries and symmetries, ethics, figurative scheme, and cognitive polyphasia. Second, social representations refer to concrete social phenomena and to forms of apprehending and creating social realities in and through communication, experience, social practices, and interventions. Human thinking is characterized by the capacity to make distinctions and understand phenomena as dyadic antinomies or themata. Thematization of dyadic antinomies is linked with anchoring and objectification, through which social representations are formed and transformed.}
}
@article{SHU2025111052,
title = {Optimal power flow in hybrid AC-DC systems considering N-k security constraints in the preventive-corrective control stage},
journal = {Electric Power Systems Research},
volume = {238},
pages = {111052},
year = {2025},
issn = {0378-7796},
doi = {https://doi.org/10.1016/j.epsr.2024.111052},
url = {https://www.sciencedirect.com/science/article/pii/S0378779624009349},
author = {Hongchun Shu and Hongfang Zhao and Mengli Liao},
keywords = {Flexible DC transmission, AC-DC hybrid system, -, Safety constraints, Optimal power flow},
abstract = {The optimal power flow methods for AC-DC systems containing VSC-HVDC generally only consider the economy during normal operation, overlooking the distribution of line transmission power in fault conditions. As a result, lines that continue to operate after a fault may experience overloading or operate at full capacity. Thus, a method for optimal power flow calculation is proposed that incorporates N-k security constraints in the preventive-corrective control stage for secure and economic operation of hybrid AC-DC systems. This method ensures that the line transmission power in the system meets the limits in the normal, short-term fault, and long-term fault states. In addition to the optimal power flow in the normal state, the method incorporates the system's imbalance as an indicator to evaluate system resilience. It combines this indicator with the economic, network loss, and performance metrics of the system, forming a two-stage bi-level multi-objective optimization model. Furthermore, to address the curse of dimensionality in anticipating system fault sets, a method for generating the anticipated fault set using non-sequential Monte Carlo simulation is proposed, along with a fault scenario search approach based on robust thinking to identify the most severe faults. Finally, the traditional IEEE 30-bus system was improved, and simulation verification was conducted using examples of an AC/DC system with a three-terminal DC network and a wind-solar-storage hybrid AC/DC system with a three-terminal DC network. The simulation results indicate that the proposed optimal power flow method considering the preventive-corrective control stage with N-k security constraints can effectively enhance system resilience. Furthermore, it improves the economic efficiency while ensuring the secure operation of the system.}
}
@incollection{HALFORD2020327,
title = {Cognitive Developmental Theories☆},
editor = {Janette B. Benson},
booktitle = {Encyclopedia of Infant and Early Childhood Development (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {327-336},
year = {2020},
isbn = {978-0-12-816511-9},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.05787-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245057874},
author = {G.S. Halford},
keywords = {Analogy, Cognitive complexity, Conceptual chunking, Dynamic systems, Information processing, Mental models, Neural net, Object permanence, Relational knowledge, Symbolic processes, Theory of mind, Working memory},
abstract = {Theories of cognitive development are reviewed, beginning with pioneering theories by Piaget and Vygotsky. Neo-Piagetian theories which integrated Piagetian theory with other conceptions of cognition were developed by McLaughlin, Pascual-Leone, Case, Fischer, and Chapman. Complexity theories propose that children become capable of dealing with more complex relations as they develop. Information processing theories, neural net theories, dynamic systems theories, and theories of reasoning processes all provide models of the reasoning processes employed by children at different ages. Microgenetic analysis methods are used to study the processes of transition from one level of thinking to the next. Conceptual coherence is achieved by categorizing cognitive processes according to their core properties.}
}
@article{BRENTDANIEL2023105630,
title = {Extremely rapid, Lagrangian modeling of 2D flooding: A rivulet-based approach},
journal = {Environmental Modelling & Software},
volume = {161},
pages = {105630},
year = {2023},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2023.105630},
url = {https://www.sciencedirect.com/science/article/pii/S1364815223000166},
author = {W. {Brent Daniel} and Corinne Roth and Xue Li and Cindy Rakowski and Tim McPherson and David Judi},
keywords = {Modeling, Fluid flow, Flood modeling, Hydrodynamic model, Rivulet, Lagrangian},
abstract = {Estimates of potential flood inundation areas and depths are critical to informing the preparedness, response, and investment decisions of many government agencies and private sector organizations, especially under a changing climate. The standard modeling approaches, however, are often either computationally intensive or constrained in their accuracy or applicability. A novel, rivulet-based, 2D model of flooding is described in this article that is 10,000 to 10 million times less computationally complex than the full solution of the shallow water equations, yet achieves inundation area hit rates of between 0.8 and 0.9, relative absolute mean errors of 10%–20% across a wide range of flow depths, and comparable accuracy at forecasting empirical high-water marks. This combination of accuracy and efficiency will significantly enhance real-time depth estimates during flood events, support detailed sensitivity analyses, and allow for the generation of large ensembles to enable complex uncertainty analyses.}
}
@article{THANKACHAN2024101283,
title = {A mathematical formulation of learner cognition for personalised learning experiences},
journal = {Cognitive Systems Research},
volume = {88},
pages = {101283},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101283},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724000779},
author = {Jeena A. Thankachan and Bama Srinivasan},
keywords = {Virtual Learning Environment (VLE), Cognitive Evaluation Metrics (CEM), Multimode evaluation, Cognitive abilities, Learning tasks, Reinforcement learning},
abstract = {The paper focuses on the assessment of cognitive skills within Virtual Learning Environments (VLEs). In response to the global shift to remote learning amid the COVID-19 pandemic, VLEs, which include learning management systems (LMS) and online collaboration platforms, gained prominence. The proposed work leverages an established Cattell–Horn–Carroll (CHC) theory to propose eight metrics, which collectively form a part of Cognitive Evaluation Metrics (CEM). The proposed metrics introduce a novel computational approach for multimode evaluation of learners’ cognitive abilities for each learning task within a learning environment. The paper details the formalism for the evaluation of the metrics and makes a contribution towards the potential of the proposed methodology to evaluate cognitive abilities. Additionally, the work implements CEM integration into the learner module of a Game-Based Learning (GBL) environment. Analysis of simulations in the GBL environment, along with statistical analysis, provides insights into the normal distribution of cognitive metrics. This reveals diverse ranges in various abilities such as long or short term memory, working memory, reasoning, attention, and processing speed. The paper also explores the impact of virtual assistants, which highlights their limited relevance to enhance cognitive abilities but serve as valuable on-demand support resources.}
}
@article{YIM2014144,
title = {A development of a quantitative situation awareness measurement tool: Computational Representation of Situation Awareness with Graphical Expressions (CoRSAGE)},
journal = {Annals of Nuclear Energy},
volume = {65},
pages = {144-157},
year = {2014},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2013.10.029},
url = {https://www.sciencedirect.com/science/article/pii/S0306454913005598},
author = {Ho Bin Yim and Seung Min Lee and Poong Hyun Seong},
keywords = {Quantitative measure, Situation awareness, Graphical expression, NPP MCR operators},
abstract = {Operator performance measures are used for multiple purposes, such as control room design, human system interface (HSI) evaluation, training, and so on. Performance measures are often focused on results; however, especially for a training purpose – at least in a nuclear industry, more detailed descriptions about processes are required. Situation awareness (SA) measurements have directly/indirectly played as a complimentary measure and provided descriptive insights on how to improve performance of operators for the next training. Unfortunately, most of the well-developed SA measurement techniques, such as Situation Awareness Global Assessment Technique (SAGAT) need an expert opinion which sometimes troubles easy spread of measurement’s application or usage. A quantitative SA measurement tool named Computational Representation of Situation Awareness with Graphical Expressions (CoRSAGE) is introduced to resolve some of these concerns. CoRSAGE is based on production rules to represent a human operator’s cognitive process of problem solving, and Bayesian inference to quantify it. Petri Net concept is also used for graphical expressions of SA flow. Three components – inference transition, volatile/non-volatile memory tokens – were newly developed to achieve required functions. Training data of a Loss of Coolant Accident (LOCA) scenario for an emergency condition and an earthquake scenario for an abnormal condition by real plant operators were used to validate the tool. The validation result showed that CoRSAGE performed a reasonable match to other performance results.}
}
@article{FOWLER20245,
title = {Will variants of uncertain significance still exist in 2030?},
journal = {The American Journal of Human Genetics},
volume = {111},
number = {1},
pages = {5-10},
year = {2024},
issn = {0002-9297},
doi = {https://doi.org/10.1016/j.ajhg.2023.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0002929723004007},
author = {Douglas M. Fowler and Heidi L. Rehm},
abstract = {Summary
In 2020, the National Human Genome Research Institute (NHGRI) made ten “bold predictions,” including that “the clinical relevance of all encountered genomic variants will be readily predictable, rendering the diagnostic designation ‘variant of uncertain significance (VUS)’ obsolete.” We discuss the prospects for this prediction, arguing that many, if not most, VUS in coding regions will be resolved by 2030. We outline a confluence of recent changes making this possible, especially advances in the standards for variant classification that better leverage diverse types of evidence, improvements in computational variant effect predictor performance, scalable multiplexed assays of variant effect capable of saturating the genome, and data-sharing efforts that will maximize the information gained from each new individual sequenced and variant interpreted. We suggest that clinicians and researchers can realize a future where VUSs have largely been eliminated, in line with the NHGRI’s bold prediction. The length of time taken to reach this future, and thus whether we are able to achieve the goal of largely eliminating VUSs by 2030, is largely a consequence of the choices made now and in the next few years. We believe that investing in eliminating VUSs is worthwhile, since their predominance remains one of the biggest challenges to precision genomic medicine.}
}
@article{ELLIOT2022112418,
title = {An expanded framing of ecosystem services is needed for a sustainable urban future},
journal = {Renewable and Sustainable Energy Reviews},
volume = {162},
pages = {112418},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2022.112418},
url = {https://www.sciencedirect.com/science/article/pii/S1364032122003264},
author = {T. Elliot and J.A. Torres-Matallana and B. Goldstein and J. {Babí Almenar} and E. Gómez-Baggethun and V. Proença and B. Rugani},
keywords = {Urban ecosystem services, Urban metabolism, Life cycle thinking, Land cover change, System dynamics modelling, Urban land teleconnections},
abstract = {Urban activities are an important driver of ecosystem services decline. Sustainable urbanisation necessitates anticipating and mitigating these negative socio-ecological impacts, both within and beyond city boundaries. There is a lack of scalable, dynamic models of changes to ecosystems wrought by urban processes. We developed a system dynamics model, ESTIMUM, to predict locations, types, and magnitude of changes in ecosystem services. We tested the model in Lisbon (Portugal) under four specific urban development scenarios – a base case scenario and three local sustainability-driven scenarios – to the year 2050. Our results show that urban sustainability policies focused on reducing impacts within Lisbon can be undermined by increased impacts in the extended regions that supply resources to the city. In particular, carbon sequestration from urban greening pales in comparison to growing greenhouse gases from the consumption of food, energy and construction materials. We also find that policies targeted at these extended environmental impacts can be much more effective than those with a limited focus on the urban form. For example, dietary shifts could support positive changes outside that city to increase global climate regulation by 54% compared to a mere 1% increase through intensive urban greening. This highlights the urgent need for a reframing of urban sustainability in policy and scholarly circles from city-centric focus towards an expanded multi-scalar conceptualisation of urban sustainability that accounts for urban impacts beyond the city boundaries.}
}
@article{SCHAEFER198897,
title = {A history of ab initio computational quantum chemistry: 1950–1960},
journal = {Tetrahedron Computer Methodology},
volume = {1},
number = {2},
pages = {97-102},
year = {1988},
issn = {0898-5529},
doi = {https://doi.org/10.1016/0898-5529(88)90014-0},
url = {https://www.sciencedirect.com/science/article/pii/0898552988900140},
author = {Henry F. Schaefer},
keywords = {Quantum chemistry, Ab initio, Electronic structure theory, Molecular quantum mechanics, Computations},
abstract = {Although ab initio computational quantum chemistry produced virtually no predictions of chemical interest during the 1950's, an important foundation for future work was laid during this decade. Much of this fundamental computational research was carried out in the laboratories of Frank Boys in Cambridge (England) and Clemens Roothaan and Robert Mulliken in Chicago. Other senior contributors to ab initio chemical theory during this period include Klaus Ruedenberg, Robert Parr, John Pople, Robert Nesbet, Harrison Shull, Per-Olov Löwdin, Isaiah Shavitt, Albert Matsen, Douglas McLean, and Bernard Ransil.}
}
@incollection{TIRAPELLE20233465,
title = {Practical learning activities to increase the interest of university applicants in STEM careers in the era of Industry 4.0},
editor = {Antonios C. Kokossis and Michael C. Georgiadis and Efstratios Pistikopoulos},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {52},
pages = {3465-3470},
year = {2023},
booktitle = {33rd European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-15274-0.50553-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443152740505539},
author = {Monica Tirapelle and Dian Ning Chia and Fanyi Duanmu and Konstantinos Katsoulas and Alberto Marchetto and Eva Sorensen},
keywords = {Engineering Education, Hands-on activities, Active learning, Orientation to university, PSE computational tools},
abstract = {Inspiring young students, especially young girls, about STEM disciplines is crucial to address the current shortage of engineers. Since the engineering skills that are required by graduates are evolving in line with technological progress, there is now an even stronger need for graduates with strong Process Systems Engineering skills. In this work, we describe an effective way to promote the chemical engineering curriculum, with particular emphasis on computational tools, to a group of Year 12 high school students during a one-week course in our department. The course was designed to engage students in active learning through interactive sessions and practical hands-on activities. Through the course, the students gained a better understanding of the importance of STEM subjects and, in particular, of the challenges and opportunities that engineers encounter in the era of Industry 4.0 with ever-increasing use of digitalization in process design and operation.}
}
@article{PIOLOPEZ2023103585,
title = {Morphoceuticals: Perspectives for discovery of drugs targeting anatomical control mechanisms in regenerative medicine, cancer and aging},
journal = {Drug Discovery Today},
volume = {28},
number = {6},
pages = {103585},
year = {2023},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2023.103585},
url = {https://www.sciencedirect.com/science/article/pii/S1359644623001010},
author = {Léo Pio-Lopez and Michael Levin},
keywords = {Biomedicine, Drug discovery, Morphogenesis},
abstract = {Morphoceuticals are a new class of interventions that target the setpoints of anatomical homeostasis for efficient, modular control of growth and form. Here, we focus on a subclass: electroceuticals, which specifically target the cellular bioelectrical interface. Cellular collectives in all tissues form bioelectrical networks via ion channels and gap junctions that process morphogenetic information, controlling gene expression and allowing cell networks to adaptively and dynamically control growth and pattern formation. Recent progress in understanding this physiological control system, including predictive computational models, suggests that targeting bioelectrical interfaces can control embryogenesis and maintain shape against injury, senescence and tumorigenesis. We propose a roadmap for drug discovery focused on manipulating endogenous bioelectric signaling for regenerative medicine, cancer suppression and antiaging therapeutics.}
}
@article{STREVENS202192,
title = {Permissible idealizations for the purpose of prediction},
journal = {Studies in History and Philosophy of Science Part A},
volume = {85},
pages = {92-100},
year = {2021},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2020.09.009},
url = {https://www.sciencedirect.com/science/article/pii/S0039368120301813},
author = {Michael Strevens},
keywords = {Prediction, Idealization, Modeling, Difference-making, Causal relevance},
abstract = {Every model leaves out or distorts some factors that are causally connected to its target phenomenon—the phenomenon that it seeks to predict or explain. If we want to make predictions, and we want to base decisions on those predictions, what is it safe to omit or to simplify, and what ought a causal model to describe fully and correctly? A schematic answer: the factors that matter are those that make a difference to the target phenomenon. There are several ways to understand differencemaking. This paper advances a view as to which is the most relevant to the forecaster and the decision-maker. It turns out that the right notion of differencemaking for thinking about idealization in prediction is also the right notion for thinking about idealization in explanation; this suggests a carefully circumscribed version of Hempel’s famous thesis that there is a symmetry between explanation and prediction.}
}
@article{LI2024112467,
title = {Study on correlation between perioperative cognitive function and nutritional status in elderly patients with gastric cancer},
journal = {Experimental Gerontology},
volume = {193},
pages = {112467},
year = {2024},
issn = {0531-5565},
doi = {https://doi.org/10.1016/j.exger.2024.112467},
url = {https://www.sciencedirect.com/science/article/pii/S0531556524001098},
author = {Rong Li and Yuping Liu and Yingtao Meng and Xianlin Qu and Meimei Shang and Lihui Yang and Jie Chai},
keywords = {Elderly, Gastric cancer, Perioperative period, Cognitive function, Nutritional status, Correlation, Analysis},
abstract = {Objective: To investigate the cognitive function and nutritional status of elderly patients with gastric cancer during perioperative period, and to analyze their correlation. Methods: Aged patients undergoing gastric cancer surgery in The Affiliated Cancer Hospital of Shandong First Medical University from March to October 2021 were selected as the subjects of this study. The monitoring data of cognitive function and nutritional status were retrospectively analyzed from 1 to 3 days before surgery, 1 and 3 days after surgery, 7 days after surgery (before discharge) and 30 days after surgery to analyze the correlation between cognitive function and nutritional status in elderly patients with gastric cancer. Results: the incidence of mild cognitive impairment in elderly patients with gastric cancer was 52.43 %, the visual space of the two groups' (mild cognitive impairment) ability of execution, name, attention, language, abstract thinking, delayed memory and cognitive function scores were lower than 1 set of directional force (cognitive function in normal group), statistically significant difference (P < 0.05). The nutritional status of elderly patients with gastric cancer was lower than that of healthy elderly group at the same period (P < 0.05). The scores of visual spatial executive function, name, attention, delayed memory, orientation and total score of cognitive function in elderly gastric cancer patients were positively correlated with nutritional status (P < 0.05). Conclusions: The cognitive function and nutritional status of elderly patients with gastric cancer are both in a low state during treatment and a higher level of cognitive function can help patients maintain a more correct nutritional cognition, and the nutritional status of patients will be relatively better. There is a positive correlation between cognitive function and nutritional status in elderly patients with gastric cancer, which should be paid attention to in the treatment.}
}
@incollection{FROEMER2025234,
title = {Belief updates, learning and adaptive decision making},
editor = {Jordan Henry Grafman},
booktitle = {Encyclopedia of the Human Brain (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {234-251},
year = {2025},
isbn = {978-0-12-820481-8},
doi = {https://doi.org/10.1016/B978-0-12-820480-1.00059-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128204801000590},
author = {Romy Froemer and Matthew R. Nassar},
keywords = {Reinforcement learning, Reward, Value, Action, Dopamine, Belief updating, Sequential sampling, Attention, Confidence, Context, Experience, Goal-directed behavior, Cost-benefit decision-making},
abstract = {People make decisions every day and the outcomes of those decisions often lead them to change their beliefs and in some cases shape their future behavior. How does the brain decide which meal to order at a restaurant, and how does it learn from the experience of eating that meal? Here we review work from neuroscience, psychology and economics that shapes our understanding of how the brain makes decisions and learns through experience. We focus on computational mechanisms that can explain core phenomena in learning and decision making as well as how such mechanisms are implemented in the brain. Our review highlights both the considerable progress made in the last decades elucidating mechanisms of learning and decision making as well as the vast territory of open questions that remain to be answered.}
}
@article{ADRIAENSEN2023106294,
title = {Systems-theoretic interdependence analysis in robot-assisted warehouse management},
journal = {Safety Science},
volume = {168},
pages = {106294},
year = {2023},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2023.106294},
url = {https://www.sciencedirect.com/science/article/pii/S0925753523002369},
author = {Arie Adriaensen and Liliane Pintelon and Francesco Costantino and Giulio {Di Gravio} and Riccardo Patriarca},
keywords = {FRAM, Human-machine interaction, Industry 4.0, Industry 5.0, Cobots},
abstract = {The safe and efficient application of collaborative robots requires an understanding of actual work practices transformation, emerging from the adoption of new technological instruments. Functional systems-thinking is largely absent in literature about collaborative robot applications. In this context, this study proposes a framework that combines two safety analysis methods, being the Functional Resonance Analysis Method and Interdependence Analysis. Both safety and efficiency are examined by selected case study highlights to gain an in-depth understanding of human operators’ role as the central driver of human–machine (eco)systems in a warehouse distribution system, in which warehouse robot assistance is provided. Whereas the Functional Resonance Analysis Method first maps the work system interactions as a whole, Interdependence Analysis is subsequently applied to investigate individual inter-agent exchanges by the principles of Observability, Predictability, and Directability as a core principle for goal coordination between multiple agents, including warehouse robot agents. The case study examples reveal the combined effects of the working system environment and the robot application but also demonstrate possible operational solutions to deal with socio-technical complexity.}
}
@article{NAGOEV2020615,
title = {Model of the reasoning process in a multiagent cognitive system},
journal = {Procedia Computer Science},
volume = {169},
pages = {615-619},
year = {2020},
note = {Postproceedings of the 10th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2019 (Tenth Annual Meeting of the BICA Society), held August 15-19, 2019 in Seattle, Washington, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.202},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920303252},
author = {Zalimhan Nagoev and Inna Pshenokova and Murat Anchekov},
keywords = {Multi-Agent Systems, Neurocognitive Architecture, Simulation Model, Artificial Intelligence Systems, Reasoning Models},
abstract = {A model of the reasoning process in a multiagent cognitive system for the synthesis of intelligent solutions of the problem is presented. The approach based on the computational abstraction of multi-agent neurocognitive systems that illustrates architectural conformity to self-organizing neurocognitive networks of the brain. The model represents the process of reasoning in the form of cognitive blocks that synthesize intelligent solutions and allow the user to effectively solve the tasks.}
}
@article{KNOWLTON2012373,
title = {A neurocomputational system for relational reasoning},
journal = {Trends in Cognitive Sciences},
volume = {16},
number = {7},
pages = {373-381},
year = {2012},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2012.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S1364661312001283},
author = {Barbara J. Knowlton and Robert G. Morrison and John E. Hummel and Keith J. Holyoak},
abstract = {The representation and manipulation of structured relations is central to human reasoning. Recent work in computational modeling and neuroscience has set the stage for developing more detailed neurocomputational models of these abilities. Several key neural findings appear to dovetail with computational constraints derived from a model of analogical processing, ‘Learning and Inference with Schemas and Analogies’ (LISA). These include evidence that (i) coherent oscillatory activity in the gamma and theta bands enables long-distance communication between the prefrontal cortex and posterior brain regions where information is stored; (ii) neurons in prefrontal cortex can rapidly learn to represent abstract concepts; (iii) a rostral-caudal abstraction gradient exists in the PFC; and (iv) the inferior frontal gyrus exerts inhibitory control over task-irrelevant information.}
}
@article{OFFENHUBER2023264,
title = {Reconsidering Representation in College Design Curricula},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {9},
number = {2},
pages = {264-282},
year = {2023},
note = {The Future of Design Education: Rethinking Design Education for the 21st Century},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2023.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S2405872623000394},
author = {Dietmar Offenhuber and Joy Mountford},
keywords = {Representation, Data, Models, Maps, Visualization, Sensory modalities},
abstract = {The Future of Design Education working group on representation addressed the roles of data, maps, models, and interfaces as a continuum from representation to action. The article traces historical ideas of representation grounded by a linguistic paradigm to more recent approaches based on performance, embodiment, and sensory modalities other than vision. Discussions include the use of representations in the design process. Designers are able to use traditional forms of representation in the design of artifacts, such as sketches. These forms of representation are not sufficient for the design of systems. System design requires models that allow stakeholders to negotiate their view of a situation and design teams to iterate how things might work. Core ideas in the working group recommendations address issues of, substitution, formal rules, motivation, context dependency, materiality, provisionality, latency, performance, externalization, facilitation and negotiation, mediation, and measurement and evaluation. Discussions address the socio-political implications of representation and the expanding role of computing and data that call for a systems view.}
}
@article{BATTISTELLI2022,
title = {Online Strategies To Improve Quantitative Skills in Microbiology Laboratory Classes},
journal = {Journal of Microbiology & Biology Education},
volume = {23},
number = {1},
year = {2022},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.00333-21},
url = {https://www.sciencedirect.com/science/article/pii/S1935787722000995},
author = {Joseph M. Battistelli and Rima B. Franklin},
keywords = {quantitative literacy, quantitative biology, problem solving, word problems, math skills, formula question, Canvas, spreadsheets, algebra, formula questions},
abstract = {Biology is an increasingly quantitative science. Thus, it is important that undergraduate biology curricula include frequent opportunities for students to practice their quantitative skills.
ABSTRACT
Biology is an increasingly quantitative science. Thus, it is important that undergraduate biology curricula include frequent opportunities for students to practice their quantitative skills. This can create a substantial grading burden for faculty teaching online and/or large enrollment courses, but the “formula question” feature present in many learning management systems (LMS) offers a solution. Using this feature, faculty set up a basic scaffold for an algebraic word problem, and the LMS can then automatically generate and grade many different versions of the question. In this paper, we describe the use of “formula questions” in an undergraduate microbiology course and specifically focus on how the strategic use of algebraic word problems at multiple points throughout the semester can help build quantitative literacy. Key to the success of this approach is that faculty provide a review of foundational mathematical skills early in the semester, even in upper-level classes. This should include reacquainting students with formatting conventions (e.g., rounding and scientific notation), familiarizing them with any idiosyncrasies of the technology platforms, and demonstrating how to solve math problems using spreadsheets. This initial effort increases student success when more complex problems are introduced later in the semester. Though the tips summarized in this paper focus on undergraduate microbiology teaching laboratories using Canvas, the approach can easily be modified to help students develop their critical thinking and quantitative reasoning skills at other levels and in other disciplines.}
}
@incollection{HEGARTY2010265,
title = {Chapter 7 - Components of Spatial Intelligence},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {52},
pages = {265-297},
year = {2010},
booktitle = {The Psychology of Learning and Motivation},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(10)52007-3},
url = {https://www.sciencedirect.com/science/article/pii/S0079742110520073},
author = {Mary Hegarty},
abstract = {This chapter identifies two basic components of spatial intelligence, based on analyses of performance on tests of spatial ability and on complex spatial thinking tasks in domains such as mechanics, chemistry, medicine, and meteorology. The first component is flexible strategy choice between mental imagery (or mental simulation more generally) and more analytic forms of thinking. Research reviewed here suggests that mental simulation is an important strategy in spatial thinking, but that it is augmented by more analytic strategies such as task decomposition and rule-based reasoning. The second is meta-representational competence [diSessa, A. A. (2004). Metarepresentation: Native competence and targets for instruction. Cognition and Instruction, 22, 293–331], which encompasses ability to choose the optimal external representation for a task and to use novel external representations productively. Research on this aspect of spatial intelligence reveals large individual differences in ability to adaptively choose and use external visual–spatial representations for a task. This research suggests that we should not just think of interactive external visualizations as ways of augmenting spatial intelligence, but also consider the types of intelligence that are required for their use.}
}
@article{SCHWARZ201359,
title = {Business wargaming for teaching strategy making},
journal = {Futures},
volume = {51},
pages = {59-66},
year = {2013},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2013.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0016328713000864},
author = {Jan Oliver Schwarz},
keywords = {Business wargaming, Teaching, Simulation, Management education, Strategy making, Strategic thinking},
abstract = {An increasingly complex and dynamic business environment requires new approaches to teaching strategy to management students. Business wargaming, a dynamic strategic simulation, is discussed as a management simulation which can respond to the contemporary challenges in management education. Reflecting on the practical use of business wargaming in the classroom, it is described how such simulations prepare management students for making strategic decisions in complex and dynamic environments characterised by high uncertainty concerning the future.}
}
@article{WANG2025113691,
title = {Effect of interlayer spacing on the mechanical properties of the graphene oxide/thermoplastic polyurethane nanocomposite},
journal = {Computational Materials Science},
volume = {250},
pages = {113691},
year = {2025},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2025.113691},
url = {https://www.sciencedirect.com/science/article/pii/S0927025625000345},
author = {Yuyang Wang and Guofu Yin and Junpeng Liu and Jiao Li and Chunqiang Wei and Minjie Li},
keywords = {Thermoplastic Polyurethane, Graphene Oxide, Interlayer Spacing, Mechanical Properties, Molecular Dynamics},
abstract = {In this paper, in order to investigate the effect of graphene oxide (GO) interlayer spacing on the overall mechanical properties of GO/thermoplastic polyurethane (TPU) nanocomposite, the uniaxial tensile simulation on the computational model of GO/TPU nanocomposite with monolayer and bilayer graphene sheets were carried out. During the tensile process, the variation of potential energy, void percentage, tensile strain contour, and density distribution with tensile strain were applied to analyze the underlying microscopic mechanism of stress change of monolayer GO/TPU system. The results show that when the system was within the stress yield region, the micro rearrangement motion and relative sliding of TPU chains play a major role. Furthermore, when the system enters into the stress softening region until stress failure, the void formation and nuclear within the system dominates the stress change, which is attributed to the interfacial structure of GO/TPU. Subsequently, based on the above-mentioned results in the case of monolayer GO/TPU result, the effects of different layer spacings on the overall mechanical properties of GO/TPU nanocomposite system were discussed by varying the spacing of GO layers. The results show that with the increase of GO layer spacing, the elastic modulus and yield strength of the system show a tendency of increasing and then decreasing, and the failure strain is the opposite, and when the GO dispersion is better, it can also play the role of delayed damage failure of the system.}
}
@article{CHONG2016257,
title = {A generalized cognitive hierarchy model of games},
journal = {Games and Economic Behavior},
volume = {99},
pages = {257-274},
year = {2016},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2016.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0899825616300847},
author = {Juin-Kuan Chong and Teck-Hua Ho and Colin Camerer},
keywords = {Cognitive hierarchy, Level- model, Level- model, Generalized cognitive hierarchy, Non-equilibrium structural models, Behavioral game theory},
abstract = {Subjects in simple games frequently exhibit non-equilibrium behaviors. Cognitive hierarchy (CH) and level k (LK) are two prevailing structural models that capture such behaviors well. This paper proposes a generalized CH (GCH) model that nests a variant of the LK model, called LM. GCH differs from CH in two ways. First, each lower level's actual frequency is exponentially weighted with α to form level-k's belief on relative proportions; α captures stereotype bias. CH assumes no stereotype bias (α=1) and LM assumes extreme bias (α=∞). Second, GCH replaces random choice with minimum aversion for level 0. Level 0s are more likely to choose strategies that never yield the minimum payoff for any of the opponent's strategies. GCH captures behaviors better than CH and LK in fifty-five n×m games from four datasets. Robustness tests using three new games further validate GCHs descriptive strength over CH and LK.}
}
@article{CHEN2025121691,
title = {A novel attribute reduction algorithm based on granular sequential three-way decision},
journal = {Information Sciences},
volume = {694},
pages = {121691},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.121691},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524016050},
author = {Yuliang Chen and Yunlong Cheng and Binbin Luo and Yabin Shao and Mingfu Zhao and Qinghua Zhang},
keywords = {Granular computing, Sequential three-way decision, Granular rough sets, Attribute reduction},
abstract = {Attribute reduction plays a crucial role in knowledge discovery, and sequential three-way decision (S3WD) provides a new method for attribute reduction. However, the three regions of the S3WD model are usually represented as three sets, which leads to two disadvantages. On one hand, it is difficult to obtain the condition of a decision rule when multiple equivalence classes are merged into a set because different equivalence classes have different descriptions. On the other hand, if the boundary region of the upper level of S3WD is a set, one has to partition the upper level with all the acquired attributes rather than the newly added attribute. That is, there is double counting. Therefore, this paper focuses on how to retain the topology of equivalence classes in S3WD, and how to use this topology to enhance semantic interpretation and improve computational efficiency. To this end, a granular version of S3WD, called granular sequential three-way decision (GS3WD), is first developed to retain the information structure of equivalence classes. And then, three acceleration strategies and an efficient granular sequential three-way reduction (GS3WR) are proposed. Finally, a concept tree can be generated simultaneously in the process of GS3WR, and the decision rules with multi-granularity can be extracted from this concept tree directly. Experimental results show that GS3WR can obtain the same core attributes and reducts as the representative attribute reduction algorithms in rough sets and the computational efficiency is improved by hundreds of times.}
}
@article{KAZEMI2002203,
title = {Exploring test performance in mathematics: the questions children’s answers raise},
journal = {The Journal of Mathematical Behavior},
volume = {21},
number = {2},
pages = {203-224},
year = {2002},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00118-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302001189},
author = {Elham Kazemi},
keywords = {Children’s thinking, Mathematical performance, Interpreting problems, Testing},
abstract = {This article investigates children’s mathematical performance on test items, specifically multiple-choice questions. Using interviews with 90 fourth-graders, it reveals why particular kinds of items are more or less difficult for students. By using multiple-choice questions and juxtaposing them with similar open-ended problems, the findings underscore the costs of not attending to children’s thinking in designing and interpreting problems. The data from this study suggest that when answering multiple-choice questions, students’ attention is drawn to the choices themselves. They do not necessarily think through the problem first and thus make their choices based on (often incorrect) generalizations they have made about problem-solving. Whether students answered a multiple-choice question or a similar open-ended problem first impacted both their performance and their reasoning. Moreover, children draw on their life experiences when the context of the problem is salient, thus ignoring important parameters of the stated problem. Implications for investigating children’s thinking, instruction, and test design are discussed.}
}
@article{LENG20242963,
title = {An Improved YOLOv8-Based Method for Real-Time Detection of Harmful Tea Leaves in Complex Backgrounds},
journal = {Phyton-International Journal of Experimental Botany},
volume = {93},
number = {11},
pages = {2963-2981},
year = {2024},
issn = {0031-9457},
doi = {https://doi.org/10.32604/phyton.2024.057166},
url = {https://www.sciencedirect.com/science/article/pii/S0031945724001643},
author = {Xin Leng and Jiakai Chen and Jianping Huang and Lei Zhang and Zongxuan Li},
keywords = {Harmful tea leaves, YOLO-DBD, Focal-CIoU Loss, dynamic head, Bi-Level Routing Attention},
abstract = {Tea, a globally cultivated crop renowned for its unique flavor profile and health-promoting properties, ranks among the most favored functional beverages worldwide. However, diseases severely jeopardize the production and quality of tea leaves, leading to significant economic losses. While early and accurate identification coupled with the removal of infected leaves can mitigate widespread infection, manual leaves removal remains time-consuming and expensive. Utilizing robots for pruning can significantly enhance efficiency and reduce costs. However, the accuracy of object detection directly impacts the overall efficiency of pruning robots. In complex tea plantation environments, complex image backgrounds, the overlapping and occlusion of leaves, as well as small and densely harmful leaves can all introduce interference factors. Existing algorithms perform poorly in detecting small and densely packed targets. To address these challenges, this paper collected a dataset of 1108 images of harmful tea leaves and proposed the YOLO-DBD model. The model excels in efficiently identifying harmful tea leaves with various poses in complex backgrounds, providing crucial guidance for the posture and obstacle avoidance of a robotic arm during the pruning process. The improvements proposed in this study encompass the Cross Stage Partial with Deformable Convolutional Networks v2 (C2f-DCN) module, Bi-Level Routing Attention (BRA), Dynamic Head (DyHead), and Focal Complete Intersection over Union (Focal-CIoU) Loss function, enhancing the model’s feature extraction, computation allocation, and perception capabilities. Compared to the baseline model YOLOv8s, mean Average Precision at IoU 0.5 (mAP0.5) increased by 6%, and Floating Point Operations Per second (FLOPs) decreased by 3.3 G.}
}
@incollection{MAMATHA2024259,
title = {Chapter Eleven - Bio-intelligent computing and optimization techniques for developing computerized solutions},
editor = {Anupam Biswas and Alberto Paolo Tonda and Ripon Patgiri and Krishn Kumar Mishra},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {135},
pages = {259-288},
year = {2024},
booktitle = {Applications of Nature-Inspired Computing and Optimization Techniques},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2023.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S006524582300089X},
author = {G.S. Mamatha and Haripriya V. Joshi and R. Amith},
keywords = {Bio-intelligent, Bio-inspired, Computing, Optimization technique, Bio-engineering},
abstract = {Bio-inspired computing is a field of study that Lois lee knits together subfields related to the connectionism, social behavior and emergence. It is often closely related to the field of artificial intelligence as many of its pursuits can be linked to machine learning. It relies heavily on fields of biology, computer science and mathematics. Briefly it is the use of computers to model the living phenomena and simultaneously the study of life to improve the usage of computer. Biologically inspired computation is a major subset of natural computation areas of research. Some areas of study encompassed under the canon of biologically inspired computing and their biological counterparts are, genetic algorithms, evolution, biodegradability prediction, biodegradation, cellular automata, life emergent system ants, termites, bees, wasps, neural networks, artificial immune systems rendering patterning and animal skins, bird feathers, mollusk shells and bacterial colonies. Linder Mayer systems, plant structures, communication networks and protocol, epidemiology and the spared of disease, intra membrane molecular processes in living cells, excitable media forest fires the wave heart conditions axons and sensor networks sensory organs. Optimization techniques takes more bottom-up decentralized approach and often involves the methods of specifying a set of simple rules, a set of simple organisms which adhere to those rules and method of iteratively applying those rules for example, training virtual insect to investigate to an unknown terrain for finding food includes six simple rules which can be adopted. After several generations of rules application, it is usually the case where some forms of complex behavior get built upon complexity until the end results is something markedly complex and quite often completely counterintuitive from what the original rules would be expected to produce. For this reason, most technology-oriented solutions like neural network models, algorithms and other techniques came in to existence for accurate measurements and analysis that can be used to refine statistical inference and extrapolation as system complexity increases. The rules of nature inspired computing are the principle simple rules yet after being used for over millions of years have produced remarkably complex optimization techniques. All these techniques for developing software applications along with optimization techniques are discussed in the chapter.}
}
@incollection{OXMAN2001269,
title = {Chapter 12 - The Mind in Design: A Conceptual Framework for Cognition in Design Education},
editor = {Charles M. Eastman and W. Michael McCracken and Wendy C. Newstetter},
booktitle = {Design Knowing and Learning: Cognition in Design Education},
publisher = {Elsevier Science},
address = {Oxford},
pages = {269-295},
year = {2001},
isbn = {978-0-08-043868-9},
doi = {https://doi.org/10.1016/B978-008043868-9/50012-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780080438689500127},
author = {Rivka Oxman},
abstract = {Publisher Summary
This chapter considers the role of cognitive content of design and design thinking as a basis for developing an educational approach. Various design researchers discussed cognitive approaches in design, and the role of knowledge and representations as a cognitive design-thinking tool. Most of these studies are related directly to design and design thinking rather than to the learning task in design learning and design education. Irrespective of the specific design domain, traditional educational models in design education are based upon the replication of professional-task performance. The measure of learning is generally equated with the evaluation of the product of designing rather than on what might be considered a learning increment. The cognitive properties of design learning have never been the subject of design education. As a consequence, there presently exists a lack of educational theories of learning that function as an underpinning of design education. It is now possible to demonstrate that the derivation of design knowledge through constructive processes, in itself, provides a medium for design learning. This chapter suggests that special design learning environments must be developed to enhance and supplement formal education and foster personal development in design learning.}
}
@article{DEAN2020482,
title = {Deep into that darkness peering: A computational analysis of the role of depression in Edgar Allan Poe's life and death},
journal = {Journal of Affective Disorders},
volume = {266},
pages = {482-491},
year = {2020},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2020.01.098},
url = {https://www.sciencedirect.com/science/article/pii/S0165032719322554},
author = {Hannah J. Dean and Ryan L. Boyd},
keywords = {Edgar Allan Poe, LIWC, Depression, Suicide, Digital humanities},
abstract = {Background
To help shed light on the peculiar circumstances surrounding the death of the famed macabre and mystery writer, poet, editor, and literary critic, we explored the potential role of depression in the life and death of Edgar Allan Poe via his written language.
Method
Using computerized language analysis, we analyzed works from Poe's corpora of personal letters (N = 309), poems (N = 49), and short stories (N = 63), and investigated whether a pattern of linguistic cues consistent with depression and suicidal cognition were discernible throughout the writer's life, particularly in his final years. Building on past work, language scores were collapsed into a composite depression metric for each text. Data from each work type was subsequently compiled and graphed into a single plot by year, with scores exceeding the 95th percentile (p < 0.05) considered statistically significant and treated as potential depressive episodes.
Results
Significant, consistent patterns of depression were not found and do not support suicide as a cause of death. However, linguistic evidence was found suggesting the presence of several potential depressive episodes over the course of Poe's life – these episodes were the most pronounced during years of Poe's greatest success, as well as those following the death of his late wife.
Limitations
Given the sampling method, it is not possible to establish direct causality; results should be considered informed but tentative.
Conclusion
This investigation demonstrates the utility of language analysis for capturing disruptive/maladaptive emotional responses to life events.}
}