@article{EKINS2014115,
title = {Progress in computational toxicology},
journal = {Journal of Pharmacological and Toxicological Methods},
volume = {69},
number = {2},
pages = {115-140},
year = {2014},
issn = {1056-8719},
doi = {https://doi.org/10.1016/j.vascn.2013.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1056871913003250},
author = {Sean Ekins},
keywords = {Bayesian, Computational toxicology, Machine learning, Support Vector Machine},
abstract = {Introduction: Computational methods have been widely applied to toxicology across pharmaceutical, consumer product and environmental fields over the past decade. Progress in computational toxicology is now reviewed. Methods: A literature review was performed on computational models for hepatotoxicity (e.g. for drug-induced liver injury (DILI)), cardiotoxicity, renal toxicity and genotoxicity. In addition various publications have been highlighted that use machine learning methods. Several computational toxicology model datasets from past publications were used to compare Bayesian and Support Vector Machine (SVM) learning methods. Results: The increasing amounts of data for defined toxicology endpoints have enabled machine learning models that have been increasingly used for predictions. It is shown that across many different models Bayesian and SVM perform similarly based on cross validation data. Discussion: Considerable progress has been made in computational toxicology in a decade in both model development and availability of larger scale or ‘big data’ models. The future efforts in toxicology data generation will likely provide us with hundreds of thousands of compounds that are readily accessible for machine learning models. These models will cover relevant chemistry space for pharmaceutical, consumer product and environmental applications.}
}
@article{SUO2024109268,
title = {A review of three-way decision: Triadic understanding, organization, and perspectives},
journal = {International Journal of Approximate Reasoning},
volume = {173},
pages = {109268},
year = {2024},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109268},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24001555},
author = {Langwangqing Suo and Han Yang and Qiaoyi Li and Hai-Long Yang and Yiyu Yao},
keywords = {Three-way decision, Triadic thinking, Three-way literature review,  method, Three-way bibliometrics analytics},
abstract = {A theory of three-way decision is about thinking, problem-solving, and computing in threes or through triads. In this paper, we review fifteen years of research on three-way decision by using the philosophy-theory-application triad and the who-what-when triad. First, we discuss the philosophy, theory, and application of three-way decision. At the philosophy level, we delve into the philosophical roots and fundamental nature of three-way decision to reveal the underlying philosophical thinking. At the theory level, we provide an insightful analysis of the theory and methodology of three-way decision. At the application level, we examine the integration of three-way decision with other theories and their applications and effectiveness in real-world scenarios. Second, we focus on bibliometrics analytics by using the who-what-when triad, which attempts to answer a fundamental question of “who did what when”. We propose a 3×3 model by applying the 3×3 method of three-way decision. The first 3 is the author-topic-time triad. The second 3 represents a three-level analysis for each of the first three: (1) categorizing authors into the three levels of prolific authors, frequent authors, and occasional authors, (2) classifying topics into the three levels of the core topics, emerging topics, and to-be-explored topics, and (3) dividing articles into the three levels of initial investigations, further developments, and most recent studies. Finally, we perform a bibliometrics analysis of three-way decision articles by using the 3×3 model of three-way decision. The results not only reveal the current status and trend of three-way decision research but also provide a road map for future research.}
}
@incollection{JUDD2006881,
title = {Chapter 17 Computationally Intensive Analyses in Economics},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {881-893},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02017-4},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020174},
author = {Kenneth L. Judd},
keywords = {computational economics, economic methodology},
abstract = {Computer technology presents economists with new tools, but also raises novel methodological issues. This essay discusses the challenges faced by computational researchers, and proposes some solutions.}
}
@article{SAHA2021113452,
title = {Hierarchical Deep Learning Neural Network (HiDeNN): An artificial intelligence (AI) framework for computational science and engineering},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {373},
pages = {113452},
year = {2021},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2020.113452},
url = {https://www.sciencedirect.com/science/article/pii/S004578252030637X},
author = {Sourav Saha and Zhengtao Gan and Lin Cheng and Jiaying Gao and Orion L. Kafka and Xiaoyu Xie and Hengyang Li and Mahsa Tajdari and H. Alicia Kim and Wing Kam Liu},
keywords = {Deep learning, Machine learning, Reduced order model, Data-driven discovery, Multiscale simulation, Artificial intelligence},
abstract = {In this work, a unified AI-framework named Hierarchical Deep Learning Neural Network (HiDeNN) is proposed to solve challenging computational science and engineering problems with little or no available physics as well as with extreme computational demand. The detailed construction and mathematical elements of HiDeNN are introduced and discussed to show the flexibility of the framework for diverse problems from disparate fields. Three example problems are solved to demonstrate the accuracy, efficiency, and versatility of the framework. The first example is designed to show that HiDeNN is capable of achieving better accuracy than conventional finite element method by learning the optimal nodal positions and capturing the stress concentration with a coarse mesh. The second example applies HiDeNN for multiscale analysis with sub-neural networks at each material point of macroscale. The final example demonstrates how HiDeNN can discover governing dimensionless parameters from experimental data so that a reduced set of input can be used to increase the learning efficiency. We further present a discussion and demonstration of the solution for advanced engineering problems that require state-of-the-art AI approaches and how a general and flexible system, such as HiDeNN-AI framework, can be applied to solve these problems.}
}
@article{MCCLELLAND20221047,
title = {Capturing advanced human cognitive abilities with deep neural networks},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {12},
pages = {1047-1050},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.09.018},
url = {https://www.sciencedirect.com/science/article/pii/S136466132200239X},
author = {James L. McClelland},
keywords = {scientific reasoning, mathematical cognition, neural networks, goal-directed thinking, artificial intelligence},
abstract = {How can artificial neural networks capture the advanced cognitive abilities of pioneering scientists? I suggest they must learn to exploit human-invented tools of thought and human-like ways of using them, and must engage in explicit goal-directed problem solving as exemplified in the activities of scientists and mathematicians and taught in advanced educational settings.}
}
@article{DEMARTINO20131222,
title = {In the Mind of the Market: Theory of Mind Biases Value Computation during Financial Bubbles},
journal = {Neuron},
volume = {79},
number = {6},
pages = {1222-1231},
year = {2013},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2013.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0896627313005680},
author = {Benedetto De Martino and John P. O’Doherty and Debajyoti Ray and Peter Bossaerts and Colin Camerer},
abstract = {Summary
The ability to infer intentions of other agents, called theory of mind (ToM), confers strong advantages for individuals in social situations. Here, we show that ToM can also be maladaptive when people interact with complex modern institutions like financial markets. We tested participants who were investing in an experimental bubble market, a situation in which the price of an asset is much higher than its underlying fundamental value. We describe a mechanism by which social signals computed in the dorsomedial prefrontal cortex affect value computations in ventromedial prefrontal cortex, thereby increasing an individual’s propensity to ‘ride’ financial bubbles and lose money. These regions compute a financial metric that signals variations in order flow intensity, prompting inference about other traders’ intentions. Our results suggest that incorporating inferences about the intentions of others when making value judgments in a complex financial market could lead to the formation of market bubbles.}
}
@article{HENDRIARTO20241225,
title = {The development of mobile application for the deaf to learn better},
journal = {Procedia Computer Science},
volume = {245},
pages = {1225-1237},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.352},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031600},
author = {Helena Angelie Margaretha Hendriarto and Yudhistya Ayu Kusumawati and Rudi Yulio Arindiono},
keywords = {Deaf, Education, Learning features, Mobile application},
abstract = {Education is very important for all individuals, including people with disabilities such as the deaf, to advance the nation and survive. In this case, effective communication of educational material is important to create a conducive learning environment. Most people also believe that deaf people can make a big contribution to society if they receive the right education, and this becomes a challenge for deaf teachers and students. Therefore, this paper aims to find a solution that can become a means of independent education for deaf people. This paper is using design thinking method to achieve the goal. The result of this research is the development of an educational mobile application specifically for the deaf, namely 'V-Voice'. This application provides various learning features, such as; animated videos, education games and texts that are attractively designed. Through 'V-Voice', it is hoped that deaf people can study harder independently and be helped to manage information and develop their soft skills and hard skills.}
}
@article{LAWNICZAK20102227,
title = {Computational intelligence based architecture for cognitive agents},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {2227-2235},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.249},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910002504},
author = {Anna T. Lawniczak and Bruno N. {Di Stefano}},
keywords = {Agent, Agent modeling, Cognitive agent, Computational intelligence},
abstract = {We discuss some limitations of reflexive agents to motivate the need to develop cognitive agents and propose a hierarchical, layered, architecture for cognitive agents. Our examples often involve the discussion of cognitive agents in highway traffic models. A cognitive agent is an agent capable of performing cognitive acts, i.e. a sequence of the following activities: “Perceiving” information in the environment and provided by other agents, “Reasoning” about this information using existing knowledge, “Judging” the obtained information using existing knowledge, “Responding” to other cognitive agents or to the external environment, as it may be required, and “Learning”, i.e. changing (and, hopefully augmenting) the existing knowledge if the newly acquired information allows it. We describe how computational intelligence techniques (e.g., fuzzy logic, neural networks, genetic algorithms, etc) allow mimicking to a certain extent the cognitive acts performed by human beings. The order with which the cognitive actions take place is important and so is the order with which the various computational intelligence techniques are applied. We believe that a hierarchical layered model should be defined for the generic cognitive agents in a style akin to the hierarchical OSI 7 layer model used in data communication. We outline in broad sense such a reference model.}
}
@article{THIRUNAVUKARASU2022106020,
title = {Towards computational solutions for precision medicine based big data healthcare system using deep learning models: A review},
journal = {Computers in Biology and Medicine},
volume = {149},
pages = {106020},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106020},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522007429},
author = {Ramkumar Thirunavukarasu and George Priya Doss C and Gnanasambandan R and Mohanraj Gopikrishnan and Venketesh Palanisamy},
keywords = {Personalized medicine, Precision medicine, Artificial intelligence, Deep learning, Healthcare big data},
abstract = {The emergence of large-scale human genome projects, advances in DNA sequencing technologies, and the massive volume of electronic medical records [EMR] shift the transformation of healthcare research into the next paradigm, namely ‘Precision Medicine.’ This new clinical system model uses patients' genomic profiles and disparate healthcare data sources to a greater extent and provides personalized deliverables. As an advanced analytical technique, deep learning models significantly impact precision medicine because they can process voluminous amounts of diversified data with improved accuracy. Two salient features of deep learning models, namely processing a massive volume of multi-model data at multiple levels of abstraction and the ability to identify inherent features from the input data on their own, attract the implication of deep learning techniques in precision medicine research. The proposed review highlights the importance of deep learning-based analytical models in handling diversified and disparate big data sources of precision medicine. To augment further, state-of-the-art precision medicine research based on the taxonomy of deep learning models has been reviewed along with their research outcomes. The diversified data inputs used in research attempts, their applications, benchmarking data repositories, and usage of various evaluation measures for accuracy estimations are highlighted in this review. This review also brings out some promising analytical avenues of precision medicine research that give directions for future exploration.}
}
@article{REN201310351,
title = {Challenges in the assignment of relative and absolute configurations of complex molecules: computation can resolve conflicts between theory and experiment},
journal = {Tetrahedron},
volume = {69},
number = {48},
pages = {10351-10356},
year = {2013},
issn = {0040-4020},
doi = {https://doi.org/10.1016/j.tet.2013.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S004040201301538X},
author = {Jie Ren and Guo-You Li and Lan Shen and Guo-Lin Zhang and Laurance A. Nafie and Hua-Jie Zhu},
keywords = {Absolute configuration reassignment, DFT, Chiroptical spectroscopy, Transition state, X-ray},
abstract = {The configuration of (−)-brevianamides was assigned as (2S,13S) based on X-ray structure analysis and hydrolysis experiments. However, our theoretical investigation of its chiroptical properties strongly implied that the correct configuration should be (2R,13R). The reasons for the incorrect earlier assignment are analyzed by calculations of conversion energy barriers among different intermediates, starting materials and final products. This study demonstrates that conflicting theoretical and, experimental results suggest that it is premature to assign the configuration of a natural product.}
}
@article{PSYCHARIS2011547,
title = {The computational experiment and its effects on approach to learning and beliefs on physics},
journal = {Computers & Education},
volume = {56},
number = {3},
pages = {547-555},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2010.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0360131510002642},
author = {Sarantos Psycharis},
keywords = {ICT, Programming, Interactive learning environments, Physics learning, Computational experiment},
abstract = {Contemporary instructional approaches expect students to be active producers of knowledge. This leads to the need for creation of instructional tools and tasks that can offer students opportunities for active learning. This study examines the effect of a computational experiment as an instructional tool-for Grade 12 students, using a computer simulation environment created in Java for the domain of “linear oscillations without damping”. In this study we use the computational experiment as an integration of the computational science with the discovery learning method. The computational experiment supports both types of research, the exploratory as well as the inventive research, helping the learners to develop not only exploratory but also expressive models. The aim of the paper is threefold. At first we want to examine the influence of the computational experiment on students’ learning performance. The other two aims are related to the investigation of the experiment’s influence on students’ approach to learning and their beliefs on physics. Our results indicate that there is a strong shift on students’ conceptual understanding and to the consideration of the coherence of physics, as well as to the realization that physics is strongly connected to mathematics. Finally students realized that mathematics, physics and information theory are strongly connected cognitive disciplines.}
}
@incollection{MOORE2013200,
title = {Gene Interaction},
editor = {Stanley Maloy and Kelly Hughes},
booktitle = {Brenner's Encyclopedia of Genetics (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {200-201},
year = {2013},
isbn = {978-0-08-096156-9},
doi = {https://doi.org/10.1016/B978-0-12-374984-0.00592-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123749840005921},
author = {J.H. Moore},
keywords = {Epistasis, Synergy, Systems genetics},
abstract = {Gene interaction is a broad term used to describe the joint role of multiple genes in determining phenotypic variability. It is often studied from the molecular point of view as biomolecular interactions or from a more genetic point of view as phenotypic effects due to the role of DNA sequence variations and their influence on biological processes. We are now moving from an era of thinking about interactions among several genes to interacting networks or systems of many genes in a genome-wide scale. The study of gene interactions using systems genetics approaches is being made possible by advances in DNA sequencing technology and more powerful experimental, statistical, and computational methods.}
}
@article{XU2011331,
title = {New Recursive Construction of Magic Squares Using Kronecker Compositional Operations and Its Application in Engineering Computation},
journal = {Systems Engineering Procedia},
volume = {2},
pages = {331-337},
year = {2011},
note = {Complexity System and Engineering Management},
issn = {2211-3819},
doi = {https://doi.org/10.1016/j.sepro.2011.10.046},
url = {https://www.sciencedirect.com/science/article/pii/S2211381911001354},
author = {Dandan Xu and Zisen Mao and Bei Chen and Ping Huang},
keywords = {Magic squares, symmetrical, pandiagonal, construction, engineering computation},
abstract = {Owing to the depth research on the remarkable properties of magic squares, a new recursive method for constructing high order magic squares will be firstly presented, based on the matrix operations, we refer to as the Kronecker compositional operations. Furthermore, popularizing this method,, we successfully demonstrate that large size magic squares of odd order with symmetrical and pandiagonal features can be generated by lower order initiators,which leads to the impressive application in engineering computation. Finally, we enumerate two small symmetrical and pandiagonal magic squares.}
}
@article{MOHAMMADIZIABARI2018376,
title = {Computational Analysis of Gender Differences in Coping with Extreme Stressful Emotions},
journal = {Procedia Computer Science},
volume = {145},
pages = {376-385},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.088},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323767},
author = {S. Sahand {Mohammadi Ziabari} and Jan Treur},
keywords = {Adaptive Network, Rumination, Extreme Emotion, Gender},
abstract = {In this paper a computational analysis is presented of differences between men and women in coping with extreme emotions. This analysis is based on an adaptive temporal-causal network model. It takes into account the suppression of connections between preparation states and sensory representations of action effects due to an extreme stressful emotion. It is shown how this model can be used to represent the difference between males and females facing an extreme emotion, thereby performing their own methods in coping with the extreme emotion, for males fight or flight and for females tend-and-befriend.}
}
@article{DAYAN2011661,
title = {Networks, circuits and computation},
journal = {Current Opinion in Neurobiology},
volume = {21},
number = {5},
pages = {661-663},
year = {2011},
note = {Networks, circuits and computation},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2011.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438811001267},
author = {Peter Dayan and Marla Feller and Dan Feldman}
}
@article{WESTERA201732,
title = {How people learn while playing serious games: A computational modelling approach},
journal = {Journal of Computational Science},
volume = {18},
pages = {32-45},
year = {2017},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2016.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1877750316304483},
author = {Wim Westera},
keywords = {Serious gaming, Learning, Simulation, Modelling, Flow theory, Methodology},
abstract = {This paper proposes a computational modelling approach for investigating the interplay of learning and playing in serious games. A formal model is introduced that allows for studying the details of playing a serious game under diverse conditions. The dynamics of player action and motivation is based on cognitive flow theory, which is expressed in quantitative terms for this purpose. Seven extensive simulation studies involving over 100,000 iterations have demonstrated the stability of the model and its potential as a research instrument for serious gaming. The model allows researchers to deeply investigate quantitative dependences between relevant game variables, gain deeper understanding of how people learn from games, and develop approaches to improving serious game design.}
}
@incollection{CARETTE202215,
title = {Chapter Two - Embracing the laws of physics: Three reversible models of computation},
editor = {Ali R. Hurson},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {126},
pages = {15-63},
year = {2022},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2021.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0065245821000838},
author = {Jacques Carette and Roshan P. James and Amr Sabry},
keywords = {Reversible programming, Reversible Boolean circuits, Monoidal categories, Type isomorphisms, Commutative semirings, Homotopy-type theory, Quantum circuits, Permutations},
abstract = {Our main models of computation (the Turing Machine and the RAM) and most modern computer architectures make fundamental assumptions about which primitive operations are realizable on a physical computing device. The consensus is that these primitive operations include logical operations like conjunction, disjunction and negation, as well as reading and writing to a large collection of memory locations. This perspective conforms to a macro-level view of physics and indeed these operations are realizable using macro-level devices involving thousands of electrons. This point of view is however incompatible with computation realized using quantum devices or analyzed using elementary thermodynamics as both these fundamental physical theories imply that information is a conserved quantity of physical processes and hence of primitive computational operations. Our aim is to redevelop foundational computational models in a way that embraces the principle of conservation of information. We first define what information is and what its conservation means in a computational setting. We emphasize the idea that computations must be reversible transformations on data. One can think of data as modeled using topological spaces and programs as modeled by reversible deformations of these spaces. We then illustrate this idea using three notions of data and their associated reversible computational models. The first instance only assumes unstructured finite data, i.e., discrete topological spaces. The corresponding notion of reversible computation is that of permutations. We show how this simple model subsumes conventional computations on finite sets. We then consider a modern structured notion of data based on the Curry–Howard correspondence between logic and type theory. We develop the corresponding notion of reversible deformations using a sound and complete programming language for witnessing type isomorphisms and proof terms for commutative semirings. We then “move up a level” to examine spaces that treat programs as data, which is a crucial notion for any universal model of computation. To derive the corresponding notion of reversible programs between programs, i.e., reversible program equivalences, we look at the “higher dimensional” analog to commutative semirings: symmetric rig groupoids. The coherence laws for these groupoids turn out to be exactly the sound and complete reversible program equivalences we seek. We conclude with some possible generalizations inspired by homotopy type theory and survey several open directions for further research.}
}
@article{YANG2012852,
title = {Computational Optimization, Modelling and Simulation: Smart Algorithms and Better Models},
journal = {Procedia Computer Science},
volume = {9},
pages = {852-856},
year = {2012},
note = {Proceedings of the International Conference on Computational Science, ICCS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.04.091},
url = {https://www.sciencedirect.com/science/article/pii/S1877050912002128},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, derivative-free method, optimization algorithm, modelling, nonlinear optimization, surragate-based optimization, simulation},
abstract = {Computational optimization is becoming a standard tool that is widely used in engineering design and industrial applications. Products and services are often concerned with the maximization of profits and reduction of cost, but also aim at being more energy-efficient, environment-friendly and safety-ensured; at the same time they are limited by resources, time and money. Despite of increasing computer power and availability of better simulation packages, there are a number of challenges remaining when applying numerical optimization methods for real-world engineering problems. Also, new challenges emerge when attempting to attack problems whose solution by means of simulation-based optimization was not even possible in the past. This third workshop on Computational Optimization, Modelling and Simulation (COMS 2012) at ICCS 2012 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry.}
}
@article{CARUSI20171,
title = {Validation and models in computational biomedical sciences: Philosophy, science, engineering},
journal = {Progress in Biophysics and Molecular Biology},
volume = {129},
pages = {1-2},
year = {2017},
note = {Validation of Computer Modelling},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S007961071730192X},
author = {Annamaria Carusi and Blanca Rodriguez and Kevin Burrage}
}
@article{OZKAYA2006381,
title = {Requirement-driven design: assistance for information traceability in design computing},
journal = {Design Studies},
volume = {27},
number = {3},
pages = {381-398},
year = {2006},
note = {Digital Design},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2005.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X0500089X},
author = {Ipek Ozkaya and Ömer Akin},
keywords = {requirement-driven design, information processing, design knowledge, design process, design methods},
abstract = {We describe requirement-driven computational design thinking as an approach to leverage the distinctive characteristics of the digital design process. We primarily focus on information continuity and traceability in the digital medium. Requirement-driven design is an information-based approach facilitating consistent design rationale tracking and evaluation, verification, and validation of design. We present the characteristics of requirement-driven design, which leverage the pervasive nature of digital design thinking. We demonstrate a requirement–design coupling approach, modeling a continuous and interactive design process for integrating problem formulation and form exploration.}
}
@article{ZHU2006287,
title = {Children can solve Bayesian problems: the role of representation in mental computation},
journal = {Cognition},
volume = {98},
number = {3},
pages = {287-308},
year = {2006},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2004.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0010027705000132},
author = {Liqi Zhu and Gerd Gigerenzer},
keywords = {Bayesian problems, Computation, Binary hypothesis},
abstract = {Can children reason the Bayesian way? We argue that the answer to this question depends on how numbers are represented, because a representation can do part of the computation. We test, for the first time, whether Bayesian reasoning can be elicited in children by means of natural frequencies. We show that when information was presented to fourth, fifth, and sixth graders in terms of probabilities, their ability to estimate the Bayesian posterior probability was zero. Yet when the same information was presented in natural frequencies, Bayesian reasoning showed a steady increase from fourth to sixth grade, reaching an average level of 19, 39, and 53%, respectively, in two studies. Sixth graders' performance with natural frequencies matched the performance of adults with probabilities. But this general increase was accompanied by striking individual differences. More than half of the sixth graders solved most or all problems, whereas one third could not solve a single one. An analysis of the children's responses provides evidence for the use of three non-Bayesian strategies. These follow an overlapping wave model of development and continue to be observed in the minds of adults. More so than adults' probabilistic reasoning, children's reasoning depends on a proper representation of information.}
}
@incollection{DAVIS2017xv,
title = {Survival of the Fittest Computational Chemists, Computers, and Reference Works (Over a 30-Year Period)},
editor = {Samuel Chackalamannil and David Rotella and Simon E. Ward},
booktitle = {Comprehensive Medicinal Chemistry III},
publisher = {Elsevier},
address = {Oxford},
pages = {xv-xxii},
year = {2017},
isbn = {978-0-12-803201-5},
doi = {https://doi.org/10.1016/B978-0-12-409547-2.12337-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124095472123376},
author = {A.M. Davis and C.M. Edge}
}
@article{COOPER201442,
title = {Implementations are not specifications: Specification, replication and experimentation in computational cognitive modeling},
journal = {Cognitive Systems Research},
volume = {27},
pages = {42-49},
year = {2014},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2013.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041713000314},
author = {Richard P. Cooper and Olivia Guest},
keywords = {Theory specification, Implementation detail, Replication, Sensitivity analysis, Computational experimentation},
abstract = {Contemporary methods of computational cognitive modeling have recently been criticized by Addyman and French (2012) on the grounds that they have not kept up with developments in computer technology and human–computer interaction. They present a manifesto for change according to which, it is argued, modelers should devote more effort to making their models accessible, both to non-modelers (with an appropriate easy-to-use user interface) and modelers alike. We agree that models, like data, should be freely available according to the normal standards of science, but caution against confusing implementations with specifications. Models may embody theories, but they generally also include implementation assumptions. Cognitive modeling methodology needs to be sensitive to this. We argue that specification, replication and experimentation are methodological approaches that can address this issue.}
}
@article{DHAYAKA20241238,
title = {BeKarsa: A strategic approach to alleviate unemployment challenges in Malang City},
journal = {Procedia Computer Science},
volume = {245},
pages = {1238-1248},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.353},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031612},
author = {Pricillia Yohana Dhayaka and Yudhistya Ayu Kusumawati and Rudi Yulio Arindiono},
keywords = {Unemployment, Malang city, Work},
abstract = {Creating decent work and economic growth is not an easy thing. Decent work and economic growth aim to create a decent work environment and financial stability. Malang City, known as the City of Education, has a relatively high unemployment rate, although it has decreased since it spiked during the COVID-19 pandemic. This figure is also still higher than the unemployment rate in East Java. One of the problems contributing to this unemployment rate is the ineffective dissemination of skills training and job vacancies, so this needs to be improved. To overcome this problem and find the most effective solution to reduce the unemployment rate in Malang City, this research is being conducted. The purpose of this research is to determine the most effective solution to the problem using the design thinking method to help decrease the high unemployment rates. To assist the audience in obtaining information related to certified training and job vacancies, the researcher aims to design a platform in the form of a website so that the audience can access information effectively. The semantical differential method is also used in this research to assess the audience's impression of the solution and determine whether the solution is acceptable to the target audience and can help with the problem of information dissemination. This solution is expected to help people obtain information related to certified training and job openings. In addition, this research will improve certified training information services in Malang City to be more effective and easily accessible to the public.}
}
@incollection{RAMOS2018720,
title = {8.36 - Bioinformatics and Computational Biology in Toxicology: Gateways for Precision Medicine☆},
editor = {Charlene A. McQueen},
booktitle = {Comprehensive Toxicology (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {720-728},
year = {2018},
isbn = {978-0-08-100601-6},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.99176-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383991761},
author = {K.S. Ramos and M. Martin and I.N. Ramos and G.A. Rempala},
keywords = {Bioinformatics, Computational biology, Precision medicine, Systems biology},
abstract = {The National Center for Biotechnology Information (NCBI) defines bioinformatics as “… the field of science in which biology, computer science, and information technology merge to form a single discipline”. As such, the field of bioinformatics includes computer scientists who develop algorithms for sequence analysis, biostatisticians who develop and implement methods of analyses for large clinical datasets, mathematicians or physical scientists who develop models to describe the interactions of genes, proteins, and small molecules within cells, and all those engaged in the development of software and databases for manipulation, storage, and retrieval of information in support of their research. This chapter focuses on how computational biology has been enabled by molecular informatics to provide the basis for in silico studies that facilitate the collection, organization, and analysis of datasets that explain biological phenomena and that help to drive biological discovery with applications in precision medicine.}
}
@incollection{SEDERBERG2010145,
title = {Learning and Memory: Computational Models},
editor = {George F. Koob and Michel Le Moal and Richard F. Thompson},
booktitle = {Encyclopedia of Behavioral Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {145-153},
year = {2010},
isbn = {978-0-08-045396-5},
doi = {https://doi.org/10.1016/B978-0-08-045396-5.00140-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780080453965001408},
author = {P.B. Sederberg and K.A. Norman},
keywords = {Computational models, Context, Cortex, Episodic memory, Hippocampus, Learning, Memory, Neural networks, Recognition, Recall, Semantic memory, Synaptic plasticity},
abstract = {The goal of learning and memory research is to understand how we store and retrieve information based on our experiences. Computational models provide formal implementations of memory theories that attempt to predict both behavior and neural data. This article describes computational models of declarative memory, including episodic memory (memory for specific events) and semantic memory (memory for meanings), with a particular focus on the role of context in supporting both types of memory.}
}
@article{JUNG201787,
title = {Computational Collective Intelligence with Big Data: Challenges and Opportunities},
journal = {Future Generation Computer Systems},
volume = {66},
pages = {87-88},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16302837},
author = {Jason J. Jung},
keywords = {Computational collective intelligence, Computer-supported collaboration, Big data},
abstract = {Collective intelligence has been an important research topic in many AI communities. With The big data phenomenon, we have been facing on many research problems on how to integrate the big data with collective intelligence. This special issue has selected 9 high quality papers covering various research issues.}
}
@article{VALENTINOV2015491,
title = {Nonprofit organizations, institutional economics, and systems thinking},
journal = {Economic Systems},
volume = {39},
number = {3},
pages = {491-501},
year = {2015},
note = {Symposium: Financial System and Development in China},
issn = {0939-3625},
doi = {https://doi.org/10.1016/j.ecosys.2014.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0939362515000278},
author = {Vladislav Valentinov and Stefan Hielscher and Ingo Pies},
keywords = {Nonprofit organizations, John Kenneth Galbraith, Countervailing power, Niklas Luhmann},
abstract = {The present paper applies the logic of John Kenneth Gailbraith's institutional economics analysis of corporate power to inquiring into the societal role of the nonprofit sector. Building on Galbraith's insight that corporations cause subtle but pervasive societal imbalances, the paper locates the role of nonprofit organizations in compensating for these imbalances, thus showing corporations and nonprofit organizations to be mutually complementary rather than antagonistic actors. This argument is supported by Niklas Luhmann's vision of the precarious relationship between the complexity and sustainability of social systems as well as by Kenneth Boulding's analysis of the farmer and labor movement. Luhmann's and Boulding's perspectives show profit-seeking corporations to be social systems developing high technological complexity at the cost of sacrificing their societal sustainability, while the improvement of the latter constitutes the rationale of many nonprofit organizations. The same systems-theoretic logic suggests, however, that nonprofit organizations may tend to underestimate the technological complexity of implementing their mission-related activities, thereby undermining their own effectiveness.}
}
@article{DESTEXHE2011717,
title = {Intracellular and computational evidence for a dominant role of internal network activity in cortical computations},
journal = {Current Opinion in Neurobiology},
volume = {21},
number = {5},
pages = {717-725},
year = {2011},
note = {Networks, circuits and computation},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2011.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0959438811001012},
author = {Alain Destexhe},
abstract = {The mammalian cerebral cortex is characterized by intense spontaneous activity, depending on brain region, age, and behavioral state. Classically, the cortex is considered as being driven by the senses, a paradigm which corresponds well to experiments in quiescent or deeply anesthetized states. In awake animals, however, the spontaneous activity cannot be considered as ‘background noise’, but is of comparable—or even higher—amplitude than evoked sensory responses. Recent evidence suggests that this internal activity is not only dominant, but also it shares many properties with the responses to natural sensory inputs, suggesting that the spontaneous activity is not independent of the sensory input. Such evidence is reviewed here, with an emphasis on intracellular and computational aspects. Statistical measures, such as the spike-triggered average of synaptic conductances, show that the impact of internal network state on spiking activity is major in awake animals. Thus, cortical activity cannot be considered as being driven by the senses, but sensory inputs rather seem to modulate and modify the internal dynamics of cerebral cortex. This view offers an attractive interpretation not only of dreaming activity (absence of sensory input), but also of several mental disorders.}
}
@incollection{ALEKSANDER200777,
title = {Computational studies of consciousness},
editor = {Rahul Banerjee and Bikas K. Chakrabarti},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {168},
pages = {77-93},
year = {2007},
booktitle = {Models of Brain and Mind},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(07)68007-8},
url = {https://www.sciencedirect.com/science/article/pii/S0079612307680078},
author = {Igor Aleksander and Helen Morton},
keywords = {brain modelling, consciousness, neural architectures},
abstract = {In this chapter we present a computational architecture intended to add clarity to the concept of consciousness. We briefly review some of the motivations of work done in this area in various institutes around the world and looks closely at our own work which specifically includes phenomenology, the sense of a self in a perceptual world. This breaks consciousness into five axioms: presence, imagination, attention, volition and emotions. It develops plausible mechanisms of each and how they interact to give a single sensation. An abstract architecture, the kernel architecture, is introduced as a starting point for building computational models. It is shown that through this architecture it is possible to discuss puzzling aspects of consciousness, for example are animals conscious? What happens when we dream? What goes on when we experience an illusion? This paper is intended to elucidate and update some concepts introduced in Aleksander (2005).}
}
@article{SU2022100049,
title = {Artificial intelligence in early childhood education: A scoping review},
journal = {Computers and Education: Artificial Intelligence},
volume = {3},
pages = {100049},
year = {2022},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2022.100049},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X22000042},
author = {Jiahong Su and Weipeng Yang},
keywords = {Artificial intelligence, Early childhood education, Teaching and learning, Machine learning, Computer science},
abstract = {Artificial intelligence (AI) tools are increasingly being used in the field of early childhood education (ECE) to enhance learning and development among young children. Previous proof-of-concept studies have demonstrated that AI can effectively improve teaching and learning in ECE; however, there is a scarcity of knowledge about how these studies are conducted and how AI is used across these studies. We conducted this scoping review to evaluate, synthesize and display the latest literature on AI in ECE. This review analyzed 17 eligible studies conducted in different countries from 1995 to 2021. Although few studies on this critical issue have been found, the existing references provide up-to-date insights into different aspects (knowledge, tools, activities, and impacts) of AI for children. Most studies have shown that AI has significantly improved children's concepts regarding AI, machine learning, computer science, and robotics and other skills such as creativity, emotion control, collaborative inquiry, literacy skills, and computational thinking. Future directions are also discussed for researching AI in ECE.}
}
@article{MARSIK2021108,
title = {Introducing ⦇ λ ⦈, a λ-calculus for effectful computation},
journal = {Theoretical Computer Science},
volume = {869},
pages = {108-155},
year = {2021},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2021.02.038},
url = {https://www.sciencedirect.com/science/article/pii/S0304397521001225},
author = {Jirka Maršík and Maxime Amblard and Philippe {de Groote}},
keywords = {Side effects, Monads, -calculus, Handlers, CRS, IDTS},
abstract = {We present ⦇λ⦈, a calculus with special constructions for dealing with effects and handlers. This is an extension of the simply-typed λ-calculus (STLC). We enrich STLC with a type for representing effectful computations alongside with operations to create and process values of this type. The calculus is motivated by natural language modelling, and especially semantic representation. Traditionally, the meaning of a sentence is calculated using λ-terms, but some semantic phenomena need more flexibility. In this article we introduce the calculus and show that the calculus respects the laws of algebraic structures and it enjoys strong normalisation. To do so, confluence is proven using the Combinatory Reduction Systems (CRSs) of Klop and termination using the Inductive Data Type Systems (IDTSs) of Blanqui.}
}
@article{WHALLEY2001743,
title = {Reliability and uncertainty in flow measurement techniques - some current thinking},
journal = {Physics and Chemistry of the Earth, Part C: Solar, Terrestrial & Planetary Science},
volume = {26},
number = {10},
pages = {743-749},
year = {2001},
issn = {1464-1917},
doi = {https://doi.org/10.1016/S1464-1917(01)95019-6},
url = {https://www.sciencedirect.com/science/article/pii/S1464191701950196},
author = {N. Whalley and R.S. Iredale and A.F. Clare},
keywords = {flow measurement, current meter gauging, flow measurement structures, calibration, stage-discharge relationship},
abstract = {Improvements in the quality and availability of flow measurement equipment are undoubtedly capable of enhancing the reliability and accuracy of the hydrometric data that we require. However much of the UK's hydrometric data is acquired by the tried and trusted methods that have remained the mainstay of flow monitoring for many years. Should the results provided by these established techniques always be so readily accepted given the range of assumptions on which they are based? Current meter gauging is the principle technique used for the establishment of stage discharge relationships in the UK. Either directly for the establishment of stage-discharge relationships in open channels, indirectly for calibration of flow measurement equipment (e.g. ultrasonic Doppler velocity meters) or as a means of verification of existing flow measurement structures. Recent projects involving current meter gauging techniques have provoked much thought as to the validity of established techniques and in particular the assumptions on which they are based. The chosen case studies highlight a number of projects where there have been questions regarding the reliability and uncertainty of the flow measurement techniques employed. The alternative approaches required to deal with such problems are also discussed.}
}
@article{ALISHA20241202,
title = {Interactive role-playing game for elementary students to introducing Javan Langur},
journal = {Procedia Computer Science},
volume = {245},
pages = {1202-1212},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.350},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031582},
author = {Nurulizza Eshal Alisha and Yudhistya Ayu Kusumawati},
keywords = {Endangered animals, Interactive Game, Javan Langur, Learning Media},
abstract = {Indonesia is a country with a lot of biodiversity, both in the form of animals and plants, unfortunately, some of the biodiversity is classified as almost extinct, or even extinct, and the Javan Langur is included in the group of endangered animals because of its declining population, recorded at the Javan Langur Center there are only a few of Javan Langurs that have been successfully repatriated. Javan Langurs are also not widely known to people about their existence and extinction conditions, so there must be media to provide information to the wider community, especially to elementary students to form knowledge and prevention. With the rapid development of technology in the current era, there are various learning media that can be used, one of which is interactive games. This work aims to help students recognize endangered animals, including the Javan Langur, and help teaching institutions provide effective learning media for students. This research use design thinking as the research method. Questionnaires and interviews with resource persons who are elementary school students in grades 5 and 6, teachers, and parents. The result of this research is an interactive learning media in the form of a game with storytelling feature. This storytelling feature also include lesson contents and some challenge games with a character that will guide the storyline, much like a role-playing game or RPG.}
}
@article{BILORIA2012259,
title = {Interactive morphologies: An investigation into integrated nodal networks and embedded computation processes for developing real-time responsive spatial systems},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {3},
pages = {259-271},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000465},
author = {Nimish Biloria},
keywords = {Real-time interaction, Sensing and actuation, Performance, Adaptation, Emergence},
abstract = {The design-research illustrated in this research article focus on the emerging field of interactive architecture focusing on developing real-time information exchanging architectural bodies. These interactive bodies demonstrate a fusion between the material, the electronic and the digital domains. This fusion is explicitly attained through a synergistic merger between the fields of ambient sensing, control systems, ubiquitous computing, architectural design, pneumatic systems and computation. The resultant spatial bodies are thus visualised as complex adaptive systems, continually engaged in activities of data-exchange resulting in physical and ambient adaptations of their constituting components in response to contextual variations. Interdependent nodal networks, where every node/junction of a spatial prototype becomes a potential information hub by means of its ability to collect, process and communicate contextual data apart from working as an actuated detail owing to its ability to kinetically re-position itself in three-dimensional space is thus a critical outcome of this inter-disciplinary way of working. A strategy apt for binding material logistics with the digital to materialize dynamic spatial behaviours owing to real time data exchange between the prototypes and their context is thus embarked upon via three research and design projects, namely: Electronic Media Augmented Spatial Skins, The InteractiveWall and the Muscle Re-configured.}
}
@article{KLIEMANN20181,
title = {The social neuroscience of mentalizing: challenges and recommendations},
journal = {Current Opinion in Psychology},
volume = {24},
pages = {1-6},
year = {2018},
note = {Social Neuroscience},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X17302786},
author = {Dorit Kliemann and Ralph Adolphs},
abstract = {Our ability to understand and think about the mental states of other people is referred to as ‘mentalizing’ or ‘theory of mind’. It features prominently in all social behavior, is essential for maintaining relationships, and shows pronounced individual differences. Here we review new approaches to study the underlying psychological mechanisms and discuss how they could best be investigated using modern tools from social neuroscience. We list key desiderata for the field, such as validity, specificity, and reproducibility, and link them to specific recommendations for the future. We also discuss new computational modeling approaches, and the application to psychopathology.}
}
@article{LADLEY20152412,
title = {The impact of individual versus group rewards on work group performance and cooperation: A computational social science approach},
journal = {Journal of Business Research},
volume = {68},
number = {11},
pages = {2412-2425},
year = {2015},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2015.02.020},
url = {https://www.sciencedirect.com/science/article/pii/S0148296315001022},
author = {Daniel Ladley and Ian Wilkinson and Louise Young},
keywords = {Cooperation, Work groups, Incentive, Iterated, Group versus individual reward systems, Complex systems, Agent based models, Computational social science},
abstract = {Purpose
To examine the effect of individual versus group evaluation and reward systems on work group behavior and performance under different task conditions.
Methodology
Uses computational social methods using Agent Based Models to simulate work group interactions as different forms of iterated games.
Findings
Group based systems outperform individual based and mixed systems, producing more cooperative behavior, the best performing groups and individuals in most types of interaction games. A new role emerges, the self-sacrificer, who plays a critical role in enabling other group members and the group, to perform better at their own expense.
Research Implications
Suggest opportunities for model development and guidelines for designing real world experiments.
Practical Implications
Helps firms engineer better performing work groups as well as the design of other business systems.
Social Implications
Identifies mechanisms by which cooperation can be developed in social systems.
Originality/Value
Demonstrates the role and value of computational social science methods and agent based models to business research.}
}
@article{YANG2018242,
title = {Multi-disciplinary and multi-objective optimization problem re-formulation in computational design exploration: A case of conceptual sports building design},
journal = {Automation in Construction},
volume = {92},
pages = {242-269},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.03.023},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517309317},
author = {Ding Yang and Shibo Ren and Michela Turrin and Sevil Sariyildiz and Yimin Sun},
keywords = {Multi-disciplinary optimization, Multi-objective optimization, Computational design exploration, Knowledge extraction, Statistical analysis techniques, Optimization problem re-formulation, Sports buildings, Architectural performance, Climate performance, Structural performance},
abstract = {The benefits of applying multi-objective optimization (MOO) in building design have been increasingly recognized in recent decades. The existing or traditional computational design optimization (CDO) approaches mostly focus on optimization problem solving (OPS), as they often conduct optimizations directly by assuming the optimization problems in question are good enough. In contrast, the computational design exploration (CDE) approaches defined in this research mainly focus on optimization problem formulation (OPF), which are considered more essential and aim to achieve or ensure appropriate optimization problems before conducting optimizations. However, the application of the CDE is very limited especially in conceptual architectural design. The necessity of re-formulating original optimization problems and its potential impacts on optimization results are often overlooked or not emphasized enough. This paper proposes a new CDE approach that highlights the knowledge-supported re-formulation of a changeable initial optimization problem. It improves upon the traditional CDO approach by introducing a changeable initial OPF and inserting a CDE module. The changeable initial OPF allows expanding the dimensionality of an objective space and design space being investigated, and the CDE module can re-formulate the changeable optimization problem using the information and knowledge extracted from statistical analyses. To facilitate designers in achieving the proposed approach, an improved computational platform is used which combines parametric modeling software (including simulation plug-ins) and design optimization software. Assisted by the platform, the proposed approach is applied to the conceptual design of an indoor sports building that considers multi-disciplinary performance criteria (including architecture-, climate- and structure-related criteria) and a wide range of geometric variations. Through the case study, this paper demonstrates the use of the proposed approach, verifies its benefits over the traditional method, and unveils the factors that may affect the behaviour of the proposed approach. Besides, it also shows the suitability of the computational platform used.}
}
@article{CONSTABLE201760,
title = {The practice of chemistry still needs to change},
journal = {Current Opinion in Green and Sustainable Chemistry},
volume = {7},
pages = {60-62},
year = {2017},
note = {New Synthetic Methods 2017},
issn = {2452-2236},
doi = {https://doi.org/10.1016/j.cogsc.2017.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2452223617300755},
author = {David J.C. Constable},
abstract = {There is now over a 20-year history of green and sustainable chemistry efforts in the US, but for a majority of chemicals that have been synthesized, chemists and chemical engineers lack key information about what it takes to commercialize them, their toxicity to humans or the environment, their degradability (biological or otherwise), their ability to be recycled or reused, or their ability to be source renewably. While the depth, breadth, and variety of innovations in chemistry gives one hope that chemists and chemical engineers will make many significant advances in the next 20 years, there is still a need to incorporate systems and life cycle thinking into chemistry. This is especially true as one considers limitations in the supply of key elements chemists rely on very heavily. Recent advances in computational chemistry and machine learning show great promise for moving chemistry toward a more sustainable practice of chemistry.}
}
@article{CROLLEN2019549,
title = {Recruitment of the occipital cortex by arithmetic processing follows computational bias in the congenitally blind},
journal = {NeuroImage},
volume = {186},
pages = {549-556},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.11.034},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918321153},
author = {Virginie Crollen and Latifa Lazzouni and Mohamed Rezk and Antoine Bellemare and Franco Lepore and Marie-Pascale Noël and Xavier Seron and Olivier Collignon},
keywords = {Blindness, Mental arithmetic, Multiplication, Neural correlates, Subtraction},
abstract = {Arithmetic reasoning activates the occipital cortex of congenitally blind people (CB). This activation of visual areas may highlight the functional flexibility of occipital regions deprived of their dominant inputs or relate to the intrinsic computational role of specific occipital regions. We contrasted these competing hypotheses by characterizing the brain activity of CB and sighted participants while performing subtraction, multiplication and a control letter task. In both groups, subtraction selectively activated a bilateral dorsal network commonly activated during spatial processing. Multiplication triggered activity in temporal regions thought to participate in memory retrieval. No between-group difference was observed for the multiplication task whereas subtraction induced enhanced activity in the right dorsal occipital cortex of the blind individuals only. As this area overlaps with regions showing selective tuning to auditory spatial processing and exhibits increased functional connectivity with a dorsal “spatial” network, our results suggest that the recruitment of occipital regions during high-level cognition in the blind actually relates to the intrinsic computational role of the activated regions.}
}
@article{MOGHADDAM2020112879,
title = {A neuro-inspired computational model for adaptive fault diagnosis},
journal = {Expert Systems with Applications},
volume = {140},
pages = {112879},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.112879},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419305895},
author = {Mohsen Moghaddam and Qiliang Chen and Abhijit V. Deshmukh},
keywords = {Machine consciousness, Deep learning, Convolutional neural networks, Transfer learning},
abstract = {Fault diagnosis is a key process to ensure reliable and cost-effective performance of time-critical engineered systems. This article develops a data-driven computational model for adaptive fault diagnosis by drawing an analogy with the neurobiological process of conscious attention—a dynamic process that brings only the most novel 0.01% of the signals we receive with our five senses to our conscious experience. A model of conscious attention based on the theory of dynamic core hypothesis is first outlined, followed by a computational model that mimics key stages of the conscious attention process. Convolutional neural networks serve as a basis for modeling perceptual categorization and concept formation through automatic feature extraction, due to their analogy with the processes of neural group selection and reentry in the brain. Further, the process of incremental learning and its impact on signal novelty are modeled via transfer learning. The model is tested on the NASA C-MAPSS turbofan engine model, which indicated 95–99% fault diagnosis accuracy. This study aims at familiarizing the engineering community with the neurobiological process of conscious attention and its applications for adaptive process monitoring and improvement in engineered systems.}
}
@article{VARTIAINEN2020100182,
title = {Learning machine learning with very young children: Who is teaching whom?},
journal = {International Journal of Child-Computer Interaction},
volume = {25},
pages = {100182},
year = {2020},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2020.100182},
url = {https://www.sciencedirect.com/science/article/pii/S2212868920300155},
author = {Henriikka Vartiainen and Matti Tedre and Teemu Valtonen},
keywords = {Machine learning, Computational thinking, K-12, Participatory learning, Early childhood, Participatory research, Artificial intelligence},
abstract = {While artificial intelligence and machine learning is becoming a commonplace feature of people’s everyday lives, so far few theoretical or empirical studies have focused on investigating it in K-12​ education. Drawing on the sociocultural theory of learning and participation, this case study explored how six very young children taught and explored Google’s Teachable Machine in nonschool settings. Through fine-grained analysis of video recordings and interviews with the children, the article illustrates the content and the process of teaching where 3–9 year old children were producing machine learning data sets and models as well as observing, exploring, and explaining their own interaction with machine learning systems. The results illustrate the quick-paced and embodied nature of the child-computer interaction that also supported children to reason about the relationship between their own bodily expressions and the output of an interactive ML-based tool. The article concludes with discussions on the emergent process of teaching and learning as well as on ways of promoting children’s participation and sense of agency in the age of machine learning.}
}
@article{NIGHTINGALE2016558,
title = {Impact responses of the cervical spine: A computational study of the effects of muscle activity, torso constraint, and pre-flexion},
journal = {Journal of Biomechanics},
volume = {49},
number = {4},
pages = {558-564},
year = {2016},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2016.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0021929016000154},
author = {Roger W. Nightingale and Jake Sganga and Hattie Cutcliffe and Cameron R. ‘Dale’ Bass},
keywords = {Biomechanics, Cervical spine, Bilateral facet Dislocation, Buckling, Muscle, Initial conditions, Compression, Pre-flexion, Preflexion, Alignment},
abstract = {Cervical spine injuries continue to be a costly societal problem. Future advancements in injury prevention depend on improved physical and computational models, which are predicated on a better understanding of the neck response during dynamic loading. Previous studies have shown that the tolerance of the neck is dependent on its initial position and its buckling behavior. This study uses a computational model to examine three important factors hypothesized to influence the loads experienced by vertebrae in the neck under compressive impact: muscle activation, torso constraints, and pre-flexion angle of the cervical spine. Since cadaver testing is not practical for large scale parametric analyses, these factors were studied using a previously validated computational model. On average, simulations with active muscles had 32% larger compressive forces and 25% larger shear forces—well in excess of what was expected from the muscle forces alone. In the short period of time required for neck injury, constraints on torso motion increased the average neck compression by less than 250N. The pre-flexion hypothesis was tested by examining pre-flexion angles from neutral (0°) to 64°. Increases in pre-flexion resulted in the largest increases in peak loads and the expression of higher-order buckling modes. Peak force and buckling modality were both very sensitive to pre-flexion angle. These results validate the relevance of prior cadaver models for neck injury and help explain the wide variety of cervical spine fractures that can result from ostensibly similar compressive loadings. They also give insight into the mechanistic differences between burst fractures and lower cervical spine dislocations.}
}
@article{HERAS2011685,
title = {fKenzo: A user interface for computations in Algebraic Topology},
journal = {Journal of Symbolic Computation},
volume = {46},
number = {6},
pages = {685-698},
year = {2011},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2011.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0747717111000174},
author = {J. Heras and V. Pascual and J. Rubio and F. Sergeraert},
keywords = {Symbolic computation systems, User interface, Constructive Algebraic Topology},
abstract = {fKenzo (= friendly Kenzo) is a graphical user interface providing a user-friendly front-end for the Kenzo system, a Common Lisp program devoted to Algebraic Topology. The fKenzo system provides the user interface itself, an XML intermediary generator-translator and, finally the Kenzo kernel. We describe in this paper the main points of fKenzo, and we explain also the advantages and limitations of fKenzo with respect to Kenzo itself. The text is separated into two parts, trying to cover both the user and the developer perspectives.}
}
@article{PRADIPA20241213,
title = {Malang Voyage: A sustainable digital landscape in Malang City},
journal = {Procedia Computer Science},
volume = {245},
pages = {1213-1224},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.351},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031594},
author = {I Gede Cahya Pradipa and Yudhistya Ayu Kusumawati and Yongkie Angkawijaya},
keywords = {Sustainable tourism, Tourism development, Digital infrastructure, Malang City},
abstract = {In the scope of global tourism, Malang stands as a potential yet underutilized tourism city. Known as the "Paris of East Java," its captivating landscapes and pleasant climate offer a unique experience. Despite this, the city's tourism sector remains underdeveloped, evident from the low number of visitors compared to what it has to offer. Existing studies reveal the city's yet undiscovered potential, especially in city tourism, cultural experiences, and culinary. However, limited information and digital infrastructure pose significant challenges. This research addresses these gaps, proposing the development of a robust digital platform in the form of a dedicated social media travel hub for Malang's sustainable tourism. By utilizing design thinking methodology, the study aims to revolutionize how tourists access information and interact with local attractions. It hypothesizes that a well-designed digital infrastructure will enhance the city's tourism quality, attracting more visitors. Additionally, adopting sustainable tourism principles will further boost Malang's tourism industry. This research is not just a digital upgrade, it's a transformative journey, paving the way for Malang to emerge as a sustainable tourism hub. Through innovative design and a user-focused approach, this study is set to unlock Malang's full tourism potential of balanced growth with environmental and cultural preservation.}
}
@article{ROLLS2007962,
title = {A computational neuroscience approach to consciousness},
journal = {Neural Networks},
volume = {20},
number = {9},
pages = {962-982},
year = {2007},
note = {Brain and Consciousness},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2007.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S089360800700189X},
author = {Edmund T. Rolls},
keywords = {Consciousness, Higher order thought, Synchrony, Oscillations, Backward masking, Binding},
abstract = {Simultaneous recordings from populations of neurons in the inferior temporal visual cortex show that most of the information about which stimulus was shown is available in the number of spikes (or firing rate) of each neuron, and not from stimulus-dependent synchrony, so that it is unlikely that stimulus-dependent synchrony (or indeed oscillations) is an essential aspect of visual object perception. Neurophysiological investigations of backward masking show that the threshold for conscious visual perception may be set to be higher than the level at which small but significant information is present in neuronal firing and which allows humans to guess which stimulus was shown without conscious awareness. The adaptive value of this may be that the systems in the brain that implement the type of information processing involved in conscious thoughts are not interrupted by small signals that could be noise in sensory pathways. I then consider what computational processes are closely related to conscious processing, and describe a higher order syntactic thought (HOST) computational theory of consciousness. It is argued that the adaptive value of higher order thoughts is to solve the credit assignment problem that arises if a multistep syntactic plan needs to be corrected. It is then suggested that it feels like something to be an organism that can think about its own linguistic, and semantically-based thoughts. It is suggested that qualia, raw sensory and emotional feels, arise secondarily to having evolved such a higher order thought system, and that sensory and emotional processing feels like something because it would be unparsimonious for it to enter the planning, higher order thought, system and not feel like something.}
}
@article{PAPAVLASOPOULOU201850,
title = {How do you feel about learning to code? Investigating the effect of children’s attitudes towards coding using eye-tracking},
journal = {International Journal of Child-Computer Interaction},
volume = {17},
pages = {50-60},
year = {2018},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2018.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212868917300259},
author = {Sofia Papavlasopoulou and Kshitij Sharma and Michail N. Giannakos},
keywords = {Children’s attitudes, Eye-tracking, Coding, Computational thinking, Constructionism},
abstract = {Computational thinking and coding for children are attracting increasing attention. There are several efforts around the globe to implement coding frameworks for children, and there is a need to develop an empirical knowledge base of methods and tools. One major problem for integrating study results into a common body of knowledge is the relatively limited measurements applied, and the relation of the widely used self-reporting methods with more objective measurements, such as biophysical ones. In this study, eye-tracking activity was used to measure children’s learning and activity indicators. The goal of the study is to utilize eye-tracking to understand children’s activity while they learn how to code and to investigate any potential association between children’s attitudes and their gaze. In this contribution, we designed an experiment with 44 children (between 8 and 17 years old) who participated in a full-day construction-based coding activity. We recorded their gaze while they were working and captured their attitudes in relation to their learning, excitement and intention. The results showed a significant relation between children’s attitudes (what they think about coding) and their gaze patterns (how they behaved during coding). Eye-tracking data provide initial insights into the behaviour of children, for example if children have difficulty in extracting information or fail to accomplish an expected task. Therefore, further studies need to be conducted to shed additional light on children’s experience and learning duringcoding.}
}
@incollection{SEJNOWSKI200919,
title = {Computational Methods},
editor = {Larry R. Squire},
booktitle = {Encyclopedia of Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {19-22},
year = {2009},
isbn = {978-0-08-045046-9},
doi = {https://doi.org/10.1016/B978-008045046-9.01396-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080450469013966},
author = {T.J. Sejnowski},
keywords = {Brain theory, Computational models, Mathematical analysis},
abstract = {Computational neuroscience is a relatively recent approach to understanding how nervous systems develop and interact with a changing and uncertain world. Computational models can be used to interpret experimental data in new ways, to confirm and extend existing hypotheses, and to generate new hypotheses for the function of neural systems. These hypotheses provide links between levels of description, from the molecular level to the systems level. Hypotheses that are tested and validated provide a conceptual framework that can lead to more abstract theories. The ultimate aim of theoretical and computational neuroscience is to provide linking principles from neural mechanisms to behavior.}
}
@incollection{CHOE2005187,
title = {Thinking about Visual Behavior; Learning about Photoreceptor Function},
series = {Current Topics in Developmental Biology},
publisher = {Academic Press},
volume = {69},
pages = {187-213},
year = {2005},
booktitle = {Neural Development},
issn = {0070-2153},
doi = {https://doi.org/10.1016/S0070-2153(05)69007-2},
url = {https://www.sciencedirect.com/science/article/pii/S0070215305690072},
author = {Kwang‐Min Choe and Thomas R. Clandinin},
abstract = {Visual behavioral assays in Drosophila melanogaster were initially developed to explore the genetic control of behavior, but have a rich history of providing conceptual openings into diverse questions in cell and developmental biology. Here, we briefly summarize the early efforts to employ three of these behaviors: phototaxis, the UV‐visible light choice, and the optomotor response. We then discuss how each of these assays has expanded our understanding of neuronal connection specificity and synaptic function. All of these studies have contributed to the development of sophisticated tools for manipulating gene expression, assessing cell fate specification, and visualizing neuronal development. With these tools in hand, the field is now poised to return to the original goal of understanding visual behavior using genetic approaches.}
}
@article{TROGER201953,
title = {Exploitation vs. exploration—computational temporal and semantic analysis explains semantic verbal fluency impairment in Alzheimer's disease},
journal = {Neuropsychologia},
volume = {131},
pages = {53-61},
year = {2019},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2019.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S0028393218305116},
author = {Johannes Tröger and Nicklas Linz and Alexandra König and Philippe Robert and Jan Alexandersson and Jessica Peter and Jutta Kray},
keywords = {Alzheimer's disease, MCI (mild cognitive impairment), Semantic speech analysis, Temporal analysis},
abstract = {Impaired Semantic Verbal Fluency (SVF) in dementia due to Alzheimer's Disease (AD) and its precursor Mild Cognitive Impairment (MCI) is well known. Yet, it remains open whether this impairment mirrors the breakdown of semantic memory retrieval processes or executive control processes. Therefore, qualitative analysis of the SVF has been proposed but is limited in terms of methodology and feasibility in clinical practice. Consequently, research draws no conclusive picture which of these afore-mentioned processes drives the SVF impairment in AD and MCI. This study uses a qualitative computational approach—combining temporal and semantic information—to investigate exploitation and exploration patterns as indicators for semantic memory retrieval and executive control processes. Audio SVF recordings of 20 controls (C, 66–81 years), 55 MCI (57–94 years) and 20 AD subjects (66–82 years) were assessed while groups were matched according to age and education. All groups produced, on average, the same amount of semantically related items in rapid succession within word clusters. Conversely, towards AD, there was a clear decline in semantic as well as temporal exploration patterns between clusters. Results strongly point towards preserved exploitation—semantic memory retrieval processes—and hampered exploration—executive control processes—in AD and potentially in MCI.}
}
@article{LISOWSKI2014634,
title = {Computational Intelligence Methods of a Safe Ship Control},
journal = {Procedia Computer Science},
volume = {35},
pages = {634-643},
year = {2014},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 18th Annual Conference, KES-2014 Gdynia, Poland, September 2014 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.08.145},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914011107},
author = {Józef Lisowski},
keywords = {Game Control, Optimal Control, Neural Networks, Safety of Navigation, Computer-Aided Decision, Computer Simulation},
abstract = {The paper describes the application of selected methods of optimal control theory, game theory and artificial neural networks with the aim of computer support for a safe ship control in collision situations. It shows the structure of the control system and defines the task of safe control. Also presented are methodologies and models for collision avoidance strategies. Using Matlab software, positional game, risk game and dynamic optimal trajectory algorithms have been developed to provide computer support of navigator for collision avoidance at sea. A computer simulations showing safe trajectory through eighteen met ships at sea illustrates this.}
}
@incollection{READMONTAGUE2018273,
title = {Chapter 11 - Computational Phenotypes Revealed by Interactive Economic Games},
editor = {Alan Anticevic and John D. Murray},
booktitle = {Computational Psychiatry},
publisher = {Academic Press},
pages = {273-292},
year = {2018},
isbn = {978-0-12-809825-7},
doi = {https://doi.org/10.1016/B978-0-12-809825-7.00011-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128098257000110},
author = {P. {Read Montague}},
keywords = {Approach and avoidance, Computational phenotyping, Computational psychiatry, Decision-making models, Economic games, Psychopathology, Reinforcement learning, Trust game},
abstract = {Reinforcement learning models provide an excellent example of how a computational process approach can help organize ideas and understanding of underlying neurobiology. In a strong sense, this is the assumption behind computational neuroscience. Computational psychiatry, as a translational arm of computational neuroscience, can also profit from the computational process approach but applied at many levels ranging from low-level neurobiology through characterization of mental states and even up to the level of multiple interacting humans. Here, we review some of the early evidence for why reinforcement learning in its modern versions moves well beyond behaviorist accounts and provides an excellent “computational paradigm” for framing value-dependent decision-making; something that goes awry in a number of psychiatry conditions. We focus in particular on how social exchange between humans can engage reward systems and can be used as a computational device good for parsing subjects into categories that relate in interesting ways to traditional depictions of psychopathology.}
}
@article{TOZZI2018133,
title = {Syntax meets semantics during brain logical computations},
journal = {Progress in Biophysics and Molecular Biology},
volume = {140},
pages = {133-141},
year = {2018},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2018.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0079610717303140},
author = {Arturo Tozzi and James F. Peters and Andrew A. Fingelkurts and Alexander A. Fingelkurts and Leonid Perlovsky},
keywords = {Borsuk-ulam, Brouwer, Computation, Meaning, Truth, Syntactic},
abstract = {The discrepancy between syntax and semantics is a painstaking issue that hinders a better comprehension of the underlying neuronal processes in the human brain. In order to tackle the issue, we at first describe a striking correlation between Wittgenstein's Tractatus, that assesses the syntactic relationships between language and world, and Perlovsky's joint language-cognitive computational model, that assesses the semantic relationships between emotions and “knowledge instinct”. Once established a correlation between a purely logical approach to the language and computable psychological activities, we aim to find the neural correlates of syntax and semantics in the human brain. Starting from topological arguments, we suggest that the semantic properties of a proposition are processed in higher brain's functional dimensions than the syntactic ones. In a fully reversible process, the syntactic elements embedded in Broca's area project into multiple scattered semantic cortical zones. The presence of higher functional dimensions gives rise to the increase in informational content that takes place in semantic expressions. Therefore, diverse features of human language and cognitive world can be assessed in terms of both the logic armor described by the Tractatus, and the neurocomputational techniques at hand. One of our motivations is to build a neuro-computational framework able to provide a feasible explanation for brain's semantic processing, in preparation for novel computers with nodes built into higher dimensions.}
}
@article{KUGEL1986137,
title = {Thinking may be more than computing},
journal = {Cognition},
volume = {22},
number = {2},
pages = {137-198},
year = {1986},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(86)90057-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027786900570},
author = {Peter Kugel},
abstract = {The uncomputable parts of thinking (if there are any) can be studied in much the same spirit that Turing (1950) suggested for the study of its computable parts. We can develop precise accounts of cognitive processes that, although they involve more than computing, can still be modelled on the machines we call ‘computers’. In this paper, I want to suggest some ways that this might be done, using ideas from the mathematical theory of uncomputability (or Recursion Theory). And I want to suggest some uses to which the resulting models might be put. (The reader more interested in the models and their uses than the mathematics and its theorems, might want to skim or skip the mathematical parts.)
Résumé
Les éléments du raisonnement ne relevant pas du calculable (uncomputable), (s'il en existe), peuvent s'etudier dans I'optique suggérée par Turing (1950) pour l'étude des éléments calculables (computable). On peut rendre compte avec précision des processus cognitifs qui, bien qu'impliquant plus que des calculs, peuvent cependant être modélisés sur ordinateurs. Dans cet article l'auteur propose des modalités pour arriver à ces résultats en utilisant les idées de la théorie mathdmatique de la Récursion (uncomputability). L'auteur suggère aussi des utilisations pour les modéles que en découlent (Il est possible au lecteur plus intéressé par les modèles et leurs utilisations que par les mathématiques et les théorèmes de passer rapidement sur la partie mathématique ou d'omettre de la lire.)}
}
@incollection{BLACK2021105,
title = {10 - Mutual benefit from library collaboration with computational biologists: the cropPAL project at the University of Western Australia},
editor = {Jeremy Atkinson},
booktitle = {Technology, Change and the Academic Library},
publisher = {Chandos Publishing},
pages = {105-114},
year = {2021},
series = {Chandos Information Professional Series},
isbn = {978-0-12-822807-4},
doi = {https://doi.org/10.1016/B978-0-12-822807-4.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128228074000105},
author = {Kylie Black},
keywords = {cropPAL, partnerships, collaboration, commercialisation, market research, DeweyFish, ON Prime},
abstract = {In 2016–17, the University of Western Australia (UWA) Library partnered with researchers in the Australian Research Council’s Centre of Excellence in Plant Energy Biology to produce cropPAL2, a database providing the subcellular locations for proteins in crops significant for food production. The project team consisted of computational biologists, software engineers and a librarian, in which the Library contributed expertise in developing search strategies, research data management and enhancing discoverability of cropPAL2 and its dataset. The Library continues to be a key player in this collaboration, a first for UWA, both in the innovative process and as a key driver in directing the development of commercial software for the wider benefit of researchers at UWA and beyond.}
}
@article{WANG2020106763,
title = {Fuzzy Linear regression based on approximate Bayesian computation},
journal = {Applied Soft Computing},
volume = {97},
pages = {106763},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106763},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620307018},
author = {Ning Wang and Marek Reformat and Wen Yao and Yong Zhao and Xiaoqian Chen},
keywords = {Fuzzy linear regression, Bayes statistics, Approximate Bayesian computation},
abstract = {Fuzzy linear regression with crisp inputs and fuzzy output data constitutes an important modeling problem. Basic strategies used to solve this problem, i.e., the possibilistic method and the least squares method, together with their extensions, have some drawbacks. The possibilistic methods put emphasis on an inclusion property while the least squares methods focus on a central tendency property. Therefore, many researchers work on combining these two methods to obtain a better performance. In this paper, in contrast to most existing techniques which treat fuzzy linear regression as an optimization problem, we set the problem of constructing a fuzzy linear regression model in Bayesian statistics and propose a new fuzzy linear regression method based on approximate Bayesian computation (ABC). The method applies the likelihood-free inference algorithm ABC to generate independent samples of unknown model coefficients from Bayesian posterior distribution. This overcomes difficulty of defining likelihood function in fuzzy environment. By adjusting a prior distribution and a threshold of the ABC algorithm, the proposed approach can flexibly balance the inclusion property of the possibilistic methods and the central tendency property of the least squares methods. The convergence property of the proposed ABC algorithm is verified by a numerical example. Two measuring criteria, i.e., a distance metric and a degree of fitting index, which indicate the central tendency property and the inclusion property, respectively, are introduced to evaluate the quality of regression results. Three numerical examples are applied to show the performances of the proposed method. The numerical results are also compared with those obtained by some classical and recently proposed approaches. Additionally, a practical engineering application example is used to illustrate effectiveness of the proposed method.}
}
@article{CHEN2016222,
title = {Constraint local principal curve: Concept, algorithms and applications},
journal = {Journal of Computational and Applied Mathematics},
volume = {298},
pages = {222-235},
year = {2016},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2015.11.041},
url = {https://www.sciencedirect.com/science/article/pii/S0377042715005956},
author = {Dewang Chen and Jiateng Yin and Shiying Yang and Lingxi Li and Peter Pudney},
keywords = {Constraint local principal curve (CLPC), GPS, Local optimization, Adaptive radius, Principal of nearest neighbor},
abstract = {Existing principal curve algorithms have some drawbacks such as time consuming and narrow application scope in practice, since these algorithms are mainly based on global optimization. In this paper, we present the concept of Constraint Local Principal Curve (CLPC), which uses local optimization methods and restricts the principal curve with two fixed endpoints to reduce the computational complexity. In addition, we propose three CLPC algorithms by Local Optimization and Adaptive Radius to expand the range of applications and increase the solution quality. The first algorithm, i.e., CLPCg is based on greedy thinking. The second algorithm, i.e., CLPCs uses one dimensional search and the last algorithm CLPCc combines the greedy thinking and one dimensional search. Then, we define six performance indices to evaluate the performance of the CLPC algorithms. Finally, we present some numerical experiments with three simulation data sets and two GPS measured data sets in both highway and railway. The results indicate that all of the three CLPC algorithms can obtain high-accuracy data from multiple low-accuracy data efficiently. The CLPC algorithms can improve the accuracy and computational speed compared with the existing K-segment principal curve (KPC) algorithm. In addition, CLPCc outperforms CLPCg and CLPCs according to the comprehensive experiments while CLPCg runs much faster than other ones.}
}
@article{MAIA2017382,
title = {Theory-Based Computational Psychiatry},
journal = {Biological Psychiatry},
volume = {82},
number = {6},
pages = {382-384},
year = {2017},
note = {Computational Psychiatry},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2017.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0006322317318164},
author = {Tiago V. Maia and Quentin J.M. Huys and Michael J. Frank}
}
@article{LI2017183,
title = {SeeMore: A kinetic parallel computer sculpture for educating broad audiences on parallel computation},
journal = {Journal of Parallel and Distributed Computing},
volume = {105},
pages = {183-199},
year = {2017},
note = {Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.01.017},
url = {https://www.sciencedirect.com/science/article/pii/S0743731517300230},
author = {Bo Li and John Mooring and Sam Blanchard and Aditya Johri and Melinda Leko and Kirk W. Cameron},
keywords = {Parallel and distributed computing, Kinetic art, Computer science education},
abstract = {We discuss the design, implementation, and evaluation of a 256-node Raspberry-Pi cluster with kinetic properties. Each compute node is attached to a servo mechanism such that movement results from local computation. The result is SeeMore, a kinetic parallel computer sculpture designed to enable visualization of parallel algorithms in an effort to educate broad audiences as to the beauty, complexity, and importance of parallel computation. The algorithms and interfaces were implemented by students from various related courses at VA Tech. We describe these designs in sufficient detail to enable others to build their own kinetic computing sculptures to augment their experiential learning programs. Our evaluations at exhibitions indicate 63% and 84% of visitors enjoyed interacting with SeeMore while 69% and 87% believed SeeMore has educational value.}
}
@article{TRYK2023101372,
title = {The electrochemistry of platinum-group and noble metals as it relates to fuel cells and water electrolysis: Vibrational spectroscopic and computational insights},
journal = {Current Opinion in Electrochemistry},
volume = {41},
pages = {101372},
year = {2023},
issn = {2451-9103},
doi = {https://doi.org/10.1016/j.coelec.2023.101372},
url = {https://www.sciencedirect.com/science/article/pii/S2451910323001655},
author = {Donald A. Tryk and Akiyoshi Kuzume},
abstract = {The intrinsic electrochemistry of platinum and other platinum-group metals and noble metals has been under intense investigation for over forty years but is still not fully understood. Various in situ spectroscopic techniques, particularly vibrational spectroscopies, have provided and continue to provide many insights, but challenges remain. The intrinsic electrochemistry is capable of being elucidated through the combination of electrochemistry, vibrational spectroscopy and theory and is then further able to clarify the catalytic reactions involved in H2–O2 fuel cells and water electrolysis.}
}
@article{FIGUEIRASAMPAIO2009484,
title = {A constructivist computational tool to assist in learning primary school mathematical equations},
journal = {Computers & Education},
volume = {53},
number = {2},
pages = {484-492},
year = {2009},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2009.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S036013150900075X},
author = {Aleandra da Silva Figueira-Sampaio and Eliane Elias Ferreira {dos Santos} and Gilberto Arantes Carrijo},
keywords = {Elementary education, Improving classroom teaching, Interactive learning environments, Virtual reality},
abstract = {In constructivist principles, learning is a process in which individuals construct knowledge. Research in Mathematics Education looks for ways to make mathematics education less dry and more attractive. When solving polynomial equations of the first degree, it is very common for teachers to work with the mistaken idea of “changing the sign” when “moving” the member. To minimize this problem, a balance can be used to illustrate the idea of equilibrium and also properties of equality. The objectives of this study were (1) develop a computational tool to replace a conventional balance in practical mathematics exercises thereby solving two material challenges for Brazilian teachers: verifying the accuracy of balances and the lack of student physical and social activity through direct participation; (2) determine how substituting the conventional balance with a computational tool for the solution of first degree polynomial equations affected the aspects inherent in the learning process like motivation, cooperation, dialogue, discussion, reflection, reciprocity, negotiation and responsibility. The results indicate that the cognitive computational tool met the challenges of Brazilian teachers. First, because it lacks mechanisms that need to be verified for accuracy in order to demonstrate equilibrium. Second, because it allows the direct participation of students (physical experience) and the use of the tool in small groups (social experience). The hands on completion of the activity, realistic appearance, the interaction with the tool, visual feedback on the panel, and two students using the same tool awakened motivation, responsibility for completing the activity, dialogue, cooperation, discussion and reflection. Doing the experiment with others aroused concern about the learning of others and reciprocity of knowledge for the improvement of the procedure to be constructed for solving 1st degree equations.}
}
@article{DENHAAN2011175,
title = {Computational suite of models with heterogeneous agents II: Multi-country real business cycle models},
journal = {Journal of Economic Dynamics and Control},
volume = {35},
number = {2},
pages = {175-177},
year = {2011},
note = {Computational Suite of Models with Heterogeneous Agents II: Multi-Country Real Business Cycle Models},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2010.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0165188910002149},
author = {Wouter J. {Den Haan} and Kenneth L. Judd and Michel Juillard},
keywords = {Numerical solutions, Simulations, Approximations},
abstract = {This paper describes the second model considered in the computational suite project that compares the performance of different numerical algorithms. It is a multi-country model in which countries face different productivity shocks. Solving such models is a challenging numerical problem unless the number of countries is small. The solutions are functions of a large set of arguments and the functional forms are unknown. Moreover, the solution procedures have to deal with high-dimensional integration problems.}
}
@article{BRODLAND201562,
title = {How computational models can help unlock biological systems},
journal = {Seminars in Cell & Developmental Biology},
volume = {47-48},
pages = {62-73},
year = {2015},
note = {Coding and non-coding RNAs & Mammalian development},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2015.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1084952115001287},
author = {G. Wayne Brodland},
keywords = {Review, Models, Computational modelling, Cell mechanics, Tissue mechanics, Embryo mechanics, Embryogenesis, Morphogenetic movements, Developmental mechanisms, Biological systems},
abstract = {With computation models playing an ever increasing role in the advancement of science, it is important that researchers understand what it means to model something; recognize the implications of the conceptual, mathematical and algorithmic steps of model construction; and comprehend what models can and cannot do. Here, we use examples to show that models can serve a wide variety of roles, including hypothesis testing, generating new insights, deepening understanding, suggesting and interpreting experiments, tracing chains of causation, doing sensitivity analyses, integrating knowledge, and inspiring new approaches. We show that models can bring together information of different kinds and do so across a range of length scales, as they do in multi-scale, multi-faceted embryogenesis models, some of which connect gene expression, the cytoskeleton, cell properties, tissue mechanics, morphogenetic movements and phenotypes. Models cannot replace experiments nor can they prove that particular mechanisms are at work in a given situation. But they can demonstrate whether or not a proposed mechanism is sufficient to produce an observed phenomenon. Although the examples in this article are taken primarily from the field of embryo mechanics, most of the arguments and discussion are applicable to any form of computational modelling.}
}
@article{LEE2012579,
title = {Developing an efficient computational method that estimates the ability of students in a Web-based learning environment},
journal = {Computers & Education},
volume = {58},
number = {1},
pages = {579-589},
year = {2012},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511002259},
author = {Young-Jin Lee},
keywords = {Ability estimation, Educational data mining, Item response theory, Log file analysis, Web-based learning environment},
abstract = {This paper presents a computational method that can efficiently estimate the ability of students from the log files of a Web-based learning environment capturing their problem solving processes. The computational method developed in this study approximates the posterior distribution of the student’s ability obtained from the conventional Bayes Modal Estimation (BME) approach to a simple Gaussian function in order to reduce the amount of computations required in the subsequent ability update processes. To verify the correctness and usefulness of this method, the abilities of 407 college students who solved 61 physics problems in a Web-based learning environment were estimated from the log files of the learning environment. The reduced chi-squared statistic and Pearson’s chi-square test for the goodness of fit indicate that the estimated abilities were able to successfully explain the observed problem solving performance of students within error. The educational implications of estimating the ability of students in Web-based learning environments were also discussed.}
}
@article{KLIMOVA20171,
title = {Where Youth strives in Computational Science: retrospective Analysis of Young Scientist Conference in HPC and Simulation},
journal = {Procedia Computer Science},
volume = {119},
pages = {1-7},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.153},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323633},
author = {Alexandra Klimova and Anna Bilyatdinova and Jari Kortelainen and Peter M.A. Sloot and Alexander Boukhanovsky},
keywords = {computational science, high-performance computing, leading scientists program, international conference},
abstract = {This volume presents the selected papers of young computational scientists – participants of YSC-2017. Annual Young Scientist Conferences (YSC) in high performance computing, modeling and simulation are traditionally held since 2012 by the University of Amsterdam (the Netherlands) and ITMO University (St. Petersburg, Russia) as the open international events which aim to develop a dialogue about the present and future of computational science with a focus on applications of modeling and simulation solving a wide range of problems of science, industry, and business. The conference has already been organized for six times, which gives us an opportunity for retrospective analysis of conference’ results and trends in high performance computing (HPC). The results are presented in this editorial.}
}
@article{GIROTTO1991111,
title = {Event controllability in counterfactual thinking},
journal = {Acta Psychologica},
volume = {78},
number = {1},
pages = {111-133},
year = {1991},
issn = {0001-6918},
doi = {https://doi.org/10.1016/0001-6918(91)90007-M},
url = {https://www.sciencedirect.com/science/article/pii/000169189190007M},
author = {Vittorio Girotto and Paolo Legrenzi and Antonio Rizzo},
abstract = {The counterfactual assessment of events, i.e. is the mental construction of alternatives to factual events, is a pervasive mental process that is quite natural for people. For example, people easily make counterfactual statements when reflecting on dramatic events (‘If only I hadn't drunk alcohol the night of the car accident…’). The way in which people select the events to mutate when requested to undo a scenario outcome seems to be governed by general rules. One is that subjects tend to select exceptional (i.e. unusual or surprising) rather than normal events (Kahneman and Tversky 1982a,b; Kahneman and Miller 1986). Another is that subjects prefer to select the first rather than the subsequent events in a causal chain (Wells, Taylor and Turtle 1987). We hypothesized that events corresponding to controllable actions (i.e. voluntary decisions) by the protagonist of a scenario are more mentally mutable than events which occur in the surrounding background. In experiment 1, we manipulated the order and the controllability of four events in a scenario. Contrary to the causal order effect hypothesis, subjects preferred to change the event corresponding to a coluntary decision of the scenario actor, regardless of its relative position in the scenario. Experiment 2 showed that subjects made this choice regardless of the normal vs. exceptional status of the voluntary action event. Experiment 3 gave evidence that an unconstrained action performed by the focal actor of a story is more mutable than a constrained action performed by the same actor. The implications of these findings for the analysis of accidents involving human errors are discussed.}
}
@article{TRASMUNDI2024101615,
title = {Dialogical cognition},
journal = {Language Sciences},
volume = {103},
pages = {101615},
year = {2024},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2024.101615},
url = {https://www.sciencedirect.com/science/article/pii/S0388000124000044},
author = {Sarah Bro Trasmundi and Sune Vork Steffensen},
keywords = {Per Linell, Dialogical cognition, Distributed cognition, Cognitive ethnography, Distributed language},
abstract = {In this article we review Per Linell's work within the last five decades that led to his dialogism framework, which he defines as a general epistemology of language, cognition and communication. We critically discuss how his contribution on the one hand, altered and qualified existent models within language, communication and cognitive science, because dialogism removed language and cognition from their abstract and mental seat in the brain, and embedded them instead in situational contexts and embodied interaction. In that sense, his dialogism successfully replaced monological assumptions about the mind, action and thinking with more contextual and temporally distributed ones. On the other hand, we also question why Linell has not pursued a more rigorous empirical program for studying human cognition, when he did establish a theoretical apparatus for approaching cognition from a dialogical starting point. In going through Linell's arguments over the past five decades we suggest that this absence of an empirical program is due to his humanistic roots which both have sensitised him to appreciating the contingencies and dynamics of human sense making and cognition, and have impeded him from buying into a necessary condition for pursuing a cognitive analysis, even if he conceptually and methodologically accepts a distributed view on cognition. The outcome of this discussion leads to an empirical-based cognitive analysis of a medical interaction. Altogether, the purpose of this article is to show how Linell's conceptual framework can be put to use in ways that make a dialogical cognitive science achievable.}
}
@article{TEZDUYAR20061872,
title = {Parallel finite element computations in fluid mechanics},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {195},
number = {13},
pages = {1872-1884},
year = {2006},
note = {A Tribute to Thomas J.R. Hughes on the Occasion of his 60th Birthday},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2005.05.038},
url = {https://www.sciencedirect.com/science/article/pii/S0045782505003105},
author = {Tayfun E. Tezduyar and Ahmed Sameh},
keywords = {Parallel computing, Fluid mechanics, Moving boundaries and interfaces, Mesh update, Preconditioned iterative algorithms},
abstract = {We provide an overview of the role of parallel finite element computations in fluid mechanics. We emphasize the class of flow problems involving moving boundaries and interfaces. Some of the computationally most challenging flow problems, such as fluid–object and fluid–structure interactions as well as free-surface and two-fluid flows, belong to this class. In the development of the methods targeting this class of problems, the computational challenges involved need to be addressed in such a way that 3D computation of complex applications can be carried out efficiently on parallel computers. This requirement has to be one of the key factors in designing various components of the overall solution approach, such as solution techniques for the discretized equations and mesh update methods for handling the changes in the spatial domain occupied by the fluid. This overview includes a description of how the computational challenges are addressed and how the computational schemes can be enhanced with special preconditioning techniques.}
}
@article{GONDOCS2024102769,
title = {AI in medical diagnosis: AI prediction & human judgment},
journal = {Artificial Intelligence in Medicine},
volume = {149},
pages = {102769},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102769},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000113},
author = {Dóra Göndöcs and Viktor Dörfler},
keywords = {Medical diagnosis, Melanoma, Human-computer interaction, Augmented intelligence, Explainability, Responsible AI},
abstract = {AI has long been regarded as a panacea for decision-making and many other aspects of knowledge work; as something that will help humans get rid of their shortcomings. We believe that AI can be a useful asset to support decision-makers, but not that it should replace decision-makers. Decision-making uses algorithmic analysis, but it is not solely algorithmic analysis; it also involves other factors, many of which are very human, such as creativity, intuition, emotions, feelings, and value judgments. We have conducted semi-structured open-ended research interviews with 17 dermatologists to understand what they expect from an AI application to deliver to medical diagnosis. We have found four aggregate dimensions along which the thinking of dermatologists can be described: the ways in which our participants chose to interact with AI, responsibility, ‘explainability’, and the new way of thinking (mindset) needed for working with AI. We believe that our findings will help physicians who might consider using AI in their diagnosis to understand how to use AI beneficially. It will also be useful for AI vendors in improving their understanding of how medics want to use AI in diagnosis. Further research will be needed to examine if our findings have relevance in the wider medical field and beyond.}
}
@article{LEE2023121253,
title = {Artificial intelligence enabled energy-efficient heating, ventilation and air conditioning system: Design, analysis and necessary hardware upgrades},
journal = {Applied Thermal Engineering},
volume = {235},
pages = {121253},
year = {2023},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2023.121253},
url = {https://www.sciencedirect.com/science/article/pii/S1359431123012826},
author = {Dasheng Lee and Shang-Tse Lee},
keywords = {Artificial intelligence (AI), Heating, ventilation and air conditioning (HVAC), Energy saving, Design thinking, Hardware upgrade},
abstract = {Literature search across different databases showed that the application of artificial intelligence (AI) in heating, ventilation and air conditioning (HVAC) equipment has been extensively studied. On the commercial front, Internet search suggested that numerous AI-equipped HVAC products have been launched. These products apply AI in very different ways, and their energy-saving effects are also different. Such divergence and uncertain energy-saving effects may hinder AI application. To overcome this difference and accelerate the development of AI applications, the present study proposed a double diamond preferred reporting items for systematic reviews and meta-analysis (PRISMA) method—an analysis method that combined literature review with design thinking. Through a process of divergence-convergence-re-divergence, this study described how to design AI functions for energy-efficient HVAC systems, taking into account more than 1,700 research papers it had reviewed. However, there was a limitation on the part re-divergence. Because the vast majority of research papers only published results of successful AI applications, no cases of failed applications were available for review, making it impossible to re-think profoundly. Instead, this study collected raw data from 88 research papers and used these data to analyze the effectiveness and ineffectiveness of AI in depth. It was concluded that AI application must be accompanied by necessary hardware improvements to achieve effective energy savings. AI-enabled energy-saving effects for chillers, air-handing units, heating systems, and air conditioners, as well as corresponding hardware upgrades, were discussed.}
}
@article{SIETTOS20061632,
title = {A systems-based approach to multiscale computation: Equation-free detection of coarse-grained bifurcations},
journal = {Computers & Chemical Engineering},
volume = {30},
number = {10},
pages = {1632-1642},
year = {2006},
note = {Papers form Chemical Process Control VII},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2006.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0098135406001360},
author = {C.I. Siettos and R. Rico-Martinez and I.G. Kevrekidis},
keywords = {Multiscale, Equation-free, Bifurcation},
abstract = {We discuss certain basic features of the equation-free (EF) approach to modeling and computation for complex/multiscale systems. We focus on links between the equation-free approach and tools from systems and control theory (design of experiments, data analysis, estimation, identification and feedback). As our illustrative example, we choose a specific numerical task (the detection of stability boundaries in parameter space) for stochastic models of two simplified heterogeneous catalytic reaction mechanisms. In the equation-free framework the stochastic simulator is treated as an experiment (albeit a computational one). Short bursts of fine scale simulation (short computational experiments) are designed, executed, and their outputs processed and fed back to the process, in integrated protocols aimed at performing the particular coarse-grained task (the detection of a macroscopic instability). Two distinct approaches are presented; one is a direct translation of our previous protocol for adaptive detection of instabilities in laboratory experiments [Rico-Martinez, R., Krisher, K., Flatgen, G., Anderson, J. S., & Kevrekidis, I. G. (2003). Adaptive detection of instabilities: An experimental feasibility study. Physica D, 176, 1–18]; the second approach is motivated from numerical bifurcation algorithms for critical point detection. A comparison of the two approaches brings forth a key feature of equation-free computation: computational experiments can be easily initialized at will, in contrast to laboratory ones.}
}
@article{TOIVONEN202052,
title = {Computational creativity beyond machine learning},
journal = {Physics of Life Reviews},
volume = {34-35},
pages = {52-53},
year = {2020},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300373},
author = {Hannu Toivonen}
}
@article{TURKHEIMER2015211,
title = {The brain's code and its canonical computational motifs. From sensory cortex to the default mode network: A multi-scale model of brain function in health and disease},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {211-222},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001189},
author = {Federico E. Turkheimer and Robert Leech and Paul Expert and Louis-David Lord and Anthony C. Vernon},
keywords = {Brain networks, Functional connectivity, Interneurons, Gamma-oscillations, NMDA, GABA, Lateral inhibition, Feedback inhibition, Feed-forward inhibition, Canonical neural computation, Motifs, Default mode network, fMRI, Schizophrenia},
abstract = {A variety of anatomical and physiological evidence suggests that the brain performs computations using motifs that are repeated across species, brain areas, and modalities. The computational architecture of cortex, for example, is very similar from one area to another and the types, arrangements, and connections of cortical neurons are highly stereotyped. This supports the idea that each cortical area conducts calculations using similarly structured neuronal modules: what we term canonical computational motifs. In addition, the remarkable self-similarity of the brain observables at the micro-, meso- and macro-scale further suggests that these motifs are repeated at increasing spatial and temporal scales supporting brain activity from primary motor and sensory processing to higher-level behaviour and cognition. Here, we briefly review the biological bases of canonical brain circuits and the role of inhibitory interneurons in these computational elements. We then elucidate how canonical computational motifs can be repeated across spatial and temporal scales to build a multiplexing information system able to encode and transmit information of increasing complexity. We point to the similarities between the patterns of activation observed in primary sensory cortices by use of electrophysiology and those observed in large scale networks measured with fMRI. We then employ the canonical model of brain function to unify seemingly disparate evidence on the pathophysiology of schizophrenia in a single explanatory framework. We hypothesise that such a framework may also be extended to cover multiple brain disorders which are grounded in dysfunction of GABA interneurons and/or these computational motifs.}
}
@article{ISMAILOVA2018183,
title = {Basic Constructions of the Computational Model of Support for Access Operations to the Semantic Network},
journal = {Procedia Computer Science},
volume = {123},
pages = {183-188},
year = {2018},
note = {8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.01.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918300310},
author = {Larisa Yu. Ismailova and Viacheslav E. Wolfengagen and Sergey V. Kosikov},
keywords = {informational objects, semantics, computational model, semantic network, intensional logic, access operation},
abstract = {The paper considers the approach to solving the task of storing data in the Web environment using semantic networks (SN). The control over the access to SN is identified as a critical task. An approach to the solution based on the use of the controlling SN is proposed. The rationale for the approach involves developing a computational model for supporting the access operations. The construction of a model based on intensional logic is proposed. The basic logical constructions, necessary for building a model, are considered. The testing of the model’s constructions was performed when building the tools of semantic support for the implementation of the best available technologies (BAT).}
}
@article{CUI2022104203,
title = {Pore-network modeling of flow in shale nanopores: Network structure, flow principles, and computational algorithms},
journal = {Earth-Science Reviews},
volume = {234},
pages = {104203},
year = {2022},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2022.104203},
url = {https://www.sciencedirect.com/science/article/pii/S0012825222002872},
author = {Ronghao Cui and S. Majid Hassanizadeh and Shuyu Sun},
keywords = {Pore-network modeling, Shale rock, Nanoporous media, Flow theory, Thermodynamics},
abstract = {Hydrocarbons in subsurface nanoporous media, such as shale, are promising energy resources to compensate for the shortage of conventional reservoirs. Pore-network modeling serves as a valuable tool for simulating microscale fluid transport and elucidating flow physics in porous media. However, traditional pore-network models have failed to capture features of spatial structure and fluid flow in unconventional shale rock. This work presents a critical review of pore-network modeling of single-phase and two-phase flow in shale rock. Pore-network modeling advances of shale are reviewed based on three major parts: network morphology and geometries, flow principles in nanocapillaries, and pore-network computational algorithms. First, based on key geological features of shale rock, we analyze network topology, multiscale network, pore geometries, and network representativeness of shale pore-network models. Then, we discuss four important aspects that may influence flow principles of fluids in nanocapillaries: gas and liquid slippage, sorption and diffusion behavior, hydrocarbon thermodynamics, and the presence of water. Finally, we present pore-network modeling methods used for flow simulations in shale rock, including quasi-static and dynamic algorithms. We hope that this review could shed light on fundamentals of pore-network modeling of shale rock.}
}
@article{ATANCE2010297,
title = {Thinking about false belief: It’s not just what children say, but how long it takes them to say it},
journal = {Cognition},
volume = {116},
number = {2},
pages = {297-301},
year = {2010},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2010.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0010027710001101},
author = {Cristina M. Atance and Daniel M. Bernstein and Andrew N. Meltzoff},
keywords = {Theory of mind, False-belief reasoning, Conceptual development, Response latencies},
abstract = {We examined 240 children’s (3.5-, 4.5-, and 5.5-year-olds) latency to respond to questions on a battery of false-belief tasks. Response latencies exhibited a significant cross-over interaction as a function of age and response type (correct vs. incorrect). 3.5-year-olds’ incorrect latencies were faster than their correct latencies, whereas the opposite pattern emerged for 4.5- and 5.5-year-olds. Although these results are most consistent with conceptual change theories of false-belief reasoning, no extant theory fully accounts for our data pattern. We argue that response latency data provide new information about underlying cognitive processes in theory of mind reasoning, and can shed light on concept acquisition more broadly.}
}
@article{BRASCH2012299,
title = {Thinking outside the cell: how cadherins drive adhesion},
journal = {Trends in Cell Biology},
volume = {22},
number = {6},
pages = {299-310},
year = {2012},
issn = {0962-8924},
doi = {https://doi.org/10.1016/j.tcb.2012.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0962892412000529},
author = {Julia Brasch and Oliver J. Harrison and Barry Honig and Lawrence Shapiro},
abstract = {Cadherins are a superfamily of cell surface glycoproteins whose ectodomains contain multiple repeats of β-sandwich extracellular cadherin (EC) domains that adopt a similar fold to immunoglobulin domains. The best characterized cadherins are the vertebrate ‘classical’ cadherins, which mediate adhesion via trans homodimerization between their membrane-distal EC1 domains that extend from apposed cells, and assemble intercellular adherens junctions through cis clustering. To form mature trans adhesive dimers, cadherin domains from apposed cells dimerize in a ‘strand-swapped’ conformation. This occurs in a two-step binding process involving a fast-binding intermediate called the ‘X-dimer’. Trans dimers are less flexible than cadherin monomers, a factor that drives junction assembly following cell–cell contact by reducing the entropic cost associated with the formation of lateral cis oligomers. Cadherins outside the classical subfamily appear to have evolved distinct adhesive mechanisms that are only now beginning to be understood.}
}
@article{ZHAO2015194,
title = {Bring CS2013 Recommendations into c Programming Course},
journal = {Procedia - Social and Behavioral Sciences},
volume = {176},
pages = {194-199},
year = {2015},
note = {International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.461},
url = {https://www.sciencedirect.com/science/article/pii/S187704281500498X},
author = {Lingling Zhao and Xiaohong Su and Tiantian Wang},
keywords = {CS2013, C programming course, CS curriculum planning, CS major ;},
abstract = {Computer Science Curriculum 2013 has become the guidance of computing education since it was released in 2013by the ACM/IEEE-Computer Society. This paper analyzes the CS curriculum development trend, trying to dig the programming-related core from CS2013 with respect to the knowledge areas, topics, organization of teaching, and the building of students’ capability. Considering the characteristic of our local institution and undergraduates, we present an updated teaching curriculum and lab curriculum for C Programming Language course in relation to CS2013 recommendations, which highlight the development of the students’ abilities on programming, problem-solving, self-regulated learning, and computational thinking. Finally, we present and assess the implementation of the resulting curriculum.}
}
@article{ROSSITER202473,
title = {A MATLAB virtual laboratory to support learning of auto-tuning PID approaches},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {7},
pages = {73-78},
year = {2024},
note = {4th IFAC Conference on Advances in Proportional-Integral-Derivate Control PID 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.013},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324007250},
author = {J.A. Rossiter and A. Visioli and S. Dormido and R. Bars},
keywords = {Control101 toolbox, PID compensation, virtual laboratories, independent learning},
abstract = {This paper presents a small number of MATLAB APPs and livescript files designed to help students both understand and implement PID tuning. The paper presents the thinking behind the use of MATLAB and the topic itself before then describing the proposed resources in detail. The resources split into files with detailed mathematical and coding background students can use for self-study and assignments, and a virtual laboratory which is more intuitive and interactive and useful for familiarisation with core concepts. The files were recently added to the control101 toolbox (Rossiter, 2023).}
}
@article{DOIRON2019iii,
title = {Editorial overview: Computational neuroscience},
journal = {Current Opinion in Neurobiology},
volume = {58},
pages = {iii-vii},
year = {2019},
note = {Computational Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959438819300728},
author = {Brent Doiron and Máté Lengyel}
}
@article{DOUKAS2013227,
title = {Modelling of linguistic variables in multicriteria energy policy support},
journal = {European Journal of Operational Research},
volume = {227},
number = {2},
pages = {227-238},
year = {2013},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2012.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0377221712008740},
author = {Haris Doukas},
keywords = {Decision support, Multicriteria analysis, Linguistic variables, Energy policy, Sustainable development},
abstract = {The climate change and the increasing complexity of the energy sector along with the prerequisite for sustainability have broadened the energy policy shaping field by bringing out new challenges. Decision support tools and methods, such as Multicriteria Decision Aid (MCDA), are necessary for energy policy, in the pursuit of appropriate approaches necessary to support the restructuring of the energy sector, concerning patterns of energy extraction, generation, transformation and use, from unsustainable to sustainable forms of development. Papers devoted to the investigation of MCDA models using linguistic variables for energy policy support seem to be not available in the international literature. The scope of this paper is to explore different linguistic representation and computational models in MCDA that are or can be applied to energy policy support and to establish a clear linkage between them. This paper argues that MCDA methodologies with direct computation on linguistic variables can support energy policy frameworks, bridging the gap between energy policy makers thinking, reasoning, representation and computing. Finally, current trends, open questions and prospects in this topic are pointed out.}
}
@article{CHANG20161,
title = {COMPUTATIONAL DESIGN in the past, present and future of digital architecture},
journal = {Automation in Construction},
volume = {72},
pages = {1-2},
year = {2016},
note = {Computational and generative design for digital fabrication: Computer-Aided Architectural Design Research in Asia (CAADRIA)},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2016.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S092658051630303X},
author = {Teng-Wen Chang and Tane J. Moleta and Daekwon Park}
}
@article{TREMOLIERE2012379,
title = {Mortality salience and morality: Thinking about death makes people less utilitarian},
journal = {Cognition},
volume = {124},
number = {3},
pages = {379-384},
year = {2012},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2012.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0010027712001035},
author = {Bastien Trémolière and Wim De Neys and Jean-François Bonnefon},
keywords = {Mortality salience, Moral judgment, Utilitarian responses, Cognitive resources},
abstract = {According to the dual-process model of moral judgment, utilitarian responses to moral conflict draw on limited cognitive resources. Terror Management Theory, in parallel, postulates that mortality salience mobilizes these resources to suppress thoughts of death out of focal attention. Consequently, we predicted that individuals under mortality salience would be less likely to give utilitarian responses to moral conflicts. Two experiments corroborated this hypothesis. Experiment 1 showed that utilitarian responses to non-lethal harm conflicts were less frequent when participants were reminded of their mortality. Experiment 2 showed that the detrimental effect of mortality salience on utilitarian conflict judgments was comparable to that of an extreme concurrent cognitive load. These findings raise the question of whether private judgment and public debate about controversial moral issues might be shaped by mortality salience effects, since these issues (e.g., assisted suicide) often involve matters of life and death.}
}
@article{DUGGAN2024101426,
title = {ChatGPT performance on radiation technologist and therapist entry to practice exams},
journal = {Journal of Medical Imaging and Radiation Sciences},
volume = {55},
number = {4},
pages = {101426},
year = {2024},
issn = {1939-8654},
doi = {https://doi.org/10.1016/j.jmir.2024.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S193986542400122X},
author = {Ryan Duggan and Kaitlyn M. Tsuruda},
keywords = {Radiography, Radiotherapy, Nuclear Medicine, Magnetic Resonance Imaging, AI (Artificial Intelligence), Natural Language Processing, Teaching, Educational Measurement},
abstract = {Background
The aim of this study was to describe the proficiency of ChatGPT (GPT-4) on certification style exams from the Canadian Association of Medical Radiation Technologists (CAMRT), and describe its performance across multiple exam attempts.
Methods
ChatGPT was prompted with questions from CAMRT practice exams in the disciplines of radiological technology, magnetic resonance (MRI), nuclear medicine and radiation therapy (87-98 questions each). ChatGPT attempted each exam five times. Exam performance was evaluated using descriptive statistics, stratified by discipline and question type (knowledge, application, critical thinking). Light's Kappa was used to assess agreement in answers across attempts.
Results
Using a passing grade of 65 %, ChatGPT passed the radiological technology exam only once (20 %), MRI all five times (100 %), nuclear medicine three times (60 %), and radiation therapy all five times (100 %). ChatGPT's performance was best on knowledge questions across all disciplines except radiation therapy. It performed worst on critical thinking questions. Agreement in ChatGPT's responses across attempts was substantial within the disciplines of radiological technology, MRI, and nuclear medicine, and almost perfect for radiation therapy.
Conclusion
ChatGPT (GPT-4) was able to pass certification style exams for radiation technologists and therapists, but its performance varied between disciplines. The algorithm demonstrated substantial to almost perfect agreement in the responses it provided across multiple exam attempts. Future research evaluating ChatGPT's performance on standardized tests should consider using repeated measures.
RÉSUMÉ
Contexte
L'objectif de cette étude était de décrire la compétence du ChatGPT (GPT-4) dans les examens d'agrément de l'Association canadienne des technologues en radiation médicale (ACTRM), et de décrire sa performance à travers plusieurs tentatives d'examen.
Méthodes
ChatGPT a été invité à répondre à des questions provenant des examens pratiques de l'ACTRM dans les disciplines de la technologie de radiologie, de la résonance magnétique (IRM), de la médecine nucléaire et de la radiothérapie (87-98 questions pour chaque discipline). ChatGPT a tenté chaque examen cinq fois. La performance à l'examen a été évaluée à l'aide de statistiques descriptives, stratifiées par discipline et par type de question (connaissances, application, réflexion critique). Le Kappa de Light a été utilisé pour évaluer la concordance des réponses entre les tentatives.
Résultats
En utilisant une note de passage de 65 %, ChatGPT a réussi l'examen de technologie de radiologie une seule fois (20 %), l'IRM les cinq fois (100 %), la médecine nucléaire trois fois (60 %), et la radiothérapie les cinq fois (100 %). Les performances de ChatGPT ont été les meilleures pour les questions de connaissances dans toutes les disciplines, à l'exception de la radiothérapie. Il a été le moins performant pour les questions de réflexion critique. La concordance des réponses du ChatGPT entre les tentatives était substantielle dans les disciplines de la technologie de radiologie, de l'IRM et de la médecine nucléaire, et presque parfaite pour la radiothérapie.
Conclusion
ChatGPT (GPT-4) a été capable de réussir les examens d'agrément pour les technologues en radiation médicale et les radiothérapeutes, mais ses performances ont varié selon les disciplines. L'algorithme a démontré une concordance substantielle à presque parfaite dans les réponses qu'il a fournies à travers de multiples tentatives d'examen. Les futures recherches évaluant les performances de ChatGPT sur des tests standardisés devraient envisager l'utilisation de mesures répétées.}
}
@article{WANG2014638,
title = {Computational Psychiatry},
journal = {Neuron},
volume = {84},
number = {3},
pages = {638-654},
year = {2014},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2014.10.018},
url = {https://www.sciencedirect.com/science/article/pii/S0896627314009167},
author = {Xiao-Jing Wang and John H. Krystal},
abstract = {Psychiatric disorders such as autism and schizophrenia, arise from abnormalities in brain systems that underlie cognitive, emotional, and social functions. The brain is enormously complex and its abundant feedback loops on multiple scales preclude intuitive explication of circuit functions. In close interplay with experiments, theory and computational modeling are essential for understanding how, precisely, neural circuits generate flexible behaviors and their impairments give rise to psychiatric symptoms. This Perspective highlights recent progress in applying computational neuroscience to the study of mental disorders. We outline basic approaches, including identification of core deficits that cut across disease categories, biologically realistic modeling bridging cellular and synaptic mechanisms with behavior, and model-aided diagnosis. The need for new research strategies in psychiatry is urgent. Computational psychiatry potentially provides powerful tools for elucidating pathophysiology that may inform both diagnosis and treatment. To achieve this promise will require investment in cross-disciplinary training and research in this nascent field.}
}
@article{BAKER2023238,
title = {13Ccarbene nuclear magnetic resonance chemical shift analysis confirms CeIVC double bonding in cerium(iv)–diphosphonioalkylidene complexes††Electronic supplementary information (ESI) available: Computational details. See DOI: https://doi.org/10.1039/d3sc04449a},
journal = {Chemical Science},
volume = {15},
number = {1},
pages = {238-249},
year = {2023},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d3sc04449a},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023058364},
author = {Cameron F. Baker and John A. Seed and Ralph W. Adams and Daniel Lee and Stephen T. Liddle},
abstract = {Diphosphonioalkylidene dianions have emerged as highly effective ligands for lanthanide and actinide ions, and the resulting formal metal–carbon double bonds have challenged and developed conventional thinking about f-element bond multiplicity and covalency. However, f-element–diphosphonioalkylidene complexes can be represented by several resonance forms that render their metal–carbon double bond status unclear. Here, we report an experimentally-validated 13C Nuclear Magnetic Resonance computational assessment of two cerium(iv)–diphosphonioalkylidene complexes, [Ce(BIPMTMS)(ODipp)2] (, BIPMTMS = {C(PPh2NSiMe3)2}2−; Dipp = 2,6-diisopropylphenyl) and [Ce(BIPMTMS)2] (). Decomposing the experimental alkylidene chemical shifts into their corresponding calculated shielding (σ) tensor components verifies that these complexes exhibit CeC double bonds. Strong magnetic coupling of CeC σ/π* and π/σ* orbitals produces strongly deshielded σ11 values, a characteristic hallmark of alkylidenes, and the largest 13C chemical shift tensor spans of any alkylidene complex to date (, 801 ppm; , 810 ppm). In contrast, the phosphonium-substituent shielding contributions are much smaller than the CeC σ- and π-bond components. This study confirms significant Ce 4f-orbital contributions to the CeC bonding, provides further support for a previously proposed inverse-trans-influence in , and reveals variance in the 4f spin–orbit contributions that relate to the alkylidene hybridisation. This work thus confirms the metal–carbon double bond credentials of f-element–diphosphonioalkylidenes, providing quantified benchmarks for understanding diphosphonioalkylidene bonding generally.}
}
@article{KANIZSA198523,
title = {Seeing and thinking},
journal = {Acta Psychologica},
volume = {59},
number = {1},
pages = {23-33},
year = {1985},
issn = {0001-6918},
doi = {https://doi.org/10.1016/0001-6918(85)90040-X},
url = {https://www.sciencedirect.com/science/article/pii/000169188590040X},
author = {G. Kanizsa},
abstract = {According to ratiomorphic theories of perception every visual phenomenon would be the result of unconscious inferences through which the visual system, starting from a set of axioms and premises, reaches certain conclusions (which constitute actually the visual phenomena) by a process analogous to a reasoning process. The author presents some examples from the area of amodal completion which, according to him, hardly support a ratiomorphic theory. Instead they constitute counterexamples that rather support the hypothesis that seeing and thinking function according to different rules.}
}
@article{LEONARDI2018824,
title = {A Method for the computation of entropy in the Recurrence Quantification Analysis of categorical time series},
journal = {Physica A: Statistical Mechanics and its Applications},
volume = {512},
pages = {824-836},
year = {2018},
issn = {0378-4371},
doi = {https://doi.org/10.1016/j.physa.2018.08.058},
url = {https://www.sciencedirect.com/science/article/pii/S0378437118309981},
author = {Giuseppe Leonardi},
keywords = {Recurrence Quantification Analysis, Entropy, Categorical time series, Dynamical measures, Recurrence Plot},
abstract = {In this work, I propose a new method for the computation of informational entropy from Recurrence Plots when the analyzed time series are categorical in nature. In such cases, there is typically a simplification in choosing the parameters of the analysis, in the sense that no embedding in multidimensional space is usually assumed and that recurrence is restricted to exact matching (equivalence) of the numerically coded categories. However, such a simplified parameterization brings about some notable changes in the appearance of the obtained Recurrence Plots, which has consequences for the extraction of the standard dynamical measures. Specifically, a categorical Recurrence Plot is often composed of rectangular structures rather than line structures (diagonal and horizontal/vertical), over which the recurrence quantification measures were originally proposed. Starting from this observation, I consider alternative computational procedures to extract a non-biased measure of entropy for the categorical case, showing the viability of such a choice with simulated data}
}
@article{YANG2013855,
title = {Computational Optimization, Modelling and Simulation: Recent Trends and Challenges},
journal = {Procedia Computer Science},
volume = {18},
pages = {855-860},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.250},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913003931},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, optimization algorithm, modelling, metaheursitics, nonlinear optimization, stochastic optimization, surragate-based optimization, simulation ;},
abstract = {Modelling, simulation and optimization form an integrated part of modern design practice in engineering and industry. Tremendous progress has been observed for all three components over the last few decades. However, many challenging issues remain unresolved, and the current trends tend to use nature-inspired algorithms and surrogate-based techniques for modelling and optimization. This 4th workshop on Computational Optimization, Modelling and Simulation (COMS 2013) at ICCS 2013 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry. In this review paper, we will analyse the recent trends in modelling and optimization, and their associated challenges. We will discuss important topics for further research, including parameter-tuning, large-scale problems, and the gaps between theory and applications.}
}
@article{MASELLI20235395,
title = {Computational analysis of five neurodegenerative diseases reveals shared and specific genetic loci},
journal = {Computational and Structural Biotechnology Journal},
volume = {21},
pages = {5395-5407},
year = {2023},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2023.10.031},
url = {https://www.sciencedirect.com/science/article/pii/S2001037023003835},
author = {Francesca Maselli and Salvatore D’Antona and Mattia Utichi and Matteo Arnaudi and Isabella Castiglioni and Danilo Porro and Elena Papaleo and Paolo Gandellini and Claudia Cava},
keywords = {Neurodegenerative diseases, Bioinformatics, GWAS, SNPs},
abstract = {Neurodegenerative diseases (ND) are heterogeneous disorders of the central nervous system that share a chronic and selective process of neuronal cell death. A computational approach to investigate shared genetic and specific loci was applied to 5 different ND: Amyotrophic lateral sclerosis (ALS), Alzheimer's disease (AD), Parkinson's disease (PD), Multiple sclerosis (MS), and Lewy body dementia (LBD). The datasets were analyzed separately, and then we compared the obtained results. For this purpose, we applied a genetic correlation analysis to genome-wide association datasets and revealed different genetic correlations with several human traits and diseases. In addition, a clumping analysis was carried out to identify SNPs genetically associated with each disease. We found 27 SNPs in AD, 6 SNPs in ALS, 10 SNPs in PD, 17 SNPs in MS, and 3 SNPs in LBD. Most of them are located in non-coding regions, with the exception of 5 SNPs on which a protein structure and stability prediction was performed to verify their impact on disease. Furthermore, an analysis of the differentially expressed miRNAs of the 5 examined pathologies was performed to reveal regulatory mechanisms that could involve genes associated with selected SNPs. In conclusion, the results obtained constitute an important step toward the discovery of diagnostic biomarkers and a better understanding of the diseases.}
}
@article{MISZTAL2017731,
title = {Invited review: efficient computation strategies in genomic selection},
journal = {Animal},
volume = {11},
number = {5},
pages = {731-736},
year = {2017},
issn = {1751-7311},
doi = {https://doi.org/10.1017/S1751731116002366},
url = {https://www.sciencedirect.com/science/article/pii/S1751731116002366},
author = {I. Misztal and A. Legarra},
keywords = {genomic selection, single-step, genomic relationship matrix, inverse, REML},
abstract = {The purpose of this study is review and evaluation of computing methods used in genomic selection for animal breeding. Commonly used models include SNP BLUP with extensions (BayesA, etc), genomic BLUP (GBLUP) and single-step GBLUP (ssGBLUP). These models are applied for genomewide association studies (GWAS), genomic prediction and parameter estimation. Solving methods include finite Cholesky decomposition possibly with a sparse implementation, and iterative Gauss–Seidel (GS) or preconditioned conjugate gradient (PCG), the last two methods possibly with iteration on data. Details are provided that can drastically decrease some computations. For SNP BLUP especially with sampling and large number of SNP, the only choice is GS with iteration on data and adjustment of residuals. If only solutions are required, PCG by iteration on data is a clear choice. A genomic relationship matrix (GRM) has limited dimensionality due to small effective population size, resulting in infinite number of generalized inverses of GRM for large genotyped populations. A specific inverse called APY requires only a small fraction of GRM, is sparse and can be computed and stored at a low cost for millions of animals. With APY inverse and PCG iteration, GBLUP and ssGBLUP can be applied to any population. Both tools can be applied to GWAS. When the system of equations is sparse but contains dense blocks, a recently developed package for sparse Cholesky decomposition and sparse inversion called YAMS has greatly improved performance over packages where such blocks were treated as sparse. With YAMS, GREML and possibly single-step GREML can be applied to populations with >50 000 genotyped animals. From a computational perspective, genomic selection is becoming a mature methodology.}
}
@article{PATAC2025101301,
title = {Using ChatGPT for academic support: Managing cognitive load and enhancing learning efficiency – A phenomenological approach},
journal = {Social Sciences & Humanities Open},
volume = {11},
pages = {101301},
year = {2025},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2025.101301},
url = {https://www.sciencedirect.com/science/article/pii/S2590291125000282},
author = {Louida P. Patac and Adriano V. Patac},
keywords = {Cognitive load theory, ChatGPT, AI in education, Academic support, Mathematics education, Phenomenology},
abstract = {This study aims to discuss the effects of ChatGPT on the management of students' cognitive load and learning outcomes. Participants used ChatGPT for answering particular questions, checking information, and solving complex problems involving equations. Results show that ChatGPT lowers intrinsic and extrinsic cognitive load with very detailed responses and efficient search for information, even though it has difficulties in entering mathematical notation. Students consider that ChatGPT is a tool able to enhance understanding, engage, and promote critical thinking. These findings underline that the level of AI assistance must be balanced against independent learning and critical evaluation.}
}
@article{LIU2021110585,
title = {Computational insights into electronic characteristics of 2D PtSe2 nanomaterials: Effects of vacancy defects and strain engineering},
journal = {Vacuum},
volume = {194},
pages = {110585},
year = {2021},
issn = {0042-207X},
doi = {https://doi.org/10.1016/j.vacuum.2021.110585},
url = {https://www.sciencedirect.com/science/article/pii/S0042207X21005340},
author = {Guogang Liu and Tong Chen and Zhonghui Xu and Guanghui Zhou and Xianbo Xiao},
keywords = {PtSe, Electronic structure, Defects, Strain engineering},
abstract = {The epitaxial growth of PtSe2 monolayer has brings new opportunities for the application and development of materials science. Using first-principles calculations, the effect of vacancy defects, and strain engineering on the electronic properties of PtSe2 monolayer are systematically investigated. The results show that the Pt single vacancy induces a large magnetic moment of 4.0 μB on PtSe2 monolayer and transforms it from semiconductor to metal. However, the Se single vacancy systems are nonmagnetic and realize the PtSe2 from an indirect semiconductor to a direct one. Moreover, the band gap of PtSe2 monolayer can be prominently modulated within a appreciable uniaxial strain range, and the band gap are monotonically increase/decrease as decrease/increase the magnitude of the compressive/tensile strain. In particular, when a specific strain applied, a wide and high absorption peak across near-infrared, visible light and ultraviolet region. These findings not only enrich the fundamental understanding of PtSe2 monolayer but also provide useful guidance to design PtSe2-based spintronic, optoelectronic and gas sensing applications.}
}
@incollection{HARDIN2025519,
title = {Disinformation, Misinformation, and Fake News: The Latest Trends and Issues in Research},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {519-530},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00171-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895001711},
author = {Greg Hardin},
keywords = {Disinformation, Evaluating sources, Fake news, Information literacy, Malinformation, Misinformation},
abstract = {Information comes in many forms and there are various ways in which false or fabricated information travels throughout the information ecosystem. Fake news, disinformation, misinformation, and malinformation have similarities and differences, but all have in common that they cause harm. Understanding misinformation in all its various forms is key to minimizing the negative effects on individuals and society. While it may be impossible to eradicate misinformation in all its various forms, librarians have a history of and are poised to promote information literacy and critical thinking skills.}
}
@incollection{BARTHEYE2020385,
title = {Chapter 19 - Human-machine sense making in context-based computational decision},
editor = {William F. Lawless and Ranjeev Mittu and Donald A. Sofge},
booktitle = {Human-Machine Shared Contexts},
publisher = {Academic Press},
pages = {385-398},
year = {2020},
isbn = {978-0-12-820543-3},
doi = {https://doi.org/10.1016/B978-0-12-820543-3.00019-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128205433000195},
author = {Olivier Bartheye and Laurent Chaudron},
keywords = {Human/machine sense making, Knowledge processing, Decision mechanism, Causal break, Hopf algebras, Computational contexts, Continuous inference},
abstract = {In this chapter, we present what should be the inner structure of a decision algebra whose motivation is to fill a causal break induced by context invalidity to ultimately permit human-machine interactions. It turns out that such a decision structure can be qualified using the context change arrow as a disruptive process or as a phase transition according to the geometrical representation of computational contexts as double S-curves. In particular a computational context is always characterized by a shift between sense making and temporal causality. That is, once a causal break occurs, it has to be filled locally by a decision. A causal break is always continuous and never discrete; in effect, in the discrete case, combinatoric analysis causes unwanted complexity due to a lack of knowledge, whereas we need full knowledge thanks to a very precise semantic of a causal break. Intuitively, rather than separating brutally models and counter-models as a proof can do by setting a strong negation operator, we prefer to use the continuous inference as an implementation of sense making. Sense is that way taken as the rationality of the transition. Full knowledge requires a special structure, a Hopf algebra in which the continuous property we cannot implement is replaced by the computable co-continuous property in the co-algebraic component of the decision Hopf algebra. We hope that thanks to co-continuous structures and to co-dimensional exterior algebras, we’ll be able to find out a representation of the continuous inference able to compute a decision rather than admitting definitely and desperately that “such a mechanism is totally out of bounds” and will never ever concern a machine.}
}
@incollection{PENN2006338,
title = {Symbolic Computational Linguistics: Overview},
editor = {Keith Brown},
booktitle = {Encyclopedia of Language & Linguistics (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {338-352},
year = {2006},
isbn = {978-0-08-044854-1},
doi = {https://doi.org/10.1016/B0-08-044854-2/00875-0},
url = {https://www.sciencedirect.com/science/article/pii/B0080448542008750},
author = {G. Penn},
keywords = {computational linguistics, concept ontologies, lambda calculus, logic, phrase structure trees, typed feature structures},
abstract = {Symbolic computational linguistics is a diverse body of research that uses logical, graphical and other discrete mathematical representations to model structure and meaning at the various levels of linguistic investigation. This article provides an informal introduction to these representations, along with a discussion of their applications.}
}
@article{NEWHALL2025105044,
title = {An introductory-level undergraduate CS course that introduces parallel computing},
journal = {Journal of Parallel and Distributed Computing},
volume = {199},
pages = {105044},
year = {2025},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2025.105044},
url = {https://www.sciencedirect.com/science/article/pii/S0743731525000115},
author = {Tia Newhall and Kevin C. Webb and Vasanta Chaganti and Andrew Danner},
keywords = {CS curriculum, Parallel computing, Introductory CS},
abstract = {We present the curricular design, pedagogy, and goals of an introductory-level course on computer systems that introduces parallel and distributed computing (PDC) to students who have only a CS1 background. With the ubiquity of multicore processors, cloud computing, and hardware accelerators, PDC topics have become fundamental knowledge areas in the undergraduate CS curriculum. As a result, it is increasingly important for students to learn a common core of introductory parallel and distributed computing topics and to develop parallel thinking skills early in their CS studies. Our introductory-level course focuses on three main curricular goals: 1) understanding how a computer runs a program, 2) evaluating system costs associated with running a program, and 3) taking advantage of the power of parallel computing. We elaborate on the goals and details of our course's key modules, and we discuss our pedagogical approach that includes active-learning techniques. We also include an evaluation of our course and a discussion of our experiences teaching it since Fall 2012. We find that the PDC foundation gained through early exposure in our course helps students gain confidence in their ability to expand and apply their understanding of PDC concepts throughout their CS education.}
}
@incollection{OREILLY2019317,
title = {Chapter 17 - Computational models of motivated frontal function},
editor = {Mark D'Esposito and Jordan H. Grafman},
series = {Handbook of Clinical Neurology},
publisher = {Elsevier},
volume = {163},
pages = {317-332},
year = {2019},
booktitle = {The Frontal Lobes},
issn = {0072-9752},
doi = {https://doi.org/10.1016/B978-0-12-804281-6.00017-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128042816000173},
author = {Randall C. O’Reilly and Jacob Russin and Seth A. Herd},
keywords = {Computational models, Frontal cortex, Basal ganglia, Goal-directed, Motivation, Working memory, Reinforcement learning},
abstract = {Computational models of frontal function have made important contributions to understanding how the frontal lobes support a wide range of important functions, in their interactions with other brain areas including, critically, the basal ganglia (BG). We focus here on the specific case of how different frontal areas support goal-directed, motivated decision-making, by representing three essential types of information: possible plans of action (in more dorsal and lateral frontal areas), affectively significant outcomes of those action plans (in ventral, medial frontal areas including the orbital frontal cortex), and the overall utility of a given plan compared to other possible courses of action (in anterior cingulate cortex). Computational models of goal-directed action selection at multiple different levels of analysis provide insight into the nature of learning and processing in these areas and the relative contributions of the frontal cortex versus the BG. The most common neurologic disorders implicate these areas, and understanding their precise function and modes of dysfunction can contribute to the new field of computational psychiatry, within the broader field of computational neuroscience.}
}
@article{LEONELLI201229,
title = {Re-thinking organisms: The impact of databases on model organism biology},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {43},
number = {1},
pages = {29-36},
year = {2012},
note = {Data-Driven Research in the Biological and Biomedical Sciences On Nature and Normativity: Normativity, Teleology, and Mechanism in Biological Explanation},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2011.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1369848611000793},
author = {Sabina Leonelli and Rachel A. Ankeny},
keywords = {Database, Data, Model organism, Data-intensive science, Curator},
abstract = {Community databases have become crucial to the collection, ordering and retrieval of data gathered on model organisms, as well as to the ways in which these data are interpreted and used across a range of research contexts. This paper analyses the impact of community databases on research practices in model organism biology by focusing on the history and current use of four community databases: FlyBase, Mouse Genome Informatics, WormBase and The Arabidopsis Information Resource. We discuss the standards used by the curators of these databases for what counts as reliable evidence, acceptable terminology, appropriate experimental set-ups and adequate materials (e.g., specimens). On the one hand, these choices are informed by the collaborative research ethos characterising most model organism communities. On the other hand, the deployment of these standards in databases reinforces this ethos and gives it concrete and precise instantiations by shaping the skills, practices, values and background knowledge required of the database users. We conclude that the increasing reliance on community databases as vehicles to circulate data is having a major impact on how researchers conduct and communicate their research, which affects how they understand the biology of model organisms and its relation to the biology of other species.}
}
@article{SNIDER2021108795,
title = {Reinforcer pathology in cocaine use disorder: Temporal window determines cocaine valuation},
journal = {Drug and Alcohol Dependence},
volume = {225},
pages = {108795},
year = {2021},
issn = {0376-8716},
doi = {https://doi.org/10.1016/j.drugalcdep.2021.108795},
url = {https://www.sciencedirect.com/science/article/pii/S0376871621002908},
author = {Sarah E. Snider and Jamie K. Turner and Samuel M. McClure and Warren K. Bickel},
keywords = {Reinforcer pathology, Experimental medicine approach, Episodic future thinking, Delay discounting, Behavioral economic demand, Cocaine use disorder},
abstract = {Aims
The Experimental Medicine Approach offers a unique perspective to determine clinical behavior change by engaging a target underlying the cause of a disorder. The present work engaged a novel target of addiction, Reinforcer Pathology, in two studies to test changes in behavior among individuals with cocaine use disorder.
Methods
In Study 1, n = 44 participants engaged the temporal window with episodic future thinking (EFT), a positive prospection exercise. Changes in temporal view and cocaine valuation were tested using delay discounting and behavioral economic demand, respectively. Additionally, a computational model assessed the relative reliance on the near- and far-sighted systems during EFT. In Study 2, n = 71 engaged the temporal window with a negatively-valenced hurricane scenario to test the opposite effects on window length and cocaine valuation.
Results
Results demonstrated systematic and symmetrical engagement of the behavioral target. Study 1 robustly replicated previous work, wherein EFT lengthened the temporal window and decreased cocaine valuation. Moreover, EFT increased the weighting of the modeled far-sighted system, increasing the relative impact of long-term discounting decisions. Study 2 produced opposite outcomes, shortened temporal window and increased cocaine valuation.
Conclusions
This approximately equal and opposite reaction to the manipulations supports reinforcer pathology theory and implicates the temporal window over which rewards are valued as a target to be pushed and pulled to produce clinically meaningful behavior change. Using the Experimental Medicine Approach as a guide, future work should identify new potential interventions to engage reinforcer pathology and use the clinically relevant outcomes as a litmus test for mechanism.}
}