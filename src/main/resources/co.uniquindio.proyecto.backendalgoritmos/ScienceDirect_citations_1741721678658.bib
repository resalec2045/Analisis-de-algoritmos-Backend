@article{FUCHS2023103688,
title = {A post-Cartesian economic and Buddhist view on tourism},
journal = {Annals of Tourism Research},
volume = {103},
pages = {103688},
year = {2023},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2023.103688},
url = {https://www.sciencedirect.com/science/article/pii/S0160738323001615},
author = {Matthias Fuchs},
keywords = {Economic growth ideology, Post-Cartesian ontology, Post-mechanistic economic theory, Buddhist philosophy, Transformative tourism},
abstract = {Insuperable socio-economic and ecological crises demonstrate the need to challenge economic growth ideology that is often embedded in contemporary tourism science. By borrowing from Buddhist philosophy this essay describes inconsistencies in economic theorizing due to its adoption of the Cartesian ontology implying a mechanistic thinking form. Following philosopher Brodbeck (2014), economic science is neither an empirically exact science nor value-free but represents an implicit ethics. To build on this, the elements of a post-mechanistic economic theory are sketched (Brodbeck, 2001). The applicability of this concept is corroborated by instances of current tourism research. After reinterpreting the homo economicus and the nature of money an agenda for a transformative tourism science building upon post-Cartesian economic thinking and Buddhist philosophy is elaborated.}
}
@incollection{DELLANGELO2022299,
title = {13 - Computational chemistry and the study and design of catalysts},
editor = {Liliana Mammino},
booktitle = {Green Chemistry and Computational Chemistry},
publisher = {Elsevier},
pages = {299-332},
year = {2022},
series = {Advances in Green and Sustainable Chemistry},
isbn = {978-0-12-819879-7},
doi = {https://doi.org/10.1016/B978-0-12-819879-7.00010-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128198797000106},
author = {David Dell’Angelo},
keywords = {CO capture, conversion and utilization, Energy storage, Free energy techniques, Metal-organic frameworks (MOFs), Nanohazard simulations, Photocatalysis technologies, Roles of catalysis in green chemistry, Simulation methods in molecular modelling, Solvent effects on chemical reactivity, Zeolites and catalysis},
abstract = {Several theoretical and computational chemistry works may yield results that prove useful for a better understanding of phenomena relevant to green chemistry, or may specifically focus on addressing green chemistry issues. This chapter presents an overview of results of this type, considering their various application areas. At the same time, it devotes particular attention to the roles that computationally obtained information may play for an efficient design of catalysts and for a better understanding of catalytic processes. This particular attention is motivated by the fundamental roles of catalysis in the design of ‘greener’ processes, where ‘greener’ may refer to a variety of aspects, such as the use of safer reactants and products, the use of benign solvents, the increase in energy efficiency and other features that make a process more environmentally friendly.}
}
@article{SUO2024109268,
title = {A review of three-way decision: Triadic understanding, organization, and perspectives},
journal = {International Journal of Approximate Reasoning},
volume = {173},
pages = {109268},
year = {2024},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109268},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24001555},
author = {Langwangqing Suo and Han Yang and Qiaoyi Li and Hai-Long Yang and Yiyu Yao},
keywords = {Three-way decision, Triadic thinking, Three-way literature review,  method, Three-way bibliometrics analytics},
abstract = {A theory of three-way decision is about thinking, problem-solving, and computing in threes or through triads. In this paper, we review fifteen years of research on three-way decision by using the philosophy-theory-application triad and the who-what-when triad. First, we discuss the philosophy, theory, and application of three-way decision. At the philosophy level, we delve into the philosophical roots and fundamental nature of three-way decision to reveal the underlying philosophical thinking. At the theory level, we provide an insightful analysis of the theory and methodology of three-way decision. At the application level, we examine the integration of three-way decision with other theories and their applications and effectiveness in real-world scenarios. Second, we focus on bibliometrics analytics by using the who-what-when triad, which attempts to answer a fundamental question of “who did what when”. We propose a 3×3 model by applying the 3×3 method of three-way decision. The first 3 is the author-topic-time triad. The second 3 represents a three-level analysis for each of the first three: (1) categorizing authors into the three levels of prolific authors, frequent authors, and occasional authors, (2) classifying topics into the three levels of the core topics, emerging topics, and to-be-explored topics, and (3) dividing articles into the three levels of initial investigations, further developments, and most recent studies. Finally, we perform a bibliometrics analysis of three-way decision articles by using the 3×3 model of three-way decision. The results not only reveal the current status and trend of three-way decision research but also provide a road map for future research.}
}
@article{FERGUSON2024286,
title = {Social uncertainty in the digital world},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {4},
pages = {286-289},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000329},
author = {Amanda M. Ferguson and Georgia Turner and Amy Orben},
keywords = {Bayesian inference, digital affordances, social media, social uncertainty},
abstract = {The social world is inherently uncertain. We present a computational framework for thinking about how increasingly popular online environments modulate the social uncertainty we experience, depending on the type of social inferences we make. This framework draws on Bayesian inference, which involves combining multiple informational sources to update our beliefs.}
}
@article{YERION20151967,
title = {An Introductory Course in the Computational Modeling of Nature},
journal = {Procedia Computer Science},
volume = {51},
pages = {1967-1976},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.461},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915012697},
author = {Kathie A. Yerion},
keywords = {Modeling, Agent-based, System-dynamics},
abstract = {This introductory course in computational modeling of nature contains the development of three kinds of models of phenomena in nature -- agent-based models and simple finite difference models using the environment of the NetLogo language and complex finite difference models using the language of C++. No prior programming experience is assumed. The natural phenomena modeled include some standard ones (e.g. ants following pheromone trails, the interaction of sheep and wolves) and some non-standard ones (the creation of the world, 3 dogs playing games, and formation of stripes and spots in the skins of animals). The emphasis of the course is on the modeling process. A distinguishing feature is that students are able to compare and critique these models.}
}
@article{BOERS2025100095,
title = {Exploring cognitive strategies in human-AI interaction: ChatGPT's role in creative tasks},
journal = {Journal of Creativity},
volume = {35},
number = {1},
pages = {100095},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2025.100095},
url = {https://www.sciencedirect.com/science/article/pii/S2713374525000020},
author = {Jelle Boers and Terra Etty and Martine Baars and Kim {van Boekhoven}},
keywords = {Human-AI interaction, Cognitive strategies, Creativity, Higher education},
abstract = {This study investigated the cognitive strategies employed by dyads when utilizing ChatGPT's examples to generate ideas in creative tasks. Fourteen university students generated ideas for both function-first and form-first creative tasks in interaction with ChatGPT. Their 591 turns were analyzed using both self-reports and coded transcripts to categorize cognitive strategies such as conceptual combination, inspiration, improvement, and repetition. The results indicated that students less frequently employ cognitive strategies focusing on human-AI interaction (e.g., inspiration, improve, combine), but that most of the ideas were produced by repeating ChatGPT's idea. This tendency suggests that, when given freedom, students may rely heavily on AI-generated suggestions rather than actively engaging in more complex cognitive processes. A key practical implication of these findings is the importance of educating students on different cognitive strategies they can adopt in collaboration with AI tools. By guiding students to employ more diverse and active cognitive strategies, ChatGPT has the potential to become a more effective tool for enhancing creative thinking in higher education.}
}
@article{GISSEL201661,
title = {A case of fixed asset accounting: Initial and subsequent measurement},
journal = {Journal of Accounting Education},
volume = {37},
pages = {61-66},
year = {2016},
issn = {0748-5751},
doi = {https://doi.org/10.1016/j.jaccedu.2016.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0748575116300422},
author = {Jodi L. Gissel},
keywords = {Fixed asset acquisition, Depreciation, Interest capitalization, Nonmonetary exchange, Impairment, IFRS},
abstract = {This instructional case integrates multiple accounting concepts relating to fixed asset acquisition and subsequent measurement. You must apply accounting knowledge, professional judgment, and critical thinking skills to evaluate fixed assets and make recommendations. You must also analyze differences between fixed asset accounting under US generally accepted accounting principles and IFRS. As a student, you generally understand basic application of asset cost computation that simply recognizes the amount of cash paid for acquiring the asset. However, determining asset cost becomes challenging when you encounter more complex situations. You must consider initial measurement issues relating to a land purchase (demolition of existing building and a special assessment expenditure), interest capitalization for a self-constructed building, a nonmonetary asset exchange, and an asset retirement obligation. The case also considers subsequent measurement issues in terms of depreciation (straight-line and accelerated methods), replacement of an asset component, and impairment. The case structure is flexible and the teaching notes include alternatives for using scaled-down versions.}
}
@article{LIU20111907,
title = {The effect of simulation games on the learning of computational problem solving},
journal = {Computers & Education},
volume = {57},
number = {3},
pages = {1907-1918},
year = {2011},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2011.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0360131511000832},
author = {Chen-Chung Liu and Yuan-Bang Cheng and Chia-Wen Huang},
keywords = {Game-based learning, Problem solving, Simulation, Flow experience},
abstract = {Simulation games are now increasingly applied to many subject domains as they allow students to engage in discovery processes, and may facilitate a flow learning experience. However, the relationship between learning experiences and problem solving strategies in simulation games still remains unclear in the literature. This study, thus, analyzed the feedback and problem solving behaviors of 117 students in a simulation game, designed to assist them to learn computational problem solving. It was found that students when learning computational problem solving with the game were more likely to perceive a flow learning experience than in traditional lectures. The students’ intrinsic motivation was also enhanced when they learned with the simulation game. In particular, the results of the study found a close association between the students’ learning experience states and their problem solving strategies. The students who perceived a flow experience state frequently applied trial-and-error, learning-by-example, and analytical reasoning strategies to learn the computational problem solving skills. However, a certain portion of students who experienced states of boredom and anxiety did not demonstrate in-depth problem solving strategies. For instance, the students who felt anxious in the simulation game did not apply the learning-by-example strategy as frequently as those in the flow state. In addition, the students who felt bored in the simulation game only learned to solve the problem at a superficial level.}
}
@article{HAWTHORNE2022100931,
title = {Reconceptualizing a mathematical domain on the basis of student reasoning: Considering teachers’ perspectives about integers},
journal = {The Journal of Mathematical Behavior},
volume = {65},
pages = {100931},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100931},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000924},
author = {Casey Hawthorne and Randolph A. Philipp and Lisa L. Lamb and Jessica P. Bishop and Ian Whitacre and Bonnie P. Schappelle},
keywords = {Integers, Student thinking, Mathematical knowledge for teaching},
abstract = {Integers have historically been approached as a system of rules. However, to teach any mathematical domain for understanding, teachers must conceptualize it as comprised of more than procedures. Using as a lens the four types of integer reasoning identified by Bishop et al. (2014a, 2014b), we interviewed 7th-grade teachers to investigate their own integer reasoning and how this corresponds to their approaches to teaching integers and to their interpretations of students’ reasoning. The teachers not only correctly solved integer tasks but also most reasoned using more than rules, demonstrating a flexibility of strategies. Additionally, although they attempted to introduce integers in meaningful ways, most teachers viewed teaching integers as helping their students apply procedures, an orientation that constrained their understanding of students’ integer reasoning. Results indicate that teachers possess productive conceptual resources but need a structure to leverage their understandings to teach integers as more than a set of rules.}
}
@article{LETONSAARI2017131,
title = {Modeling computational algorithms using nonlinear storytelling methods of computer game design},
journal = {Procedia Computer Science},
volume = {119},
pages = {131-138},
year = {2017},
note = {6th International Young Scientist Conference on Computational Science, YSC 2017, 01-03 November 2017, Kotka, Finland},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.11.169},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917323797},
author = {Mika Letonsaari and Jukka Selin},
keywords = {Twine, visual programming, rapid prototyping, algorithm design, digital storytelling},
abstract = {Computational algorithms can be described in many methods and implemented in many languages. Here we present an approach using storytelling methods of computer game design in modeling some finite-state machine algorithms and applications requiring user interaction. An open source software Twine is used for the task. Interactive nonlinear stories created with Twine are applications that can be executed in a web browser. Storytelling approach provides an easy-to-understand view on computational algorithms allowing communication with people with no computer science education. It also allows rapid prototyping and testing in mixed background work teams.}
}
@article{LIU2024100642,
title = {A systematic review on how educators teach AI in K-12 education},
journal = {Educational Research Review},
volume = {45},
pages = {100642},
year = {2024},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2024.100642},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X24000514},
author = {Xiaofan Liu and Baichang Zhong},
keywords = {K-12 education, AI education, AI literacy, Research design, Teaching practice},
abstract = {Developing Artificial Intelligence (AI) education in K-12 contexts, i.e., teaching students about AI, is critical to promote students' AI literacy. However, the state-of-the-art of AI education is not clear enough. To this end, this study reviewed 45 high-quality empirical studies on K-12 AI education over the past decade from both research and instruction perspectives. Regarding the research design, this study revealed the relationship between publication year, sample size, learning stage, educational setting, research method, research focus and duration. Regarding the instruction design, this study revealed the relationship between learning stage, pedagogical strategy, learning tool, learning activity, learning content, assessment method and learning effect. Besides, this study also derived recommendations for research (i.e., time allocation, samples selection, longitudinal design, rigorous methodology and technical democracy) and instruction (i.e., group learning, authentic context, teacher involvement, triangular evidence and learning scaffolding). Overall, the main findings indicate that K-12 AI education has the potential to develop students’ AI literacy, which contains AI knowledge, AI affectivity, and AI thinking. However, deficiencies in research and instructional design still remain, including short durations, small sample sizes, non-standardized research methods, lack of long-term and cross-age AI curriculum, etc. This study also discussed several critical topics for future research and instruction.}
}
@incollection{IACOBONI2000523,
title = {17 - Mapping Human Cognition: Thinking, Numerical Abilities, Theory of Mind, Consciousness},
editor = {Arthur W. Toga and John C. Mazziotta},
booktitle = {Brain Mapping: The Systems},
publisher = {Academic Press},
address = {San Diego},
pages = {523-534},
year = {2000},
isbn = {978-0-12-692545-6},
doi = {https://doi.org/10.1016/B978-012692545-6/50019-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780126925456500192},
author = {Marco Iacoboni},
abstract = {Publisher Summary
This chapter discusses the mapping the brain activity associated with complex cognitive functions—problem solving, reasoning, numerical processing, and consciousness. One of the most widely used tasks in brain mapping studies of problem solving is the Raven's progressive matrices. The role of frontoparietal circuits in numerical cognition has been confirmed by a positron emission tomography (PET) investigation of number multiplication and number comparison, in which bilateral frontoparietal networks are activated during both tasks. Various other regions are also found activated in this investigation, in which an exploratory, hypotheses-generating approach determined relatively “liberal” statistical thresholds. The consciousness of action is an important component of consciousness. However, the most common approach to the study of consciousness and its neural counterpart in cognitive neuroscience is via perception and visual awareness. A variety of brain mapping techniques, from PET and functional magnetic resonance imaging to electrical scalp recording, have been already used in investigations directly addressing visual awareness in normal subjects and patients with neurological disorders. A paradigm that is extremely suitable for the examination of conscious perception is binocular rivalry. A different mapping approach to the study of conscious perception is the mapping of temporal neural events.}
}
@article{SHENGLAI20124318,
title = {Study on Simulation Modeling and Approximate Synchronous Computation Technology for the Active Structural Stiffness Design},
journal = {Procedia Engineering},
volume = {29},
pages = {4318-4324},
year = {2012},
note = {2012 International Workshop on Information and Electronics Engineering},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2012.01.664},
url = {https://www.sciencedirect.com/science/article/pii/S1877705812006741},
author = {Xia Shenglai and He Jingwu and Chu Hongyu and Yang Xuan},
keywords = {active structural stiffness design (ASSD), stiffness criterion, simulation modeling, computation analysis, section stiffness},
abstract = {In the past, structure design mainly adopted strength criterion. At the same time, many problems occurred due to structural stiffness deficiency. In order to resolve many practical problems resulted from structural stiffness in aircraft structure, and draw out structural potential better, the design idea of active structural stiffness, namely, the method of active structural stiffness design (ASSD) is put forward at the beginning of the structure design. For ASSD, there are three key factors should be considered, that is, stiffness criterion, simulation modeling and computation analysis. In this paper, stiffness criterion, which is important at the preliminary stage of structural design, will be researched; Simulation modeling adopts parametric modeling technology; computation analysis is based on engineering beam theory, which is compiled and embedded into CATIA to compute structural stiffness. Using simulation modeling and computation analysis technologies, ASSD can be achieved quickly and conveniently.}
}
@article{EDELMAN201791,
title = {Language and other complex behaviors: Unifying characteristics, computational models, neural mechanisms},
journal = {Language Sciences},
volume = {62},
pages = {91-123},
year = {2017},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2017.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0388000117300128},
author = {Shimon Edelman},
abstract = {Similar to other complex behaviors, language is dynamic, social, multimodal, patterned, and purposive, its purpose being to promote desirable actions or thoughts in others and self (Edelman, 2017b). An analysis of the functional characteristics shared by complex sequential behaviors suggests that they all present a common overarching computational problem: dynamically controlled constrained navigation in concrete or abstract situation spaces. With this conceptual framework in mind, I compare and contrast computational models of language and evaluate their potential for explaining linguistic behavior and for elucidating the brain mechanisms that support it.}
}
@article{FIGLIOLIA2020102968,
title = {An FPGA multiprocessor architecture for Bayesian online change point detection using stochastic computation},
journal = {Microprocessors and Microsystems},
volume = {74},
pages = {102968},
year = {2020},
issn = {0141-9331},
doi = {https://doi.org/10.1016/j.micpro.2019.102968},
url = {https://www.sciencedirect.com/science/article/pii/S0141933119304727},
author = {Tomas Figliolia and Andreas G. Andreou},
keywords = {Changepoint analysis, Changepoint detection, Image segmentation, Bayesian inference, On-line algorithm, Stochastic processing, Precision on demand, ASIC, VHDL, Probabilistic event representation},
abstract = {In this paper we report on an event-based stochastic architecture for the Adams/McKay Bayesian Online Change Point Detection algorithm (BOCPD) [1]. In the stochastic computational structures, probabilities are represented natively as stochastic events and computation is carried out directly with these probabilities and not probability density functions. A fully programmable BOCPD processor is synthesized in VHDL. The BOCPD algorithm with on-line learning, to perform foreground/background image segmentation with online learning. Running on a single Kintex 7 FPGA (Opal Kelly XEM7350-K410T) the architecture is capable of real-time processing a 160 × 120 pixels image, at 10 frames per second.}
}
@article{GRIGORIADIS2022618,
title = {Computational and conceptual blends: Material considerations and agency in a multi-material design workflow},
journal = {Frontiers of Architectural Research},
volume = {11},
number = {4},
pages = {618-629},
year = {2022},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2022.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S2095263522000449},
author = {Kostas Grigoriadis},
keywords = {Digital design, Multi-materials, Computer simulation, Material agency, Materially anchored conceptual blends},
abstract = {The assimilation of functionally graded (or multi-) materials into architecture is deemed to enable the rethinking of current architectural design practice and bring back material considerations at the heart of the early design process. In response, the paper outlines a functionally graded material (FGM) design workflow that departs from standard early-stage CAD, which is typically performed via computer elements devoid of materiality. It then analyses this workflow from a theoretical perspective, namely through Edwin Hutchins' materially anchored conceptual blending, Lambros Malafouris' Material Engagement Theory (MET) and John Searle's concepts of intentionality. The aim is to demonstrate that due to the superimposition of material considerations that precede and succeed the CAD operation, working with material-less entities during early-stage FGM design is not logically sustainable. Additionally, multi-materiality allows for the questioning of authorship in the design process and leads to a repositioning of agency from the subject to the locus of engagement with digital materials and their affordances.}
}
@article{LI2024108089,
title = {Population characteristic exploitation-based multi-orientation multi-objective gene selection for microarray data classification},
journal = {Computers in Biology and Medicine},
volume = {170},
pages = {108089},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108089},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524001732},
author = {Min Li and Rutun Cao and Yangfan Zhao and Yulong Li and Shaobo Deng},
keywords = {Gene selection, Microarray data, Multi-orientation, Multi-objective, Reverse thinking},
abstract = {Gene selection is a process of selecting discriminative genes from microarray data that helps to diagnose and classify cancer samples effectively. Swarm intelligence evolution-based gene selection algorithms can never circumvent the problem that the population is prone to local optima in the process of gene selection. To tackle this challenge, previous research has focused primarily on two aspects: mitigating premature convergence to local optima and escaping from local optima. In contrast to these strategies, this paper introduces a novel perspective by adopting reverse thinking, where the issue of local optima is seen as an opportunity rather than an obstacle. Building on this foundation, we propose MOMOGS-PCE, a novel gene selection approach that effectively exploits the advantageous characteristics of populations trapped in local optima to uncover global optimal solutions. Specifically, MOMOGS-PCE employs a novel population initialization strategy, which involves the initialization of multiple populations that explore diverse orientations to foster distinct population characteristics. The subsequent step involved the utilization of an enhanced NSGA-II algorithm to amplify the advantageous characteristics exhibited by the population. Finally, a novel exchange strategy is proposed to facilitate the transfer of characteristics between populations that have reached near maturity in evolution, thereby promoting further population evolution and enhancing the search for more optimal gene subsets. The experimental results demonstrated that MOMOGS-PCE exhibited significant advantages in comprehensive indicators compared with six competitive multi-objective gene selection algorithms. It is confirmed that the “reverse-thinking" approach not only avoids local optima but also leverages it to uncover superior gene subsets for cancer diagnosis.}
}
@article{THABTAH2018112,
title = {A new computational intelligence approach to detect autistic features for autism screening},
journal = {International Journal of Medical Informatics},
volume = {117},
pages = {112-124},
year = {2018},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2018.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S1386505618300546},
author = {Fadi Thabtah and Firuz Kamalov and Khairan Rajab},
keywords = {Accuracy, Autism Spectrum Disorder, Behaviour science, Classifiers, Computational intelligence, Data mining, Feature analysis, Machine learning, Sensitivity, Specificity},
abstract = {Autism Spectrum Disorder (ASD) is one of the fastest growing developmental disability diagnosis. General practitioners (GPs) and family physicians are typically the first point of contact for patients or family members concerned with ASD traits observed in themselves or their family member. Unfortunately, some families and adult patients are unaware of ASD traits that may be exhibited and as a result do not seek out necessary diagnostic services or contact their GP. Therefore, providing a quick, accessible, and simple tool utilizing items related to ASD to these families may increase the likelihood they will seek professional assessment and is vital to the early detection and treatment of ASD. This study aims at identifying fewer, albeit influential, features in common ASD screening methods in order to achieve efficient screening as demands on evaluating the items’ influences on ASD within existing tools is urgent. To achieve this aim, a computational intelligence method called Variable Analysis (Va) is proposed that considers feature-to-class correlations and reduces feature-to-feature correlations. The results of the Va have been verified using two machine learning algorithms by deriving automated classification systems with respect to specificity, sensitivity, positive predictive values (PPVs), negative predictive values (NPVs), and predictive accuracy. Experimental results using cases and controls related to items in three common screening methods, along with features related to individuals, have been analysed and compared with results obtained from other common filtering methods. The results exhibited that Va was able to derive fewer numbers of features from adult, adolescent, and child screening methods yet maintained competitive predictive accuracy, sensitivity, and specificity rates.}
}
@article{MARTIN2000195,
title = {What do animals do all day?: The division of labor, class bodies, and totemic thinking in the popular imagination},
journal = {Poetics},
volume = {27},
number = {2},
pages = {195-231},
year = {2000},
issn = {0304-422X},
doi = {https://doi.org/10.1016/S0304-422X(99)00025-X},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X9900025X},
author = {John Levi Martin},
keywords = {Animals, Totemism, Class body, Busytown, Symbolic domination, Division of labor},
abstract = {This article uses relatively new methods of the analysis of qualitative data to investigate the socio-logical relation between animal species and occupation in the popular imagination, specifically in the world of children's literature, in order to test a claim that the class habitus that naturalizes the division of labor, erasing the contingent nature of class domination, does not simply arise via the internalization of objective social divisions into a subjective social vision, but rather begins with the application of a totemic logic which maps differences between people onto differences between animals, thereby exaggerating and naturalizing them. Children are evidently instructed in the reality of class bodies and the logic of social structure before they have any first-hand acquaintance with these social processes; indeed, by working the embodied relations of class domination into the role play and role learning of the pre-school years, we make it difficult for them to have any unmediated first-hand experience that would militate against these habitual distinctions.}
}
@article{SADEGHIPOUR2012213,
title = {Gesture processing as grounded motor cognition: Towards a computational model},
journal = {Procedia - Social and Behavioral Sciences},
volume = {32},
pages = {213-223},
year = {2012},
note = {The 4th International Conference of Cognitive Science},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.01.032},
url = {https://www.sciencedirect.com/science/article/pii/S187704281200033X},
author = {Amir Sadeghipour and Stefan Kopp},
keywords = {Motor Cognition, embodiment, grounded cognition, gestures, social interaction, computational model, embodied conversational agents},
abstract = {In this paper, we present an approach to treat and model the processing (i.e. recognition and production) of communicative gestures as grounded motor cognition. We first review cognitive theories and neuropsychological studies on human motor cognition. On this basis, we propose a computational framework that connects the sensorimotor processing of hand gestures in representational structures of meaning (visuospatial imagery), other modalities (language), and communicative intentions. We present an implementation that enables an embodied virtual agent to engage in gesture-based interaction with a human user.}
}
@article{ZAROUALI2024108024,
title = {Personality and susceptibility to political microtargeting: A comparison between a machine-learning and self-report approach},
journal = {Computers in Human Behavior},
volume = {151},
pages = {108024},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.108024},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003758},
author = {Brahim Zarouali and Tom Dobber and Jurrian Schreuder},
keywords = {Political microtargeting, Persuasion, Personality, Social media, Algorithms},
abstract = {Based on recent technological advances, campaigners and political actors can use psychographic-based political marketing. Yet, empirical evidence about its effectiveness is still very limited. Based on self-congruity theory, a pre-registered experiment (N = 280) investigated the persuasion effects of personality-congruent political microtargeting on the attitude toward the political party and voting intentions of citizens. More precisely, the focus was on the thinking vs feeling personality dimension (MBTI), and it was tested whether this personality “interacts” with exposure to a matching advertising appeal: rational vs. emotional political ad. To do so, two different methodological approaches were used: 1) a machine learning approach; 2) a self-report survey measure of personality. Results revealed significant “congruence effects” between personality and ad appeal, and showed that perceived ad relevance was serving as the underlying mechanism (mediator). However, these results were only found when the self-report measure of personality was used. When the algorithmic approach was used, no significant results were found. These findings feed into timely societal, methodological, and theoretical contributions.}
}
@article{LIU20121773,
title = {ACE - A Model Centered REU Program Standing on the Three Legs of CSE: Analysis, Computation and Experiment},
journal = {Procedia Computer Science},
volume = {9},
pages = {1773-1782},
year = {2012},
note = {Proceedings of the International Conference on Computational Science, ICCS 2012},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2012.04.195},
url = {https://www.sciencedirect.com/science/article/pii/S187705091200316X},
author = {Hong P. Liu and Andrei Ludu},
keywords = {CSE Education, REU, Project-Oriented Pedagogy},
abstract = {Enhancing REU (research experience for undergraduates) has become a popular strategy for many selective universities to enhance quality of undergraduate education and recruit gifted new students. The university that the authors are affiliated has set REU as one of the major outcomes for our QEP (quality enhancement program) for next 5 years. This paper presents a model centered REU program entitled as ACE standing for Analysis, Computation and Experiment. As a work in progress, the program is planned to run for the next 5 years and to serve for 20-30 undergraduate students who are gifted in mathematics and computing annually. ACE is to use interdisciplinary research projects, the guided exploration based on sound pedagogical practice and the top niche analogical and virtual dual lab facility bring measurable impacts to over a hundred of gifted undergraduates.}
}
@article{KOKOLAKIS2023110732,
title = {Bounded rational Dubins vehicle coordination for target tracking using reinforcement learning},
journal = {Automatica},
volume = {149},
pages = {110732},
year = {2023},
issn = {0005-1098},
doi = {https://doi.org/10.1016/j.automatica.2022.110732},
url = {https://www.sciencedirect.com/science/article/pii/S0005109822005982},
author = {Nick-Marios T. Kokolakis and Kyriakos G. Vamvoudakis},
keywords = {Game theory, Target tracking, Bounded rationality, Reinforcement learning, Switched systems, Target allocation},
abstract = {In this paper, we address the problem of cooperative tracking of multiple heterogeneous targets by deploying multiple and heterogeneous pursuers exhibiting different decision-making capabilities. Initially, under infinite resources, we formulate a game between the evader and the pursuing team, with an evader being the maximizing player and the pursuing team being the minimizing one. Subsequently, we relax the perfect rationality assumption via the use of a level-k thinking framework that allows the evaders to not exhibit the same levels of rationality. Such rationality policies are computed by using a reinforcement learning-based architecture and are proven to form Nash policies as the thinking levels increase. Finally, in the case of multiple pursuers against multiple targets, we develop a switched learning scheme with multiple convergence sets by assigning the most intelligent pursuers to the most intelligent evaders.}
}
@article{CALVIN20241192,
title = {ShopMe: a mobile app to introduce Indonesian local MSMEs},
journal = {Procedia Computer Science},
volume = {245},
pages = {1192-1201},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.349},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031570},
author = {Jeremiah Calvin and Yudhistya Ayu Kusumawati and Asri Radhitanti},
keywords = {Economic Inequality, MSMEs, Income, Platform, Poverty},
abstract = {The poverty rate in Malang Raya is decreasing, although this is a good thing, another problem is emerging, namely economic inequality. Economic inequality impacts many parties, both rich and poor. This problem started with the COVID-19 pandemic, with uncertain economic stability. With this reality, one of the factors that will have an impact on the current economy is MSMEs. Moreover, with the increasing economic inequality in Malang, MSMEs will have minimal income and if MSMEs do not run as they should, the country's economy will not be good. be good. This research aims to find a solution by creating a platform to unite MSMEs that are under the radar to improve their playing field, especially F&B MSMEs, with the main benefits being given to MSMEs. To understand this problem, this research uses a design thinking process, with interviews and questionnaires as the main research, as well as a literature review as the method for conducting this research. The result of this research is the development of a mobile app which can be a bridge for MSMEs to become better known to the public. With the publication of this research, it is hoped that it will be an inspiration for the public to find ways to overcome these problems.}
}
@incollection{2009339,
title = {Appendix A - Thinking in MATLAB},
editor = {Pascal Wallisch and Michael Lusignan and Marc Benayoun and Tanya I. Baker and Adam S. Dickey and Nicholas G. Hatsopoulos},
booktitle = {Matlab for Neuroscientists},
publisher = {Academic Press},
address = {London},
pages = {339-344},
year = {2009},
isbn = {978-0-12-374551-4},
doi = {https://doi.org/10.1016/B978-0-12-374551-4.00034-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123745514000348}
}
@article{KNIGHT20151,
title = {Computational making},
journal = {Design Studies},
volume = {41},
pages = {1-7},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000721},
author = {Terry Knight and Theodora Vardouli}
}
@article{JONCZYK2024120752,
title = {Operating in a second language lowers cognitive interference during creative idea generation: Evidence from brain oscillations in bilinguals},
journal = {NeuroImage},
volume = {297},
pages = {120752},
year = {2024},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2024.120752},
url = {https://www.sciencedirect.com/science/article/pii/S1053811924002490},
author = {Rafał Jończyk and Iga Krzysik and Olga Witczak and Katarzyna Bromberek-Dyzman and Guillaume Thierry},
keywords = {Creativity, Bilingualism, EEG, Alternate uses task, Alpha frequency, Beta frequency},
abstract = {Tasks measuring human creativity overwhelmingly rely on both language comprehension and production. Although most of the world's population is bilingual, few studies have investigated the effects of language of operation on creative output. This is surprising given that fluent bilinguals master inhibitory control, a mechanism also at play in creative idea evaluation. Here, we compared creative output in the two languages of Polish(L1)-English(L2) bilinguals engaged in a cyclic adaptation of the Alternative Uses Task increasing the contribution of idea evaluation (convergent thinking). We show that Polish-English bilinguals suffer less cognitive interference when generating unusual uses for common objects in the L2 than the L1, without incurring a significant drop in idea originality. Right posterior alpha oscillation power, known to reflect creative thinking, increased over cycles. This effect paralleled the increase in originality ratings over cycles, and lower alpha power (8–10 Hz) was significantly greater in the L1 than the L2. Unexpectedly, we found greater beta (16.5–28 Hz) desynchronization in the L2 than the L1, suggesting that bilingual participants suffered less interference from competing mental representations when performing the task in the L2. Whereas creative output seems unaffected by language of operation overall, the drop in beta power in the L2 suggests that bilinguals are not subjected to the same level of semantic flooding in the second language as they naturally experience in their native language.}
}
@article{ZENDEHROUH2015112,
title = {A new computational account of cognitive control over reinforcement-based decision-making: Modeling of a probabilistic learning task},
journal = {Neural Networks},
volume = {71},
pages = {112-123},
year = {2015},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2015.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0893608015001604},
author = {Sareh Zendehrouh},
keywords = {Cognitive control, Reinforcement learning, Goal-directed behavior, Dual system theory, Cost function, Probabilistic learning task},
abstract = {Recent work on decision-making field offers an account of dual-system theory for decision-making process. This theory holds that this process is conducted by two main controllers: a goal-directed system and a habitual system. In the reinforcement learning (RL) domain, the habitual behaviors are connected with model-free methods, in which appropriate actions are learned through trial-and-error experiences. However, goal-directed behaviors are associated with model-based methods of RL, in which actions are selected using a model of the environment. Studies on cognitive control also suggest that during processes like decision-making, some cortical and subcortical structures work in concert to monitor the consequences of decisions and to adjust control according to current task demands. Here a computational model is presented based on dual system theory and cognitive control perspective of decision-making. The proposed model is used to simulate human performance on a variant of probabilistic learning task. The basic proposal is that the brain implements a dual controller, while an accompanying monitoring system detects some kinds of conflict including a hypothetical cost-conflict one. The simulation results address existing theories about two event-related potentials, namely error related negativity (ERN) and feedback related negativity (FRN), and explore the best account of them. Based on the results, some testable predictions are also presented.}
}
@article{DOLAN2023,
title = {Using Shopping Data to Improve the Diagnosis of Ovarian Cancer: Computational Analysis of a Web-Based Survey},
journal = {JMIR Cancer},
volume = {9},
year = {2023},
issn = {2369-1999},
doi = {https://doi.org/10.2196/37141},
url = {https://www.sciencedirect.com/science/article/pii/S2369199923000174},
author = {Elizabeth H Dolan and James Goulding and Laila J Tata and Alexandra R Lang},
keywords = {carcinoma, ovarian epithelial, ovarian neoplasms, self-medication, diagnostic errors, symptom assessment, machine learning, nonprescription drugs, over-the-counter, pharmaceutical, symptom, ovary, ovarian cancer, oncology, cancer},
abstract = {Background
Shopping data can be analyzed using machine learning techniques to study population health. It is unknown if the use of such methods can successfully investigate prediagnosis purchases linked to self-medication of symptoms of ovarian cancer.
Objective
The aims of this study were to gain new domain knowledge from women’s experiences, understand how women’s shopping behavior relates to their pathway to the diagnosis of ovarian cancer, and inform research on computational analysis of shopping data for population health.
Methods
A web-based survey on individuals’ shopping patterns prior to an ovarian cancer diagnosis was analyzed to identify key knowledge about health care purchases. Logistic regression and random forest models were employed to statistically examine how products linked to potential symptoms related to presentation to health care and timing of diagnosis.
Results
Of the 101 women surveyed with ovarian cancer, 58.4% (59/101) bought nonprescription health care products for up to more than a year prior to diagnosis, including pain relief and abdominal products. General practitioner advice was the primary reason for the purchases (23/59, 39%), with 51% (30/59) occurring due to a participant’s doctor believing their health problems were due to a condition other than ovarian cancer. Associations were shown between purchases made because a participant’s doctor believing their health problems were due to a condition other than ovarian cancer and the following variables: health problems for longer than a year prior to diagnosis (odds ratio [OR] 7.33, 95% CI 1.58-33.97), buying health care products for more than 6 months to a year (OR 3.82, 95% CI 1.04-13.98) or for more than a year (OR 7.64, 95% CI 1.38-42.33), and the number of health care product types purchased (OR 1.54, 95% CI 1.13-2.11). Purchasing patterns are shown to be potentially predictive of a participant’s doctor thinking their health problems were due to some condition other than ovarian cancer, with nested cross-validation of random forest classification models achieving an overall in-sample accuracy score of 89.1% and an out-of-sample score of 70.1%.
Conclusions
Women in the survey were 7 times more likely to have had a duration of more than a year of health problems prior to a diagnosis of ovarian cancer if they were self-medicating based on advice from a doctor rather than having made the decision to self-medicate independently. Predictive modelling indicates that women in such situations, who are self-medicating because their doctor believes their health problems may be due to a condition other than ovarian cancer, exhibit distinct shopping behaviors that may be identifiable within purchasing data. Through exploratory research combining women sharing their behaviors prior to diagnosis and computational analysis of these data, this study demonstrates that women’s shopping data could potentially be useful for early ovarian cancer detection.}
}
@article{VARNER2017170,
title = {Computational models of airway branching morphogenesis},
journal = {Seminars in Cell & Developmental Biology},
volume = {67},
pages = {170-176},
year = {2017},
note = {Extracellular Vesicles Cellular Mechanisms of Morphogenesis},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2016.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1084952116301653},
author = {Victor D. Varner and Celeste M. Nelson},
keywords = {Quantitative models, Morphodynamics, Mechanobiology, Turing patterns},
abstract = {The bronchial network of the mammalian lung consists of millions of dichotomous branches arranged in a highly complex, space-filling tree. Recent computational models of branching morphogenesis in the lung have helped uncover the biological mechanisms that construct this ramified architecture. In this review, we focus on three different theoretical approaches – geometric modeling, reaction-diffusion modeling, and continuum mechanical modeling – and discuss how, taken together, these models have identified the geometric principles necessary to build an efficient bronchial network, as well as the patterning mechanisms that specify airway geometry in the developing embryo. We emphasize models that are integrated with biological experiments and suggest how recent progress in computational modeling has advanced our understanding of airway branching morphogenesis.}
}
@article{WANG2003457,
title = {Thinking as saying: shuo (‘say’) in Taiwan Mandarin conversation and BBS talk},
journal = {Language Sciences},
volume = {25},
number = {5},
pages = {457-488},
year = {2003},
issn = {0388-0001},
doi = {https://doi.org/10.1016/S0388-0001(03)00020-2},
url = {https://www.sciencedirect.com/science/article/pii/S0388000103000202},
author = {Yu-Fang Wang and Aya Katz and Chih-Hua Chen},
keywords = {Grammaticalization, Metaphor, Propositional, Textual, Expressive},
abstract = {The research reported here is an attempt to explore the functions of shuo ‘say’ in informal Chinese speech and writing. We further probe into the grammaticalization of shuo, discussing how the various lexical, grammatical and discourse functions have come into being, with reference to the general tendencies of semantic change proposed by Traugott [(1982). In: Lehmann and Malkiel (Eds.) Perspectives on Historical Linguistics. Benjamins, Amsterdam. pp. 245–272; (1989) Language 65(1), 31–55] and Traugott and König [In: Traugott and Heine (Eds.), Approaches to Grammaticalization, Vol. I. John Benjamins, Philadelphia. pp. 189–218], and the metaphor MIND-AS-BODY proposed by Sweetser [(1990). From Etymology to Pragmatics. Cambridge University Press, Cambridge]. The corpus used in this study contains two sets of data: non-face-to-face talk on BBS (the Electronic Bulletin Board System) and face-to-face daily conversation, mainly produced by young people in Taiwan. Our data indicate that shuo, in addition to acting as a complementizer as discussed by S. Huang [On the (almost perfect) identify of speech and thought: Evidence from Chinese dialects. (1982). Paper presented at Fourteenth International Conference on Sino-Tibetan Languages and Linguistics] and Cheng [(1997). In: Cheng (Ed.), Taiwanese and Mandarin Structures and Their Developmental Trends in Taiwan II: Contacts between Taiwanese and Mandarin and Restructuring of their Synonyms. Yuan-Liou Publishing Co. Taipei. pp. 105–131], can also occur in an utterance-initial position, functioning as a marker of hearsay, and in an utterance-final position, as a marker of counterexpectation or as an intensifier. On the whole, the data suggest that the initial and final shuo's are innovations serving an expressive function. In particular, the lexeme shuo is moving from the propositional level to the expressive level; i.e., it is evolving from a verb meaning ‘say’ that prefaces an utterance conveying information into a discourse marker that encodes the attitude of the speaker toward the proposition.}
}
@article{LEE2023101274,
title = {Storytelling as a learning tool in creative education: A case study in an architecture design studio},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101274},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101274},
url = {https://www.sciencedirect.com/science/article/pii/S1871187123000445},
author = {Keunhye Lee and Eunki Kang and Eun Joo Park},
keywords = {Storytelling, Creative thinking, Architecture design studio, Creative education, Communicative representation},
abstract = {This paper investigates the significant aspects of storytelling, when used as a pedagogical method to enhance students critical and creative thinking and communicative technique, by applying it to first-year students in the architecture design studio. Creativity is a substantial part of architectural education as it improves students’ design processes in innovative ways. This paper considers how the architecture design studio can form a creative design solution that can be learned and developed by learner-centred activity; it concentrates on aspects of storytelling, which many scholars have begun to discuss its significance in creative education. Thus, this paper aims to develop a creative learning strategy for use in the architecture design studio and suggest a new learning method by engaging storytelling in the design process. This paper starts with discussions about storytelling and its usages in the architecture design studio, referring to several theorists and educators, particularly focusing on McDrury and Alterio (2003); it helps to create a framework and develop a curriculum for the architecture design studio. The overall results suggest that using storytelling as a learning method in an architecture design studio is important in contextualising and articulating design work, from ideas to analysis, visualisation and expression, in a coherent context. It helps students gain better design skills and a greater understanding of the design process across the disciplines of the design studio, improving students creative thinking during the unique design process.}
}
@article{LISSACK2024389,
title = {Responsible Use of Large Language Models: An Analogy with the Oxford Tutorial System},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {389-413},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000959},
author = {Michael Lissack and Brenden Meagher},
keywords = {responsible AI, Oxford Tutorial, large language models (LLMs), human-AI collaboration, critical thinking},
abstract = {In the rapidly evolving landscape of artificial intelligence, large language models (LLMs) have emerged as powerful tools with the potential to revolutionize how we process information, generate content, and solve complex problems. However, integrating these sophisticated AI systems into academic and professional practices raises critical questions about responsible use, ethical considerations, and the preservation of human expertise. This article introduces a novel framework for understanding and implementing responsible AI use by drawing an analogy between the optimal use of LLMs and the role of the second student in an Oxford Tutorial. Through an in-depth exploration of the Oxford Tutorial system and its parallels with LLM interaction, we propose a nuanced approach to leveraging AI language models while maintaining human agency, fostering critical thinking, and upholding ethical standards. The article examines the implications of this analogy, discusses potential risks of misuse, and provides detailed practical scenarios across various fields. By grounding the use of cutting-edge AI technology in a well-established and respected educational model, this research contributes to the ongoing discourse on AI ethics. It offers valuable insights for academics, professionals, and policymakers grappling with the challenges and opportunities presented by LLMs.}
}
@article{FIELDS2025256,
title = {Thoughts and thinkers: On the complementarity between objects and processes},
journal = {Physics of Life Reviews},
volume = {52},
pages = {256-273},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000089},
author = {Chris Fields and Michael Levin},
keywords = {Active inference, Cognitive light cone, Emergence, Evo/devo/eco, Multiscale competency architecture, Niche construction, Semantics},
abstract = {We argue that “processes versus objects” is not a useful dichotomy. There is, instead, substantial theoretical utility in viewing “objects” and “processes” as complementary ways of describing persistence through time, and hence the possibility of observation and manipulation. This way of thinking highlights the role of memory as an essential resource for observation, and makes it clear that “memory” and “time” are also mutually inter-defined, complementary concepts. We formulate our approach in terms of the Free Energy Principle (FEP) of Friston and colleagues and the fundamental idea from quantum theory that physical interactions can be represented by linear operators. Following Levin (2024) [30], we emphasize that memory is, first and foremost, an interpretative function, from which the idea of memory as a record, at some level of accuracy, of past events is derivative. We conclude that the distinction between objects and processes is always contrived, and always misleading, and that science would be better served by abandoning it entirely.}
}
@article{BILORIA2012259,
title = {Interactive morphologies: An investigation into integrated nodal networks and embedded computation processes for developing real-time responsive spatial systems},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {3},
pages = {259-271},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000465},
author = {Nimish Biloria},
keywords = {Real-time interaction, Sensing and actuation, Performance, Adaptation, Emergence},
abstract = {The design-research illustrated in this research article focus on the emerging field of interactive architecture focusing on developing real-time information exchanging architectural bodies. These interactive bodies demonstrate a fusion between the material, the electronic and the digital domains. This fusion is explicitly attained through a synergistic merger between the fields of ambient sensing, control systems, ubiquitous computing, architectural design, pneumatic systems and computation. The resultant spatial bodies are thus visualised as complex adaptive systems, continually engaged in activities of data-exchange resulting in physical and ambient adaptations of their constituting components in response to contextual variations. Interdependent nodal networks, where every node/junction of a spatial prototype becomes a potential information hub by means of its ability to collect, process and communicate contextual data apart from working as an actuated detail owing to its ability to kinetically re-position itself in three-dimensional space is thus a critical outcome of this inter-disciplinary way of working. A strategy apt for binding material logistics with the digital to materialize dynamic spatial behaviours owing to real time data exchange between the prototypes and their context is thus embarked upon via three research and design projects, namely: Electronic Media Augmented Spatial Skins, The InteractiveWall and the Muscle Re-configured.}
}
@article{DALLACHIARA201669,
title = {A first-order epistemic quantum computational semantics with relativistic-like epistemic effects},
journal = {Fuzzy Sets and Systems},
volume = {298},
pages = {69-90},
year = {2016},
note = {Special Issue on Graded Logical Approaches and Their Applications},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2015.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S0165011415004145},
author = {Maria Luisa {Dalla Chiara} and Roberto Giuntini and Roberto Leporini and Giuseppe Sergioli},
keywords = {Quantum computation, Quantum computational logics, Epistemic operators},
abstract = {Quantum computation has suggested new forms of quantum logic, called quantum computational logics. In these logics well-formed formulas are supposed to denote pieces of quantum information: possible pure states of quantum systems that can store the information in question. At the same time, the logical connectives are interpreted as quantum logical gates: unitary operators that process quantum information in a reversible way, giving rise to quantum circuits. Quantum computational logics have been mainly studied as sentential logics (whose alphabet consists of atomic sentences and of logical connectives). In this article we propose a semantic characterization for a first-order epistemic quantum computational logic, whose language can express sentences like “Alice knows that everybody knows that she is pretty”. One can prove that (unlike the case of logical connectives) both quantifiers and epistemic operators cannot be generally represented as (reversible) quantum logical gates. The “act of knowing” and the use of universal (or existential) assertions seem to involve some irreversible “theoretic jumps”, which are similar to quantum measurements. Since all epistemic agents are characterized by specific epistemic domains (which contain all pieces of information accessible to them), the unrealistic phenomenon of logical omniscience is here avoided: knowing a given sentence does not imply knowing all its logical consequences.}
}
@article{LI2025126039,
title = {Correct like humans: Progressive learning framework for Chinese text error correction},
journal = {Expert Systems with Applications},
volume = {265},
pages = {126039},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.126039},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424029063},
author = {Yinghui Li and Shirong Ma and Shaoshen Chen and Haojing Huang and Shulin Huang and Yangning Li and Hai-Tao Zheng and Ying Shen},
keywords = {Chinese text error correction, Progressive learning, Natural language processing, Computational linguistics},
abstract = {Chinese Text Error Correction (CTEC) aims to detect and correct errors in the input text, which benefits human daily life and various downstream tasks. With the extensive research on Pre-trained Language Models (PLMs), Chinese Spelling Correction (CSC) and Chinese Grammatical Error Correction (CGEC), two subtasks of CTEC, have achieved good results. However, researchers usually study these two tasks separately. In addition, we argue that previous studies still overlook the importance of human thinking patterns. To enhance the development of PLMs for CTEC, inspired by humans’ daily error-correcting behavior, we propose a novel model-agnostic progressive learning framework, named ProTEC, which guides PLMs-based CTEC models to learn to correct like humans and can be applied to various existing CTEC models in both CSC and CGEC. During the training process, ProTEC guides the model to learn text error correction by incorporating these sub-tasks into a progressive paradigm. During the inference process, the model completes these sub-tasks in turn to generate the correction results. Extensive experiments and detailed analyses demonstrate the effectiveness and efficiency of our proposed model-agnostic ProTEC framework.}
}
@article{HEINZLE201621,
title = {Computational models of eye movements and their application to schizophrenia},
journal = {Current Opinion in Behavioral Sciences},
volume = {11},
pages = {21-29},
year = {2016},
note = {Computational modeling},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2016.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S2352154616300754},
author = {Jakob Heinzle and Eduardo A Aponte and Klaas Enno Stephan},
abstract = {Patients with neuropsychiatric disorders, in particular schizophrenia, show a variety of eye movement abnormalities that putatively reflect alterations of perceptual inference, learning and cognitive control. While these abnormalities are consistently found at the group level, a particularly difficult and important challenge is to translate these findings into clinically useful tests for single patients. In this paper, we argue that generative models of eye movement data, which allow for inferring individual computational and physiological mechanisms, could contribute to filling this gap. We present a selective overview of eye movement paradigms with clinical relevance for schizophrenia and review existing computational approaches that rest on (or could be turned into) generative models. We conclude by outlining desirable clinical applications at the individual subject level and discuss the necessary validation studies.}
}
@article{MURANO2020577,
title = {Model-checking graded computation-tree logic with finite path semantics},
journal = {Theoretical Computer Science},
volume = {806},
pages = {577-586},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.09.021},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519305651},
author = {Aniello Murano and Mimmo Parente and Sasha Rubin and Loredana Sorrentino},
keywords = {Computation tree logic, Model checking, Finite paths},
abstract = {This paper introduces Graded Computation Tree Logic with finite path semantics (GCTLf⁎, for short), a variant of Computation Tree Logic CTL⁎, in which path quantifiers are interpreted over finite paths and can count the number of such paths. State formulas of GCTLf⁎ are interpreted over Kripke structures. The syntax of GCTLf⁎ has path quantifiers of the form E≥gψ which express that there are at least g many distinct finite paths that satisfy ψ. After defining and justifying the logic GCTLf⁎, we solve its model checking problem and establish that its computational complexity is PSPACE-complete. Moreover, we investigate GCTLf⁎ under the imperfect information setting. Precisely, we introduce GCTLKf⁎, an epistemic extension of GCTLf⁎ and prove that the model checking problem also in this case is PSPACE-complete.}
}
@article{BOTANA2016115,
title = {Some issues on the automatic computation of plane envelopes in interactive environments},
journal = {Mathematics and Computers in Simulation},
volume = {125},
pages = {115-125},
year = {2016},
note = {8th Workshop STRUCTURAL DYNAMICAL SYSTEMS: Computational Aspects; Edited by Nicoletta Del Buono, Roberto Garrappa and Giulia Spaletta and Nonstandard Applications of Computer Algebra (ACA’2013); Edited by Francisco Botana, Antonio Hernando, Eugenio Roanes-Lozano and Michael J. Wester},
issn = {0378-4754},
doi = {https://doi.org/10.1016/j.matcom.2014.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S0378475414001529},
author = {Francisco Botana and Tomas Recio},
keywords = {Envelope, Dynamic Geometry, Automatic computation, GröbnerCover algorithm},
abstract = {This paper addresses some concerns, and describes some proposals, on the ellusive concept of envelope of an algebraic family of varieties, and on its automatic computation. We describe how to use the recently developed Gröbner Cover algorithm to study envelopes of families of algebraic curves, and we give a protocol towards its implementation in dynamic geometry environments. The proposal is illustrated through some examples. A beta version of GeoGebra is used to highlight new envelope abilities in interactive environments, and limitations of our approach are discussed, since the computations are performed in an algebraically closed field.}
}
@article{WANG2024,
title = {News Coverage of the COVID-19 Pandemic on Social Media and the Public’s Negative Emotions: Computational Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48491},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400308X},
author = {Hanjing Wang and Yupeng Li and Xuan Ning},
keywords = {web news coverage, emotions, social media, Facebook, COVID-19},
abstract = {Background
Social media has become an increasingly popular and critical tool for users to digest diverse information and express their perceptions and attitudes. While most studies endeavor to delineate the emotional responses of social media users, there is limited research exploring the factors associated with the emergence of emotions, particularly negative ones, during news consumption.
Objective
We aim to first depict the web coverage by news organizations on social media and then explore the crucial elements of news coverage that trigger the public’s negative emotions. Our findings can act as a reference for responsible parties and news organizations in times of crisis.
Methods
We collected 23,705 Facebook posts with 1,019,317 comments from the public pages of representative news organizations in Hong Kong. We used text mining techniques, such as topic models and Bidirectional Encoder Representations from Transformers, to analyze news components and public reactions. Beyond descriptive analysis, we used regression models to shed light on how news coverage on social media is associated with the public’s negative emotional responses.
Results
Our results suggest that occurrences of issues regarding pandemic situations, antipandemic measures, and supportive actions are likely to reduce the public’s negative emotions, while comments on the posts mentioning the central government and the Government of Hong Kong reveal more negativeness. Negative and neutral media tones can alleviate the rage and interact with the subjects and issues in the news to affect users’ negative emotions. Post length is found to have a curvilinear relationship with users’ negative emotions.
Conclusions
This study sheds light on the impacts of various components of news coverage (issues, subjects, media tone, and length) on social media on the public’s negative emotions (anger, fear, and sadness). Our comprehensive analysis provides a reference framework for efficient crisis communication for similar pandemics at present or in the future. This research, although first extending the analysis between the components of news coverage and negative user emotions to the scenario of social media, echoes previous studies drawn from traditional media and its derivatives, such as web newspapers. Although the era of COVID-19 pandemic gradually brings down the curtain, the commonality of this research and previous studies also contributes to establishing a clearer territory in the field of health crises.}
}
@article{SLOOT2010131,
title = {The cross-disciplinary road to true computational science},
journal = {Journal of Computational Science},
volume = {1},
number = {3},
pages = {131},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000451},
author = {Peter M.A. Sloot}
}
@article{IGNATOWSKI2014264,
title = {Wishful thinking or effective threat? Tightening bank resolution regimes and bank risk-taking},
journal = {Journal of Financial Stability},
volume = {15},
pages = {264-281},
year = {2014},
issn = {1572-3089},
doi = {https://doi.org/10.1016/j.jfs.2014.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1572308914000485},
author = {Magdalena Ignatowski and Josef Korte},
keywords = {Bank resolution, Orderly Liquidation Authority, FDIC, Bank behavior, Risk-taking},
abstract = {We propose a framework for testing the effects of changes in bank resolution regimes on bank behavior. By exploiting the differential relevance of recent changes in U.S. bank resolution (i.e., the introduction of the Orderly Liquidation Authority, OLA) for different types of banks, we are able to simulate a quasi-natural experiment using a difference-in-difference framework. We find that banks that are more affected by the introduction of the OLA (1) significantly decrease their overall risk-taking and (2) shift their loan origination toward lower risk, indicating the general effectiveness of the regime change. This effect, however, does (3) not hold for the largest and most systemically important banks. Hence, the introduction of the OLA in the U.S. alone does not appear to have solved the too-big-to-fail problem and might need to be complemented with other measures to limit financial institutions’ risk-taking.}
}
@article{LONG201960,
title = {The mammalian kinetochore–microtubule interface: robust mechanics and computation with many microtubules},
journal = {Current Opinion in Cell Biology},
volume = {60},
pages = {60-67},
year = {2019},
note = {Cell Dynamics},
issn = {0955-0674},
doi = {https://doi.org/10.1016/j.ceb.2019.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0955067419300250},
author = {Alexandra F Long and Jonathan Kuhn and Sophie Dumont},
abstract = {The kinetochore drives chromosome segregation at cell division. It acts as a physical link between chromosomes and dynamic microtubules, and as a signaling hub detecting and processing microtubule attachments to control anaphase onset. The mammalian kinetochore is a large macromolecular machine that forms a dynamic interface with the many microtubules that it binds. While we know most of the kinetochore’s component parts, how they work together to give rise to its robust functions remains poorly understood. Here we highlight recent findings that shed light on this question, driven by an expanding physical and molecular toolkit. We present emerging principles that underlie the kinetochore’s robust microtubule grip, such as redundancy, specialization, and dynamicity, and present signal processing principles that connect this microtubule grip to robust computation. Throughout, we identify open questions, and define simple engineering concepts that provide insight into kinetochore function.}
}
@article{ARSLAN2024340,
title = {Computational analysis of linguistic features in speech samples of first-episode bipolar disorder and psychosis},
journal = {Journal of Affective Disorders},
volume = {363},
pages = {340-347},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.07.102},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724011595},
author = {Berat Arslan and Elif Kizilay and Burcu Verim and Cemal Demirlek and Muhammed Demir and Ezgi Cesim and Merve S. Eyuboglu and Simge Uzman Ozbek and Ekin Sut and Berna Yalincetin and Emre Bora},
keywords = {Psychosis, Bipolar, First-episode, Natural language processing, Semantic similarity},
abstract = {Background
In recent years, automated analyses using novel NLP methods have been used to investigate language abnormalities in schizophrenia. In contrast, only a few studies used automated language analyses in bipolar disorder. To our knowledge, no previous research compared automated language characteristics of first-episode psychosis (FEP) and bipolar disorder (FEBD) using NLP methods.
Methods
Our study included 53 FEP, 40 FEBD and 50 healthy control participants who are native Turkish speakers. Speech samples of the participants in the Thematic Apperception Test (TAT) underwent automated generic and part-of-speech analyses, as well as sentence-level semantic similarity analysis based on SBERT.
Results
Both FEBD and FEP were associated with the use of shorter sentences and increased sentence-level semantic similarity but less semantic alignment with the TAT pictures. FEP also demonstrated reduced verbosity and syntactic complexity. FEP differed from FEBD in reduced verbosity, decreased first-person singular pronouns, fewer conjunctions, increased semantic similarity as well as shorter sentence and word length. The mean classification accuracy was 82.45 % in FEP vs HC, 71.1 % in FEBD vs HC, and 73 % in FEP vs FEBD. After Bonferroni correction, the severity of negative symptoms in FEP was associated with reduced verbal output and increased 5th percentile of semantic similarity.
Limitations
The main limitation of this study was the cross-sectional nature.
Conclusion
Our findings demonstrate that both patient groups showed language abnormalities, which were more severe and widespread in FEP compared to FEBD. Our results suggest that NLP methods reveal transdiagnostic linguistic abnormalities in FEP and FEBD.}
}
@article{COX2005104,
title = {Metacognition in computation: A selected research review},
journal = {Artificial Intelligence},
volume = {169},
number = {2},
pages = {104-141},
year = {2005},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2005.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0004370205001530},
author = {Michael T. Cox},
keywords = {Cognitive monitoring, Computational introspection, Limited rationality, Metacognition, Meta-explanation, Metaknowledge, Meta-level architecture, Metareasoning, Self-reference, Reflection},
abstract = {Various disciplines have examined the many phenomena of metacognition and have produced numerous results, both positive and negative. I discuss some of these aspects of cognition about cognition and the results concerning them from the point of view of the psychologist and the computer scientist, and I attempt to place them in the context of computational theories. I examine metacognition with respect to both problem solving (e.g., planning) and to comprehension (e.g., story understanding) processes of cognition.}
}
@incollection{JIAO202081,
title = {Chapter 3 - Theoretical basis of natural computation},
editor = {Licheng Jiao and Ronghua Shang and Fang Liu and Weitong Zhang},
booktitle = {Brain and Nature-Inspired Learning Computation and Recognition},
publisher = {Elsevier},
pages = {81-95},
year = {2020},
isbn = {978-0-12-819795-0},
doi = {https://doi.org/10.1016/B978-0-12-819795-0.00003-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128197950000037},
author = {Licheng Jiao and Ronghua Shang and Fang Liu and Weitong Zhang},
keywords = {Artificial immune system, Evolutionary algorithms, Multiobjective optimization, Theoretical basis},
abstract = {Enlightened by nature, the natural computing method has the ability of self-adaptation, self-organization, and self-learning, and can solve complex problems which are difficult to be solved by traditional computing methods. Natural computing is not only a new hotspot in artificial intelligence research, but also a new thinking in the development of artificial intelligence. It is also a new achievement in the transformation of methodology. Its research results include evolutionary algorithms, artificial immune system, multiobjective optimization, and so on. Natural computing can solve many complex problems which are difficult to be solved by traditional computing methods. It has good application prospects in solving large-scale complex optimization problems, intelligent control, computer network security, and other fields.}
}
@article{WHITE1985287,
title = {Thinking about learning about thinking: An interview with Seymour Papert},
journal = {New Ideas in Psychology},
volume = {3},
number = {3},
pages = {287-292},
year = {1985},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(85)90025-X},
url = {https://www.sciencedirect.com/science/article/pii/0732118X8590025X},
author = {Barbara Y. White}
}
@article{YANG20111230,
title = {Computational optimization, modelling and simulation: Recent advances and overview},
journal = {Procedia Computer Science},
volume = {4},
pages = {1230-1233},
year = {2011},
note = {Proceedings of the International Conference on Computational Science, ICCS 2011},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.04.132},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911001906},
author = {Xin-She Yang and Slawomir Koziel and Leifur Leifsson},
keywords = {algorithm, black-box modelling, computational optimization, derivative-free method, optimization algorithm, modelling, nonlinear optimization, surragate-based optimization, simulation},
abstract = {Computational optimization is becoming increasingly important in engineering design and industrial applications. Products and services are often concerned with the maximization of profits and reduction of cost, but also aim at being more energy-efficient, environment-friendly and safety-ensured; at the same time they are limited by resources, time and money. This second workshop on Computational Optimization, Modelling and Simulation (COMS 2011) at ICCS 2011 will further summarize the latest developments of optimization and modelling and their applications in science, engineering and industry.}
}
@article{RUSCH2020107488,
title = {Theory of mind and decision science: Towards a typology of tasks and computational models},
journal = {Neuropsychologia},
volume = {146},
pages = {107488},
year = {2020},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2020.107488},
url = {https://www.sciencedirect.com/science/article/pii/S0028393220301597},
author = {Tessa Rusch and Saurabh Steixner-Kumar and Prashant Doshi and Michael Spezio and Jan Gläscher},
keywords = {Theory of mind, Computational modeling, Decision making, Interactivity, Uncertainty},
abstract = {The ability to form a Theory of Mind (ToM), i.e., to theorize about others’ mental states to explain and predict behavior in relation to attributed intentional states, constitutes a hallmark of human cognition. These abilities are multi-faceted and include a variety of different cognitive sub-functions. Here, we focus on decision processes in social contexts and review a number of experimental and computational modeling approaches in this field. We provide an overview of experimental accounts and formal computational models with respect to two dimensions: interactivity and uncertainty. Thereby, we aim at capturing the nuances of ToM functions in the context of social decision processes. We suggest there to be an increase in ToM engagement and multiplexing as social cognitive decision-making tasks become more interactive and uncertain. We propose that representing others as intentional and goal directed agents who perform consequential actions is elicited only at the edges of these two dimensions. Further, we argue that computational models of valuation and beliefs follow these dimensions to best allow researchers to effectively model sophisticated ToM-processes. Finally, we relate this typology to neuroimaging findings in neurotypical (NT) humans, studies of persons with autism spectrum (AS), and studies of nonhuman primates.}
}
@article{GARCIANUNES2020102607,
title = {A computational tool for weak signals classification – Detecting threats and opportunities on politics in the cases of the United States and Brazilian presidential elections},
journal = {Futures},
volume = {123},
pages = {102607},
year = {2020},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2020.102607},
url = {https://www.sciencedirect.com/science/article/pii/S0016328720300999},
author = {Pedro Ivo Garcia-Nunes and Pedro Artico Rodrigues and Kaulitz Guimarães Oliveira and Ana Estela Antunes {da Silva}},
keywords = {Conceptual systems, Opportunities, Threats, Weak signals},
abstract = {The literature on weak signals (WS) has been fruitful in recent years and this specific type of information has attracted the attention of several disciplines, notably the futures studies. However, most of these studies still focus on conceptual discussions, terminology, or the proposal for frameworks that do not take advantage of the evolution of information and communication technologies. In this paper, authors discussed the lack of tools to computationally support WS handling. In response to this lack, a computational tool was developed considering a previously published method for WS classification based on conceptual systems. This tool was applied and evaluated in experimental cases about surprising events that occurred in politics in recent years, considering traditional metrics of information retrieval. Experiments illustrate that organizations can create several conceptual systems to represent different scenarios and types of knowledge; after all, results showed that the tool can operate according to different artifacts of knowledge representation. This capacity is useful to mitigate the effects of the surveillance filter though the evidence does not directly confirm its usefulness for the monitoring activities. Furthermore, the tool provides a list of threats, opportunities and unlabeled WS that can trigger other steps of sensemaking about these signals.}
}
@article{FILOMENA201914,
title = {A computational approach to ‘The Image of the City’},
journal = {Cities},
volume = {89},
pages = {14-25},
year = {2019},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2019.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0264275118309776},
author = {Gabriele Filomena and Judith A. Verstegen and Ed Manley},
keywords = {Image of the City, Cognitive maps, Kevin Lynch, Street network, GIScience},
abstract = {In The Image of the City Lynch describes how individuals perceive and recall features in urban spaces. The most distinctive elements in the urban landscape - categorised in paths, nodes, edges, districts and landmarks - give shape to individuals' mental representation of the city. Lynch’s approach has stimulated research into spatial cognition, urban design and artificial intelligence, and it still represents an essential pillar in the analysis of urban dynamics. Nevertheless, an explicit link between The Image of the City and GIScience has not been completely explored yet. In this paper, a computational approach to The Image of the City is proposed. Different perspectives in spatial cognition and GIS research are integrated to obtain a complete Image of the City, in which the most salient elements are shared by a large part of citizens. Nodes, paths and districts were identified through network science techniques. Methods drawn from the information approach to The Image of the City are used to detect landmarks, integrating the complexity of points of reference in their visual, structural and semantic components, as conceptualised by Lynch and successive research. The methods were applied to the central area of Boston and built using freely available spatial datasets. Results were compared to Lynch’s maps to evaluate the methodology: besides a considerable discrepancy with regard to landmarks, a good correspondence for paths, nodes, edges and districts was found.}
}
@incollection{BLACK2021105,
title = {10 - Mutual benefit from library collaboration with computational biologists: the cropPAL project at the University of Western Australia},
editor = {Jeremy Atkinson},
booktitle = {Technology, Change and the Academic Library},
publisher = {Chandos Publishing},
pages = {105-114},
year = {2021},
series = {Chandos Information Professional Series},
isbn = {978-0-12-822807-4},
doi = {https://doi.org/10.1016/B978-0-12-822807-4.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128228074000105},
author = {Kylie Black},
keywords = {cropPAL, partnerships, collaboration, commercialisation, market research, DeweyFish, ON Prime},
abstract = {In 2016–17, the University of Western Australia (UWA) Library partnered with researchers in the Australian Research Council’s Centre of Excellence in Plant Energy Biology to produce cropPAL2, a database providing the subcellular locations for proteins in crops significant for food production. The project team consisted of computational biologists, software engineers and a librarian, in which the Library contributed expertise in developing search strategies, research data management and enhancing discoverability of cropPAL2 and its dataset. The Library continues to be a key player in this collaboration, a first for UWA, both in the innovative process and as a key driver in directing the development of commercial software for the wider benefit of researchers at UWA and beyond.}
}
@article{MOLINSRUANO2018428,
title = {Phogo: A low cost, free and “maker” revisit to Logo},
journal = {Computers in Human Behavior},
volume = {80},
pages = {428-440},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.09.029},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217305551},
author = {Pablo Molins-Ruano and Carlos Gonzalez-Sacristan and Carlos Garcia-Saura},
keywords = {Computational thinking, Technology education, Educational robots, LOGO, Pre-university education},
abstract = {Today it is almost impossible to spend a single day without depending on an information system, a computer or any other form of computation. Though the starting barrier is low, fundamental concepts are still required in order to manage the technicalities of the engineering environment and everyday computational systems. In 1967, Logo proposed to teach abstract programming concepts by providing a set of functions that had intuitive, visible effects over a robotic Turtle. LOGO was a success, but the robots quickly migrated into computer simulations. From LOGO, many followed. Scratch and Lego Mindstorm are some of the most notorious examples. Both introduced graphical block-based programming interfaces. We propose to bring back the powerful ideas behind LOGO by updating it with state of the art technologies. Phogo combines Python, Arduino and 3D printing into a low cost robot that is easy to build and control. The robot has a pen to draw shapes and can be commanded from a computer via a wireless link that is transparent to the students. The use of a physical robot can make programming more accessible for students with disabilities. The open and maker philosophies behind Phogo makes it more interesting as students will be able to access and study the electronic components. The textual programing language can be a long life companion for the students. In this work we discuss LOGO and other projects inspired by it, and we also share the methodology and design decisions behind Phogo, the results of its application in a workshop and the improvements we are currently developing.}
}
@article{BUKOWSKI202116,
title = {Computational medicine, present and the future: obstetrics and gynecology perspective},
journal = {American Journal of Obstetrics and Gynecology},
volume = {224},
number = {1},
pages = {16-34},
year = {2021},
issn = {0002-9378},
doi = {https://doi.org/10.1016/j.ajog.2020.08.057},
url = {https://www.sciencedirect.com/science/article/pii/S0002937820308851},
author = {Radek Bukowski and Karl Schulz and Kelly Gaither and Keri K. Stephens and Dave Semeraro and Justin Drake and Gordon Smith and Craig Cordola and Thaleia Zariphopoulou and Thomas J.R. Hughes and Christopher Zarins and Dimitri Kusnezov and Donna Howard and Tinsley Oden},
keywords = {computation, data, data-driven models, machine learning, modeling, physics-based models, theory-based models, uncertainty},
abstract = {Medicine is, in its essence, decision making under uncertainty; the decisions are made about tests to be performed and treatments to be administered. Traditionally, the uncertainty in decision making was handled using expertise collected by individual providers and, more recently, systematic appraisal of research in the form of evidence-based medicine. The traditional approach has been used successfully in medicine for a very long time. However, it has substantial limitations because of the complexity of the system of the human body and healthcare. The complex systems are a network of highly coupled components intensely interacting with each other. These interactions give those systems redundancy and thus robustness to failure and, at the same time, equifinality, that is, many different causative pathways leading to the same outcome. The equifinality of the complex systems of the human body and healthcare system demand the individualization of medical care, medicine, and medical decision making. Computational models excel in modeling complex systems and, consequently, enabling individualization of medical decision making and medicine. Computational models are theory- or knowledge-based models, data-driven models, or models that combine both approaches. Data are essential, although to a different degree, for computational models to successfully represent complex systems. The individualized decision making, made possible by the computational modeling of complex systems, has the potential to revolutionize the entire spectrum of medicine from individual patient care to policymaking. This approach allows applying tests and treatments to individuals who receive a net benefit from them, for whom benefits outweigh the risk, rather than treating all individuals in a population because, on average, the population benefits. Thus, the computational modeling–enabled individualization of medical decision making has the potential to both improve health outcomes and decrease the costs of healthcare.}
}
@article{KARA2015526,
title = {A Critical Look at the Digital Technologies in Architectural Education: When, where, and how?},
journal = {Procedia - Social and Behavioral Sciences},
volume = {176},
pages = {526-530},
year = {2015},
note = {International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.506},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815005431},
author = {Levent Kara},
keywords = {architectural pedagogy, architectural design, digital architecture, CAD, CAM, computational design, architectural design studio, architectural drawing, architectural modeling, architectural thinking, architectural geometry},
abstract = {In the past decade, architectural education has seen an increasing amount of digital technologies being involved in the design studio curricula. Following the trends in the profession, these various technologies of computer aided drafting, enumerating, modeling, and analysis became not only key pedagogical nodes in the design studio, but also started to shape the overall curricular structure of architectural education as they also needed to be implemented as support courses in order to compensate the learning curves and the number of software available to architects. These digital technologies range from one end of simple drafting, conventional three dimensional modeling, and more sophisticated animation of buildings with a computer, to the other end of inventing new tectonic and spatial geometries using parametric computations. In this context, it will be unrealistic to argue against teaching and using digital technologies in architectural education. When one thinks how the profession has evolved in the past decade, it is necessary to embrace these tools in the architectural curriculum. However, a discussion that has not been clearly resolved is when, where, and how these digital tools are thought and used in the architectural education. My paper argues that the conventional tools of hand drawing, physical modeling, and hand making should be embraced in the foundational levels, and the digital tools should be introduced after developing a certain set of skills of one-to-one physical making where a sense of tectonic resolution, scale, and spatial experience is cultivated as a basis of architectural thinking with digital tools. In what follows, I will discuss this viewpoint through examples from architectural design studio education in the United States and in Turkey.}
}
@article{CADDY1996219,
title = {Regime shifts and paradigm changes: is there still a place for equilibrium thinking?},
journal = {Fisheries Research},
volume = {25},
number = {3},
pages = {219-230},
year = {1996},
issn = {0165-7836},
doi = {https://doi.org/10.1016/0165-7836(95)00443-2},
url = {https://www.sciencedirect.com/science/article/pii/0165783695004432},
author = {J.F. Caddy}
}
@article{STOLPE2024100159,
title = {Artificial intelligence literacy for technology education},
journal = {Computers and Education Open},
volume = {6},
pages = {100159},
year = {2024},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2024.100159},
url = {https://www.sciencedirect.com/science/article/pii/S2666557324000016},
author = {Karin Stolpe and Jonas Hallström},
keywords = {AI literacy, Ethical issues, AI in education},
abstract = {The interest in artificial intelligence (AI) in education has erupted during the last few years, primarily due to technological advances in AI. It is therefore argued that students should learn about AI, although it is debated exactly how it should be applied in education. AI literacy has been suggested as a way of defining competencies for students to acquire to meet a future everyday- and working life with AI. This study argues that researchers and educators need a framework for integrating AI literacy into technological literacy, where the latter is viewed as a multiliteracy. This study thus aims to critically analyse and discuss different components of AI literacy found in the literature in relation to technological literacy. The data consists of five AI literacy frameworks related to three traditions of technological knowledge: technical skills, technological scientific knowledge, and socio-ethical technical understanding. The results show that AI literacy for technology education emphasises technological scientific knowledge (e.g., knowledge about what AI is, how to recognise AI, and systems thinking) and socio-ethical technical understanding (e.g., AI ethics and the role of humans in AI). Technical skills such as programming competencies also appear but are less emphasised. Implications for technology education are also discussed, and a framework for AI literacy for technology education is suggested.}
}
@article{LEE2025100890,
title = {Generative ecodesign for mechanical products: A design workflow},
journal = {Cleaner Engineering and Technology},
volume = {24},
pages = {100890},
year = {2025},
issn = {2666-7908},
doi = {https://doi.org/10.1016/j.clet.2025.100890},
url = {https://www.sciencedirect.com/science/article/pii/S2666790825000138},
author = {Amos Wei Lun Lee and Kevin Kai Wern Seah and Bing Feng Ng and Ee Teng Zhang and Wen Feng Lu and Jonathan Sze Choong Low},
keywords = {Carbon emission, Generative design, Product design, Environmental sustainability, Ecodesign},
abstract = {Harnessing advancements in artificial intelligence, generative design holds great potential to support designers in their ecodesign efforts by enabling them to explore design solutions beyond the limits of their imagination and expertise. However, a systematic literature review on the application of generative design in ecodesign reveals a clear underrepresentation, highlighting a missed opportunity in the field. To bridge this gap, a seven-component generative ecodesign workflow for mechanical products was developed. This workflow combines generative design algorithms, typically used for geometry lightweighting, with life cycle thinking. It facilitates the generation, evaluation, and identification of design solutions by considering the design tri-factor: material choice, manufacturing process, and geometry. This represents the first reported product ecodesign tool to integrate generative design with ecodesign principles while simultaneously addressing all three elements of the design tri-factor. To showcase its utility, environmentally optimal design alternatives were created for a mountain bicycle's handlebar stem.}
}
@article{JARMAN2022225,
title = {Critical measurement issues in the assessment of social media influence on body image},
journal = {Body Image},
volume = {40},
pages = {225-236},
year = {2022},
issn = {1740-1445},
doi = {https://doi.org/10.1016/j.bodyim.2021.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S1740144521001583},
author = {Hannah K. Jarman and Siân A. McLean and Scott Griffiths and Samantha J. Teague and Rachel F. Rodgers and Susan J. Paxton and Emma Austen and Emily Harris and Trevor Steward and Adrian Shatte and Long {Khanh-Dao Le} and Tarique Anwar and Cathrine Mihalopoulos and Alexandra G. Parker and Zali Yager and Matthew Fuller-Tyszkiewicz},
keywords = {Social media, Body image, Qualitative, Survey, Experimental, Momentary assessment, Web scraping, Computational modelling, Measurement, Assessment},
abstract = {Progress towards understanding how social media impacts body image hinges on the use of appropriate measurement tools and methodologies. This review provides an overview of common (qualitative, self-report survey, lab-based experiments) and emerging (momentary assessment, computational) methodological approaches to the exploration of the impact of social media on body image. The potential of these methodologies is detailed, with examples illustrating current use as well as opportunities for expansion. A key theme from our review is that each methodology has provided insights for the body image research field, yet is insufficient in isolation to fully capture the nuance and complexity of social media experiences. Thus, in consideration of gaps in methodology, we emphasise the need for big picture thinking that leverages and combines the strengths of each of these methodologies to yield a more comprehensive, nuanced, and robust picture of the positive and negative impacts of social media.}
}
@incollection{COUCLELIS2009245,
title = {Computational Human Geography},
editor = {Rob Kitchin and Nigel Thrift},
booktitle = {International Encyclopedia of Human Geography},
publisher = {Elsevier},
address = {Oxford},
pages = {245-250},
year = {2009},
isbn = {978-0-08-044910-4},
doi = {https://doi.org/10.1016/B978-008044910-4.00669-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780080449104006696},
author = {H. Couclelis},
keywords = {Agent-based models, Cellular automata, Geocomputation, Geo(infor)matics, GIS, Location-based services, Models/modeling, Public participation GIS, Spatial analysis},
abstract = {Computational human geography refers to the use of computational methods and techniques to solve problems in human geography research and applications. Geographic information systems (GIS) and science are a big part of computational human geography but the notion is considerably broader, encompassing spatial process modeling and simulation, the modeling of spatial decision and behavior, visualization techniques, most aspects of spatial analysis, and an increasing number of other areas. Computation in human geography goes back to the beginnings of the quantitative revolution and is philosophically related though methodologically distinct from it. Two major thrusts have persisted through the years: the use of numerical techniques to solve large, complex quantitative problems; and the development of models of complex spatial processes expressed directly in computational terms. Typical exponents of the latter kinds of applications are cellular automata models of urban and environmental processes, and agent-based models of spatial decision and behavior. More recent developments involve applications of mobile and portable computing. Critiques of computational human geography originate from both within the field and from the humanistic and social theory perspectives. The former address a number of epistemological and methodological problems while the latter tend to focus on issues of ontology and representation.}
}
@article{ALI20201425,
title = {Re-thinking adaptive immunity in the beetles: Evolutionary and functional trajectories of lncRNAs},
journal = {Genomics},
volume = {112},
number = {2},
pages = {1425-1436},
year = {2020},
issn = {0888-7543},
doi = {https://doi.org/10.1016/j.ygeno.2019.08.012},
url = {https://www.sciencedirect.com/science/article/pii/S0888754319302034},
author = {Ali Ali and Hesham M. {Abd El Halim}},
keywords = {Immune memory, Priming, , Macrophage},
abstract = {Unlike vertebrate animals, invertebrates lack lymphocytes and therefore have historically been believed not to develop immune memory. A few studies have reported evidence of immune priming in insects; however, these studies lack the molecular mechanism and proposed it might be different among taxa. Since lncRNAs are known to regulate the immune response, we identified 10,120 lncRNAs in Tribolium castaneum genome-wide followed by transcriptome analysis of primed and unprimed larvae of different infectious status. A shift in lncRNA expression between Btt primed larvae and other treatment groups provides evidence of immune memory response. A few “priming” lncRNAs (n = 9) were uniquely regulated in Btt primed larvae. Evidence suggests these lncRNAs are likely controlling immune priming in Tribolium by regulating expression of genes involved in proteasomal machinery, Notch system, zinc metabolism, and methyltransferase activity, which are necessary to modulate phagocytosis. Our results support a conserved immune priming mechanism in a macrophage-dependent manner.}
}
@article{SWANSON2020100961,
title = {The relationship between executive processing and computational growth among monolingual and english learners with and without math difficulties: Does it help to be bilingual?},
journal = {Cognitive Development},
volume = {56},
pages = {100961},
year = {2020},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2020.100961},
url = {https://www.sciencedirect.com/science/article/pii/S0885201420301155},
author = {H. Lee Swanson},
keywords = {Math difficulties, English learner, Bilingual, Working memory, Cognition, Math computation},
abstract = {Does the commonly reported math achievement gap among elementary school monolingual and English learners (ELs) with and without math difficulties reflect variations in executive processing? This cohort-sequential study (N = 841) explored the cognitive processes that underlie in elementary school children’s math computational growth who are monolingual (English-only) or English learners with Spanish as a first language. Three language subgroups (proficient ELs [relatively proficient in both English and Spanish vocabulary], less proficient ELs [more proficient in English when compared to Spanish vocabulary] and monolingual [English-only]) children with and without math difficulties (MD) were compared on measures of math computation and cognitive growth. As expected, children with MD identified at wave 1 underperformed children without MD in their rate of growth and their level of computational and working memory (WM) performance in the final testing wave. However, two additional findings occurred. First, executive processing measures (working memory and inhibition) were significantly related to computational growth even when measures of reading, fluid intelligence, STM, naming speed and SES were partialed in the analysis. Second, no statistical advantages in executive processing or computation emerged in favor of EL children relative to monolingual children. Taken together, the results support the notion that (a) growth in math computation is tied to growth in the executive system and (b) EL children relatively proficient in English and Spanish experience no growth advantages in WM or computation compared to monolingual children.}
}
@article{YANG20101297,
title = {Computational optimization, modelling and simulation–a paradigm shift},
journal = {Procedia Computer Science},
volume = {1},
number = {1},
pages = {1297-1300},
year = {2010},
note = {ICCS 2010},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.04.144},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910001456},
author = {Xin-She Yang and Slawomir Koziel},
keywords = {Algorithm, Black-box modelling, Computational optimization, Derivative-free method, Optimization algorithm, Modelling, Nonlinear optimization, Surragate-based optimization, Simulation},
abstract = {Computational optimization forms an integrated part of modern computational science. Any good design should intend to achieve certain optimality, though optimal solutions are often difficult to find in practice since uncertainty and nonlinearity always present in almost all real-world problems. As resources, time and money are always limited, optimization becomes even more important in practice. This workshop on Computational Optimization, Modelling and Simulation (COMS 2010) at ICCS 2010 will summarize the latest developments of optimization and modelling and their applications in science, engineering and industry}
}
@article{BYSTRITSKY2012428,
title = {Computational non-linear dynamical psychiatry: A new methodological paradigm for diagnosis and course of illness},
journal = {Journal of Psychiatric Research},
volume = {46},
number = {4},
pages = {428-435},
year = {2012},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2011.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0022395611002615},
author = {A. Bystritsky and A.A. Nierenberg and J.D. Feusner and M. Rabinovich},
keywords = {Phenomenology, Mathematical models, Non-linear dynamics, Winner less competition, Psychopathology},
abstract = {The goal of this article is to highlight the significant potential benefits of applying computational mathematical models to the field of psychiatry, specifically in relation to diagnostic conceptualization. The purpose of these models is to augment the current diagnostic categories that utilize a “snapshot” approach to describing mental states. We hope to convey to researchers and clinicians that non-linear dynamics can provide an additional useful longitudinal framework to understand mental illness. Psychiatric phenomena are complex processes that evolve in time, similar to many other processes in nature that have been successfully described and understood within deterministic chaos and non-linear dynamic computational models. Dynamical models describe mental processes and phenomena that change over time, more like a movie than a photograph, with multiple variables interacting over time. The use of these models may help us understand why and how current diagnostic categories are insufficient. They may also provide a new, more descriptive and ultimately more predictive approach leading to better understanding of the interrelationship between psychological, neurobiological, and genetic underpinnings of mental illness.}
}
@article{AILON2020234,
title = {Paraunitary matrices, entropy, algebraic condition number and Fourier computation},
journal = {Theoretical Computer Science},
volume = {814},
pages = {234-248},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2020.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0304397520300797},
author = {Nir Ailon},
keywords = {Fourier transform, Lower bounds, Complexity, Linear algebraic computation},
abstract = {The Fourier Transform is one of the most important linear transformations used in science and engineering. Cooley and Tukey's Fast Fourier Transform (FFT) from 1964 is a method for computing this transformation in time O(nlog⁡n). From a lower bound perspective, relatively little is known. Ailon shows in 2013 an Ω(nlog⁡n) bound for computing the normalized Fourier Transform assuming only unitary operations on two coordinates are allowed at each step, and no extra memory is allowed. In 2014, Ailon then improved the result to show that, in a κ-well conditioned computation, Fourier computation can be sped up by no more than O(κ). The main conjecture is that Ailon's result can be exponentially improved, in the sense that κ-well condition cannot admit ω(log⁡κ) speedup. The main result here is that ‘algebraic’ κ-well condition cannot admit ω(κ) speedup. One equivalent definition of algebraic condition number is related to the degree of polynomials naturally arising as the computation evolves. Using the maximum modulus theorem from complex analysis, we show that algebraic condition number upper bounds standard condition number, and equals it in certain cases. Algebraic condition number is an interesting measure of numerical computation stability in its own right, and provides a novel computational lens. Moreover, based on evidence from other recent related work, we believe that the approach of algebraic condition number has a good chance of establishing an algebraic version of the main conjecture.}
}
@incollection{WARD2018,
title = {Analogy☆},
booktitle = {Reference Module in Neuroscience and Biobehavioral Psychology},
publisher = {Elsevier},
year = {2018},
isbn = {978-0-12-809324-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.21889-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245218890},
author = {Thomas B. Ward},
keywords = {ACME, Analogy, Case study, Computational modeling, Laboratory study, In vivo study, Mapping, Multiconstraint theory, One-to-one correspondence, Parallel connectivity, Retrieval, SME, Source domain, Structure-mapping theory, Systematicity, Target domain},
abstract = {Analogical thinking is a fundamental cognitive process underlying creativity. Analogies map structured knowledge from one domain to another and serve as information for understanding, explaining and creating. Analogy is studied through case study, laboratory, in vivo, neuroscience and computational modeling approaches. The use of analogy is often suggested to be a helpful technique in applied approaches to creativity.}
}
@article{TURKHEIMER2015211,
title = {The brain's code and its canonical computational motifs. From sensory cortex to the default mode network: A multi-scale model of brain function in health and disease},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {211-222},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001189},
author = {Federico E. Turkheimer and Robert Leech and Paul Expert and Louis-David Lord and Anthony C. Vernon},
keywords = {Brain networks, Functional connectivity, Interneurons, Gamma-oscillations, NMDA, GABA, Lateral inhibition, Feedback inhibition, Feed-forward inhibition, Canonical neural computation, Motifs, Default mode network, fMRI, Schizophrenia},
abstract = {A variety of anatomical and physiological evidence suggests that the brain performs computations using motifs that are repeated across species, brain areas, and modalities. The computational architecture of cortex, for example, is very similar from one area to another and the types, arrangements, and connections of cortical neurons are highly stereotyped. This supports the idea that each cortical area conducts calculations using similarly structured neuronal modules: what we term canonical computational motifs. In addition, the remarkable self-similarity of the brain observables at the micro-, meso- and macro-scale further suggests that these motifs are repeated at increasing spatial and temporal scales supporting brain activity from primary motor and sensory processing to higher-level behaviour and cognition. Here, we briefly review the biological bases of canonical brain circuits and the role of inhibitory interneurons in these computational elements. We then elucidate how canonical computational motifs can be repeated across spatial and temporal scales to build a multiplexing information system able to encode and transmit information of increasing complexity. We point to the similarities between the patterns of activation observed in primary sensory cortices by use of electrophysiology and those observed in large scale networks measured with fMRI. We then employ the canonical model of brain function to unify seemingly disparate evidence on the pathophysiology of schizophrenia in a single explanatory framework. We hypothesise that such a framework may also be extended to cover multiple brain disorders which are grounded in dysfunction of GABA interneurons and/or these computational motifs.}
}
@article{VANDENAMEELE2014334,
title = {Thinking out of the dish: what to learn about cortical development using pluripotent stem cells},
journal = {Trends in Neurosciences},
volume = {37},
number = {6},
pages = {334-342},
year = {2014},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2014.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S0166223614000447},
author = {Jelle {van den Ameele} and Luca Tiberi and Pierre Vanderhaeghen and Ira Espuny-Camacho},
abstract = {The development of the cerebral cortex requires the tightly coordinated generation of dozens of neuronal subtypes that will populate specific layers and areas. Recent studies have revealed how pluripotent stem cells (PSC), whether of mouse or human origin, can differentiate into a wide range of cortical neurons in vitro, which can integrate appropriately into the brain following in vivo transplantation. These models are largely artificial but recapitulate a substantial fraction of the complex temporal and regional patterning events that occur during in vivo corticogenesis. Here, we review these findings with emphasis on the new perspectives that they have brought for understanding of cortical development, evolution, and diseases.}
}
@incollection{MAERTENS2025358,
title = {Regrettable Substitutions},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {358-364},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00099-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157424000995},
author = {Alexandra Maertens and Thomas Hartung},
keywords = {Alternative assessments, Chemical policy, Environmental justice, Exposure science, Green toxicology, Hazard, Life cycle analysis, Toxicity mechanisms},
abstract = {Regrettable substitutions refer to the unintended consequences that arise when replacing one substance with another, often resulting in new problems or uncertainties. Regrettable substitutions have been observed in various functional classes, such as flame retardants, where initial solutions aimed at enhancing fire safety but have raised concerns about persistent environmental pollution and potential health risks. Regrettable substitutions are often caused by a lack of data about hazard or exposure, life-cycle considerations or a failure to consider other functionality more broadly. Initial solutions aimed at enhancing fire safety, product performance or crop protection have ended up raising new concerns about persistent environmental pollution, ecosystem effects, occupational hazards and long-term health risks. To avoid future regrettable substitutions, a more holistic, data-driven approach to chemical alternatives assessment is needed. This should incorporate human-relevant mechanistic toxicity testing, quantitative exposure modeling, life cycle thinking, and consideration of safer chemistry solutions that maintain product functionality. Enhanced cross-sector collaboration, data sharing, and clear risk communication to consumers is also critical. Integrating these green toxicology principles into chemical design and evaluation can help achieve sustainable substitutions that maximize benefits and minimize risks.}
}
@article{BRASCH2012299,
title = {Thinking outside the cell: how cadherins drive adhesion},
journal = {Trends in Cell Biology},
volume = {22},
number = {6},
pages = {299-310},
year = {2012},
issn = {0962-8924},
doi = {https://doi.org/10.1016/j.tcb.2012.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0962892412000529},
author = {Julia Brasch and Oliver J. Harrison and Barry Honig and Lawrence Shapiro},
abstract = {Cadherins are a superfamily of cell surface glycoproteins whose ectodomains contain multiple repeats of β-sandwich extracellular cadherin (EC) domains that adopt a similar fold to immunoglobulin domains. The best characterized cadherins are the vertebrate ‘classical’ cadherins, which mediate adhesion via trans homodimerization between their membrane-distal EC1 domains that extend from apposed cells, and assemble intercellular adherens junctions through cis clustering. To form mature trans adhesive dimers, cadherin domains from apposed cells dimerize in a ‘strand-swapped’ conformation. This occurs in a two-step binding process involving a fast-binding intermediate called the ‘X-dimer’. Trans dimers are less flexible than cadherin monomers, a factor that drives junction assembly following cell–cell contact by reducing the entropic cost associated with the formation of lateral cis oligomers. Cadherins outside the classical subfamily appear to have evolved distinct adhesive mechanisms that are only now beginning to be understood.}
}
@incollection{HUDLICKA2017383,
title = {Chapter 16 - Computational Modeling of Cognition–Emotion Interactions: Theoretical and Practical Relevance for Behavioral Healthcare},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {383-436},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00016-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000161},
author = {Eva Hudlicka},
keywords = {emotion–cognition modeling, modeling mechanism of therapeutic action, computational models of affective disorders and psychopathology, therapeutic games, behavioral healthcare technology, transdiagnostic model},
abstract = {Recent years have witnessed an increasing interest in developing computational models of emotion and emotion–cognition interaction, within the emerging area of computational affective science. At the same time, emotion theorists and clinical psychologists have begun to recognize the importance of moving beyond descriptive characterizations of psychopathology, and identifying the underlying mechanisms that mediate both the etiology of affective disorders, and their treatment: the transdiagnostic approach to psychopathology. Computational models of cognition–emotion interactions have the potential to facilitate more accurate assessment and diagnosis of affective disorders, and to provide a basis for more efficient and targeted approaches to their treatment, through an improved understanding of the underlying mechanisms. This chapter discusses the state-of-the-art in modeling emotion–cognition interaction and the relevance of these models for understanding the mechanisms mediating psychopathology and therapeutic action. The discussion is limited to symbolic models and theories defined at the psychological, versus neural, level. The chapter also outlines how these models can support the development of serious therapeutic games, to enhance assessment and treatment methods in behavioral healthcare.}
}
@article{MAXIM2025,
title = {Identifying Key Principles and Commonalities in Digital Serious Game Design Frameworks: Scoping Review},
journal = {JMIR Serious Games},
volume = {13},
year = {2025},
issn = {2291-9279},
doi = {https://doi.org/10.2196/54075},
url = {https://www.sciencedirect.com/science/article/pii/S2291927925000315},
author = {Raluca Ionela Maxim and Joan Arnedo-Moreno},
keywords = {entertainment game design frameworks, serious game design frameworks, design principles, empathic design thinking, artificial intelligence},
abstract = {Background
Digital serious games (DSGs), designed for purposes beyond entertainment and consumed via electronic devices, have garnered attention for their potential to enhance learning and promote behavior change. Their effectiveness depends on the quality of their design. Frameworks for DSG design can guide the creation of engaging games tailored to objectives such as education, health, and social impact.
Objective
This study aims to review, analyze, and synthesize the literature on digital entertainment game design frameworks and DSG design frameworks (DSGDFWs). The focus is on conceptual frameworks offering high-level guidance for the game creation process rather than component-specific tools. We explore how these frameworks can be applied to create impactful serious games in fields such as health care and education. Key goals include identifying design principles, commonalities, dependencies, gaps, and opportunities in the literature. Suggestions for future research include empathic design thinking, artificial intelligence integration, and iterative improvements. The findings culminate in a synthesized 4-phase design process, offering generic guidelines for designers and developers to create effective serious games that benefit society.
Methods
A 2-phase methodology was used: a scoping literature review and cluster analysis. A targeted search across 7 databases (ACM, Scopus, Springer, IEEE, Elsevier, JMIR Publications, and SAGE) was conducted using PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 guidelines. Studies included academic or industry papers evaluating digital game design frameworks. Cluster analysis was applied to categorize the data, revealing trends and correlations among frameworks.
Results
Of 987 papers initially identified, 25 (2.5%) met the inclusion criteria, with an additional 22 identified through snowballing, resulting in 47 papers. These papers presented 47 frameworks, including 16 (34%) digital entertainment game design frameworks and 31 (66%) DSGDFWs. Thematic analysis grouped frameworks into categories, identifying patterns and relationships between design elements. Commonalities, dependencies, and gaps were analyzed, highlighting opportunities for empathic design thinking and artificial intelligence applications. Key considerations in DSG design were identified and presented in a 4-phase design baseline with the outcome of a list of design guidelines that might, according to the literature, be applied to an end-to-end process of designing and building future innovative solutions.
Conclusions
The main benefits of using DSGDFWs seem to be related to enhancing the effectiveness of serious games in achieving their intended objectives, such as learning, behavior change, and social impact. Limitations primarily seem to be related to constraints associated with the specific contexts in which the serious games are developed and used. Approaches in the future should be aimed at refining and adapting existing frameworks to different contexts and purposes, as well as exploring new frameworks that incorporate emerging technologies and design principles.}
}
@article{MITTAL1994253,
title = {Massively parallel finite element computation of incompressible flows involving fluid-body interactions},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {112},
number = {1},
pages = {253-282},
year = {1994},
issn = {0045-7825},
doi = {https://doi.org/10.1016/0045-7825(94)90029-9},
url = {https://www.sciencedirect.com/science/article/pii/0045782594900299},
author = {S. Mittal and T.E. Tezduyar},
abstract = {We describe our massively parallel finite element computations of unsteady incompressible flows involving fluid-body interactions. These computations are based on the Deforming-Spatial-Domain/Stabilized-Space-Time (DSD/SST) finite element formulation. Unsteady flows past a stationary NACA 0012 airfoil are computed for Reynolds numbers 1000, 5000 and 100 000. Significantly different flow patterns are observed for these three cases. The method is then applied to computation of the dynamics of an airfoil falling in a viscous fluid under the influence of gravity. It is observed that the location of the center of gravity of the airfoil plays an important role in determining its pitch stability. Computations are reported also for simulation of the dynamics of a two-dimensional ‘projectile’ that has a certain initial velocity. Specially designed mesh moving schemes are employed to eliminate the need for remeshing. All these computations were carried out on the Thinking Machines CM-200 and CM-5 supercomputers, with major speed-ups compared to traditional supercomputers. The implicit equation systems arising from the finite element discretizations of these large-scale problems are solved iteratively by using the GMRES update technique with diagonal preconditioners. The finite element formulations and their parallel implementations assume unstructured meshes.}
}
@article{HAO20231,
title = {A Commentary on Towards autonomous artificial agents with an active self: Modeling sense of control in situated action},
journal = {Cognitive Systems Research},
volume = {79},
pages = {1-3},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1389041722001085},
author = {Chenxu Hao and Nele Russwinkel and Daniel F.B. Haeufle and Philipp Beckerle},
keywords = {Human–robot interaction, Unified models of HRI, Anticipatory thinking},
abstract = {Kahl et al., (2022) present a computational model of an autonomous agent implemented with an active self. With ideas based on the Free Energy Principle (Friston and Kiebel, 2009), their model tackles the challenge to unify higher-level cognitive activities and lower-level sensorimotor control as the autonomous agent maintains situational awareness while interacting with the environment. While Kahl et al., (2022) focus on modeling a single agent, we argue that this challenge similarly appears in modeling human–robot interaction (HRI). In this commentary, we discuss how the conceptual framework from Kahl et al., (2022) could inspire unified models of physical and cognitive HRI and how the modeling approach from Kahl et al., (2022) can potentially be applied to anticipatory thinking in robotics to support the human in daily life.}
}
@article{DELGADO2019133,
title = {Computational methods for Gene Regulatory Networks reconstruction and analysis: A review},
journal = {Artificial Intelligence in Medicine},
volume = {95},
pages = {133-145},
year = {2019},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2018.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0933365718303865},
author = {Fernando M. Delgado and Francisco Gómez-Vela},
keywords = {Gene Network, Systems biology, Networks validation, Gene Regulatory Network, Gene Network inference},
abstract = {In the recent years, the vast amount of genetic information generated by new-generation approaches, have led to the need of new data handling methods. The integrative analysis of diverse-nature gene information could provide a much-sought overview to study complex biological systems and processes. In this sense, Gene Regulatory Networks (GRN) arise as an increasingly-promising tool for the modelling and analysis of biological processes. This review is an attempt to summarize the state of the art in the field of GRNs. Essential points in the field are addressed, thereof: (a) the type of data used for network generation, (b) machine learning methods and tools used for network generation, (c) model optimization and (d) computational approaches used for network validation. This survey is intended to provide an overview of the subject for readers to improve their knowledge in the field of GRN for future research.}
}
@article{COHEN1981285,
title = {The power of parallel thinking},
journal = {Journal of Economic Behavior & Organization},
volume = {2},
number = {4},
pages = {285-306},
year = {1981},
issn = {0167-2681},
doi = {https://doi.org/10.1016/0167-2681(81)90011-1},
url = {https://www.sciencedirect.com/science/article/pii/0167268181900111},
author = {Michael D. Cohen},
abstract = {A small computer model demonstrates that an appropriate organization of boundedly rational individuals can find optimal policies in an environment that is overwhelmingly complex for unorganized decision makers. The model is also used to identify conditions under which optimal — or even good — policies are not found. The demonstrated adaptive power of the model is interpreted in light of recent developments in the theory of computational complexity that place new stress on powerful methods of search, and of new models from computer science which markedly advance search effectiveness by harnessing parallel structures of information processing.}
}
@article{SHARP2025118,
title = {Anxiety involves altered planning},
journal = {Trends in Cognitive Sciences},
volume = {29},
number = {2},
pages = {118-121},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324002924},
author = {Paul B. Sharp},
keywords = {planning, anxiety, reinforcement learning},
abstract = {Clinicians have suggested but not shown how anxiety involves altered planning. Here, I synthesize and extend computational models of planning in a framework that can be used to explain planning biases in anxiety. To spur its development, I spotlight two of its promising areas: task construal and meta-control.}
}
@article{COWARD2014164,
title = {Brain Computational Primitives},
journal = {Procedia Computer Science},
volume = {41},
pages = {164-175},
year = {2014},
note = {5th Annual International Conference on Biologically Inspired Cognitive Architectures, 2014 BICA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.11.100},
url = {https://www.sciencedirect.com/science/article/pii/S1877050914015452},
author = {L. Andrew Coward},
abstract = {The brain uses computational primitives that are analogous with but qualitatively different from the computational primitives used in electronic computer systems. The primary computational primitives of the brain are described, and their implementation in anatomy and physiology discussed. Combinations and sequences of these primitives implement cognitive tasks. Many of the primitives have also been implemented electronically. The brain is a very effective general learning system, and although an artificial general intelligence system will be required to learn a different range of behaviours from the brain, the computational primitives used by the brain are the best available guide to appropriate primitives for such an AGI system.}
}
@article{BEYTIA2022101732,
title = {Towards a Digital Reflexive Sociology: Using Wikipedia's Biographical Repository as a Reflexive Tool},
journal = {Poetics},
volume = {95},
pages = {101732},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101732},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001140},
author = {Pablo Beytía and Hans-Peter Müller},
keywords = {Reflexive sociology, digital sociology, sociology of knowledge, computational social science, digital methods},
abstract = {We propose the development of 'digital reflexive sociology', understood as the use of digital methods and Big Data to reflect on the social and historical circumstances of sociologists and sociological thinking. To show this approach's potential, we employ Wikipedia as a ‘reflexive tool’, i.e., an external artefact of self-observation that can help sociologists to notice conventions, biases, and blind spots within their discipline. We analyse the collective patterns of the 500 most notable sociologists on Wikipedia, performing structural, network, and text analyses of their biographies. Our exploration reveals patterns in their historical frequency, gender composition, geographical concentration, birth-death mobility, centrality degree, biographical clustering, and proximity between countries, also stressing institutions, events, places, and relevant dates from a biographical point of view. Linking these patterns in a diachronic way, we distinguish five generations of sociologists recorded on Wikipedia and emphasise the high historical concentration of the discipline in geographical areas, gender, and schools of thought. Drawing on these results, we discuss the potential of using digital repositories and methods to enhance reflexivity within sociology.}
}
@article{MURRAY2018777,
title = {Biophysical Modeling of Large-Scale Brain Dynamics and Applications for Computational Psychiatry},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {3},
number = {9},
pages = {777-787},
year = {2018},
note = {Computational Methods and Modeling in Psychiatry},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2018.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2451902218301782},
author = {John D. Murray and Murat Demirtaş and Alan Anticevic},
keywords = {Computational model, Functional connectivity, Neuroimaging, Resting-state, Schizophrenia, Transcriptomics},
abstract = {Noninvasive neuroimaging has revolutionized the study of the organization of the human brain and how its structure and function are altered in psychiatric disorders. A critical explanatory gap lies in our mechanistic understanding of how systems-level neuroimaging biomarkers emerge from underlying synaptic-level perturbations associated with a disease state. We describe an emerging computational psychiatry approach leveraging biophysically based computational models of large-scale brain dynamics and their potential integration with clinical and pharmacological neuroimaging. In particular, we focus on neural circuit models, which describe how patterns of functional connectivity observed in resting-state functional magnetic resonance imaging emerge from neural dynamics shaped by inter-areal interactions through underlying structural connectivity defining long-range projections. We highlight the importance of local circuit physiological dynamics, in combination with structural connectivity, in shaping the emergent functional connectivity. Furthermore, heterogeneity of local circuit properties across brain areas, which impacts large-scale dynamics, may be critical for modeling whole-brain phenomena and alterations in psychiatric disorders and pharmacological manipulation. Finally, we discuss important directions for future model development and biophysical extensions, which will expand their utility to link clinical neuroimaging to neurobiological mechanisms.}
}
@article{LIU2017168,
title = {A landmark-based data-driven approach on 2.5D facial attractiveness computation},
journal = {Neurocomputing},
volume = {238},
pages = {168-178},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.01.050},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217301248},
author = {Shu Liu and Yang-Yu Fan and Zhe Guo and Ashok Samal and Afan Ali},
keywords = {Facial attractiveness computation, 2.5 D, Geometric features, Data-driven, BJUT-3D},
abstract = {Investigating the nature and components of face attractiveness from a computational view has become an emerging topic in facial analysis research. In this paper, a multi-view (frontal and profile view, 2.5D) facial attractiveness computational model is developed to explore how face geometry affects its attractiveness. A landmark-based, data-driven method is introduced to construct a huge dimension of three kinds of geometric facial measurements, including ratios, angles, and inclinations. An incremental feature selection algorithm is proposed to systematically select the most discriminative subset of geometric features, which are finally mapped to an attractiveness score through the application of support vector regression (SVR). On a dataset of 360 facial images pre-processed from BJUT-3D Face Database and an attractiveness score dataset collected from human raters, we show that the computational model performs well with low statistic error (MSE=0.4969) and good predictability (R2=0.5756).}
}
@incollection{YERPUDE2022335,
title = {CHAPTER FOURTEEN - Computational analysis of nanofluids-based drug delivery system: Preparation, current development and applications of nanofluids},
editor = {Shriram S. Sonawane and Hussein A. Mohammed and Arvind Kumar Mungray and Shirish H. Sonawane},
booktitle = {Applications of Nanofluids in Chemical and Bio-medical Process Industry},
publisher = {Elsevier},
pages = {335-364},
year = {2022},
isbn = {978-0-323-90564-0},
doi = {https://doi.org/10.1016/B978-0-323-90564-0.00014-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323905640000143},
author = {S.T. Yerpude and A.K. Potbhare and P.R. Bhilkar and Parag Thakur and Pratiksha Khiratkar and Martin F. Desimone and P.R. Dhongle and Shriram S. Sonawane and Clara Goncalves and R.G. Chaudhary},
keywords = {CFD, Computational analysis, Drug delivery, Mathematical modeling, Nanofluids, Nano-drugs},
abstract = {Nanoparticles have been widely employed as a drug delivery carrier and a direct targeting agent. Off course, nanoparticles have been precisely and accurately designed to improve their therapeutical efficacy. Nowadays, computational modeling is frequently used to design novel and smart nanoparticles. In this chapter, we provide an overview and general idea about nanofluids in association with computational applications aimed at the improvement of nano-drug delivery coordination. Nanotechnology and nanobiotechnology-based conceptual innovations in combination with computational modeling are extensively employed in various areas of basic and applied sciences. On the same line, these technologies have a greater impact in the field of medicine and biology. We intended to look upon different aspects regarding nano-drugs and nanofluids comprising their preparation and stabilization methods and also focusing on mathematical modeling, stability mechanism, and biomedical applications of nanofluids. Similarly, imperative and special concern was given to the topic of computational fluid dynamics (CFD).}
}
@incollection{GOMEZPEROSANZ2019906,
title = {Computational Immunogenetics},
editor = {Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology},
publisher = {Academic Press},
address = {Oxford},
pages = {906-930},
year = {2019},
isbn = {978-0-12-811432-2},
doi = {https://doi.org/10.1016/B978-0-12-809633-8.20452-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128096338204524},
author = {Marta {Gómez Perosanz} and Giulia Russo and Jose Luis {Sanchez-Trincado Lopez} and Marzio Pennisi and Pedro A. Reche and Adrian Shepherd and Francesco Pappalardo},
keywords = {Agent based modelling, Antibody modelling, Bioinformatics for immune system modelling, Crystallography, Epitopes prediction, Immune system modelling, Immune system pathways, Immunotherapies, In silico trials, Molecular and cellular modelling, Multi-scale modelling, ODE modelling, Petri nets, T and B cells, Vaccines},
abstract = {Computational immunogenetics encompasses the use and application of bioinformatics methods, mathematical models and statistical techniques for the study of immune system function. The considerable heterogeneity of the immune system requires systems approaches to be used to model such a complexity and to respond to questions posed by biomedical audience to help them solve biomedical questions. Computational approaches are increasingly vital to understand the implications of the wealth of gene expression and epigenomics data being gathered from immune cells, and dozens of immune databases play a vital role in organizing the vast quantities of experimental data generated by modern high-throughput technologies. Multi-scale methodologies are increasingly being used to characterise the interplay between the molecular, cellular and organism levels of the immune system. Finally, computational immunology is making an important contribution to an emerging field of computational biomedicine: in silico clinical trials.}
}
@article{THANATIPANONDA202138,
title = {A multi-computational exploration of some games of pure chance},
journal = {Journal of Symbolic Computation},
volume = {104},
pages = {38-68},
year = {2021},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2020.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747717120300183},
author = {Thotsaporn “Aek” Thanatipanonda and Doron Zeilberger},
keywords = {Experimental mathematics, Games of pure chance, Symbolic computation},
abstract = {In the spirit of “multi-culturalism”, we use four kinds of computations: simulation, numeric, symbolic, and “conceptual”, to explore some “games of pure chance” inspired by children board games like “Snakes and Ladders” (aka “Chutes and Ladders”) and “gambler's ruin with unlimited credit”. Even more interesting than the many computer-generated specific results described in this paper and its web-site extension, is our broad-minded, ecumenical approach, not favoring, a priori, any one of the above four kinds of computation, but showing that, a posteriori, symbolic computation is the most important one, since (except for simulation) numerics can be made more efficient with the help of symbolics (in the “downward” direction), and, (in the “upward” direction) the mere existence of certain symbolic-computational algorithms imply interesting “qualitative” results, that certain numbers are always rational, or always algebraic, and certain sequences are always polynomial, or C-recursive, or algebraic, or holonomic. This article is accompanied by four Maple packages, and numerous input and output files, that readers can use as templates for their own investigations.}
}
@article{BELLO2025100031,
title = {Cloud computing for chatbot in the construction industry: An implementation framework for conversational-BIM voice assistant},
journal = {Digital Engineering},
volume = {5},
pages = {100031},
year = {2025},
issn = {2950-550X},
doi = {https://doi.org/10.1016/j.dte.2024.100031},
url = {https://www.sciencedirect.com/science/article/pii/S2950550X24000311},
author = {Sururah A. Bello and Lukumon O. Oyedele and Lukman A. Akanbi and Abdul-Lateef Bello},
keywords = {Software project management, Amazon web services, Cloud computing, Building information modelling (BIM), Conversational AI, Construction industry, Framework implementation, Chatbot, construction workers, Design thinking methodology, Focus group, Stakeholders management},
abstract = {This study presents a structural framework for selecting cloud services for the Conversational AI system implementation in the construction industry using Design Thinking Methodology. A focus group discussion approach was used to obtain user requirements from construction workers to implement the Conversational AI for BIM. This resulted in five factors: finance, speed of operation, privacy, estimation, and interface. The user specifications were mapped into technical modules, which were used to select cloud services employed to implement the virtual assistant for the construction industry. The study thus presented the comprehensive requirements for the different categories of construction workers to implement the Conversational-BIM Chatbot (Conversational-BIM) system. Furthermore, the study presented the architecture of Conversational-BIM using Amazon Web Services. The study is useful to researchers and IT developers in implementing chatbots for the construction industry as it presents the relevant considerations for conversational AI applications in the industry.}
}
@article{GEORGAKARAKOS2017291.e15,
title = {Custom-Made Conical Endograft in the Treatment of Saccular Abdominal Aortic Aneurysms with Tight and Calcified Distal Neck: Thinking Out of the Box},
journal = {Annals of Vascular Surgery},
volume = {39},
pages = {291.e15-291.e19},
year = {2017},
issn = {0890-5096},
doi = {https://doi.org/10.1016/j.avsg.2016.08.018},
url = {https://www.sciencedirect.com/science/article/pii/S0890509616312419},
author = {Efstratios Georgakarakos and Christos Argyriou and Nikolaos Schoretsanitis and George S. Georgiadis},
abstract = {Background
To describe the use of the combination of a conical custom-made TREO® (TREO CM) stent graft in the treatment of a saccular abdominal aortic endograft (AAA) with long but tight and calcified distal neck.
Materials and Methods
A 65-year-female patient was treated for a saccular 5.2 cm AAA with a 3-cm long but calcified and tight (16 mm) distal neck, precluding the safe use of a bifurcated endograft. Because the patient refused an open surgery, a conical TREO CM endograft was manufactured with 20% proximal oversizing, whereas the 3-cm caudal sealing segment demonstrated a conical configuration comprising a 2-cm and 1-cm nitinol-supported zones of 20% and 10% oversizing, respectively, to avoid excessive strain and incomplete expand at the most distal calcified area, leading ultimately to an insidious infolding and consequent type Ib endoleak. A 24 × 40 mm Treovance aortic cuff was centrally deployed resulting in a 30 mm overlap with the main endograft.
Results
After 6 months, there was complete sealing, and the AAA sac has been shrunk to 45 mm.
Conclusions
The use of a conical TREO CM endograft with a proximal cuff provides a firm fixation centrally and a sufficient distal sealing design in AAAs with calcified and tight distal aorta, constituting a reliable alternative to bifurcated endografts or aortouniliac configurations followed by crossover adjuncts.}
}
@article{MANCHES2020105859,
title = {Identifying embodied metaphors for computing education},
journal = {Computers in Human Behavior},
volume = {105},
pages = {105859},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.12.037},
url = {https://www.sciencedirect.com/science/article/pii/S074756321830623X},
author = {Andrew Manches and Peter E. McKenna and Gnanathusharan Rajendran and Judy Robertson},
keywords = {Embodied cognition, Gesture, Metaphor, Computing education, Computational thinking, Representation},
abstract = {Computing education is increasing in global importance, with calls for greater understanding of conceptual development that can inform pedagogy. Here, we report a study investigating elementary computing concepts through the lens of Embodied Cognition. Sixteen students (9 female) studying university-level computing were asked to explain their understanding of computing concepts (without materials) in individually video-recorded sessions. We analysed the gestures generated for three elementary concepts: algorithms, loops, and conditional statements. In total, 368 representational gestures were identified across 48 (16 × 3) explanations, thereby providing evidence that offline thinking in this domain is embodied. Our analysis of representational gestures showed that participants drew upon two overarching embodied metaphors in their explanations: 1) Computing Constructs as Physical Objects, in which participants simulated manipulating physical objects (e.g., pinching) when referring to range of computing constructs, and 2) Computing Processes as Motion along a Path, whereby participants moved their hands along one of three body-based axes when referring to temporal sequences. We contrast our findings to similar research in mathematics and discuss implications for computing pedagogy – namely the role of gesture in the classroom and technologies that can exploit embodied metaphors.}
}
@article{LEVIN2019125,
title = {Planarian regeneration as a model of anatomical homeostasis: Recent progress in biophysical and computational approaches},
journal = {Seminars in Cell & Developmental Biology},
volume = {87},
pages = {125-144},
year = {2019},
note = {Planarian regeneration},
issn = {1084-9521},
doi = {https://doi.org/10.1016/j.semcdb.2018.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1084952117301970},
author = {Michael Levin and Alexis M. Pietak and Johanna Bischof},
keywords = {Planaria, Dugesia japonica, Regeneration, Patterning, Morphostasis},
abstract = {Planarian behavior, physiology, and pattern control offer profound lessons for regenerative medicine, evolutionary biology, morphogenetic engineering, robotics, and unconventional computation. Despite recent advances in the molecular genetics of stem cell differentiation, this model organism’s remarkable anatomical homeostasis provokes us with truly fundamental puzzles about the origin of large-scale shape and its relationship to the genome. In this review article, we first highlight several deep mysteries about planarian regeneration in the context of the current paradigm in this field. We then review recent progress in understanding of the physiological control of an endogenous, bioelectric pattern memory that guides regeneration, and how modulating this memory can permanently alter the flatworm’s target morphology. Finally, we focus on computational approaches that complement reductive pathway analysis with synthetic, systems-level understanding of morphological decision-making. We analyze existing models of planarian pattern control and highlight recent successes and remaining knowledge gaps in this interdisciplinary frontier field.}
}
@article{VANDENBOS201842,
title = {Computational neuroscience across the lifespan: Promises and pitfalls},
journal = {Developmental Cognitive Neuroscience},
volume = {33},
pages = {42-53},
year = {2018},
note = {Methodological Challenges in Developmental Neuroimaging: Contemporary Approaches and Solutions},
issn = {1878-9293},
doi = {https://doi.org/10.1016/j.dcn.2017.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S1878929317301068},
author = {Wouter {van den Bos} and Rasmus Bruckner and Matthew R. Nassar and Rui Mata and Ben Eppinger},
keywords = {Computational neuroscience, Reinforcement learning, Risk-taking, Decision-making, Brain development, Identification, Strategies},
abstract = {In recent years, the application of computational modeling in studies on age-related changes in decision making and learning has gained in popularity. One advantage of computational models is that they provide access to latent variables that cannot be directly observed from behavior. In combination with experimental manipulations, these latent variables can help to test hypotheses about age-related changes in behavioral and neurobiological measures at a level of specificity that is not achievable with descriptive analysis approaches alone. This level of specificity can in turn be beneficial to establish the identity of the corresponding behavioral and neurobiological mechanisms. In this paper, we will illustrate applications of computational methods using examples of lifespan research on risk taking, strategy selection and reinforcement learning. We will elaborate on problems that can occur when computational neuroscience methods are applied to data of different age groups. Finally, we will discuss potential targets for future applications and outline general shortcomings of computational neuroscience methods for research on human lifespan development.}
}
@incollection{PHIPPEN20253,
title = {Artificial Intelligence},
editor = {David Baker and Lucy Ellis},
booktitle = {Encyclopedia of Libraries, Librarianship, and Information Science (First Edition)},
publisher = {Academic Press},
edition = {First Edition},
address = {Oxford},
pages = {3-11},
year = {2025},
isbn = {978-0-323-95690-1},
doi = {https://doi.org/10.1016/B978-0-323-95689-5.00098-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323956895000985},
author = {Andy Phippen},
keywords = {Artificial intelligence, Computer science, Deep learning, Digital literacy, Ethics, Information science, Large language models, Machine learning, Natural language processing},
abstract = {Artificial Intelligence (AI) is attracting considerable, and justified, attention about its potential and impact on information systems. However, it is important to look at this evolution against its history. AI’s historical evolution has been beset with underperformance and ethical concerns in data training and responsible deployment. Information science has undergone significant changes with AI׳s integration, impacting information retrieval, classification, and library automation. More specifically Machine Learning plays a crucial role in understanding human requirements for information and processing large data set, but challenges like bias persist. Large Language Models (LLMs) like ChatGPT represent the vanguard of public adoption of AI driven information systems and have exhibited remarkable performance in natural language processing. While they enhance information searching and content creation, users must understand limitations, biases, and practice critical thinking for responsible utilisation in a digital age.}
}
@article{DROSATOS2014170,
title = {Privacy-preserving computation of participatory noise maps in the cloud},
journal = {Journal of Systems and Software},
volume = {92},
pages = {170-183},
year = {2014},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2014.01.035},
url = {https://www.sciencedirect.com/science/article/pii/S0164121214000430},
author = {George Drosatos and Pavlos S. Efraimidis and Ioannis N. Athanasiadis and Matthias Stevens and Ellie D’Hondt},
keywords = {Privacy-preserving computation, Cloud computing, Participatory sensing},
abstract = {This paper presents a privacy-preserving system for participatory sensing, which relies on cryptographic techniques and distributed computations in the cloud. Each individual user is represented by a personal software agent, deployed in the cloud, where it collaborates on distributed computations without loss of privacy, including with respect to the cloud service providers. We present a generic system architecture involving a cryptographic protocol based on a homomorphic encryption scheme for aggregating sensing data into maps, and demonstrate security in the Honest-But-Curious model both for the users and the cloud service providers. We validate our system in the context of NoiseTube, a participatory sensing framework for noise pollution, presenting experiments with real and artificially generated data sets, and a demo on a heterogeneous set of commercial cloud providers. To the best of our knowledge our system is the first operational privacy-preserving system for participatory sensing. While our validation pertains to the noise domain, the approach used is applicable in any crowd-sourcing application relying on location-based contributions of citizens where maps are produced by aggregating data – also beyond the domain of environmental monitoring.}
}
@article{SLOOT2012439,
title = {Young Russian researchers take up challenges in the computational sciences},
journal = {Journal of Computational Science},
volume = {3},
number = {6},
pages = {439-440},
year = {2012},
note = {Next Generation Computational Scientists: Russian Federation},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2012.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S1877750312000981},
author = {Peter M.A. Sloot and Alexander V. Boukhanovsky}
}
@article{SCHORLEMMER2021118,
title = {A uniform model of computational conceptual blending},
journal = {Cognitive Systems Research},
volume = {65},
pages = {118-137},
year = {2021},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2020.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041720300759},
author = {Marco Schorlemmer and Enric Plaza},
keywords = {Conceptual blending, Computational creativity, Amalgams, Category theory, Case-based reasoning},
abstract = {We present a mathematical model for the cognitive operation of conceptual blending that aims at being uniform across different representation formalisms, while capturing the relevant structure of this operation. The model takes its inspiration from amalgams as applied in case-based reasoning, but lifts them into category theory so as to follow Joseph Goguen’s intuition for a mathematically precise characterisation of conceptual blending at a representation-independent level of abstraction. We prove that our amalgam-based category-theoretical model of conceptual blending is essentially equivalent to the pushout model in the ordered category of partial maps as put forward by Goguen. But unlike Goguen’s approach, our model is more suitable to capture computational realisations of conceptual blending, and we exemplify this by concretising our model to computational conceptual blends for various representation formalisms and application domains.}
}
@article{NEWHALL2025105044,
title = {An introductory-level undergraduate CS course that introduces parallel computing},
journal = {Journal of Parallel and Distributed Computing},
volume = {199},
pages = {105044},
year = {2025},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2025.105044},
url = {https://www.sciencedirect.com/science/article/pii/S0743731525000115},
author = {Tia Newhall and Kevin C. Webb and Vasanta Chaganti and Andrew Danner},
keywords = {CS curriculum, Parallel computing, Introductory CS},
abstract = {We present the curricular design, pedagogy, and goals of an introductory-level course on computer systems that introduces parallel and distributed computing (PDC) to students who have only a CS1 background. With the ubiquity of multicore processors, cloud computing, and hardware accelerators, PDC topics have become fundamental knowledge areas in the undergraduate CS curriculum. As a result, it is increasingly important for students to learn a common core of introductory parallel and distributed computing topics and to develop parallel thinking skills early in their CS studies. Our introductory-level course focuses on three main curricular goals: 1) understanding how a computer runs a program, 2) evaluating system costs associated with running a program, and 3) taking advantage of the power of parallel computing. We elaborate on the goals and details of our course's key modules, and we discuss our pedagogical approach that includes active-learning techniques. We also include an evaluation of our course and a discussion of our experiences teaching it since Fall 2012. We find that the PDC foundation gained through early exposure in our course helps students gain confidence in their ability to expand and apply their understanding of PDC concepts throughout their CS education.}
}
@article{ALEXANDROV20151685,
title = {Computational Science Research Methods for Science Education at PG Level},
journal = {Procedia Computer Science},
volume = {51},
pages = {1685-1693},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.305},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915011138},
author = {Nia Alexandrov and Vassil Alexandrov},
keywords = {Computational Science Research Methods, Postgraduate Education, Science Subjects},
abstract = {The role of Computational Science research methods teaching to science students at PG level is to enhance their research profile developing their abilities to investigate complex problems, analyze the resulting data and use adequately HPC environments and tools for computation and visualization. The paper analyses the current state and proposes a program that encompasses mathematical modelling, data science, advanced algorithms development, parallel programming and visualization tools. It also gives examples of specific scientific domains with explicitly taught and embedded Computational Science subjects.}
}
@article{GARDNER201582,
title = {A new Canadian interdisciplinary Ph.D. in computational sciences},
journal = {Journal of Computational Science},
volume = {9},
pages = {82-87},
year = {2015},
note = {Computational Science at the Gates of Nature},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2015.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S1877750315000666},
author = {William B. Gardner and Gary Grewal and Deborah Stacey and David A. Calvert and Stefan C. Kremer and Fangju Wang},
keywords = {Interdisciplinary, Computational science, Computer science, Postgraduate studies},
abstract = {In response to growing demands of society for experts trained in computational skills applied to various domains, the School of Computer Science at the University of Guelph is creating a new approach to doctoral studies called an interdisciplinary Ph.D. in computational sciences. The program is designed to appeal to candidates with strong backgrounds in either computer science or an application discipline who are not necessarily seeking a traditional academic career. Thesis based, it features minimal course requirements and short duration, with the student’s research directed by co-advisors from computer science and the application discipline. The degree program’s rationale and special characteristics are described. Related programs in Ontario and reception of this innovative proposal at the institutional level are discussed.}
}
@article{JOLLY20171,
title = {Computational systems biology of epithelial-hybrid-mesenchymal transitions},
journal = {Current Opinion in Systems Biology},
volume = {3},
pages = {1-6},
year = {2017},
note = {• Mathematical modelling • Mathematical modelling, Dynamics of brain activity at the systems level • Clinical and translational systems biology},
issn = {2452-3100},
doi = {https://doi.org/10.1016/j.coisb.2017.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S2452310016300191},
author = {Mohit Kumar Jolly and Herbert Levine},
keywords = {Metastasis, Epithelial–mesenchymal plasticity, Hybrid epithelial/mesenchymal, Cancer stem cells, Computational modeling},
abstract = {Metastasis accounts for more than 90% of cancer-related deaths, and is fueled by fine-tuned transitions among many cellular phenotypes. Transitions among epithelial (strong cell–cell adhesion, no or little migration), mesenchymal (no cell–cell adhesion, high migration), and hybrid epithelial/mesenchymal (both cell–cell adhesion and cell migration) phenotypes are considered to be a hallmark of metastasis. Recent years have witnessed rapid progress in mapping the regulatory networks underlying these transitions. This progress has enabled the capability to develop computational systems biology models to characterize how various intracellular and extracellular signals can drive these transitions. Here, we discuss how different mathematical models have contributed to elucidating the underlying principles of these transitions and guided further experiments to address key unanswered questions concerning metastasis.}
}
@incollection{WEIKUM200220,
title = {Chapter 4 - Self-tuning Database Technology and Information Services: From Wishful Thinking to Viable Engineering},
editor = {Philip A. Bernstein and Yannis E. Ioannidis and Raghu Ramakrishnan and Dimitris Papadias},
booktitle = {VLDB '02: Proceedings of the 28th International Conference on Very Large Databases},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {20-31},
year = {2002},
isbn = {978-1-55860-869-6},
doi = {https://doi.org/10.1016/B978-155860869-6/50011-1},
url = {https://www.sciencedirect.com/science/article/pii/B9781558608696500111},
author = {Gerhard Weikum and Axel Moenkeberg and Christof Hasse and Peter Zabback},
abstract = {Publisher Summary
The COMFORT project was started in 1990, and it was then expected that automatic tuning could be achieved with a few simple principles. While the feedback control loop framework provides useful guidance, the difficult problems are in the details of the various tuning issues. For robust solutions, workload statistics and mathematical models are key assets, and for viable engineering, these must be carefully designed to ensure acceptable overhead. The field, in general, has made significant progress towards self-tuning database technology, but there is no breakthrough. The biggest challenges that the research community should address as high-priority problems are the interactions of different system components and their tuning knobs, and the interference between different workload classes. For tackling this complexity, it is believed that a drastic simplification of today's overly complex system architectures is overdue. If one is able to build individually self-tuning components, the composition of these building blocks into higher-level e-services with service-quality guarantees seems feasible only with sufficiently simple component interfaces and radical minimization of cross talk.}
}
@article{WANG20152603,
title = {Bayesian Computational Sensor Networks: Small-scale Structural Health Monitoring},
journal = {Procedia Computer Science},
volume = {51},
pages = {2603-2612},
year = {2015},
note = {International Conference On Computational Science, ICCS 2015},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.05.368},
url = {https://www.sciencedirect.com/science/article/pii/S187705091501176X},
author = {Wenyi Wang and Anshul Joshi and Nishith Tirpankar and Philip Erickson and Michael Cline and Palani Thangaraj and Thomas C. Henderson},
keywords = {Bayesian Computational Sensor Networks, Uncertainty, Structural Health Monitoring, Cloud Computing},
abstract = {The Bayesian Computational Sensor Network methodology is applied to small-scale structural health monitoring. A mobile robot, equipped with vision and ultrasound sensors, maps small-scale structures for damage (e.g., holes, cracks) by localizing itself and the damage in the map. The combination of vision and ultrasound reduces the uncertainty in damage localization. The data storage and analysis takes place exploiting cloud computing mechanisms, and there is also an off-line computational model calibration component which returns information to the robot concerning updated on-board models as well as proposed sampling points. The approach is validated in a set of physical experiments.}
}