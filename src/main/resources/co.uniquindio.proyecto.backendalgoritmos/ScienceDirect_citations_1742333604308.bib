@article{JOKONYA20141533,
title = {Towards a Big Data Framework for the Prevention and Control of HIV/AIDS, TB and Silicosis in the Mining Industry},
journal = {Procedia Technology},
volume = {16},
pages = {1533-1541},
year = {2014},
note = {CENTERIS 2014 - Conference on ENTERprise Information Systems / ProjMAN 2014 - International Conference on Project MANagement / HCIST 2014 - International Conference on Health and Social Care Information Systems and Technologies},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2014.10.175},
url = {https://www.sciencedirect.com/science/article/pii/S2212017314004022},
author = {Osden Jokonya},
keywords = {Tuberculosis, Big Data, HIV/AIDS, Silicosis, Systems Approach, Viable Systems Model, Organizational Cybernetics, Hard Systems Thinking, Soft Systems Thinking, Emancipatory Systems Thinking, Critical Systems Thinking, Epidemiology},
abstract = {This paper proposes a big data integrated framework to assist with prevention and control of HIV/AIDS, TB and silicosis (HATS) in the mining industry. The linkage between HATS presents a major challenge to the mining industry globally. When the immune system is compromised by HIV/AIDS and silicosis, it makes it easier for tuberculosis to infect the body. In addition, the silica dust which affects the lungs may also cause silicosis and tuberculosis. The objective of this paper is to posit a big data integrated framework to assist in the prevention and control of HATS in the mining industry. Literature was reviewed in order to build a conceptual framework. Although this study is not the first to apply big data in healthcare, to the researcher's knowledge, it is the first to apply big data in understanding the linkage between HATS in the mining industry. The literature review indicates only a few studies using big data in healthcare with no research found on big data and HATS. It therefore makes a contribution to existing body of literature on the control of HATS. The proposed big data framework has the potential of addressing the needs of predictive epidemiology which is important in forecasting and disease control in the mining industry. The paper therefore lays a foundation for the use of viable systems model and big data to address the challenges of HATS in the mining industry. As part of future work, the framework will be validated using sequential explanatory mixed methods case study approach in mining organizations.}
}
@article{JOHNSON20013201,
title = {Methods for 3D computation of fluid–object interactions in spatially periodic flows},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {24},
pages = {3201-3221},
year = {2001},
note = {Advances in Computational Methods for Fluid-Structure Interaction},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(00)00389-3},
url = {https://www.sciencedirect.com/science/article/pii/S0045782500003893},
author = {Andrew Johnson and Tayfun Tezduyar},
abstract = {We present computational methods for 3D simulation of fluid–object interactions in spatially periodic flows. These methods include a stabilized space-time finite element formulation for incompressible flows with spatial periodicity, automatic mesh generation and update techniques for fluid–object mixtures with spatial periodicity, and parallel implementations. The methods can be applied to uni-periodic (i.e., periodic in one direction), bi-periodic, or tri-periodic flows. The methods are described here in the context of tri-periodic flows with fluid–object interactions, and are applied to the simulation of sedimentation of particles in a fluid. We present several case studies where the results obtained provide notable insight into the behavior of fluid–particle mixtures during sedimentation.}
}
@article{GROSS199653,
title = {The Electronic Cocktail Napkin—a computational environment for working with design diagrams},
journal = {Design Studies},
volume = {17},
number = {1},
pages = {53-69},
year = {1996},
issn = {0142-694X},
doi = {https://doi.org/10.1016/0142-694X(95)00006-D},
url = {https://www.sciencedirect.com/science/article/pii/0142694X9500006D},
author = {Mark D. Gross},
keywords = {conceptual design, computer-based environment, diagrams, sketching},
abstract = {The Electronic Cocktail Napkin is an experimental computer-based environment for sketching and diagramming in conceptual design. The project's goal is to develop a computational drawing environment to support conceptual designing in a way that leads smoothly from diagrams to more formal and structured representations of schematic design. With computational representations for conceptual designs, computer-supported editing, critquing, analysis, and simulation can be employed earlier in the design process, where it can have a greater impact on outcomes. The paper describes the Electronic Cocktail Napkin program-its recognition and parsing of diagrams and management of spatial constraints, its drawing environment, and two experimental query-by-diagram schemes for retrieving information from architectural databases.}
}
@article{EMER20252196,
title = {Examples of Potential Applications of Bio-intelligent Manufacturing},
journal = {Procedia Computer Science},
volume = {253},
pages = {2196-2205},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.280},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925002881},
author = {Asja Emer and Matteo {De Marchi} and Angelika Hofer and Benedikt G. Mark and Walburga Kerschbaumer and Erwin Rauch and Dominik T. Matt},
keywords = {Sustainable Manufacturing, Industry 4.0, Industry 5.0, Biological Transformation, Bio-Intelligent Manufacturing, SME},
abstract = {Bio-intelligence in manufacturing integrates biological principles and advanced computational techniques to enhance industrial processes. This interdisciplinary approach is based on already known principles like biomimicry, bio-sensing, and bio-based materials with the aim to further innovate and optimize industrial production by combining manufacturing and biology / biotechnology. Although there is a raising interest in research, it is not yet clear where and how bio-intelligence will have practical implications for manufacturing enterprises. In this work we use systematic literature review methodology to identify and analyze the current status quo of scientific literature related to biointelligent manufacturing. A main result of this work was to deduce potential applications, their suitability for small and medium sized enterprises (SME) and to highlight still existing challenges such as scalability, integration with existing systems, and economic viability.}
}
@article{CLERJUSTE2024105922,
title = {Unpacking the challenges and predictors of elementary–middle school students’ use of the distributive property},
journal = {Journal of Experimental Child Psychology},
volume = {244},
pages = {105922},
year = {2024},
issn = {0022-0965},
doi = {https://doi.org/10.1016/j.jecp.2024.105922},
url = {https://www.sciencedirect.com/science/article/pii/S0022096524000626},
author = {Sarah N. Clerjuste and Claire Guang and Dana Miller-Cotto and Nicole M. McNeil},
keywords = {Distributive property, Cognitive reflection, Multiplication, Worked examples},
abstract = {The distributive property plays a pivotal role in advancing students’ understanding of multiplication, enabling the decomposition of problems and the acquisition of new facts. However, this property of multiplication is difficult for students to understand. We used two unique data sets to explore middle school students’ use of the distributive property. Study 1 involved data from 1:1 structured interviews of students (N = 24) discussing worked examples and solving associated practice problems. We examined whether or not students used the distributive property to solve the problems and whether or not interviewers followed the recommended distributive property prompts or defaulted to more conventional methods. Despite exposure to worked examples using the distributive property and a protocol calling for attention to it, students and interviewers favored methods like PEMDAS (parentheses, exponents, multiplication, division, addition, subtraction) or long multiplication. Study 2 used a data set with middle school students’ (N = 131) item-level responses on Kirkland’s (2022; doctoral dissertation, University of Notre Dame) Brief Assessment of Mature Number Sense along with several related measures of domain-general and domain-specific skills. We extracted problems involving the distributive property for analysis. Surprisingly, there was no evidence that students’ use of the distributive property improved from sixth grade to eighth grade. However, both grade-level mathematics achievement and cognitive reflection uniquely predicted the correct use of the distributive property. Results suggest that middle school students who exhibit stronger reflective thinking tend to perform better on distributive property problems. Findings highlight cognitive reflection as a potentially important construct involved in the understanding and use of the distributive property.}
}
@incollection{GARDNER2024129,
title = {Chapter 6 - Smart design for sustainable behaviors},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {129-151},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00007-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000070},
author = {Nicole Gardner},
keywords = {Behavior change, Cyber-physical system, Interaction, Physical computing, Persuasive technology, Nudge theory, Responsibilization, Smart city, Sustainability, Transition design, Urban design, Urban technology},
abstract = {While smart city initiatives have netted energy savings and carbon reductions, many cities and nations are still falling short of their sustainability targets and climate goals. This chapter draws on transitions concepts and behavior change theory to explore how smaller-scale and localized examples of existing and speculative urban technology projects that combine spatial design thinking and physical computing can help to anchor sustainability culture within everyday citizen's lives. It discusses the ethical significance of designing interactive urban technology projects that aim to nudge behavior change in relation to sustainability awareness.}
}
@incollection{PRATT198497,
title = {A Theoretical Framework for Thinking About Depiction},
editor = {W. Ray Crozier and Antlony J. Chapman},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {19},
pages = {97-109},
year = {1984},
booktitle = {Cognitive Processes in the Perception of Art},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(08)62347-X},
url = {https://www.sciencedirect.com/science/article/pii/S016641150862347X},
author = {Francis Pratt},
abstract = {Publisher Summary
This chapter provides a chronological account of the steps which describes the present theoretical framework for thinking about depiction. The experimental results provides good evidence for the following assertions: (1) knowledge is a necessary part of all acts of depiction done by people of all ages and of all levels of skill, (2) knowledge is a main determinant of looking strategies, (3) the role of knowledge in the organization of looking strategies is one of determining the level of description to be used as the basis of analytic processes, and (4) "good" copying performance (i.e., "accurate" in terms of scene-specific and view-specific relations) can be equated with level of description accessed. The chapter emphasizes on: (1) each descending level of description implies an increasing disintegration of the analytic task. (2) Analysis for depiction is concerned with variance. It is concerned with relations that change according to viewing circumstances. In effect, they can be considered as novel relations. There is much evidence that people's ability to maintain "novel" relations in memory is severely limited. (3) The model consisting of a group of straight lines is only capable of being analyzed at the lowest levels of description.}
}
@article{NEWMAN2024101778,
title = {Misinformed by images: How images influence perceptions of truth and what can be done about it},
journal = {Current Opinion in Psychology},
volume = {56},
pages = {101778},
year = {2024},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2023.101778},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X23002233},
author = {Eryn J. Newman and Norbert Schwarz},
keywords = {Visual misinformation, Truthiness, Cognitive fluency, Artificial intelligence (AI), Memory, Truth assessment},
abstract = {We organize image types by their substantive relationship with textual claims and discuss their impact on attention, comprehension, memory, and judgment. Photos do not need to be false (altered or generated) to mislead; real photos can create a slanted representation or be repurposed from different events. Even semantically related non-probative photos, merely inserted to attract eyeballs, can increase message acceptance through increased fluency. Messages with images receive more attention and reach a wider audience. Text-congruent images can scaffold the comprehension of true and false claims and support the formation of correct and false memories. Standard laboratory procedures may underestimate the impact of images in natural media contexts: by drawing all participants' attention to a message that may be ignored without an image, they inflate message effects in the control condition. Misleading images are difficult to identify and their influence often remains outside of awareness, making it hard to curb their influence through critical-thinking interventions. Current concerns about deep fakes may reduce trust in all images, potentially limiting their power to mislead as well as inform. More research is needed to understand how knowing that an image is misleading influences inferences, impressions, and judgments beyond immediate assessments of the image's credibility.}
}
@article{CUNHA2024,
title = {Converging extended reality and Machine Learning to improve the lecturing of geometry in basic education},
journal = {Journal of Engineering Research},
year = {2024},
issn = {2307-1877},
doi = {https://doi.org/10.1016/j.jer.2024.10.016},
url = {https://www.sciencedirect.com/science/article/pii/S2307187724002736},
author = {Carlos R. Cunha and André Moreira and Sílvia Coelho and Vítor Mendonça and João Pedro Gomes},
keywords = {Geometry, Teaching, Learning, Education, Extended reality, Mixed reality, Machine learning},
abstract = {Technology is constantly supporting in the innovation of the teaching-learning process. Today’s students are more demanding actors when it comes to the environment they have at their disposal to learn, experiment and develop their critical thinking. The area of Mathematics has successively suffered from students’ learning difficulties, whether due to lack of motivation, low abstraction ability or lack of new tools for teachers to bring innovation into the classroom and outside it. While being true that digitalization has entered schools, it often follows a basic and simple process of digital replication of approaches and materials that were previously only available on physical media. This work focuses on the use of Extended Realities, more precisely, Mixed Reality, for teaching Mathematics, and very particularly in the teaching of Geometry, through the proposition of a conceptual model that combines the use of Extended Reality and Machine Learning. The proposed model was subject to prototyping, which is presented as a form of laboratory validation as a contribution to innovate the way of how the geometry teaching-learning process is developed and to promote the integration of Extended Reality technologies into the Education Sector as practical tools, as well due to its potential use to obtain useful insights for teachers, and students, throughout the process.}
}
@article{GREIF2024126,
title = {Selection, growth and form. Turing’s two biological paths towards intelligent machinery},
journal = {Studies in History and Philosophy of Science},
volume = {106},
pages = {126-135},
year = {2024},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2024.05.017},
url = {https://www.sciencedirect.com/science/article/pii/S0039368124000657},
author = {Hajo Greif and Adam P. Kubiak and Paweł Stacewicz},
keywords = {Universal computing machines, Mechanism, Connectionism, Morphogenesis, D’Arcy Thompson, Darwinian evolution, Cellular automata},
abstract = {We inquire into the role of Turing’s biological thought in the development of his concept of intelligent machinery. We trace the possible relations between his proto-connectionist notion of ‘organising’ machines in Turing (1948) on the one hand and his mathematical theory of morphogenesis in developmental biology (1952) on the other. These works were concerned with distinct fields of inquiry and followed distinct paradigms of biological theory, respectively postulating analogues of Darwinian selection in learning and mathematical laws of form in organic pattern formation. Still, these strands of Turing’s work are related, first, in terms of being amenable in principle to his (1936) computational method of modelling. Second, they are connected by Turing’s scattered speculations about the possible bearing of learning processes on the anatomy of the brain. We argue that these two theories form an unequal couple that, from different angles and in partial fashion, point towards cognition as a biological and embodied phenomenon while, for reasons inherent to Turing’s computational approach to modelling, not being capable of directly addressing it as such. We explore ways in which these two distinct-but-related theories could be more explicitly and systematically connected, using von Neumann’s contemporaneous and related work on Cellular Automata and more recent biomimetic approaches as a foil. We conclude that the nature of ‘initiative’ and the mode of material realisation are the key issues that decide on the possibility of intelligent machinery in Turing.}
}
@article{MCDERMOTT20071183,
title = {Level-headed},
journal = {Artificial Intelligence},
volume = {171},
number = {18},
pages = {1183-1186},
year = {2007},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2007.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0004370207001488},
author = {Drew McDermott},
keywords = {Speculation, Methodology, Natural language},
abstract = {I don't believe that human-level intelligence is a well defined goal. As the cognitive-science community learns more about thinking and computation, the mileposts will keep changing in ways that we can't predict, as will the esteem we assign to past accomplishments. It would be fun to have a computer that could solve brain teasers as well as the average scientist, but focusing on such things, besides being parochial, overlooks the crucial role language plays in everything humans do, a role we understand hardly at all on a computational level. I am optimistic that we will eventually figure language out, but not without new ideas. Plus, when we can talk to machines, will we understand each other?}
}
@article{BAILEY2006793,
title = {Clover: Connecting technology and character education using personally-constructed animated vignettes},
journal = {Interacting with Computers},
volume = {18},
number = {4},
pages = {793-819},
year = {2006},
note = {Special Theme Papers from Special Editorial Board Members (contains Regular Papers)},
issn = {0953-5438},
doi = {https://doi.org/10.1016/j.intcom.2005.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0953543805001153},
author = {Brian P. Bailey and Sharon Y. Tettegah and Terry J. Bradley},
keywords = {Animation, Character education, Multimedia, Narratives, Vignettes},
abstract = {Schools are increasingly integrating character education to facilitate improved moral thinking and pro social behavior among students. An effective method for delivering character education is problem solving moral and social situations represented visually as animated vignettes. However, schools are rarely able to use animated vignettes since existing tools do not allow them to be easily created and having them created externally is overly expensive. In this paper, we describe the design, use, and evaluation of a computational tool that enables students to construct their own animated vignettes. By building, sharing, and responding to vignettes, students become engaged in problem solving moral and social situations. Evaluations showed that users are able to build meaningful vignettes, our tool is easy to learn and fun to use, and our tool's multimedia features are often used and well-liked. Educators can download and use our tool while researchers can draw upon our design rationale and lessons learned when building similar tools.}
}
@article{GANO201556,
title = {Starting with Universe: Buckminster Fuller's Design Science Now},
journal = {Futures},
volume = {70},
pages = {56-64},
year = {2015},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2014.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S0016328714002055},
author = {Gretchen Gano},
keywords = {Comprehensiveness, Big data, Design science, Buckminster Fuller, Worldviews Network},
abstract = {Increasingly, decision makers seek to harness “big data” to guide choices in management and policy settings as well as in professions that manufacture, build, and innovate. Scholars examining this trend tend to diagnose it at once as techno positivist in its insistence on design yoked to quantifiable variables and computational modeling and, alternatively, as an imperative integral to realizing ecologically sustainable innovation. This article investigates this tension. It reflects on the role of futurists, designers, architects, urban planners, social scientists, and artists in interpreting and utilizing comprehensiveness as a design frame. Among nine experimental foresight workshops at the inaugural Emerge conference at Arizona State University, many focused on producing physical objects or media, one modeled and expanded upon a method pioneered by architect and polymath R. Buckminster Fuller. At a time when many of the capabilities to realize Fuller's specifications for big data have matured, I investigate whether comprehensive design as framed by Fuller's method shows promise as a trend enabling ecologically sustainable innovations. A historical look at Fuller's Design Science and the reflection on it in the Emerge workshop marks an opportunity to highlight and interpret the resurgence of comprehensive thinking in design while navigating the contradictions this orientation engenders.}
}
@article{GRANDE2022105470,
title = {Nursing competency inventory and professional competence of graduating students in six Asian countries: A cross-sectional study},
journal = {Nurse Education Today},
volume = {116},
pages = {105470},
year = {2022},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2022.105470},
url = {https://www.sciencedirect.com/science/article/pii/S0260691722002064},
author = {Rizal Angelo N. Grande and Daniel Joseph E. Berdida and Tantut Susanto and Anwar Khan and Wanpen Waelveerakup and Zahrah Saad},
keywords = {Asian countries, Competency, Graduating nursing students, Nursing competency inventory, Professional competence},
abstract = {Aims
To investigate graduating nursing students' nursing and professional competencies and the predictors of their competencies.
Background
Across Asian countries, there is a paucity of literature that explores graduating nursing students' competency and professional competence during the ongoing COVID-19 pandemic.
Design
Descriptive, cross-sectional, and predictive approaches.
Method
Convenience sampling was used among graduating nursing students from the six Asian countries (n = 375). The STROBE guidelines for cross-sectional studies were used. Two self-report instruments were utilized to collect data. We conducted multiple linear regression analyses to assess the predictors of nursing competency and professional competence domains.
Results
Country of residence and general point average (GPA) showed statistically significant multivariate effects. Value-based nursing care and critical thinking and reasoning domains recorded the highest in professional competence and competency inventory for nursing students, respectively. Country of residence, GPA, and preferred nursing major were significant predictors of graduating nursing students' nursing competency and professional competence domains.
Conclusion
Our study's findings revealed a high level of diversity among nursing students regarding ethical care obligations, caring pedagogies, and lifelong learning, all of which may be ascribed to their distinct culture, background, and belief systems.}
}
@article{WOODRUFF1994463,
title = {Some computational challenges of developing efficient parallel algorithms for data-dependent computations in thermal-hydraulics supercomputer applications},
journal = {Nuclear Engineering and Design},
volume = {146},
number = {1},
pages = {463-471},
year = {1994},
issn = {0029-5493},
doi = {https://doi.org/10.1016/0029-5493(94)90351-4},
url = {https://www.sciencedirect.com/science/article/pii/0029549394903514},
author = {S.B. Woodruff},
abstract = {The Transient Reactor Analysis Code (TRAC), which features a two-fluid treatment of thermal-hydraulics, is designed to model transients in water reactors and related facilities. One of the major computational costs associated with TRAC and similar codes is calculating constitutive coefficients. Although the formulations for these coefficients are local, the costs are flow-regime- or data-dependent; i.e., the computations needed for a given spatial node often vary widely as a function of time. Consequently, a fixed, uniform assignment of nodes to parallel processors will result in degraded computational efficiency due to the poor load balancing. A standard method for treating data-dependent models on vector architectures has been to use gather operations (or indirect addressing) to sort the nodes into subsets that (temporarily) share a common computational model. However, this method is not effective on distributed memory data parallel architectures, where indirect addressing involves expensive communication overhead. Another serious problem with this method involves software engineering challenges in the areas of maintainability and extensibility. For example, an implementation that was hand-tuned to achieve good computational efficiency would have to be rewritten whenever the decision tree governing the sorting was modified. Using an example based on the calculation of the wall-to-liquid and wall-to-vapor heat-transfer coefficients for three nonboiling flow regimes, we describe how the use of the Fortran 90 WHERE construct and automatic inlining of functions can be used to ameliorate this problem while improving both efficiency and software engineering. Unfortunately, a general automatic solution to the load-balancing problem associated with data-dependent computations is not yet available for massively parallel architectures. We discuss why developers should either wait for such solutions or consider alternative numerical algorithms, such as a neural network representation, that do not exhibit load-balancing problems.}
}
@article{MEHMOOD2023100122,
title = {A multi-stage optimisation-based decision-making framework for sustainable hybrid energy system in the residential sector},
journal = {Sustainable Futures},
volume = {6},
pages = {100122},
year = {2023},
issn = {2666-1888},
doi = {https://doi.org/10.1016/j.sftr.2023.100122},
url = {https://www.sciencedirect.com/science/article/pii/S2666188823000187},
author = {Aamir Mehmood and Long Zhang and Jingzheng Ren},
keywords = {Hybrid energy system, System thinking approach, Genetic algorithm, Multi-criteria decision-making, Energy sustainability},
abstract = {Integrating renewables into existing energy infrastructure to construct hybrid energy systems (HES) plays a vital role for advancing energy sustainability. While various approaches, such as energy systems analysis and linear or non-linear optimisation, have been employed to achieve energy sustainability mainly at the national or city level, there has been a lack of focus on achieving energy sustainability in the residential sector through a holistic optimal decision-making approach for efficient HES design. This study focuses on developing a multi-stage optimisation-based decision-making framework that models, quantifies, and optimises the performance indicators of HES, allowing for an assessment of the trade-off between benefits and systems costs under various design scenarios. The initial step involves designing the HES model and constructing scenarios that cater to the electrification requirements of water, energy, and food elements in the residential sector by using a systematic thinking approach. Then, a preliminary evaluation of the modelled scenarios is conducted to assess energy sustainability in terms of technical and economic aspects. Afterwards, an optimal decision-making setup is established by integrating a multi-objective HES model into the NSGA-II algorithm, which approximates the Pareto optimal solutions. These solutions are then ranked by using a multi-criteria decision-making method. According to the findings, the Quetta region in Pakistan contains the best optimal solution. The results underscore the utility of the developed framework in facilitating the optimal design of renewables-integrated HES for the residential sector. Furthermore, intergovernmental organizations can leverage this framework to formulate effective policies aimed at encouraging residents to invest in HES installation.}
}
@article{SKOWRON2025122078,
title = {Toward rough set based insightful reasoning in intelligent systems},
journal = {Information Sciences},
volume = {709},
pages = {122078},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2025.122078},
url = {https://www.sciencedirect.com/science/article/pii/S0020025525002105},
author = {Andrzej Skowron and Jaroslaw Stepaniuk},
keywords = {Artificial intelligence, Granular computing, Rough sets, Granular approximation process, Reasoning over granular computations},
abstract = {This paper explores a rough set-based approach for supporting insightful reasoning in Intelligent Systems (ISs). The novelty lies in the introduction of a new concept for approximate reasoning processes based on granular computations. Although many rough set theory extensions developed over time focus on reasoning about (partial) set inclusion, these approximation spaces sometimes fall short when dealing with crucial aspects of approximate reasoning within ISs. Specifically, these systems aim to construct high-quality approximations of compound decision granules that represent solutions. Here, we present the basis for insightful reasoning realized through approximate reasoning processes grounded in granular computations. By doing so, we provide a sufficiently rich basis for designing IS problem solvers. This basis allows ISs to restructure or adapt their reasoning based on the generated granular computations, ultimately leading to high-quality granular solutions.}
}
@article{KOBSIRIPAT2015227,
title = {Effects of the Media to Promote the Scratch Programming Capabilities Creativity of Elementary School Students},
journal = {Procedia - Social and Behavioral Sciences},
volume = {174},
pages = {227-232},
year = {2015},
note = {International Conference on New Horizons in Education, INTE 2014, 25-27 June 2014, Paris, France},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.651},
url = {https://www.sciencedirect.com/science/article/pii/S1877042815007028},
author = {Worarit Kobsiripat},
keywords = {Scratch programming, Higher-order Thinking, Creative Thinking, Computer Multimedia;},
abstract = {Developing creative Promote higher-order thinking processes Give learners specific ability to think on their wide variety and innovative of the original. It led to the discovery and creation of new inventions or form new ideas. Consistent with the educational goals of the program.This research aim to study a guild line of using Scratch Computer Program that leading to creativity. And study the effects of media on the Scratch programming capabilities creativity. The sample consisted of 60 students who were studying in semester 1. 2013 academic year, using purposive sampling (Purposive Sampling) tool used in this research is a lesson plan. Scratch and computer media test innovative ideas. Statistics used Data analysis were percentage, mean, standard deviation and Dependent t-test. The findings indicated that First, Mediums Scratch program can be used as a medium for learning activities. The adoption includes a multimedia interactive media as a tool to support learning. Second, Scratch media performance of computer programs is equal according to the criteria set 82.46/82.25 E1/E2 is 80/80. Creativity of students. Received instruction from the learning activities through the medium of a computer program Scratch by elements of creativity is an idea ingenious ideas flexibility. Initiatives and ideas census. Higher posttest than pretest statistically significant at the .05 level of performance, computer media Scratch equals 82.46/82.25 according to defined criteria E1/E2 is 80 /80. In conclusion the computer program Scratch media can lead creative development of students through the learning activities that promote innovative education that cause the learners’ desirable.}
}
@article{BRENNAN2023100070,
title = {Generalised Kuramoto models with time-delayed phase-resetting for k-dimensional clocks},
journal = {Brain Multiphysics},
volume = {4},
pages = {100070},
year = {2023},
issn = {2666-5220},
doi = {https://doi.org/10.1016/j.brain.2023.100070},
url = {https://www.sciencedirect.com/science/article/pii/S2666522023000084},
author = {Martin Brennan and Peter Grindrod CBE},
keywords = {Kuramoto models, Range-dependent networks, High dimensional clocks, Phase-resetting maps, The human cortex, Consciousness},
abstract = {We consider a class of Kuramoto models, with an array of N individual k-dimensional clocks (k>1), coupled within a directed, range dependent, network. For each directed connection, a signal triggered at the sending clock incurs a (real valued) time delay before arriving at the receiving clock, where it induces an instantaneous phase reset affecting all k-phases. Instantaneous phase resetting maps (PRMs) for k-dimensional clocks have received little attention. The system may be treated as open and subject to periodic, or other types of, PRM forcing at any individual clock, as a result of external forcing stimuli. We show how the full system, with Nk phase variables, responds to such stimuli, as the impact spreads across the entire network. Beyond simulations, we employ methods to reverse engineer the dynamical behaviour of the whole: estimating the intrinsic dimensions of the responses to different experiments; and by analysing pairwise comparisons between those responses. This shows that the system’s responses are governed by a hierarchy of internal dynamical modes, existing across both the Nk phases and over time. We argue that this Kuramoto system is a model for the human cortex, where each k-dimensional clock models the dynamics of a single neural column, which contains 10,000 densely inter-connected neurons. The Kuramoto model exploits the natural network of networks architecture of the human cortex. An array of N=1M such columns/clocks is at the 10B neuron scale of the human cortex. However its simulation is far more accessible than very large scale (VLS) simulations of neuron-to-neuron systems on supercomputers. The latent modes may have important implications for cognition (information processing) and for consciousness (the existence of internal phenomenological experiences). We argue that the existence of the latter plays a key role in preconditioning the former, reducing the decision sets and the cognitive load, and thus enabling a fast-thinking evolutionary advantage. This is the first time that systems of k-dimensional clocks (k> 1), coupled via time-lagged PRMs, within range dependent networks, have been deployed to demonstrate the basic internal phenomenological elements (of consciousness) and their potential role within immediate cognition. Statement of Significance: We argue that this Kuramoto system is a model for the human cortex, where each of 1M k-dimensional clocks models the dynamics of a single neural column (containing 10,000 densely inter-connected neurons). This Kuramoto model exploits the natural network of networks architecture of the human cortex. Large scale human cortex simulations, with 10B neutrons, usually require a super computer. We show that similar results, using this model, can be obtained on a laptop. In particular we show that such dynamical can support internal phenomenological elements (of conscious experience) and we discuss their potential role in preconditioning immediate cognition, furnishing a “fast thinking” evolutionary advantage to the human brain.}
}
@article{RUPESH20213320,
title = {Computational investigation of heat transfer on the surface of engine cylinder with fins of different shapes and materials},
journal = {Materials Today: Proceedings},
volume = {46},
pages = {3320-3326},
year = {2021},
note = {International Conference on Materials, Manufacturing and Mechanical Engineering for Sustainable Developments-2020 (ICMSD 2020)},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2020.11.471},
url = {https://www.sciencedirect.com/science/article/pii/S2214785320391355},
author = {P.L. Rupesh and K. Raja and N.V. {Sai Deepak Raj} and M. {Pruthviraj Bharmal} and Pandey {Aditya Ramjatan}},
keywords = {Two stroke engine, Fin, Circular fin, Tapered fin, Silumin, Thermal Conductivity},
abstract = {In everyday life the use of vehicles has expanded immensely for some ventures and house hold applications, likewise the running time of engine cycle is exceptionally long. Thus because of the consistent running enormous measure of heat is produced. At the point when this heat isn't appropriately disseminated, the engine gets more fragile very soon and life of the engine declines because of the heat development. To build the life of the engine, heat dispersal is expanded by giving fins at external of engine chamber. The shape of the fins and the material used for the fin increases its heat dissipation capacity and in turn increases the cooling of the engine for proper functioning. The present work focuses on the design of fins of circular and tapered shapes for a 2-stroke engine. The temperature distribution and the heat dissipation along the fin surface of two shapes has been observed by a steady state thermal analysis. Alusil and Silumin has been selected as the fin materials and a computational evaluation has also been done using FEM. A better shape of the fin along with a suitable material has been selected based on the results observed by FEM and on comparison with the existing shape and material of the fin.}
}
@article{ISLAM2025100417,
title = {DFT insights into the mechanical properties of NMs},
journal = {Results in Surfaces and Interfaces},
volume = {18},
pages = {100417},
year = {2025},
issn = {2666-8459},
doi = {https://doi.org/10.1016/j.rsurfi.2025.100417},
url = {https://www.sciencedirect.com/science/article/pii/S2666845925000042},
author = {Md. Aminul Islam and Nayem Hossain and Zahid Ahsan and Masud Rana and Mustafizur Rahman and Md. Abdullah},
keywords = {DFT, NMs, Elasticity, Mechanical properties, Quantum effects, Surface phenomena},
abstract = {NMs, whose dimensions are below 100 nm, provide unique mechanical properties from quantum effects, surface phenomena, and small-scale interactions that account for their importance in energy storage, biomedicine, nanoelectronics, etc. This review discusses computational prediction of mechanical properties (for example, elasticity, strength, and fracture behavior) in NMs, especially using Density Functional Theory as a central tool. By conducting DFT calculations, we can analyze how NMs will behave across different mechanical states, which is critical for designing properties for advanced applications. Problems related to the application of DFT (e.g., high computational cost and failure in modeling defects or exchange-correlation functionals) are discussed. Despite these challenges, DFT must provide insights that complement other tools and strategies. However, further development is essential for improving its quantitative predictability on temperature and multiscale models. Future work is needed to integrate ML with DFT further to refine the accuracy and computational efficiency, thereby extending the capability of DFT to accelerate the discovery of new NMs with superior mechanical properties.}
}
@article{TEEPLE2023102847,
title = {Level-k predatory trading},
journal = {Journal of Mathematical Economics},
volume = {106},
pages = {102847},
year = {2023},
issn = {0304-4068},
doi = {https://doi.org/10.1016/j.jmateco.2023.102847},
url = {https://www.sciencedirect.com/science/article/pii/S030440682300040X},
author = {Keisuke Teeple},
keywords = {Behavioral finance, Level- models, Front running, Price overshooting},
abstract = {I incorporate the level-k thinking solution concept into a simplified (Brummermeier and Pedersen, 2005) predatory trading model to investigate the possibility of arbitraging arbitrageurs. While naive financial predators prey upon a single distressed investor, higher-level thinkers best respond to this and prey upon fellow predators. For some parameter values, sophisticated predators are able to reason their way to the Nash equilibrium strategy, and prices do not oscillate. As parameter values are perturbed, the system undergoes a bifurcation and predators select strategies from a mean-preserving spread of the Nash equilibrium strategy. In these settings, prices display excess volatility and a single shock can send predators into an oscillatory trading frenzy.}
}
@article{WAUTELET2025125664,
title = {Circulise, a model-driven framework to build and align socio-technical systems for the twin transition: Fanyatu’s case of sustainability in reforestation},
journal = {Expert Systems with Applications},
volume = {262},
pages = {125664},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125664},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424025314},
author = {Yves Wautelet and Xavier Rouget},
keywords = {Circulise, Circular economy development, Cryptocurrency, Reforestation, Sustainability, Sustainability engineering, Twin transition},
abstract = {Building circular economic systems is crucial to address ecological challenges like climate change. The twin transition suggests that, to maximize the impact of sustainable solutions, humans and (disruptive) technologies need to be effectively integrated. Methods to conceptually build such (eco)systems integrating these and assess their ecological impact before implementation are lacking. This paper addresses this gap by proposing the Circulise framework, a model-driven method designed to build circular systems and evaluate their environmental performance. The approach promotes design-thinking to create socio-technical ecosystems that can be evaluated at the light of their alignment with circular economy and/or sustainability principles and be used to generate operational software behavior. The Circulise framework was developed following the methodological guidance of design science research. It is applied in this paper to the case of Fanyatu, a non-profit organization focused on reforestation in the Congo Basin, showing its ability to create a circular ecosystem not only supporting the creation of regenerative CO2-absorbing forests but also empowering and improving the quality of life of the local communities involved in the planting of trees. In Fanyatu’s case, Circulise’s strategic planning and technology integration lead to virtuous cycles, enabling a snowball effect in forest creation and the promotion of sustainable projects. The framework’s scalability and versatility allow it to be applied across various contexts, enabling the creation of customized circular ecosystems for sustainability tailored to specific human and technological needs.}
}
@article{BILLINGE20243714,
title = {Do materials have a genome, and if they do, what can be done with it?},
journal = {Matter},
volume = {7},
number = {11},
pages = {3714-3727},
year = {2024},
issn = {2590-2385},
doi = {https://doi.org/10.1016/j.matt.2024.06.026},
url = {https://www.sciencedirect.com/science/article/pii/S259023852400345X},
author = {Simon J.L. Billinge},
abstract = {Summary
Materials do not have a genome, yet for the past decade, and into the next decade, in the USA, there has been a presidential and inter-agency funding initiative called the “Materials Genome Initiative (MGI).” This initiative has nothing to do with real genomes, materials, or otherwise. However, in this paper, we, somewhat whimsically, explore some ideas about what a material’s gene could be and how it could be used to further our understanding of materials structure and properties. The result is a slightly non-conventional, less crystal-centric, view of materials structure that we believe can, will, and is resulting in novel materials insights.}
}
@article{BOWMAN201834,
title = {Big questions, informative data, excellent science},
journal = {Statistics & Probability Letters},
volume = {136},
pages = {34-36},
year = {2018},
note = {The role of Statistics in the era of big data},
issn = {0167-7152},
doi = {https://doi.org/10.1016/j.spl.2018.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0167715218300622},
author = {Adrian W. Bowman},
keywords = {Big data, Statistical models},
abstract = {The expression big data is often used in a manner which implies that immediate insight is readily available. Unfortunately, this raises unrealistic expectations. A model which encapsulates the powerful concepts of statistical thinking remains an invaluable component of good analysis.}
}
@article{TEZDUYAR199997,
title = {CFD methods for three-dimensional computation of complex flow problems},
journal = {Journal of Wind Engineering and Industrial Aerodynamics},
volume = {81},
number = {1},
pages = {97-116},
year = {1999},
issn = {0167-6105},
doi = {https://doi.org/10.1016/S0167-6105(99)00011-2},
url = {https://www.sciencedirect.com/science/article/pii/S0167610599000112},
author = {Tayfun E. Tezduyar},
keywords = {CFD methods, T*AFSM, Three-dimensional flow simulations},
abstract = {This paper provides an overview of some of the CFD methods developed by the Team for Advanced Flow Simulation and Modeling (T*AFSM) [http://www.mems.rice.edu/TAFSM/]. The paper also provides many examples of three-dimensional flow simulations carried out with these CFD methods and advanced parallel supercomputers. The methods and tools described in this paper include: stabilized finite element formulations; formulations for flows with moving boundaries and interfaces; mesh update methods; iterative solution techniques for large nonlinear equation systems; and parallel implementation of these methods. Our target is to be able to address effectively certain classes of flow simulation problems. These include: unsteady flows with interfaces; fluid–object interactions; fluid–structure interactions; airdrop systems; aerodynamics of complex shapes; and contaminant dispersion.}
}
@article{BAKER2022942,
title = {Three aspects of representation in neuroscience},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {11},
pages = {942-958},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2022.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661322002108},
author = {Ben Baker and Benjamin Lansdell and Konrad P. Kording},
keywords = {representation, information, coding, explanation, function, teleology, philosophy},
abstract = {Neuroscientists often describe neural activity as a representation of something, or claim to have found evidence for a neural representation, but there is considerable ambiguity about what such claims entail. Here we develop a thorough account of what ‘representation’ does and should do for neuroscientists in terms of three key aspects of representation. (i) Correlation: a neural representation correlates to its represented content; (ii) causal role: the representation has a characteristic effect on behavior; and (iii) teleology: a goal or purpose served by the behavior and thus the representation. We draw broadly on literature in both neuroscience and philosophy to show how these three aspects are rooted in common approaches to understanding the brain and mind. We first describe different contexts that ‘representation’ has been closely linked to in neuroscience, then discuss each of the three aspects in detail.}
}
@article{SUPPES201295,
title = {Phase-oscillator computations as neural models of stimulus–response conditioning and response selection},
journal = {Journal of Mathematical Psychology},
volume = {56},
number = {2},
pages = {95-117},
year = {2012},
issn = {0022-2496},
doi = {https://doi.org/10.1016/j.jmp.2012.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S002224961200003X},
author = {P. Suppes and J. Acacio {de Barros} and G. Oas},
keywords = {Learning, Neural oscillators, Three-oscillator Kuramoto model, Stability points of the Kuramoto model, Stimulus–response theory, Phase representation, Continuum of responses},
abstract = {The activity of collections of synchronizing neurons can be represented by weakly coupled nonlinear phase oscillators satisfying Kuramoto’s equations. In this article, we build such neural-oscillator models, partly based on neurophysiological evidence, to represent approximately the learning behavior predicted and confirmed in three experiments by well-known stochastic learning models of behavioral stimulus–response theory. We use three Kuramoto oscillators to model a continuum of responses, and we provide detailed numerical simulations and analysis of the three-oscillator Kuramoto problem, including an analysis of the stability points for different coupling conditions. We show that the oscillator simulation data are well-matched to the behavioral data of the three experiments.}
}
@incollection{KATZ2016123,
title = {Chapter 6 - Development of Counting Ability: An Evolutionary Computation Point of View},
editor = {Avishai Henik},
booktitle = {Continuous Issues in Numerical Cognition},
publisher = {Academic Press},
address = {San Diego},
pages = {123-145},
year = {2016},
isbn = {978-0-12-801637-4},
doi = {https://doi.org/10.1016/B978-0-12-801637-4.00006-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128016374000068},
author = {Gali Barabash Katz and Amit Benbassat and Moshe Sipper},
keywords = {numerical cognition, size perception, counting, evolutionary algorithms, genetic algorithms, artificial neural networks},
abstract = {Examination of numerical cognition encompasses multiple facets (eg, discrete vs. continuous properties, subitizing, estimation, counting, etc.). Many models have been suggested to explain these features. By looking into the basic ability to perceive size, against the complex one of counting, we hypothesize that counting system evolved on the basis of a primitive size perception system rather than the two systems evolved separately. In this chapter, we present a novel way of using evolutionary computation techniques to evolve artificial neural networks (ANNs) first to perceive size and then to count, and compare their counting skills to a different group of ANNs who evolved to count from scratch. The results revealed better counting skills when evolving first to perceive size (or other classification task) and then to count over those who evolved just to count. In addition, ANNs who evolved with continuous stimuli presented better counting skills than those evolved with discrete stimuli.}
}
@article{HONG201611,
title = {Ontology-based conceptual design for ultra-precision hydrostatic guideways with human–machine interaction},
journal = {Journal of Industrial Information Integration},
volume = {2},
pages = {11-18},
year = {2016},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2016.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X16300188},
author = {Haibo Hong and Yuehong Yin},
keywords = {Human machine integrated conceptual design, Information integration, High dimensional information integration, Ontology},
abstract = {This paper proposed a human–machine integrated conceptual design method based on ontology, aiming at eliminating the uncertainties and blindness during the design process of ultra-precision grinding machine, especially for its key component–the ultra-precision hydrostatic guideways. Both the required knowledge and the database of hydrostatic guideways are modelled using ontologies to provide a consensual understanding among collaborators. Moreover, a formalized knowledge searching interface is developed to obtain similar instances as references according to the design principles and rules. Based on the imaginal thinking theory, the search process and the results are attempted to be presented in the form of image in order to fit human's customary intuitive thinking frame, facilitating the decision making process. Finally, our design of hydrostatic guideways for an ultra-precision grinding machine is used to validate the effectiveness of the method.}
}
@article{SOTELOMONGE2021869,
title = {Conceptualization and cases of study on cyber operations against the sustainability of the tactical edge},
journal = {Future Generation Computer Systems},
volume = {125},
pages = {869-890},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.07.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21002788},
author = {Marco Antonio {Sotelo Monge} and Jorge {Maestre Vidal}},
keywords = {Cyber defense, Economical Denial of Sustainability, Military operations, Situational Awareness, Tactical Denial of Sustainability},
abstract = {The last decade consolidated the cyberspace as fifth domain of military operations, which extends its preliminarily intelligence and information exchange purposes towards enabling complex offensive and defensive operations supported/supportively of parallel kinetic domain actuations. Although there is a plethora of well documented cases on strategic and operational interventions of cyber commands, the cyber tactical military edge is still a challenge, where cyber fires barely integrate to the traditional joint targeting cycle due to, among others, long planning/development times, asymmetric effects, strict target reachability requirements, or the fast propagation of collateral damage; the latter rapidly deriving on hybrid impacts (political, economic, social, etc.) and evidencing significant socio-technical gaps. In this context, it is expected that Tactical Clouds disruptively facilitate cyber operations at the edge while exposing the rest of the digital assets of the operation to them. On these grounds, the main purpose of the conducted research is to review and in depth analyze the risks and opportunities of jeopardizing the sustainability of the military Tactical Clouds at their cyber edge. Along with a 1) comprehensively formulation of the researched problematic, the study 2) formalizes the Tactical Denial of Sustainability (TDoS) concept; 3) introduces the phasing, potential attack surfaces, terrains and impact of TDoS attacks; 4) emphasizes the related human and socio-technical aspects; 5) analyzes the threats/opportunities inherent to their impact on the cloud energy efficiency; 6) reviews their implications at the military cyber thinking for tactical operations; 7) illustrates five extensive CONOPS that facilitate the understanding of the TDoS concept; and given the high novelty of the discussed topics, this paper 8) paves the way for further research and development actions.}
}
@incollection{BRACHMAN20041,
title = {Chapter 1 - Introduction},
editor = {Ronald J. Brachman and Hector J. Levesque},
booktitle = {Knowledge Representation and Reasoning},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {1-14},
year = {2004},
series = {The Morgan Kaufmann Series in Artificial Intelligence},
isbn = {978-1-55860-932-7},
doi = {https://doi.org/10.1016/B978-155860932-7/50086-8},
url = {https://www.sciencedirect.com/science/article/pii/B9781558609327500868},
author = {Ronald J. Brachman and Hector J. Levesque},
abstract = {Publisher Summary
This introductory chapter discusses the main issues associated with Artificial Intelligence (AI) and the prospect of a machine that could think. AI is the study of intelligent behavior that is achieved through computational means. One striking aspect of intelligent behavior is that it is conditioned by knowledge. Knowledge representation and reasoning are the parts of AI that are concerned with how an agent uses what it knows in deciding what to do. It is the study of thinking as a computational process. The book introduces the symbolic structures invented for representing knowledge and the computational processes devised for reasoning with those symbolic structures. The reason why logic is relevant to knowledge representation and reasoning is that logic is the study of entailment relations—languages, truth conditions, and rules of inference… Despite the centrality of knowledge representation and reasoning to AI, there are alternate views. Some authors have claimed that human-level reasoning is not achievable via purely computational means. Others suggest that intelligence derives from computational mechanisms.}
}
@article{BALLESTERRIPOLL2025109368,
title = {Global sensitivity analysis of uncertain parameters in Bayesian networks},
journal = {International Journal of Approximate Reasoning},
volume = {180},
pages = {109368},
year = {2025},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2025.109368},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X2500009X},
author = {Rafael Ballester-Ripoll and Manuele Leonelli},
keywords = {Bayesian networks, Sensitivity analysis, Sobol indices, Tensor networks, Uncertainty quantification},
abstract = {Traditionally, the sensitivity analysis of a Bayesian network studies the impact of individually modifying the entries of its conditional probability tables in a one-at-a-time (OAT) fashion. However, this approach fails to give a comprehensive account of each inputs' relevance, since simultaneous perturbations in two or more parameters often entail higher-order effects that cannot be captured by an OAT analysis. We propose to conduct global variance-based sensitivity analysis instead, whereby n parameters are viewed as uncertain at once and their importance is assessed jointly. Our method works by encoding the uncertainties as n additional variables of the network. To prevent the curse of dimensionality while adding these dimensions, we use low-rank tensor decomposition to break down the new potentials into smaller factors. Last, we apply the method of Sobol to the resulting network to obtain n global sensitivity indices, one for each parameter of interest. Using a benchmark array of both expert-elicited and learned Bayesian networks, we demonstrate that the Sobol indices can significantly differ from the OAT indices, thus revealing the true influence of uncertain parameters and their interactions.}
}
@article{ZHANG2024117045,
title = {A bidirectional collaborative method based on an improved artificial fish swarm algorithm for ship pipe and equipment layout design},
journal = {Ocean Engineering},
volume = {296},
pages = {117045},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117045},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824003822},
author = {Hongshuo Zhang and Yanyun Yu and Qiaoyu Zhang and Yuansong Yang and Haiyang Liu and Yan Lin},
keywords = {Collaborative optimization, Ship engine room layout design, Multi-strategy heuristic algorithm, Hybrid-objective optimization, Coding technique, Automation design},
abstract = {Ship engine room layout design (SERLD) significantly impacts a ship's transportation efficiency and safety by focusing on the layouts of equipment and piping. However, owing to complex constraints, previous research has mainly focused on single-dimensional layout designs and has failed to provide comprehensive references for designers. To address this research gap, this study proposes a collaborative layout method based on a multistrategy hybrid-objective artificial fish swarm algorithm (HMSAFSA). In terms of the underlying mathematical representation, a more stable Manhattan trajectory-based coding method suitable for a collaborative layout is proposed. Building on this coding method, multiple strategies are incorporated into the heuristic AFSA to enhance its optimization and collaborative performance. Collaborative evaluation functions and methods are designed and refined to ensure effective layout results for multiple objectives. Furthermore, a layout procedure incorporating bidirectional guidance strategies and hierarchical thinking is proposed. This method achieves collaborative layouts through the mutual guidance of optimal objectives. Finally, the effectiveness of the proposed method is verified through representative cases of various types of ship engine rooms in practical engineering. The method demonstrates its capability to offer multiple optimal layout schemes, thus presenting substantial value for practical engineering designs.}
}
@article{EGUCHI2016692,
title = {RoboCupJunior for promoting STEM education, 21st century skills, and technological advancement through robotics competition},
journal = {Robotics and Autonomous Systems},
volume = {75},
pages = {692-699},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015001281},
author = {Amy Eguchi},
keywords = {Educational robotics, Robotics competitions, STEM education, Computational thinking, Engineering skills, 21st century skills},
abstract = {RoboCupJunior is an international educational robotics initiative, aiming to promote STEM content and skill learning among participating youth through educational robotics competition inaugurated in 2000. What makes RoboCupJunior quite unique is its relationship with RoboCup which aims to promote robotics and AI research, by offering a publicly appealing, but formidable challenge including development of soccer robots, search and rescue robots, and robots functions at home and at work. This paper introduces a case of RoboCupJunior and the effectiveness of its practice for enhancing learning of STEM contents and skills for innovation and creativity among participating students. It presents the survey results from one of the World Championships held in 2012, the anecdotal and personal account of participating US students on their learning experience from their participation in 2013 World Championship, and participating students’ technological and innovative contributions to highlight the impacts RoboCupJunior has had through over a decade of its practice.}
}
@article{YU2025110799,
title = {An adaptive incremental solution scheme for the phase field model of fracture},
journal = {Engineering Fracture Mechanics},
volume = {315},
pages = {110799},
year = {2025},
issn = {0013-7944},
doi = {https://doi.org/10.1016/j.engfracmech.2024.110799},
url = {https://www.sciencedirect.com/science/article/pii/S0013794424009627},
author = {Yuanfeng Yu and Chi Hou and Timon Rabczuk and Meiying Zhao},
keywords = {Fracture, Phase field model, Solution scheme, Adaptive increment, Computational time},
abstract = {To increase the phase field model’s computational effectiveness, an efficient and robust adaptive incremental solution scheme is presented in this work. Firstly, a time field change criterion is established based on the variation of phase field variable and its increment, so that the pseudo time increment and load increment can be adaptively regulated with the solution of displacement and phase fields, which cuts down on computation time and the number of iterations. Secondly, the implementation of the scheme is introduced. Finally, the effectiveness of proposed solution scheme is tested through some numerical examples. The results showcase that the proposed strategy can not only acquire accurate load–displacement responses and crack patterns, but also significantly reduce the computational cost. By comparing with the current standard staggered strategy and the monolithic BFGS strategy, the computation time of the presented solution scheme is about 1% of that of the standard strategy, and less than 1/3 of the time of the BFGS strategy. Meanwhile, the presented scheme also exhibits excellent convergence properties.}
}
@article{MANIKANTAN2009639,
title = {Challenges for the future modifications of the TNM staging system for head and neck cancer: Case for a new computational model?},
journal = {Cancer Treatment Reviews},
volume = {35},
number = {7},
pages = {639-644},
year = {2009},
issn = {0305-7372},
doi = {https://doi.org/10.1016/j.ctrv.2009.04.010},
url = {https://www.sciencedirect.com/science/article/pii/S0305737209000632},
author = {Kapila Manikantan and Suhail I. Sayed and Konstantinos N. Syrigos and Peter Rhys-Evans and Chris M. Nutting and Kevin J. Harrington and Rehan Kazi},
keywords = {TNM stage, Head and neck cancer, Co-morbidity},
abstract = {Summary
The TNM system of staging cancers is a simple and effective method to map the extent of tumours. It had traditionally strived to maintain a balance between being simple and user-friendly on one hand and comprehensive on the other. A number of revisions have taken place over the years with the goal of improving utility. However, numerous controversies surround the TNM system. There is a school of thought that contends that patient co-morbidity and specific tumour-related factors should be incorporated to add further prognostic capabilities in the TNM system, but this raises concerns that such an approach may unnecessarily complicate the system. This review highlights some controversies that surround the TNM system and suggests prognostic indicators that may be added to make it more useful in guiding treatment decisions and predicting outcomes.}
}
@incollection{NUNES2010457,
title = {Learning Outside of School},
editor = {Penelope Peterson and Eva Baker and Barry McGaw},
booktitle = {International Encyclopedia of Education (Third Edition)},
publisher = {Elsevier},
edition = {Third Edition},
address = {Oxford},
pages = {457-463},
year = {2010},
isbn = {978-0-08-044894-7},
doi = {https://doi.org/10.1016/B978-0-08-044894-7.00525-X},
url = {https://www.sciencedirect.com/science/article/pii/B978008044894700525X},
author = {T. Nunes},
keywords = {Guided participation, Informal learning, Informal mathematics, Learning outside school, Nonformal learning, Oral arithmetic, Situated learning, Street mathematics, Thinking in action, Work-based learning},
abstract = {Learning can take place everywhere: in the home, the community, or at work. Learning outside school is often invisible because it is taken for granted, as common sense or cultural knowledge. It happens in the course of activities not designed for learning, so it can be described as thinking in action. The representational tools (number systems, graphs) and objects (crates, coins, bills) used outside school become part of our thinking as we act and think with them. A major process in learning outside school is guided participation, where learners take responsibility for accomplishing tasks guided by a more experienced person.}
}
@incollection{PROCHAZKOVA2020121,
title = {Chapter 6 - Altered states of consciousness and creativity},
editor = {David D. Preiss and Diego Cosmelli and James C. Kaufman},
booktitle = {Creativity and the Wandering Mind},
publisher = {Academic Press},
pages = {121-158},
year = {2020},
series = {Explorations in Creativity Research},
isbn = {978-0-12-816400-6},
doi = {https://doi.org/10.1016/B978-0-12-816400-6.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128164006000067},
author = {Luisa Prochazkova and Bernhard Hommel},
keywords = {Altered states of consciousness (ASC), Cannabis, Convergent thinking, Creativity, Divergent thinking, Hallucinations, Meditation, Metactontrol, Psychedelics},
abstract = {Increasing evidence suggests that altered states of consciousness (ASC) are associated with both positive and negative effects on components of creative performance, and convergent and divergent thinking in particular. We provide a metacontrol framework that allows characterizing factors that induce ASC in terms of their general impact on the information processing style of problem solvers. We discuss behavioral and neuronal findings from three areas that reflect strong connections between ASC and the underlying effects on metacontrol on the one hand and components of creativity on the other hand: drug-induced ASC, meditation-induced ASC, and hallucinations. While more, and especially more systematic research is needed, we identify a general trend, suggesting that factors that induce ASC are likely to alter the metacontrol state by biasing it toward either persistence, which is beneficial for convergent thinking and other persistence-heavy operations, or flexibility, which is beneficial for divergent thinking and other flexibility-heavy operations.}
}
@article{ONTIVEROSARAIZA2025105361,
title = {The Neurobehavioral State hypothesis},
journal = {BioSystems},
volume = {247},
pages = {105361},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105361},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002466},
author = {Luis Fernando Ontiveros-Araiza},
keywords = {Brain networks, Neuronal dynamics, Neural code, Neurotransmitter, Electrophysiology, Neuronal computation, Behavior},
abstract = {Since the early attempts to understand the brain made by Greek philosophers more than 2000 years ago, one of the main questions in neuroscience has been how the brain perceives all the stimuli in the environment and uses this information to implement a response. Recent hypotheses of the neural code rely on the existence of an ideal observer, whether on specific areas of the cerebral cortex or distributed network composed of cortical and subcortical elements. The Neurobehavioral State hypothesis stipulates that neurons are in a quasi-stable state due to the dynamic interaction of their molecular components. This increases their computational capabilities and electrophysiological behavior further than a binary active/inactive state. Together, neuronal populations across the brain learn to identify and associate internal and external stimuli with actions and emotions. Furthermore, such associations can be stored through the regulation of neuronal components as new quasi-stable states. Using this framework, behavior arises as the result of the dynamic interaction between internal and external stimuli together with previously established quasi-stable states that delineate the behavioral response. Finally, the Neurobehavioral State hypothesis is firmly grounded on present evidence of the complex dynamics within the brain, from the molecular to the network level, and avoids the need for a central observer by proposing the brain configures itself through experience-driven associations.}
}
@article{LEVYGARBOUA2024102438,
title = {Creative cognition as a bandit problem},
journal = {Learning and Individual Differences},
volume = {111},
pages = {102438},
year = {2024},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2024.102438},
url = {https://www.sciencedirect.com/science/article/pii/S1041608024000311},
author = {Louis Lévy-Garboua and Marco Gazel and Noémi Berlin and Jan Dul and Todd Lubart},
keywords = {Creative cognition, Multi-armed bandit problem, Education and creativity, Individual differences in creative potential, Adolescents' behavior},
abstract = {This paper draws a parallel between creative cognition and a multi-armed bandit problem involving learning from experience in an uncertain environment. Special emphasis is put on the optimal sequencing of divergent and convergent behavior by showing that divergence must be inhibited at one point to converge toward creative behavior so that excessive divergence is counterproductive. We test this hypothesis with a behavioral experiment, using measures of individual divergence and convergence components of creative potential in high school students. Results confirmed that a mix of divergence and convergence predicted high performance in a bandit task but not in a purely random task or in a simple repetitive task. These predictions are maintained after controlling for sex, personality, incentives, and other factors. As hypothesized, creative cognition was necessary for high performance under the appropriate conditions. However, it was not necessary to get high grades in a traditional school system.
Educational relevance statement
Relating to the goal of educators and public policies in the 21st century to make children and adolescents more creative, and schools more receptive to creative thinking, this research focuses on the creative potential and behavior of high school students. It provides an evidence-based policy argument in support of the screening and development by the educational sector of the creative potential of students.}
}
@article{GARDNER201854,
title = {SMLXL: Scaling the smart city, from metropolis to individual},
journal = {City, Culture and Society},
volume = {12},
pages = {54-61},
year = {2018},
note = {Innovation and identity in next generation smart cities},
issn = {1877-9166},
doi = {https://doi.org/10.1016/j.ccs.2017.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S1877916617301315},
author = {Nicole Gardner and Luke Hespanhol},
keywords = {Smart cities, Architecture, Design, Physical computing, Proxemics, Computational design},
abstract = {The ‘smart city’ is an oft-cited techno-urban imaginary promoted by businesses and governments alike. It thinks big, and is chiefly imagined in terms of large-scale information communications systems that hinge on the collection of real-time and so-called ‘big data’. Less talked about are the human-scale implications and user-experience of the smart city. Much of the current academic scholarship on smart cities offers synoptic and technical perspectives, leaving the users of smart systems curiously unaccounted for. While they purport to empower citizens, smart cities initiatives are rarely focused at the citizen-scale, nor do they necessarily attend to the ways initiatives can be user-led or co-designed. Drawing on the outcomes of a university studio, this article rethinks the smart city as a series of urban scales—metropolis, community, individual, and personal—and proposes an analytical model for classifying smart city initiatives in terms of engagement. Informed by the theory of proxemics, the model proposed analyses smart city initiatives in terms of the scope of their features and audience size; the actors accountable for their deployment and maintenance; their spatial reach; and the ability of design solutions to re-shape and adapt to different urban scenarios and precincts. We argue that the significance of this model lies in its potential to facilitate modes of thinking across and between scales in ways that can gauge the levels of involvement in the design of digitally mediated urban environments, and productively re-situate citizens as central to the design of smart city initiatives.}
}
@article{MONAT2024103429,
title = {The self-awareness of the forest},
journal = {Futures},
volume = {163},
pages = {103429},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103429},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724001125},
author = {Jamie P. Monat},
keywords = {Forest, Emergence, Systems thinking, Self-awareness, Neural network},
abstract = {Systems Thinking theorist J. P. Monat has hypothesized that human-level organismal self-awareness will emerge spontaneously in a well-connected neural network as the number of interconnected nodes exceeds ∼70 billion; he speculates that computer networks may achieve self-awareness as the number of nodes approaches this figure. Forests have historically not been perceived as interconnected networks of trees; recently however, researchers have described the “wood-wide web” in which underground fungi interconnect large numbers of trees and plants via chemical and electrical signals. Some of earth’s forests number many billions of trees, and some of the world’s prairies and seagrass meadows also contain billions of individual plants. These plant ecosystems may thus be self-aware, and in fact there may be a multitude of self-aware plant-based ecosystems on earth already. The speed of signal transmission via fungi within each ecosystem is much slower than that in humans, and therefore their organismal self-awareness may be of a different nature than the self-awareness that we associate with humans and upper primates. However, the possibility that our plant systems may be aware of the environmental insults that are being wrought upon them should make us reconsider our anthropocentric activities, as well as the possibility that humanity may need to collaborate with other intelligent non-human earth-based life forms to ensure mutual survival.}
}
@article{CHEN2025126364,
title = {Strain-driven anisotropic enhancement in the thermal conductivity of KCaBi: the role of optical phonons},
journal = {International Journal of Heat and Mass Transfer},
volume = {236},
pages = {126364},
year = {2025},
issn = {0017-9310},
doi = {https://doi.org/10.1016/j.ijheatmasstransfer.2024.126364},
url = {https://www.sciencedirect.com/science/article/pii/S0017931024011931},
author = {Xue-Kun Chen and Yue Zhang and Qing-Qing Luo and Pin-Zhen Jia and Wu-Xing Zhou},
keywords = {anisotropic thermal conductivity, optical phonons, four-phonon scattering, strain engineering, machine learning potential},
abstract = {Acoustic phonons have long been believed to dominate the lattice thermal conductivity (κl) and the contribution of optical phonons can be neglected in crystal structures. KCaBi, as a high-throughput screening semiconductor with ultralow κl [J. Am. Chem. Soc. 144, 4448 (2022)], has been demonstrated that the contribution of optical phonons plays an important role in thermal transport. In this work, by solving the Boltzmann transport equation, it is found that the κl of KCaBi is 2.2 at 300K, with acoustic phonons dominating the z-direction κl and optical phonons contributing around 50% to the x-direction κl under the four-phonon picture. The uncommon contribution of optical phonons also manifests the possibility of tuning the κl anisotropy based on optical phonons. Following this line of thinking, it is found that applying tensile strain can cause a more pronounced decrease of acoustic phonon contribution than that of optical counterpart due to the highly dispersive optical branches, thus enhancing the anisotropic ratio of κl. Moreover, the microscopic mechanism is elucidated by analyzing the phonon dispersion relation, phonon mode-wise contribution and phonon scattering rates. Our study could provide appealing alternatives for the regulation of phonon transport from the viewpoint of optical phonons.}
}
@article{LAING2011306,
title = {Computational approaches to RNA structure prediction, analysis, and design},
journal = {Current Opinion in Structural Biology},
volume = {21},
number = {3},
pages = {306-318},
year = {2011},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2011.03.015},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X11000674},
author = {Christian Laing and Tamar Schlick},
abstract = {RNA molecules are important cellular components involved in many fundamental biological processes. Understanding the mechanisms behind their functions requires RNA tertiary structure knowledge. Although modeling approaches for the study of RNA structures and dynamics lag behind efforts in protein folding, much progress has been achieved in the past two years. Here, we review recent advances in RNA folding algorithms, RNA tertiary motif discovery, applications of graph theory approaches to RNA structure and function, and in silico generation of RNA sequence pools for aptamer design. Advances within each area can be combined to impact many problems in RNA structure and function.}
}
@article{SHARIF2022104090,
title = {Robotic sheet metal folding: Tool vs. material programming},
journal = {Automation in Construction},
volume = {134},
pages = {104090},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104090},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005410},
author = {Shani Sharif and Russell Gentry},
keywords = {Robotic fabrication, Mass-customization, Dieless sheet metal folding},
abstract = {This research explores how deductive engineering thinking, as opposed to an abductive design rationale, can influence how robotic methods of fabricating building components are developed. The goal of this research is to demonstrate how creative thinking can introduce alternative robotic fabrication techniques targeted for the architectural mass-customization process. For this purpose, we chose robotic dieless sheet metal folding as the main fabrication technique, due to its wide range of applications in both the architectural construction and manufacturing industries. Two robotic sheet metal folding projects were developed. The first, an example of tool programming, took advantage of an engineering approach and was focused on the affordances of the tool (an industrial robotic arm). The second project, one of material programming, employed a design methodology and was directed towards the affordances of the material (i.e., stainless steel sheet metal). By discussing the advantages and disadvantages of each approach, this research argues that both engineering and design should be considered required and complementary processes in the development of new creative fabrication solutions, allowing them to and make the overall production process more efficient.}
}
@article{FU2024107632,
title = {Dissecting behavioral inertia in shaping different resident participation behaviors in neighborhood regeneration: A quantitative behavioral experiment},
journal = {Environmental Impact Assessment Review},
volume = {109},
pages = {107632},
year = {2024},
issn = {0195-9255},
doi = {https://doi.org/10.1016/j.eiar.2024.107632},
url = {https://www.sciencedirect.com/science/article/pii/S0195925524002191},
author = {Xinyue Fu and Guiwen Liu and Hongjuan Wu and Taozhi Zhuang and Ruopeng Huang and Fanning Yuan and Yuhang Zhang},
keywords = {Neighborhood regeneration, Resident participation, Behavioral inertia, Behavioral experiment},
abstract = {Research on resident participation in neighborhood regeneration provides valuable insights for urban policymakers in environmental governance. While previous studies have extensively examined various influencing factors, they often neglect the impact of behavioral inertia. To address this gap, this study conducts a behavioral experiment to quantitatively assess the presence and impact of behavioral inertia on residents' governance and financial participation behaviors. A total of 576 valid survey questionnaires were collected, and conditional logit model and ordered logit model were utilized for analysis. The study reveals that behavioral inertia is indeed observable in residents' governance participation and financial participation behaviors. Furthermore, the findings underscore distinct drivers of behavioral inertia for these two types of participation behaviors, with emotional reactions predominantly influencing governance participation, while short-term thinking largely shapes financial participation. Theoretically, this study uses the innovative concept of “behavioral inertia” to offer a new explanatory framework for aspects of behavior that cannot be solely explained by the attributes of regeneration plans. Furthermore, the behavioral experiments utilized in this study exemplify how the research framework of behavioral science can be applied to the study of urban governance in a broad context internationally. Practically, the research findings provide valuable insights for urban policymakers to tailor measures aimed at promoting resident participation and fostering sustainable urban development.}
}
@incollection{GLENBERG199977,
title = {4 Why mental models must be embodied},
editor = {Gert Rickheit and Christopher Habel},
series = {Advances in Psychology},
publisher = {North-Holland},
volume = {128},
pages = {77-90},
year = {1999},
booktitle = {Mental Models in Discourse Processing and Reasoning},
issn = {0166-4115},
doi = {https://doi.org/10.1016/S0166-4115(99)80048-X},
url = {https://www.sciencedirect.com/science/article/pii/S016641159980048X},
author = {Arthur Glenberg},
abstract = {Publisher Summary
Mental models are related to the concept of meaning and language comprehension; in other words, comprehending a linguistic message means that an appropriate mental model has been formed. The manipulation of mental models corresponds to thinking, and it is the manipulation that generates emergent ideas. The chapter discusses the importance of considering the ways ideas combine and presents the data from two experiments that illustrate the combination of ideas. The chapter illustrates the major implications for the theories of mental models. The first implication is that the computational theories cannot account for the data. The second implication is that something like embodiment is needed, and the chapter outlines one account of embodied mental models. The third implication is the most important and most controversial. It is that the human cognition is not a computational phenomenon.}
}
@article{TSENG2025106570,
title = {Exploring artificial intelligence literacy and the use of ChatGPT and copilot in instruction on nursing academic report writing},
journal = {Nurse Education Today},
volume = {147},
pages = {106570},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106570},
url = {https://www.sciencedirect.com/science/article/pii/S026069172500005X},
author = {Li-Ping Tseng and Li-Ping Huang and Wei-Ru Chen},
keywords = {Artificial intelligence literacy, Nursing education, ChatGPT, Copilot, Academic report writing, Scaffolding teaching, Artificial intelligence},
abstract = {Background
Nursing education increasingly emphasizes academic writing and communication, critical for delivering quality patient care and professional advancement. Rapidly emerging artificial intelligence (AI) tools such as ChatGPT and Copilot are transforming educational methodologies, and a focus is being placed on embedding AI literacy to effectively bridge the gap between theoretical knowledge and clinical practice. These technologies have the potential to reshape nursing education in a technology-driven health-care landscape.
Aim
This study investigated the effectiveness of AI literacy and the application of ChatGPT and Copilot in academic nursing report writing. It assessed the level of AI literacy of nursing students, examined the integration of basic AI concepts into a curriculum, and analyzed the impact of these tools compared with traditional teaching methods.
Methods
The study adopted a sample of 203 senior nursing students from Southern Taiwan to compare an AI-enhanced teaching approach using ChatGPT and Copilot with conventional methods. The curriculum, centered on the “Writing Case Reports and Seminars” course, employed the Analyze, Design, Develop, Implement, Evaluate model and incorporated scaffolding techniques to synergistically integrate clinical skills with academic learning. AI literacy was measured using the Meta AI Literacy Scale (MAILS). Summative assessments, adhering to the Taiwan Nursing Association standards, focused on individual and group case report evaluations.
Findings
Following an 18-week AI intervention, the experimental group demonstrated significant improvements in all dimensions of the MAILS. A ChatGPT usage of 100 % was found, with a notable enhancement discovered in the “Nursing Plan” section of case reports. Although the experimental group outperformed the control group in overall case report evaluations, the connections between identified problems and proposed plans were weaker and nursing interventions tended to be less individualized for the experimental group.
Conclusions
The incorporation of AI tools such as ChatGPT and Copilot into a scaffolding teaching framework significantly boosted students' AI literacy and performance in summative assessments. Effective AI training for students, supervised use of these tools, and continuous professional development for educators are paramount to successful implementation. Addressing the current limitations of AI has the potential to further improve academic writing, foster critical thinking, and ensure responsible application in patient care, ultimately leading to higher-quality and more effective nursing education.}
}
@incollection{VARGAS201945,
title = {Cell Adhesion: Basic Principles and Computational Modeling},
editor = {Roger Narayan},
booktitle = {Encyclopedia of Biomedical Engineering},
publisher = {Elsevier},
address = {Oxford},
pages = {45-58},
year = {2019},
isbn = {978-0-12-805144-3},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.99930-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383999306},
author = {Diego A. Vargas and Hans {Van Oosterwyck}},
keywords = {Adherens junction, Adhesion dynamics, Bond lifetime, Cell adhesion, Cellularized material, Focal adhesion, Force spectroscopy, Mathematical modeling, Mechanotransduction, Multiscale modeling, Rate constant, Vertex model},
abstract = {A cell interacts with its environment through adhesion complexes. These are protein complexes that form through noncovalent interactions between adhesion receptors in the cell membrane and similar receptors in neighboring cells or ligand molecules in the surrounding extracellular matrix. Cell adhesions are crucial to maintain tissue integrity and cellular communication. Communication and sensing occur through the transmittal of forces through adhesions. This relevant role motivated researchers to develop theoretical models of adhesion. Initial models were based on studies of association kinetics of proteins, which later were expanded to explicitly include the role of force in determining bond strength. The introduction of techniques that allowed measurements of force in the range of a single adhesion produced models that describe the inner workings of the adhesion molecules themselves. Despite the relative simplicity of these models, they are still relevant. Not only were these studies novel and creative, they have been integrated into models describing larger cellular aggregates, unraveling the role of mechanics in biology. These models have been used in the study of cell migration, developmental biology, and cancer biology.}
}
@article{DUCH1996136,
title = {Computational physics of the mind},
journal = {Computer Physics Communications},
volume = {97},
number = {1},
pages = {136-153},
year = {1996},
note = {High-Performance Computing in Science},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(96)00027-6},
url = {https://www.sciencedirect.com/science/article/pii/0010465596000276},
author = {Włodzisław Duch},
abstract = {In the XIX century and earlier physicists such as Newton, Mayer, Hooke, Helmholtz and Mach were actively engaged in the research on psychophysics, trying to relate psychological sensations to intensities of physical stimuli. Computational physics allows to simulate complex neural processes giving a chance to answer not only the original psychophysical questions but also to create models of the mind. In this paper several approaches relevant to modeling of the mind are outlined. Since direct modeling of the brain functions is rather limited due to the complexity of such models a number of approximations is introduced. The path from the brain, or computational neurosciences, to the mind, or cognitive sciences, is sketched, with emphasis on higher cognitive functions such as memory and consciousness. No fundamental problems in understanding of the mind seem to arise. From a computational point of view realistic models require massively parallel architectures.}
}
@article{CAMERON2019102,
title = {Education in Process Systems Engineering: Why it matters more than ever and how it can be structured},
journal = {Computers & Chemical Engineering},
volume = {126},
pages = {102-112},
year = {2019},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2019.03.036},
url = {https://www.sciencedirect.com/science/article/pii/S0098135418311773},
author = {Ian T. Cameron and Sebastian Engell and Christos Georgakis and Norbert Asprion and Dominique Bonvin and Furong Gao and Dimitrios I. Gerogiorgis and Ignacio E. Grossmann and Sandro Macchietto and Heinz A. Preisig and Brent R. Young},
abstract = {This position paper is an outcome of discussions that took place at the third FIPSE Symposium in Rhodes, Greece, between June 20–22, 2016 (http://fi-in-pse.org). The FIPSE objective is to discuss open research challenges in topics of Process Systems Engineering (PSE). Here, we discuss the societal and industrial context in which systems thinking and Process Systems Engineering provide indispensable skills and tools for generating innovative solutions to complex problems. We further highlight the present and future challenges that require systems approaches and tools to address not only ‘grand’ challenges but any complex socio-technical challenge. The current state of Process Systems Engineering (PSE) education in the area of chemical and biochemical engineering is considered. We discuss approaches and content at both the unit learning level and at the curriculum level that will enhance the graduates’ capabilities to meet the future challenges they will be facing. PSE principles are important in their own right, but importantly they provide significant opportunities to aid the integration of learning in the basic and engineering sciences across the whole curriculum. This fact is crucial in curriculum design and implementation, such that our graduates benefit to the maximum extent from their learning.}
}
@article{MATTHEWS201973,
title = {Introducing a computational method to estimate and prioritize systemic body exposure of organic chemicals in humans using their physicochemical properties},
journal = {Computational Toxicology},
volume = {9},
pages = {73-99},
year = {2019},
issn = {2468-1113},
doi = {https://doi.org/10.1016/j.comtox.2018.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S2468111318300276},
author = {Edwin John Matthews},
keywords = {Absorption, Bioavailability, Chemical disposition, Data-gaps, Distribution, Food ingredient, GRAS, Hazard identification, , OCS (optimal chemical space), Pharmacokinetics, Physicochemical property, Preservative, Prioritization, QSAR, QSPR, Read-across, Risk-ranking, Sequestration, Signal-detection, Toxicokinetics},
abstract = {This report describes a computational method developed to predict systemic exposure (s-exposure), chemical disposition {(CD) intestinal absorption, transport, membrane permeability, distribution, sequestration, phospholipidosis and toxicokinetics} of organic chemicals in humans. The method qualitatively and quantitatively estimates a chemical's CD activity profile based upon computed molecular descriptor properties (descriptors), and it facilitates in silico signal-detection of data-gaps, prioritization, risk-ranking, read-across, and re-assessments (if mandated) of large sets of chemicals in a safety evaluation setting. The investigation used a reference set of 2372 marketed human pharmaceuticals to define decision rules for an optimal chemical space (OCS) in which chemicals have high s-exposure, good CD, and a potential for chemical toxicity (CT); conversely, chemicals outside the OCS have low s-exposure, poor CD into the body, and low potential for CT. The method requires computation of 29 descriptors, identification of OCS molecular descriptor property violations (descriptor_violations), and alignment of descriptor_violations with specific decision rules for individual CD endpoint activities. The investigation predicted the CD activities of food and cosmetic preservatives, ingredients in GRAS (generally recognized as safe). Notices submitted to the FDA, reference pharmaceuticals, and it provides prioritization metrics and indices that facilitate prioritization of chemical in silico computed CD activities.}
}
@article{RIVEST19931,
title = {On Choosing between Experimenting and Thinking when Learning},
journal = {Information and Computation},
volume = {106},
number = {1},
pages = {1-25},
year = {1993},
issn = {0890-5401},
doi = {https://doi.org/10.1006/inco.1993.1047},
url = {https://www.sciencedirect.com/science/article/pii/S0890540183710473},
author = {R.L. Rivest and R.H. Sloan},
abstract = {We introduce a model of inductive inference, or learning, that extends the conventional Bayesian approach by explicitly considering the computational cost of formulating predictions to be tested. We view the learner as a scientist who must divide her time between doing experiments and deducing predictions from promising theories, and we wish to know how she can do so most effectively. We explore several approaches based on the cost of making a prediction relative to the cost of performing an experiment. The resulting strategies share many qualitative characteristics with "real" science. This model is significant for the following reasons: •It allows us to study how a scientist might go about acquiring knowledge in a world where (as in real life) both performing experiments and making predictions from theories require time and effort.•It lays the foundation for a rigorous machine-implementable notion of "subjective probability." Good (1959, , 443-447) argues persuasively that subjective probability is at the heart of probability theory. Previous treatments of subjective probability do not handle the complication that the learner′s subjective probabilities may change as the result of pure thinking; our model captures this and other effects in a realistic manner. In addition, we begin to answer the question of how to trade off versus -a question that is fundamental for computers that must exist in the world and learn from their experience.}
}
@article{SINGH2024483,
title = {How has the AI boom impacted algorithmic biology?},
journal = {Cell Systems},
volume = {15},
number = {6},
pages = {483-487},
year = {2024},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2024.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S2405471224001522},
author = {Mona Singh and Cenk Sahinalp and Jianyang Zeng and Wei Vivian Li and Carl Kingsford and Qiangfeng Zhang and Teresa Przytycka and Joshua Welch and Jian Ma and Bonnie Berger},
abstract = {This Voices piece will highlight the impact of artificial intelligence on algorithm development among computational biologists. How has worldwide focus on AI changed the path of research in computational biology? What is the impact on the algorithmic biology research community?}
}
@article{OSINGA2022103298,
title = {Big data in agriculture: Between opportunity and solution},
journal = {Agricultural Systems},
volume = {195},
pages = {103298},
year = {2022},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2021.103298},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X21002511},
author = {Sjoukje A. Osinga and Dilli Paudel and Spiros A. Mouzakitis and Ioannis N. Athanasiadis},
keywords = {Big data solutions, Precision Agriculture, Case study, Stakeholders, Technological maturity level, Mixed-method approach},
abstract = {CONTEXT
Big data applications in agriculture evolve fast, as more experience, applications, good practices and computational power become available. Actual solutions to real-life problems are scarce. What characterizes the adoption of big data problems to solutions and to what extent is there a match between them?
OBJECTIVE
We aim to assess the conditions of the adoption of big data technologies in agricultural applications, based on the investigation of twelve real-life practical use cases in the precision agriculture and livestock domain.
METHODS
We use a mixed method approach: a case study research around the twelve use cases of Horizon 2020 project CYBELE, varying from precision arable and livestock farming to fishing and food security, and a stakeholder survey (n = 56). Our analysis focuses on four perspectives: (1) the drivers of change that initiated the use cases; (2) the big data characteristics of the problem; (3) the technological maturity level of the solution both at start and end of the project; (4) the stakeholder perspective.
RESULTS AND CONCLUSIONS
Results show that the use cases’ drivers of change are a combination of data-, technology, research- and commercial interests; most have at least a research drive. The big data characteristics (volume, velocity, variety, veracity) are well-represented, with most emphasis on velocity and variety. Technology readiness levels show that the majority of use cases started at experimental or lab environment stage and aims at a technical maturity of real-world small-scale deployment. Stakeholders’ main concern is cost, user friendliness and to embed the solution within their current work practice. The adoption of better-matching big data solutions is modest. Big data solutions do not work out-of-the-box when changing application domains. Additional technology development is needed for addressing the idiosyncrasies of agricultural applications.
SIGNIFICANCE
We add a practical, empirical assessment of the current status of big data problems and solutions to the existing body of mainly theoretical knowledge. We considered the CYBELE research project as our laboratory for this. Our strength is that we interviewed the use case representatives in person, and that we included the stakeholders’ perspective in our results. Large-scale deployments need effective interdisciplinary approaches and long-term project horizons to address issues emerging from big data characteristics, and to avoid compartmentalization of agricultural sciences. We need both an engineering perspective – to make things work in practice – and a systems thinking perspective – to offer holistic, integrated solutions.}
}
@article{CHENG2013267,
title = {Shape-anisotropic particles at curved fluid interfaces and role of Laplace pressure: A computational study},
journal = {Journal of Colloid and Interface Science},
volume = {402},
pages = {267-278},
year = {2013},
issn = {0021-9797},
doi = {https://doi.org/10.1016/j.jcis.2013.03.047},
url = {https://www.sciencedirect.com/science/article/pii/S0021979713003056},
author = {Tian-Le Cheng and Yu U. Wang},
keywords = {Capillary forces, Surface tension, Laplace pressure, Diffuse interface field approach, Gibbs–Duhem relation, Shape anisotropy, Pickering emulsions},
abstract = {The self-assembly behavior of shape-anisotropic particles at curved fluid interfaces is computationally investigated by diffuse interface field approach (DIFA). A Gibbs–Duhem-type thermodynamic formalism is introduced to treat heterogeneous pressure within the phenomenological model, in agreement with Young–Laplace equation. Computer simulations are performed to study the effects of capillary forces (interfacial tension and Laplace pressure) on particle self-assembly at fluid interfaces in various two-dimensional cases. For isolated particles, it is found that the equilibrium liquid interface remains circular and particles of different shapes do not disturb the homogeneous curvature of liquid interface, while the equilibrium position, orientation and stability of a particle at the liquid interface depend on its shape and initial location with respect to the liquid interface. For interacting particles, the curvature of local liquid interfaces is different from the apparent curvature of the particle shell; nevertheless, irrespective of the particle shapes, a particle-coated droplet always tends to deform into a circular morphology under positive Laplace pressure, loses mechanical stability and collapses under negative Laplace pressure, while adapts to any morphology and stays in neutral equilibrium under zero Laplace pressure. Finally, the collective behaviors of particles and Laplace pressure evolution in bicontinuous interfacially jammed emulsion gels (bijels) are investigated.}
}
@article{VAHLDICK2020100037,
title = {A blocks-based serious game to support introductory computer programming in undergraduate education},
journal = {Computers in Human Behavior Reports},
volume = {2},
pages = {100037},
year = {2020},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2020.100037},
url = {https://www.sciencedirect.com/science/article/pii/S2451958820300373},
author = {Adilson Vahldick and Paulo Roberto Farah and Maria José Marcelino and António José Mendes},
keywords = {Computer programming learning, Blocks-based approach, Serious games},
abstract = {Blocks-based environments have been used to promote computational thinking (CT) and programming learning mostly in elementary and middle schools. In many countries, like Brazil and Portugal, isolated initiatives have been launched to promote CT learning, but until now there is no evidence of a widespread use of this type of environments. Consequently, it is not common that students that reach higher education nowadays are familiar with CT and programming. This paper presents the development of a serious game to support the learning of basic computer programming. It is a blocks-based environment including also resources that allow the teacher to follow the student’s progress and customize in-game tasks. Four cycles of experiments were conducted, improving both the game and how it was used. Based on the results of these experiences, the key contribution of this paper is a set of fourteen findings and recommendations to the creation and use of a game-based approach to support introductory computer programming learning for novices.}
}
@article{CRUJEIRAS2013208,
title = {Challenges in the implementation of a competency-based curriculum in Spain},
journal = {Thinking Skills and Creativity},
volume = {10},
pages = {208-220},
year = {2013},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2013.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S187118711300045X},
author = {Beatriz Crujeiras and María Pilar Jiménez-Aleixandre},
keywords = {Scientific competency, Epistemic practices, Higher-order thinking, Policy},
abstract = {This paper addresses some of the challenges involved in implementing the new approach established in the Spanish National Curriculum in 2006, which brought as a major change a focus on the development of key competencies. The paper focuses on scientific competency and the challenges involved in the itinerary from policy documents to classrooms are addressed in three sections: (i) an analysis is made of the changes in the science curriculum as a consequence of the emphasis on scientific competency, comparing the assessment criteria in the previous and current steering documents; (ii) trends in teacher education are discussed; (iii) the findings of the diagnostic evaluation are analyzed. The paper is framed in a theoretical approach, viewing students’ participation in scientific practices, and the development of higher-order thinking as necessary goals of science education. We argue that the focus on competencies, characterized as the ability to apply knowledge and skills in new contexts, involves a major change towards knowledge transfer and higher-order thinking skills. Some issues emerging from the analysis relate to the implications of assessment criteria and the challenges involved in its implementation, to the trends in teacher professional development and the difficulties related to the current economic crisis and to the results of the diagnostic evaluation and time frame needed for reforms to have an impact. It is argued that the development of both competencies and higher-order thinking requires students’ prolonged engagement.}
}
@article{NIKIFORIDOU20124830,
title = {Risk Literacy in Early Childhood Education Under a Lifelong Perspective},
journal = {Procedia - Social and Behavioral Sciences},
volume = {46},
pages = {4830-4833},
year = {2012},
note = {4th WORLD CONFERENCE ON EDUCATIONAL SCIENCES (WCES-2012) 02-05 February 2012 Barcelona, Spain},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2012.06.343},
url = {https://www.sciencedirect.com/science/article/pii/S1877042812020794},
author = {Zoi Nikiforidou and Jenny Pange and Theodore Chadjipadelis},
keywords = {First keywords, second keywords, third keywords, forth keywords},
abstract = {Risk entails every action, every level and every perspective of our lives. The ability to make advantageous decisions, to deal with uncertainties, to infer and estimate more or less probable outcomes, to manage risky or riskless situations compose the wider notion of risk literacy and may be inserted from formal preschool education. The current paper aims to enlighten the notion of risk literacy and safety education as a necessity in establishing pupils ready to accept failure, to achieve success, to take initiatives, to become self-competent, to develop probabilistic and statistical thinking, to confront uncertainty and in turn to face the challenges of modern risk society. It is argued that within the formal settings of preschool education, through developmentally appropriate activities, opportunities may be implemented in order to encourage children as future citizens to construct risk literate personalities. It is concluded that risk perception and management imply awareness, assessment, avoidance and adaptation and are connected with growth, maturity, practice, experiences, intuitions and computations.}
}
@article{MEDINAOLIVA201338,
title = {PRM-based patterns for knowledge formalisation of industrial systems to support maintenance strategies assessment},
journal = {Reliability Engineering & System Safety},
volume = {116},
pages = {38-56},
year = {2013},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2013.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S0951832013000616},
author = {G. Medina-Oliva and P. Weber and B. Iung},
keywords = {Maintenance strategies, Performances analysis, Decision-making, Bayesian Networks (BN), Probabilistic Relational Model (PRM)},
abstract = {The production system and its maintenance system must be now developed on “system thinking” paradigm in order to guarantee that Key Performance Indicators (KPI) will be optimized all along the production system (operation) life. In a recursive way, maintenance system engineering has to integrate also KPI considerations with regards to its own enabling systems. Thus this paper develops a system-based methodology wherein a set of KPIs is computed in order to verify if the objectives of the production and maintenance systems are satisfied. In order to help the decision-making process for maintenance managers, a “unified” generic model have been developed. This model integrates (a) the interactions of the maintenance system with its enabling systems, (b) the impact of the maintenance strategies through the computation of some key performance indicators, and (c) different kinds of knowledge regarding the maintenance system and the system of interest, including quantitative and qualitative knowledge. This methodology is based on an executable unified model built with Probabilistic Relational Model (PRM). PRM allows a modular representation and inferences computation of large size models. The methodology added-value is shown on a test-bench.}
}
@article{DOWNES1993229,
title = {Modeling scientific practice: Paul Thagard's computational approach},
journal = {New Ideas in Psychology},
volume = {11},
number = {2},
pages = {229-243},
year = {1993},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(93)90036-D},
url = {https://www.sciencedirect.com/science/article/pii/0732118X9390036D},
author = {Stephen Downes},
abstract = {In this paper I examine Paul Thagard's computational approach to studying science, which is a contribution to the cognitive science of science. I present several criticisms of Thagard's approach and use them to motivate some suggestions for alternative approaches in cognitive science of science. I first argue that Thagard does not clearly establish the units of analysis of his study. Second, I argue that Thagard mistakenly applies the same model to both individual and group decision making. Finally, I argue that in attempting to account for psychological and social processes as well as providing a philosophical model of successful reasoning Thagard attempts to explain too much with one model, thus straining the plausibility of his model.}
}
@article{LIU2025101664,
title = {Interdigitated microband electrode arrays in paired organic electrosyntheses: Sustainability and practicality},
journal = {Current Opinion in Electrochemistry},
volume = {50},
pages = {101664},
year = {2025},
issn = {2451-9103},
doi = {https://doi.org/10.1016/j.coelec.2025.101664},
url = {https://www.sciencedirect.com/science/article/pii/S2451910325000237},
author = {Tingran Liu and Taku Suzuki-Osborne and James E. Taylor and Frank Marken},
abstract = {Electrochemical synthesis is well established for production of bulk commodities such as copper, aluminium, or ethylene oxide, but electrosynthesis could play an increasingly important role also in a broader range of organic and pharmaceutical syntheses. Electrochemical transformations linked to renewable electricity offer a low-carbon low-waste alternative to traditional chemical reactions (sustainability), although more work is needed to establish processes and reactor technology for easy implementation (practicality). Here, the application of interdigitated microband array electrodes (in conjunction with computational methods) is discussed/contrasted as a tool to (i) avoid the use of added supporting electrolyte, (ii) achieve anode–cathode process pairing, and (iii) allow very simple reactor technology to be introduced compatible with existing chemical reactionware.}
}
@article{SHI2024e35268,
title = {3D dynamic landscape simulation of artificial intelligence in environmental landscape design},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e35268},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35268},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024112996},
author = {Binbin Shi},
keywords = {Artificial intelligence, Environmental landscape design, Fuzzy analytical hierarchical process, Geographical information system, 3D dynamic landscape, Interactive design system},
abstract = {Three-dimensional (3D) simulations and precise landscape visualizations are crucial for various applications, like landscape management and planning, computer and connection of the landscape, evaluation, and tracking of land use. The consequences of several plans and a large scene cannot be communicated using older methods of comprehensive environmental planning and development in a timely, rational, and coordinated manner. Architects have trouble incorporating ideas into other comprehensive planning implementation processes. Architects did not thoroughly investigate the neighbourhood's demographics and matching behavioural needs and lacked critical thinking. The 3D dynamic landscape simulation is a detailed computerized three-dimensional simulation of the environment that can be dynamically presented. With the aid of Artificial Intelligence (AI) technology, the system possesses a strong sense of reality, a user-friendly interface, and interactive features that can be tailored to the requirements of the contemporary urban environmental landscape. Regarding exterior publicity, domestic assistance, environmental land use planning, and information systems. The novelty of the proposed Interactive Design System based on AI (IDS-AI) is to create a 3D dynamic landscape model based on a real-life environmental scene, utilizing a Geographic Information System (GIS) to optimize landscape vision. Secondly, 3D environmental landscape design simulation was implemented using GIS spatial analysis in conjunction with the Fuzzy Analytical Hierarchical Process (FAHP) to reduce the data overlap rate and help make an accurate decision. Finally, the design incorporates the development of the interactive interface system application of landscape design and environmental resources for viewing the landscape, the factors that affect them, and the area coverage ratio of various land cover types. The experimental outcomes show that the suggested IDS model increases the gradient sensitivity level of 98.3 % and area coverage ratio of 93.4 % compared to other existing models.}
}
@article{MUNSON2019100736,
title = {After eliciting: Variation in elementary mathematics teachers’ discursive pathways during collaborative problem solving},
journal = {The Journal of Mathematical Behavior},
volume = {56},
pages = {100736},
year = {2019},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2019.100736},
url = {https://www.sciencedirect.com/science/article/pii/S073231231930046X},
author = {Jen Munson},
keywords = {Classroom discourse, Eliciting, Responsiveness, Student understanding},
abstract = {Mathematics teachers are called on to craft instruction that centers students’ mathematical ideas and creates consistent, pervasive opportunities for meaning-making through discourse. In the context of collaborative problem solving, teachers can use eliciting and probing to uncover student thinking while students work together to develop mathematical ideas and strategies. After eliciting and probing, teachers can further respond to the student thinking that has been revealed. This study explored the discursive pathways two fourth grade mathematics teachers used after eliciting student thinking, when their aim was to be responsive to and advance student thinking. Drawing on interactions (n = 97) from nine lessons, qualitative analysis identified five distinct discursive pathways after eliciting, two of which, praise and funneling, were associated with the nature of student understanding uncovered during eliciting. Implications for future research and professional development on teacher-student discourse are discussed.}
}
@incollection{PENN2012143,
title = {Computational Linguistics},
editor = {Ruth Kempson and Tim Fernando and Nicholas Asher},
booktitle = {Philosophy of Linguistics},
publisher = {North-Holland},
address = {Amsterdam},
pages = {143-173},
year = {2012},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-51747-0.50005-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517470500056},
author = {Gerald Penn}
}
@article{PARK2025,
title = {Development and Validation of the Digital Sensitivity Scale for Adults: Cross-Sectional Observational Study},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/55828},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125000470},
author = {Hae In Park and Minjeong Jeon and Ji Seon Ahn and Kyungmi Chung and Jin Young Park},
keywords = {information literacy, health literacy, computer literacy, self-efficacy, attitude, digital divide},
abstract = {Background
The COVID-19 pandemic has accelerated the digitalization of modern society, extending digital transformation to daily life and psychological evaluation and treatment. However, the development of competencies and literacy in handling digital technology has not kept pace, resulting in a significant disparity among individuals. Existing measurements of digital literacy were developed before widespread information and communications technology device adoption, mainly focusing on one’s perceptions of their proficiency and the utility of device operation. In the contemporary landscape, digital transformation is evolving within specialized domains, necessitating a comprehensive evaluation of digital competencies, attitudes, and proficiency in technology application to bridge the digital divide and ensure digital compliance.
Objective
This study was designed to address the shortcomings of existing scales and formulate a digital sensitivity scale tailored to the requirements of today’s society.
Methods
Initial items of the Yongin Severance Digital Sensitivity Scale (YI-DSS) were collected through a literature review, and expert opinions were gathered to ensure content validity. An exploratory and confirmatory factor analysis included 986 adult participants evaluating 14 digital literacy items and 6 digital efficacy items. The Cronbach α confirmed internal consistency reliability, and 2-tailed t tests, ANOVAs, and post hoc tests analyzed demographic differences in digital literacy and efficacy.
Results
A robust 4-factor digital literacy solution was identified: digital application, digital communication, critical thinking, and digital ethics (Kaiser-Meyer-Olkin=0.891; Bartlett × 2=9829.713; P<.001; Cronbach α=0.782-0.947). A 2-factor solution defined digital efficacy: digital confidence and digital anxiety (Kaiser-Meyer-Olkin=0.735; Bartlett × 2=3282.217; P<.001; Cronbach α=0.787-0.912). Confirmatory factor analysis was conducted for each model (digital literacy model: χ271=676.0, comparative fit index=0.938, Tucker-Lewis index=0.921, standardized root mean square residual=0.73, and root mean square error of approximation=0.093; digital efficacy model: χ28=81.9, comparative fit index=0.977, Tucker-Lewis index=0.958, standardized root mean square residual=0.73, and root mean square error of approximation=0.097), which indicated a good fit. The YI-DSS also showed high correlation with the previously developed Digital Literacy Scale (r=0.809; P<.001).
Conclusions
The YI-DSS, as a self-assessment tool, has the potential to bridge the generational information gap by promoting acceptance, motivation, and adaptation to digital technology. Furthermore, given the remote nature of digital therapeutics, an individual’s familiarity with required technologies and digital communication strongly influences their acceptance of digital treatments and the efficacy thereof. This scale can play a pivotal role in enhancing compliance with digital therapeutics by preemptively assessing individuals’ technological literacy and competency.}
}
@article{SANCHEZTORRUBIA201212177,
title = {An approach to automatic learning assessment based on the computational theory of perceptions},
journal = {Expert Systems with Applications},
volume = {39},
number = {15},
pages = {12177-12191},
year = {2012},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2012.04.069},
url = {https://www.sciencedirect.com/science/article/pii/S0957417412006665},
author = {M. Gloria Sánchez-Torrubia and Carmen Torres-Blanc and Gracian Trivino},
keywords = {Automatic learning assessment, Computing with words and perceptions, Granular linguistic model of a phenomenon},
abstract = {E-learning systems output a huge quantity of data on a learning process. However, it takes a lot of specialist human resources to manually process these data and generate an assessment report. Additionally, for formative assessment, the report should state the attainment level of the learning goals defined by the instructor. This paper describes the use of the granular linguistic model of a phenomenon (GLMP) to model the assessment of the learning process and implement the automated generation of an assessment report. GLMP is based on fuzzy logic and the computational theory of perceptions. This technique is useful for implementing complex assessment criteria using inference systems based on linguistic rules. Apart from the grade, the model also generates a detailed natural language progress report on the achieved proficiency level, based exclusively on the objective data gathered from correct and incorrect responses. This is illustrated by applying the model to the assessment of Dijkstra’s algorithm learning using a visual simulation-based graph algorithm learning environment, called GRAPHs.}
}
@article{NIKNAM20112805,
title = {Non-smooth economic dispatch computation by fuzzy and self adaptive particle swarm optimization},
journal = {Applied Soft Computing},
volume = {11},
number = {2},
pages = {2805-2817},
year = {2011},
note = {The Impact of Soft Computing for the Progress of Artificial Intelligence},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2010.11.010},
url = {https://www.sciencedirect.com/science/article/pii/S1568494610002875},
author = {Taher Niknam and Hasan Doagou Mojarrad and Hamed Zeinoddini Meymand},
keywords = {Economic dispatch, New adaptive particle swarm optimization (NAPSO), Mutation operator, Multi-fuel effects, Self-adaptive parameter control},
abstract = {Economic dispatch (ED) problem is a nonlinear and non-smooth optimization problem when valve-point effects, multi-fuel effects and prohibited operating zones (POZs) have been considered. This paper presents an efficient evolutionary method for a constrained ED problem using the new adaptive particle swarm optimization (NAPSO) algorithm. The original PSO has difficulties in premature convergence, performance and the diversity loss in optimization process as well as appropriate tuning of its parameters. In the proposed algorithm, to improve the global searching capability and prevent the convergence to local minima, a new mutation is integrated with adaptive particle swarm optimization (APSO). In APSO, the inertia weight is tuned by using fuzzy IF/THEN rules and the cognitive and the social parameters are self-adaptively adjusted. The proposed NAPSO algorithm is validated on test systems consisting of 6, 10, 15, 40 and 80 generators with the objective functions possessing prohibited zones, multi-fuel effects and valve-point loading effects. The research results reveal the effectiveness and applicability of the proposed algorithm to the practical ED problem.}
}
@article{CASH2023101219,
title = {Method in their madness: Explaining how designers think and act through the cognitive co-evolution model},
journal = {Design Studies},
volume = {88},
pages = {101219},
year = {2023},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2023.101219},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X23000601},
author = {Philip Cash and Milene Gonçalves and Kees Dorst},
keywords = {co-evolution, design process(es), design cognition, design thinking, creativity},
abstract = {Designers often face situations where the only way forward is through the exploration of possibilities. However, there is a critical disconnect between understanding of how designer’s think and act in such situations. We address this disconnect by proposing and testing (via protocol analysis) the cognitive co-evolution model. Our model comprises a new approach to co-evolutionary design theory by explaining both the progression of the process itself and the creation of design outputs via an interplay between metacognitive perceived uncertainty, cognition, and the external world. We thus connect explanations of how designers think with descriptions of how they act. We provide a foundation for connecting to other theories, models, and questions in design research via common links to cognition and metacognition.}
}
@article{LASAPONARA202460,
title = {Temperament and probabilistic predictive coding in visual-spatial attention},
journal = {Cortex},
volume = {171},
pages = {60-74},
year = {2024},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2023.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0010945223002599},
author = {Stefano Lasaponara and Gabriele Scozia and Silvana Lozito and Mario Pinto and David Conversi and Marco Costanzi and Tim Vriens and Massimo Silvetti and Fabrizio Doricchi},
keywords = {Attention, Temperament, Personality, Posner task, Neurotransmitters},
abstract = {Cholinergic (Ach), Noradrenergic (NE), and Dopaminergic (DA) pathways play an important role in the regulation of spatial attention. The same neurotransmitters are also responsible for inter-individual differences in temperamental traits. Here we explored whether biologically defined temperamental traits determine differences in the ability to orient spatial attention as a function of the probabilistic association between cues and targets. To this aim, we administered the Structure of Temperament Questionnaire (STQ-77) to a sample of 151 participants who also performed a Posner task with central endogenous predictive (80 % valid/20 % invalid) or non-predictive cues (50 % valid/50 % invalid). We found that only participants with high scores in Plasticity and Intellectual Endurance showed a selective abatement of attentional costs with non-predictive cues. In addition, stepwise regression showed that costs in the non-predictive condition were negatively predicted by scores in Plasticity and positively predicted by scores in Probabilistic Thinking. These results show that stable temperamental characteristics play an important role in defining the inter-individual differences in attentional behaviour, especially in the presence of different probabilistic organisations of the sensory environment. These findings emphasize the importance of considering temperamental and personality traits in social and professional environments where the ability to control one's attention is a crucial functional skill.}
}
@article{VELDHUIS2025100708,
title = {Critical Artificial Intelligence literacy: A scoping review and framework synthesis},
journal = {International Journal of Child-Computer Interaction},
volume = {43},
pages = {100708},
year = {2025},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100708},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000771},
author = {Annemiek Veldhuis and Priscilla Y. Lo and Sadhbh Kenny and Alissa N. Antle},
keywords = {Artificial intelligence, Critical literacy, AI ethics, AI literacy, Computational empowerment, Literature review},
abstract = {The proliferation of Artificial Intelligence (AI) in everyday life raises concerns for children, other marginalized groups, and the general public. As new AI implementations continue to emerge, it is crucial to enable children to engage critically with AI. Critical literacy objectives and practices can encourage children to question, critique, and transform the social, political, cultural, and ethical implications of AI. As an initial step towards critical AI education, we conducted a 10-year scoping review to identify publications reporting on activities that engage children, between the ages of 5 and 18, to address the critical implications of AI. Our review identifies a wide range of participants, content, and pedagogical approaches. Through framework synthesis guided by an established critical literacy model, we examine the critical literacy learning objectives embedded in the reported activities and propose a critical AI literacy framework. This paper outlines future opportunities for critical AI literacies in the field of child–computer interaction including inspiring new learning activities, encouraging inclusive perspectives, and supporting pragmatic curriculum integration.}
}
@article{JONES2000571,
title = {Unstructured mesh computations on CCMs},
journal = {Advances in Engineering Software},
volume = {31},
number = {8},
pages = {571-580},
year = {2000},
issn = {0965-9978},
doi = {https://doi.org/10.1016/S0965-9978(00)00012-0},
url = {https://www.sciencedirect.com/science/article/pii/S0965997800000120},
author = {M.T Jones and K Ramachandran},
keywords = {Configurable computing, Floating point, Finite element},
abstract = {Configurable Computing Machines (CCMs) have been able to provide orders of magnitude increases in execution rates for applications such as image processing, signal processing, and automatic target recognition. This paper describes the use of CCMs to accelerate complex, large-scale scientific computations. These applications present a challenge for CCMs because of their large size, hundreds of thousands of lines of code, and the unstructured nature of the computations. This paper describes strategies for accelerating scientific computations on CCMs and demonstrates the effectiveness of one such strategy on the Annapolis Micro Systems WildForce board. Results from this implementation are analyzed.}
}
@article{CASTRO20242377,
title = {Product Customization based on Digital Twin and Cloud Manufacturing within a Decentralized Production System},
journal = {Procedia Computer Science},
volume = {239},
pages = {2377-2384},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.431},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924016752},
author = {Hélio Castro and Fernando Câmara and Paulo Ávila and Luís Ferreira and Manuela Cruz-Cunha},
keywords = {Industry 4.0, Digital Twin, Cyber-Physical System, Smart Factory, Product Customization, Cloud Manufacturing},
abstract = {Industry 4.0 represents a turning point in the thinking of the production model since it is based on digitalized production systems with the aim of improving productivity, product quality, and delivery time to the customer. The digitalization and evolution of information technology allowed the emulation of production system virtual models, namely in the concept of Digital Twin (DT), with the ability to simulate different scenarios providing support for better decision making. This concept not only represents a virtual copy of the physical world that obtains information about the state of the value chain but also illustrates a system capable of changing the development of the production activity according to the fulfillment of the intended business goals. In literature, the concept of the Digital Twin is exhaustively treated as a stand-alone factory (one digital factory represents one physical factory) and underestimates the possibility of a DT oriented to a customized product (a project) that requires decentralized production systems. This paper brings to discussion the relevance of product customized applying DT to smart customization, and the inclusion of decentralized production systems supported by Cloud Manufacturing.}
}
@article{CIRAOLO201378,
title = {A computational method for the Helmholtz equation in unbounded domains based on the minimization of an integral functional},
journal = {Journal of Computational Physics},
volume = {246},
pages = {78-95},
year = {2013},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2013.03.047},
url = {https://www.sciencedirect.com/science/article/pii/S0021999113002258},
author = {Giulio Ciraolo and Francesco Gargano and Vincenzo Sciacca},
keywords = {Helmholtz equation, Transparent boundary conditions, Minimization of integral functionals},
abstract = {We study a new approach to the problem of transparent boundary conditions for the Helmholtz equation in unbounded domains. Our approach is based on the minimization of an integral functional arising from a volume integral formulation of the radiation condition. The index of refraction does not need to be constant at infinity and may have some angular dependency as well as perturbations. We prove analytical results on the convergence of the approximate solution. Numerical examples for different shapes of the artificial boundary and for non-constant indexes of refraction will be presented.}
}
@article{GANGWAL2025,
title = {Artificial Intelligence in Natural Product Drug Discovery: Current Applications and Future Perspectives},
journal = {Journal of Medicinal Chemistry},
year = {2025},
issn = {1520-4804},
doi = {https://doi.org/10.1021/acs.jmedchem.4c01257},
url = {https://www.sciencedirect.com/science/article/pii/S1520480425001826},
author = {Amit Gangwal and Antonio Lavecchia},
abstract = {Drug discovery, a multifaceted process from compound identification to regulatory approval, historically plagued by inefficiencies and time lags due to limited data utilization, now faces urgent demands for accelerated lead compound identification. Innovations in biological data and computational chemistry have spurred a shift from trial-and-error methods to holistic approaches to medicinal chemistry. Computational techniques, particularly artificial intelligence (AI), notably machine learning (ML) and deep learning (DL), have revolutionized drug development, enhancing data analysis and predictive modeling. Natural products (NPs) have long served as rich sources of biologically active compounds, with many successful drugs originating from them. Advances in information science expanded NP-related databases, enabling deeper exploration with AI. Integrating AI into NP drug discovery promises accelerated discoveries, leveraging AI’s analytical prowess, including generative AI for data synthesis. This perspective illuminates AI’s current landscape in NP drug discovery, addressing strengths, limitations, and future trajectories to advance this vital research domain.
}
}
@article{AIMONE2009187,
title = {Computational Influence of Adult Neurogenesis on Memory Encoding},
journal = {Neuron},
volume = {61},
number = {2},
pages = {187-202},
year = {2009},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2008.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0896627308010192},
author = {James B. Aimone and Janet Wiles and Fred H. Gage},
keywords = {SYSNEURO, MOLNEURO, STEMCELL},
abstract = {Summary
Adult neurogenesis in the hippocampus leads to the incorporation of thousands of new granule cells into the dentate gyrus every month, but its function remains unclear. Here, we present computational evidence that indicates that adult neurogenesis may make three separate but related contributions to memory formation. First, immature neurons introduce a degree of similarity to memories learned at the same time, a process we refer to as pattern integration. Second, the extended maturation and change in excitability of these neurons make this added similarity a time-dependent effect, supporting the possibility that temporal information is included in new hippocampal memories. Finally, our model suggests that the experience-dependent addition of neurons results in a dentate gyrus network well suited for encoding new memories in familiar contexts while treating novel contexts differently. Taken together, these results indicate that new granule cells may affect hippocampal function in several unique and previously unpredicted ways.}
}
@article{STONE2004781,
title = {Intention, interpretation and the computational structure of language},
journal = {Cognitive Science},
volume = {28},
number = {5},
pages = {781-809},
year = {2004},
note = {2003 Rumelhart Prize Special Issue Honoring Aravind K. Joshi},
issn = {0364-0213},
doi = {https://doi.org/10.1016/j.cogsci.2004.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S036402130400062X},
author = {Matthew Stone},
keywords = {Dialogue, Pragmatics, Tree adjoining grammar},
abstract = {I show how a conversational process that takes simple, intuitively meaningful steps may be understood as a sophisticated computation that derives the richly detailed, complex representations implicit in our knowledge of language. To develop the account, I argue that natural language is structured in a way that lets us formalize grammatical knowledge precisely in terms of rich primitives of interpretation. Primitives of interpretation can be correctly viewed intentionally, as explanations of our choices of linguistic actions; the model therefore fits our intuitions about meaning in conversation. Nevertheless, interpretations for complex utterances can be built from these primitives by simple operations of grammatical derivation. In bridging analyses of meaning at semantic and symbol-processing levels, this account underscores the fundamental place for computation in the cognitive science of language use.}
}
@article{FIORE2006S248,
title = {Multi-scale computational analysis of fluid dynamics in the Toraymyxin adsorption cartridge},
journal = {Journal of Biomechanics},
volume = {39},
pages = {S248},
year = {2006},
note = {Abstracts of the 5th World Congress of Biomechanics},
issn = {0021-9290},
doi = {https://doi.org/10.1016/S0021-9290(06)83940-0},
url = {https://www.sciencedirect.com/science/article/pii/S0021929006839400},
author = {G.B. Fiore and G. Guadagni and M. Soncini and S. Vesentini and A. Redaelli}
}
@article{HOWARD2006464,
title = {Cumulative semantic inhibition in picture naming: experimental and computational studies},
journal = {Cognition},
volume = {100},
number = {3},
pages = {464-482},
year = {2006},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2005.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010027705001393},
author = {David Howard and Lyndsey Nickels and Max Coltheart and Jennifer Cole-Virtue},
keywords = {Semantic inhibition, Spoken word production, Picture naming, Competition, Word retrieval, Computational modelling, Priming},
abstract = {We report an experiment in which subjects named 120 pictures, consisting of series of five pictures drawn from each of 24 semantic categories (and intermixed with 45 fillers). The number of intervening trials (lag) between successive presentations of members of the same category varied from two to eight. Subjects' naming latencies were slowed by 30ms for each preceding member of the category. This effect was both cumulative and linear, and unrelated to the lag elapsing since the previous presentation of a category member. These results definitively demonstrate the occurrence of cumulative interference for word retrieval by prior retrieval of other exemplars of the same semantic category—cumulative semantic inhibition. We claim that this inhibition effect could only occur if the spoken word production system possesses three specific properties (competition, priming, and sharing of semantic activation). We provide computational-modelling evidence in support of this claim. We show that no current theory of spoken word production has all of these properties. In their current form, all these theories are falsified by these results. We briefly discuss the obstacles that may be encountered by current models were they modified to account for our findings.}
}
@article{HSU2011380,
title = {The probabilistic analysis of language acquisition: Theoretical, computational, and experimental analysis},
journal = {Cognition},
volume = {120},
number = {3},
pages = {380-390},
year = {2011},
note = {Probabilistic models of cognitive development},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2011.02.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010027711000734},
author = {Anne S. Hsu and Nick Chater and Paul M.B. Vitányi},
keywords = {Child language acquisition, Poverty of the stimulus, No negative evidence, Bayesian models, Minimum description length, Simplicity principle, Natural language, Probabilistic models, Identification in the limit},
abstract = {There is much debate over the degree to which language learning is governed by innate language-specific biases, or acquired through cognition-general principles. Here we examine the probabilistic language acquisition hypothesis on three levels: We outline a novel theoretical result showing that it is possible to learn the exact generative model underlying a wide class of languages, purely from observing samples of the language. We then describe a recently proposed practical framework, which quantifies natural language learnability, allowing specific learnability predictions to be made for the first time. In previous work, this framework was used to make learnability predictions for a wide variety of linguistic constructions, for which learnability has been much debated. Here, we present a new experiment which tests these learnability predictions. We find that our experimental results support the possibility that these linguistic constructions are acquired probabilistically from cognition-general principles.}
}
@article{CUMMINGS2003369,
title = {Computational challenges in high angle of attack flow prediction},
journal = {Progress in Aerospace Sciences},
volume = {39},
number = {5},
pages = {369-384},
year = {2003},
issn = {0376-0421},
doi = {https://doi.org/10.1016/S0376-0421(03)00041-1},
url = {https://www.sciencedirect.com/science/article/pii/S0376042103000411},
author = {Russell M. Cummings and James R. Forsythe and Scott A. Morton and Kyle D. Squires},
abstract = {Aircraft aerodynamics have been predicted using computational fluid dynamics for a number of years. While viscous flow computations for cruise conditions have become commonplace, the non-linear effects that take place at high angles of attack are much more difficult to predict. A variety of difficulties arise when performing these computations, including challenges in properly modeling turbulence and transition for vortical and massively separated flows, the need to use appropriate numerical algorithms if flow asymmetry is possible, and the difficulties in creating grids that allow for accurate simulation of the flowfield. These issues are addressed and recommendations are made for further improvements in high angle of attack flow prediction. Current predictive capabilities for high angle of attack flows are reviewed, and solutions based on hybrid turbulence models are presented.}
}
@incollection{1991344,
title = {Appendix A - Scientific chaos: a new way of thinking about dynamics},
editor = {Ralph D. Stacey},
booktitle = {The Chaos Frontier},
publisher = {Butterworth-Heinemann},
pages = {344-365},
year = {1991},
isbn = {978-0-7506-0139-9},
doi = {https://doi.org/10.1016/B978-0-7506-0139-9.50021-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780750601399500212}
}
@article{GRETREGAMEY2024104978,
title = {Key factors to enhance efficacy of 3D digital environments for transformative landscape and urban planning},
journal = {Landscape and Urban Planning},
volume = {244},
pages = {104978},
year = {2024},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2023.104978},
url = {https://www.sciencedirect.com/science/article/pii/S0169204623002979},
author = {Adrienne Grêt-Regamey and Nora Fagerholm},
abstract = {The unprecedented expansion of digital technologies has led to a rapid increase in the development and application of 3D digital environments for landscape and urban planning in the past two decades. Considering the significant challenges in guiding human societies towards sustainability, these technologies must not only assist decision-makers in adapting to changes but promote fast, transformative shifts in the relationship between human societies and nature. Based on a set of global exemplars, this Perspective Essay outlines six key factors that can enhance efficacy of 3D digital environments to guide knowledge-informed landscape and urban planning. We call for (1) explicitly representing dynamic interplay between the social, ecological, and technical systems, (2) exploring the integration of design with simulation models to address cross-scale dynamics, (3) developing features to foster imagination, (4) employing multisensory stimuli to encourage profound changes in environmentally and socially sustainable behavior, (5) tailoring the incorporation of active sensing by and with non-experts into 3D digital environments to better acknowledge indigenous and local knowledge systems, and finally, (6) carrying out a usability evaluation to facilitate participation and collaboration in an efficient co-creation process. We conclude by recommending the establishment of a collaborative knowledge platform that unites researchers, developers, and stakeholders for stimulating social-ecological-technological system thinking in the development of 3D digital environments and harnessing the technological advancements to accelerate and drive the needed transformative change within urban and landscape planning.}
}
@article{TAGHIKHAH2022101854,
title = {Machine-assisted agent-based modeling: Opening the black box},
journal = {Journal of Computational Science},
volume = {64},
pages = {101854},
year = {2022},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2022.101854},
url = {https://www.sciencedirect.com/science/article/pii/S1877750322002137},
author = {Firouzeh Taghikhah and Alexey Voinov and Tatiana Filatova and J. Gareth Polhill},
keywords = {Behavioral analytics, Social communications, Interpretable artificial intelligence, Conceptual modeling, Systems thinking},
abstract = {While agent-based modeling (ABM) has become one of the most powerful tools in quantitative social sciences, it remains difficult to explain their structure and performance. We propose to use artificial intelligence both to build the models from data, and to improve the way we communicate models to stakeholders. Although machine learning is actively employed for pre-processing data, here for the first time, we used it to facilitate model development of a simulation model directly from data. Our suggested framework, ML-ABM accounts for causality and feedback loops in a complex nonlinear system and at the same time keeps it transparent for stakeholders. As a result, beside the development of a behavioral ABM, we open the ‘blackbox’ of purely empirical models. With our approach, artificial intelligence in the simulation field can open a new stream in modeling practices and provide insights for future applications.}
}
@article{KADUWELA2024105337,
title = {Application of a human-centered design for embedded machine learning model to develop data labeling software with nurses: Human-to-Artificial Intelligence (H2AI)},
journal = {International Journal of Medical Informatics},
volume = {183},
pages = {105337},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105337},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623003556},
author = {Naomi A. Kaduwela and Susan Horner and Priyansh Dadar and Renee C.B. Manworren},
keywords = {Clinical decision support software, Data labeling, Human-centered Design for Embedded Machine Learning Solutions Machine Learning, Machine learning models},
abstract = {Background
Nurses are essential for assessing and managing acute pain in hospitalized patients, especially those who are unable to self-report pain. Given their role and subject matter expertise (SME), nurses are also essential for the design and development of a supervised machine learning (ML) model for pain detection and clinical decision support software (CDSS) in a pain recognition automated monitoring system (PRAMS). Our first step for developing PRAMS with nurses was to create SME-friendly data labeling software.
Purpose
To develop an intuitive and efficient data labeling software solution, Human-to-Artificial Intelligence (H2AI).
Method
The Human-centered Design for Embedded Machine Learning Solutions (HCDe-MLS) model was used to engage nurses. In this paper, HCDe-MLS will be explained using H2AI and PRAMS as illustrative cases.
Findings
Using HCDe-MLS, H2AI was developed and facilitated labeling of 139 videos (mean = 29.83 min) with 3189 images labeled (mean = 75 s) by 6 nurses. OpenCV was used for video-to-image pre-processing; and MobileFaceNet was used for default landmark placement on images. H2AI randomly assigned videos to nurses for data labeling, tracked labelers’ inter-rater reliability, and stored labeled data to train ML models.
Conclusions
Nurses’ engagement in CDSS development was critical for ensuring the end-product addressed nurses’ priorities, reflected nurses’ cognitive and decision-making processes, and garnered nurses’ trust for technology adoption.}
}
@article{GOLDBACH2016249,
title = {Computational Cutting Pattern Generation Using Isogeometric B-Rep Analysis},
journal = {Procedia Engineering},
volume = {155},
pages = {249-255},
year = {2016},
note = {TENSINET – COST TU1303 International Symposium 2016 "Novel structural skins - Improving sustainability and efficiency through new structural textile materials and designs"},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2016.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S1877705816321671},
author = {Ann-Kathrin Goldbach and Michael Breitenberger and Armin Widhammer and Kai-Uwe Bletzinger},
keywords = {Cutting pattern generation, Variation of Reference Strategy, Isogeometric Analysis, Isogeometric B-Rep Analysis, Design cycle of structural membranes},
abstract = {The cutting pattern plays a major role for the design of structural membranes, since it influences both their aesthetical appearance and structural behavior. A novel approach towards cutting pattern generation is the so-called Variation of Reference Strategy (VaReS) [1], which minimizes the total potential energy arising from the motion of a planar cutting pattern to its corresponding three-dimensional shape. With non-uniform rational B-Splines (NURBS) being the standard tool for geometry description in CAD, it is only consequent to use these for analysis as well. Isogeometric B-Rep Analysis (IBRA) [2] follows up on this idea and enriches the original Isogeometric Analysis (IGA), which was introduced by Hughes et al. [3], by the possibility of analysing trimmed NURBS geometries. This paper presents cutting pattern generation with the Variation of Reference Strategy in the context of IGA/IBRA. With this approach, the whole design of a membrane structure can be represented by NURBS geometries – including blueprint plans. To use the benefits of IBRA for cutting pattern generation, a NURBS-based membrane-element was developed for the VaReS routine. A developable surface serves as a benchmark example, since its analytical cutting pattern is known. Examples of double-curved geometries show the applicability and benefits of the proposed procedure for real structures.}
}
@article{SILVEIRA1980165,
title = {Generic masculine words and thinking},
journal = {Women's Studies International Quarterly},
volume = {3},
number = {2},
pages = {165-178},
year = {1980},
note = {The voices and words of women and men},
issn = {0148-0685},
doi = {https://doi.org/10.1016/S0148-0685(80)92113-2},
url = {https://www.sciencedirect.com/science/article/pii/S0148068580921132},
author = {Jeanette Silveira},
abstract = {Synopsis
It has been alleged that, in appropriate verbal contexts, man and he are generic, i.e. that the words include women as well as men, as for example in, Man is mortal, or One must watch his language. Many feminists argue for the elimination of this generic use of man and he and the substitution of such non-male words as people and they. Others argue on various grounds that these changes are unnecessary. This paper isolates the issues involved in such arguments and provisionally concludes that a reduction in the generic use of man and he would result in a long term reduction in sexist thinking. Recent feminist research on man and he is carefully reviewed. In its final section, the paper develops the implication that women experience more alienation than men in the presence of the generic man and he.}
}
@article{REICHLE20062,
title = {Computational models of eye-movement control during reading: Theories of the “eye–mind” link},
journal = {Cognitive Systems Research},
volume = {7},
number = {1},
pages = {2-3},
year = {2006},
note = {Models of Eye-Movement Control in Reading},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2005.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041705000227},
author = {Erik D. Reichle}
}
@article{KOOLSCHIJN2024101453,
title = {Resources, costs and long-term value: an integrative perspective on serotonin and meta-decision making},
journal = {Current Opinion in Behavioral Sciences},
volume = {60},
pages = {101453},
year = {2024},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2024.101453},
url = {https://www.sciencedirect.com/science/article/pii/S2352154624001049},
author = {Renée S Koolschijn and Bertalan Polner and Julie M Hoomans and Roshan Cools and Eliana Vassena and Hanneke EM {den Ouden}},
abstract = {Serotonin has been associated with a wide range of neural computations and behaviours, yet an overarching function of this neurotransmitter has been hard to pinpoint. Here, we combine recent theories and findings on serotonin and propose a framework where serotonin integrates information on resource availability and state value to represent a cost–benefit trade-off at the neural level. Critically, this framework supports meta-decision making, that is, the flexible allocation of resources to decision-making. We highlight a computational and neural implementation of this framework, and through this novel, lens interpret empirical findings in the domains of controllability and persistence.}
}
@incollection{MYUNG20012453,
title = {Computational Approaches to Model Evaluation},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2453-2457},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/00589-1},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767005891},
author = {I.J. Myung},
abstract = {The induction problem of inferring a predictive function (i.e., model) from finite data is a central component of the scientific enterprise in cognitive science, computer science and statistics, and yet the problem is fundamentally ill posed. Many models can often provide equally good fits to a given observed data set but they may differ considerably in their ability to generalize to new, as yet unseen, data sets generated from the same underlying process. To make this inductive inference problem well posed one needs to define a justifiable measure of generalizability and then use the measure to choose among a set of competing models. Many such measures have been proposed in the past, notably by scientists in the fields of machine learning and algorithmic coding theory. A representative list of such approaches includes the structural risk minimization method and Vapnik-Chervonenkis dimension, the regularization theory, and the minimum description length principle. This article presents a review of these computational approaches to model evaluation. Also discussed are the interesting connections between the computational approaches and some of the statistical approaches to model evaluation such as the Akaike information criterion, the Bayesian information criterion and Bayesian model selection.}
}
@article{ANANTHASWAMY201742,
title = {That's a termite colony between your ears},
journal = {New Scientist},
volume = {233},
number = {3112},
pages = {42-43},
year = {2017},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(17)30275-0},
url = {https://www.sciencedirect.com/science/article/pii/S0262407917302750},
author = {Anil Ananthaswamy},
abstract = {After wrestling with the nature of the mind for over half a century, Daniel Dennett uploads his latest thinking on consciousness, word-based “mind viruses” and why we must doubt the power of artificial intelligence}
}
@article{JONES20171,
title = {Diversity not quantity in caregiver speech: Using computational modeling to isolate the effects of the quantity and the diversity of the input on vocabulary growth},
journal = {Cognitive Psychology},
volume = {98},
pages = {1-21},
year = {2017},
issn = {0010-0285},
doi = {https://doi.org/10.1016/j.cogpsych.2017.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0010028516302274},
author = {Gary Jones and Caroline F. Rowland},
keywords = {Input quantity, Lexical diversity, Vocabulary acquisition, CLASSIC, Language acquisition},
abstract = {Children who hear large amounts of diverse speech learn language more quickly than children who do not. However, high correlations between the amount and the diversity of the input in speech samples makes it difficult to isolate the influence of each. We overcame this problem by controlling the input to a computational model so that amount of exposure to linguistic input (quantity) and the quality of that input (lexical diversity) were independently manipulated. Sublexical, lexical, and multi-word knowledge were charted across development (Study 1), showing that while input quantity may be important early in learning, lexical diversity is ultimately more crucial, a prediction confirmed against children’s data (Study 2). The model trained on a lexically diverse input also performed better on nonword repetition and sentence recall tests (Study 3) and was quicker to learn new words over time (Study 4). A language input that is rich in lexical diversity outperforms equivalent richness in quantity for learned sublexical and lexical knowledge, for well-established language tests, and for acquiring words that have never been encountered before.}
}
@article{RIETMAN2003249,
title = {Analog computation with rings of quasiperiodic oscillators: the microdynamics of cognition in living machines},
journal = {Robotics and Autonomous Systems},
volume = {45},
number = {3},
pages = {249-263},
year = {2003},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2003.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0921889003001520},
author = {Edward A. Rietman and Mark W. Tilden and Manor Askenazi},
keywords = {Quasiperiodic oscillators, Microdynamics, Schmitt trigger},
abstract = {We describe experimental results to demonstrate the wide-ranging computational ability of quasiperiodic oscillators built from rings of differentiating Schmitt triggers. We describe a theoretical model based on necklace functions to compute the number of states supportable by a ring circuit of a given size. Experimental results are presented to demonstrate that probabilistic state machines can be built from these ring circuits. Other experimental results are given to demonstrate that the rings can model spiking neural network circuits.}
}
@article{TRINDADE2025101104,
title = {Teaching mathematical concepts in management with generative artificial intelligence: The power of human oversight in AI-driven learning},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101104},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101104},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001757},
author = {Maria A.M. Trindade and Gihan S. Edirisinghe and Lan Luo},
keywords = {Generative artificial intelligence in education, Generative AI-Driven learning, Mathematics in management education, Operations management, Economic order quantity, Generative AI in management education},
abstract = {This study demonstrates a successful use of Generative Artificial Intelligence (AI) in teaching mathematical material to management students. We herein introduce the EOQ World Tour game, which substantially improves understanding of inventory-related concepts and long-term knowledge retention compared with traditional methods. Generative AI is revolutionizing management education, by offering innovative methods for teaching and learning. The integration of AI into quantitative business disciplines through novel learning mechanisms provides significant benefits, including enhanced data analysis, improved decision-making models, and sophisticated simulations for hands-on experience. This study introduces the EOQ World Tour game, specifically designed to teach the Economic Order Quantity concept in Operations Management. The game addresses challenges in integrating Generative AI into mathematics in management education by combining human oversight and instructor control through three innovative features: (1) a Generative AI-based simulation, (2) a macropowered Excel worksheet for validating the calculations of an AI chatbot, and (3) a Google Sheets dashboard for centralizing team-generated AI data for postgame analysis. Our study included 41 students divided into experimental and control groups. Pretest results indicated no significant differences in baseline knowledge. However, the post-test results showed that the experimental group achieved a better understanding of inventory-related concepts and practical applications, along with higher engagement, excitement, confidence, and long-term knowledge retention.}
}
@incollection{2016295,
title = {10 - Computational fluid dynamics in aerospace field and CFD-based multidisciplinary simulations},
editor = {Qun Zhang and Song Cen},
booktitle = {Multiphysics Modeling},
publisher = {Academic Press},
address = {Oxford},
pages = {295-328},
year = {2016},
series = {Elsevier and Tsinghua University Press Computational Mechanics Series},
isbn = {978-0-12-407709-6},
doi = {https://doi.org/10.1016/B978-0-12-407709-6.00010-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780124077096000109},
keywords = {aerospace engineering, finite volume method, ALE formulation, discrete geometric conservation law, mesh deformation, remeshing, flapping wing, store separation, wing flutter},
abstract = {In this chapter, the ALE formulation of the finite volume method is proposed for the simulation of compressible fluid flow. Two major topics of the discrete geometric conservation lawgeometric conservation law and mesh deformationmesh deformation algorithm in this chapter are to handle the moving boundary problem accurately and efficiently. Three examples are given to verify the effectiveness of the presented methods in multiphysics simulation for aerospace engineering problems.}
}
@article{CORREABAENA20181410,
title = {Accelerating Materials Development via Automation, Machine Learning, and High-Performance Computing},
journal = {Joule},
volume = {2},
number = {8},
pages = {1410-1420},
year = {2018},
issn = {2542-4351},
doi = {https://doi.org/10.1016/j.joule.2018.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S2542435118302289},
author = {Juan-Pablo Correa-Baena and Kedar Hippalgaonkar and Jeroen {van Duren} and Shaffiq Jaffer and Vijay R. Chandrasekhar and Vladan Stevanovic and Cyrus Wadia and Supratik Guha and Tonio Buonassisi},
keywords = {accelerated materials development, machine learning, artificial intelligence, energy materials},
abstract = {Successful materials innovations can transform society. However, materials research often involves long timelines and low success probabilities, dissuading investors who have expectations of shorter times from bench to business. A combination of emergent technologies could accelerate the pace of novel materials development by ten times or more, aligning the timelines of stakeholders (investors and researchers), markets, and the environment, while increasing return on investment. First, tool automation enables rapid experimental testing of candidate materials. Second, high-performance computing concentrates experimental bandwidth on promising compounds by predicting and inferring bulk, interface, and defect-related properties. Third, machine learning connects the former two, where experimental outputs automatically refine theory and help define next experiments. We describe state-of-the-art attempts to realize this vision and identify resource gaps. We posit that over the coming decade, this combination of tools will transform the way we perform materials research, with considerable first-mover advantages at stake.}
}
@article{PEZZULO2011275,
title = {Computational explorations of perceptual symbol systems theory},
journal = {New Ideas in Psychology},
volume = {29},
number = {3},
pages = {275-297},
year = {2011},
note = {Special Issue: Cognitive Robotics and Reevaluation of Piaget Concept of Egocentrism},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2009.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X09000336},
author = {Giovanni Pezzulo and Gianguglielmo Calvi},
keywords = {Perceptual symbol systems, Schemas, Embodiment, Anticipation, Simulation},
abstract = {The aim of this paper is twofold. First, we provide a methodological pathway from theories of situated, embodied cognition to simulations with an eye to empirical evidence, and suggest a possible cross-fertilization between cognitive robotics and psychology. Psychological theories, in particular those formulated at an abstract level, include models which are often severely underspecified at the level of mechanisms. This is true in the synchronic, constructive perspective (how can the effects observed in experiments be concretely generated by the model's mechanisms?) and in the diachronic, developmental perspective (how can such mechanisms be learned and developed?). The synthetic method of artificial cognitive systems research, and in particular of cognitive robotics, can complement research in psychology (and neurosciences) by exploring the constructive and developmental aspects of theories. Our second aim is to provide an example of such a methodology by describing simulations aiming at developing a perceptual symbol system (PSS) (Barsalou, 1999). We then describe the two main theoretical constructs of the PSS, perceptual symbols and simulators, illustrate their development in an artificial system, and test the system in prediction, categorization, and abstraction tasks.}
}
@article{2004263,
title = {Computational Statistics and Data Analysis},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {73},
number = {2},
pages = {263},
year = {2004},
issn = {0169-7439},
doi = {https://doi.org/10.1016/j.chemolab.2004.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169743904001820}
}
@article{JIANG2023119343,
title = {Film cooling comparison of shaped holes among the pressure surface, the suction surface and the leading edge of turbine vane},
journal = {Applied Thermal Engineering},
volume = {219},
pages = {119343},
year = {2023},
issn = {1359-4311},
doi = {https://doi.org/10.1016/j.applthermaleng.2022.119343},
url = {https://www.sciencedirect.com/science/article/pii/S135943112201273X},
author = {Yan Jiang and Haiwang Li and Runzhou Liu and Zhi Tao and Zhiyu Zhou},
keywords = {Film cooling, NHFR, Shaped holes, Turbine guide vane},
abstract = {The present study employed commercial computational fluid dynamics software ANSYS 2019R3 to explore the adiabatic film cooling effectiveness and the net heat flux reduction (NHFR) for the comparison of the five selected shaped holes and conventional cylindrical holes between the pressure surface, the suction surface and the leading edge. Amo4ng the shape parameters of shaped holes, the lateral divergence angle (β) and the forward divergence angle (δ) were fixed as 12° and 7° in all shaped holes structures, respectively. The others varied with different regions of the turbine vane. Results showed that different holes fit different positions of vanes. On the suction surface, laidback holes performed the worst net heat flux reduction in most blowing ratios conditions, which indicated the forward divergence angle was not conducive to the flow field and heat transfer characteristics on the suction surface. Whereas, the lateral divergence angle was beneficial to the film cooling and heat transfer characteristics. Laidback fan-shaped holes performed the best adiabatic film cooling effectiveness, but once simultaneously thinking about the heat transfer, fan-shaped holes performed better in net heat flux reduction due to less vortices at holes exit. On the leading edge, the divergence angle towards the upper wall (the lateral divergence angle of spanwise expansion holes) of vanes was not conducive to steady flow. And conical holes performed best, which indicated that coolant from holes with axial divergence angles (the lateral divergence angle in axial direction of conical holes) under the influence of mainstream impact could perform higher film cooling effectiveness and more stable flow fields. On the pressure surface, holes had a lateral divergence angle in the direction of vane height, which was conducive to increasing the coolant coverage area and improving the ability to attach to the pressure surface. Additionally, the laidback hole case was observed the lowest net heat flux reduction when the blowing ratio was less than 2, which revealed that holes that expanded only in flow direction was not conducive to film cooling and heat transfer characteristics.}
}