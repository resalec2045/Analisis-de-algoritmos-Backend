@article{SUPPES2004457,
title = {Semantic computations of truth based on associations already learned},
journal = {Journal of Applied Logic},
volume = {2},
number = {4},
pages = {457-467},
year = {2004},
note = {CMSRA},
issn = {1570-8683},
doi = {https://doi.org/10.1016/j.jal.2004.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1570868304000461},
author = {Patrick Suppes and Jean-Yves Béziau},
keywords = {Truth, Computaton, Empirical statements, Associative networks, Spreading activation},
abstract = {This article sets forth a detailed theoretical proposal of how the truth of ordinary empirical statements, often atomic in form, is computed. The method of computation draws on psychological concepts such as those of associative networks and spreading activation, rather that the concepts of philosophical or logical theories of truth. Axioms for a restricted class of cases are given, as well as some detailed examples.}
}
@incollection{CLEEREMANS200581,
title = {Computational correlates of consciousness},
editor = {Steven Laureys},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {150},
pages = {81-98},
year = {2005},
booktitle = {The Boundaries of Consciousness: Neurobiology and Neuropathology},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(05)50007-4},
url = {https://www.sciencedirect.com/science/article/pii/S0079612305500074},
author = {Axel Cleeremans},
abstract = {Over the past few years numerous proposals have appeared that attempt to characterize consciousness in terms of what could be called its computational correlates: Principles of information processing with which to characterize the differences between conscious and unconscious processing. Proposed computational correlates include architectural specialization (such as the involvement of specific regions of the brain in conscious processing), properties of representations (such as their stability in time or their strength), and properties of specific processes (such as resonance, synchrony, interactivity, or information integration). In exactly the same way as one can engage in a search for the neural correlates of consciousness, one can thus search for the computational correlates of consciousness. The most direct way of doing is to contrast models of conscious versus unconscious information processing. In this paper, I review these developments and illustrate how computational modeling of specific cognitive processes can be useful in exploring and in formulating putative computational principles through which to capture the differences between conscious and unconscious cognition. What can be gained from such approaches to the problem of consciousness is an understanding of the function it plays in information processing and of the mechanisms that subtend it. Here, I suggest that the central function of consciousness is to make it possible for cognitive agents to exert flexible, adaptive control over behavior. From this perspective, consciousness is best characterized as involving (1) a graded continuum defined over quality of representation, such that availability to consciousness and to cognitive control correlates with properties of representation, and (2) the implication of systems of meta-representations.}
}
@article{BOELSENROBINSON2021102032,
title = {Mapping factors associated with a successful shift towards healthier food retail in community-based organisations: A systems approach},
journal = {Food Policy},
volume = {101},
pages = {102032},
year = {2021},
issn = {0306-9192},
doi = {https://doi.org/10.1016/j.foodpol.2021.102032},
url = {https://www.sciencedirect.com/science/article/pii/S0306919221000105},
author = {Tara Boelsen-Robinson and Miranda R. Blake and Andrew D. Brown and Oliver Huse and Claire Palermo and Neetu A. George and Anna Peeters},
keywords = {Food retail, Systems mapping, Intervention, Community, Implementation, START map, Nutrition, Policy, Qualitative, Interviews},
abstract = {Background
Food retailers in community settings are gatekeepers to the crucial food systems changes needed to improve population nutrition. Evidence-based models of change are needed to enable shifts in these complex retail environments. Systems thinking offers unique insights by capturing potential unintended consequences and multiple pathways to success. This study sought to create a systems map for retailers, public health practitioners and other stakeholders seeking to implement healthy food retail policies. It aimed to identify (i) points of intervention through which community-based organisations can shift to healthier food provision, and (ii) key feedback loops that could drive potential unintended consequences of such policies in a complex system.
Methods
Semi-structured interviews (n = 26) were conducted, from 2015 to 2018, across four community food retail settings where healthy food retail policies had been implemented in Victoria, Australia. Interviews were coded by identifying causal relationships and their direction between factors. Vensim software was used to merge interview results and then reduce the map to the strongest and most frequent factors and relationships. Illustrative implementation stories and points of intervention were identified.
Findings
The resulting map is titled the Systems Thinking Approach for Retail Transformation (START) map. Five prominent implementation stories incorporating 17 factors highlighted that: 1) retailer resistance to change is strongest in the beginning but decreases with the demonstration of favourable initiative outcomes; 2) successive changes tend to be increasingly complex, and therefore harder for retailers to implement; 3) organisational resourcing can be influenced through multiple pathways; 4) customer acceptability of healthy changes and retailers' willingness to engage in changes influence each other; and 5) challenges in accessing healthy supply options make retailers more resistant to implementing healthy changes.
Conclusions
The application of systems thinking to the challenge of unhealthy food retail creates novel and practical insights for retailers and health promotion practitioners into what actions are most likely to promote healthy changes in complex retail environments.}
}
@article{WANG20098093,
title = {A computational narrative construction method with applications in organizational learning of social service organizations},
journal = {Expert Systems with Applications},
volume = {36},
number = {4},
pages = {8093-8102},
year = {2009},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2008.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S0957417408007495},
author = {W.M. Wang and C.F. Cheung and W.B. Lee and S.K. Kwok},
keywords = {Narrative construction, Knowledge management, Concept mapping, Knowledge-based systems, Computational, Reflective learning, Narrative simulation},
abstract = {Acquisition of knowledge must be interwoven with the process of applying it. However, traditional training methods which provide abstract knowledge have shown ineffective for gaining experience of the work. In order to solve this problem, more and more researchers have included narrative in simulation, which is known as narrative simulation. By providing the narratives, participants recognize the choices, decisions, and experience that lead to the consequences of those decisions. It has been proven that narrative simulation is very useful in facilitating in-depth learning and reflective learning. However, conventional methods of data collection and narrative construction for narrative simulation are labor intensive and time consuming. They make use of previous narratives manually and directly. They are inadequate to cope with the fast moving world where knowledge is changing rapidly. In order to provide a way for facilitating the construction of narrative simulation, a novel computational narrative construction method is proposed. By incorporating technologies of knowledge-based system (KBS), computational linguistics, and artificial intelligence (AI), the proposed method provides an efficient and effective way for collecting narratives and automating the construction of narratives. The method converts the unstructured narratives into a structural representation for abstraction and facilitating computing processing. Moreover, it constructs the narratives that combine multiple narratives into a single narrative by applying a forecasting algorithm. The proposed method was successfully implemented in early intervention in mental health care of a social service company in Hong Kong since the case records in that process have structural similarities to narrative. The accuracies of data conversion and predictive function were measured based on recall and precision and encouraging results were obtained. High recall and precision are achieved in the data conversion function, and high recall for the predictive function when new concepts are excluded. The results show that it is possible for converting multiple narratives into a single narrative automatically. Based on the approach, it helps to stimulate knowledge workers to explore new problem solving methods so as to increase the quality of their solutions.}
}
@article{SKOWRON20115939,
title = {Information systems in modeling interactive computations on granules},
journal = {Theoretical Computer Science},
volume = {412},
number = {42},
pages = {5939-5959},
year = {2011},
note = {Rough Sets and Fuzzy Sets in Natural Computing},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2011.05.045},
url = {https://www.sciencedirect.com/science/article/pii/S0304397511004634},
author = {Andrzej Skowron and Piotr Wasilewski},
keywords = {Interactive computing, Interactive systems, Multi-agent systems, Rough sets, Granular computing, Wisdom technology},
abstract = {In this paper, we discuss the importance of information systems in modeling interactive computations performed on (complex) granules and we propose a formal approach to interactive computations based on generalized information systems and rough sets which can be combined with other soft computing paradigms such as fuzzy sets or evolutionary computing, but also with machine learning and data mining techniques. Information systems are treated as dynamic granules used for representing the results of the interaction of attributes with the environment. Two kinds of attributes are distinguished, namely, the perception attributes, including sensory attributes, and the action attributes. Sensory attributes are the basic perception attributes, other perception attributes are constructed on the basis of the sensory ones. Actions are activated when their guards, being often complex and vague concepts, are satisfied to a satisfactory degree. The guards can be approximated on the basis of measurements performed by sensory attributes rather than defined exactly. Satisfiability degrees for guards are results of reasoning called the adaptive judgment. The approximations are induced using hierarchical modeling. We show that information systems can be used for modeling more advanced forms of interactions in hierarchical modeling. The role of hierarchical interactions is emphasized in the modeling of interactive computations. Some illustrative examples of interactions used in the ACT-R 6.0 system are reported. ACT-R 6.0 is based on a cognitive architecture and can be treated as an example of a highly interactive complex granule which can be involved in hierarchical interactions. For modeling of interactive computations, we propose much more general information systems than the studied dynamic information systems (see, e.g., Ciucci (2010) [8] and Pałasiński and Pancerz (2010) [32]). For example, the dynamic information systems are making it possible to consider incremental changes in information systems. However, they do not contain the perception and action attributes necessary for modeling interactive computations, in particular for modeling intrastep interactions.}
}
@incollection{HOLCOMBE2005407,
title = {30 Computational modelling of creativity in abstract art},
editor = {Grant Malcolm},
series = {Studies in Multidisciplinarity},
publisher = {Elsevier},
volume = {2},
pages = {407-424},
year = {2005},
booktitle = {Multidisciplinary Approaches to Visual Representations and Interpretations},
issn = {1571-0831},
doi = {https://doi.org/10.1016/S1571-0831(04)80058-3},
url = {https://www.sciencedirect.com/science/article/pii/S1571083104800583},
author = {Mike Holcombe and Samantha Smith and Rowan Merewood and Andy Swingeford},
abstract = {Artistic creativity is studied through the construction of computational models of a number of well-known modern artists. In particular, the work of Piet Mondrian, M.C. Escher and Paul Klee are suitable vehicles for investigation since their work is accompanied by extensive writings describing the ideas and motivation behind their compositions. In particular, we have tried to abstract from their theories, rules that describe the construction process or the properties that their finished artefacts posses in order to create software programs that can articulate these rules. In this way, we are able to simulate either automatically or with user interaction, the process of creating works of art of a similar genre and satisfying the properties desired by the artist. Since the rules are bound to be considerably more complex than those currently exposed, we are looking to use machine-learning techniques to develop more sophisticated agents, which may behave more closely like the actual artist.}
}
@article{LIN2025102895,
title = {Integrating generative AI into digital multimodal composition: A study of multicultural second-language classrooms},
journal = {Computers and Composition},
volume = {75},
pages = {102895},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102895},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000719},
author = {Chin-Hsi Lin and Keyi Zhou and Lanqing Li and Lanfang Sun},
keywords = {Generative AI, Multimodal composing, Multicultural education},
abstract = {This study examines the integration of generative AI tools into digital multimodal composition (DMC) within a multicultural context, examining their impact on students’ motivation, writing processes, and outcomes. Eleven culturally diverse students from two high schools in Hong Kong participated in the study. The study developed and employed a novel pedagogical framework, IDEA (Interpret, Design, Evaluate, and Articulate), to seamlessly incorporate generative AI into DMC practices. Data-collection methods included analysis of generative AI tool-usage history, classroom video observations, surveys, and interviews. The findings reveal that students leveraged generative AI’s capabilities across five key areas: content generation, feedback and revision, multilingual support, critical thinking, and visual representation. The integration of AI tools followed distinct stages in the composition process, resulting in enhancements to the vocabulary, grammar, and structural elements of students’ work. This research contributes to the growing body of knowledge on the intersection of generative AI, education, and multimodal literacy, with a particular emphasis on human-AI collaboration in multicultural settings. It also offers valuable insights for educators seeking to enhance students’ DMC skills through the thoughtful integration of generative AI tools, potentially increasing engagement, motivation, and creative expression among learners from diverse cultural backgrounds.}
}
@article{LIU2000261,
title = {Creativity or novelty?: Cognitive-computational versus social-cultural},
journal = {Design Studies},
volume = {21},
number = {3},
pages = {261-276},
year = {2000},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(99)00013-7},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X99000137},
author = {Yu-Tung Liu},
keywords = {creativity, design cognition, computer-aided design, problem-solving, artificial intelligence},
abstract = {This paper proposes a broader framework for understanding creativity by distinguishing different levels of creativity, namely personal and social-cultural creativity, and their interaction. Within this framework, the possible role that computer-aided design systems can play is discussed by analyzing the procedure of rule formation and the phenomena of seeing emergent subshapes.}
}
@article{AUSTIN2006544,
title = {Matrix and finite element stack machines for structural engineering computations with units},
journal = {Advances in Engineering Software},
volume = {37},
number = {8},
pages = {544-559},
year = {2006},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2005.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0965997805001833},
author = {Mark A. Austin},
keywords = {Stack machine, Matrix computations, Physical units, Scripting language design, Finite element analysis},
abstract = {Despite the well known benefits of physical units, matrices, and matrix algebra in engineering computations, most engineering analysis packages are essentially dimensionless. This paper describes the design and implementation of matrix and finite element stack machines for Aladdin, a new computational environment that embeds units inside matrix and finite element calculations. Functionality of the Aladdin stack machine is illustrated by working step by step through the setup and execution of three examples: (1) Parsing and stack machine execution for x=2in; (2) Deflection analysis of a cantilever beam, and (3) Rollup maneuver for a long cantilever beam.}
}
@article{ZHOU2022105384,
title = {Informed speculation with k-level reasoning},
journal = {Journal of Economic Theory},
volume = {200},
pages = {105384},
year = {2022},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2021.105384},
url = {https://www.sciencedirect.com/science/article/pii/S0022053121002015},
author = {Hang Zhou},
keywords = {Level- thinking, Investors' sophistication, Market instability},
abstract = {This paper investigates the effect of strategic reasoning on financial markets with a level-k thinking framework. A level-k speculator performs k rounds of iterative reasoning to infer information from asset prices. In contrast to the static rational expectations equilibrium, the level-k framework produces a unified theory of momentum and contrarian trading strategies. Besides, this paper discusses how the distribution of sophistication levels affects several market variables and it sheds new light on empirical patterns such as: (1) overreaction of asset prices, (2) the excess volatility puzzle, and (3) the excessive trading volume puzzle. Moreover, this paper explores whether the level-k strategy converges to the rational expectations equilibrium.}
}
@article{SNYDER2022100852,
title = {The role of heat resistance in yeast spoilage of thermally processed foods: highlighting the need for a probabilistic, systems-based approach to microbial quality},
journal = {Current Opinion in Food Science},
volume = {46},
pages = {100852},
year = {2022},
issn = {2214-7993},
doi = {https://doi.org/10.1016/j.cofs.2022.100852},
url = {https://www.sciencedirect.com/science/article/pii/S2214799322000546},
author = {Abigail B Snyder},
abstract = {The relationship between stress-tolerance mechanisms (cell-wall structure, metabolism, morphology, etc.) of individual fungi and the physiochemistry of their food environment selects for a small group of specific spoilage organisms (SSOs). However, common process deviations and post-processing contamination widen the lens of potentially relevant spoilage fungi. For example, although heat-resistant molds are considered the SSOs in thermally processed foods, unintended events (deviations, post-processing contamination) lead to spoilage by other propagules, notably yeast. The frequency of these unintended events changes our assessments of which spoilage fungi are relevant to a given food system. Consequently, a framework using probabilistic and systems-based thinking is needed to understand spoilage risk. Toward that goal, simple molecular tools for identification and subtyping are required.}
}
@article{EAMES2021100864,
title = {The finite-to-finite strand of a learning progression for the concept of function: A research synthesis and cognitive analysis},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100864},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100864},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000250},
author = {Cheryl L. Eames and Edith Aurora Graf and Peter W. {van Rijn} and Greg Budzban and Tammy Voepel},
keywords = {Learning progressions, Concept of function, Representation, Secondary students},
abstract = {In this paper we report validation efforts around the finite-to-finite strand of a provisional learning progression (LP) for the concept of function. We regard an LP as an empirically-verified account of how student understandings form over time and in response to instruction. The finite-to-finite strand of the LP was informed by literature on students’ thinking and learning related to functions as well as the Algebra Project’s curricular approach, which is designed for students who are traditionally underserved by mathematics education. Developing and validating an LP is a multi-step, cyclic process. Here we report on one step in this process, an item and response analysis. Data sources include 680 students’ responses to 13 multipart computer-delivered tasks. Results suggest that revisions to the items, associated scoring rubrics, and in some instances the LP are warranted. We illustrate this task, rubric, and LP revision process through an item analysis for a selected task.}
}
@article{MOSTAFA20118782,
title = {A neuro-computational intelligence analysis of the global consumer software piracy rates},
journal = {Expert Systems with Applications},
volume = {38},
number = {7},
pages = {8782-8803},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2011.01.090},
url = {https://www.sciencedirect.com/science/article/pii/S0957417411001102},
author = {Mohamed M. Mostafa},
keywords = {Global software piracy, Ethical behavior, Neural networks, Bayesian regression, Evolutionary computation models},
abstract = {Software piracy represents a major damage to the moral fabric associated with the respect of intellectual property. The rate of software piracy appears to be increasing globally, suggesting that additional research that uses new approaches is necessary to evaluate the problem. The study remedies previous econometric and methodological shortcomings by applying Bayesian, robust and evolutionary computation robust regression algorithms to formally test empirical literature on software piracy. To gain further insights into software piracy at the global level, the study also uses five neuro-computational intelligence methodologies: multi-layer perceptron neural network (MLP), probabilistic neural network (PNN), radial basis function neural network (RBF), generalized regression neural network (GRNN) and Kohonen’s self-organizing maps (SOM) to classify, predict and cluster software piracy rates among 102 nations. At the empirical level, this research shows that software piracy is significantly affected by the wealth of nation as measured by gross domestic product (GDP), the nation’s expenditure on research and development and the nation’s judicial efficiency. At the methodological level, this research shows that neuro-computational models outperform traditional statistical techniques such as regression analysis, discriminant analysis and cluster analysis in predicting, classifying and clustering software piracy rates due to their robustness and flexibility of modeling algorithms.}
}
@article{TSAI202371,
title = {Exploring the use of large language models (LLMs) in chemical engineering education: Building core course problem models with Chat-GPT},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {71-95},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000180},
author = {Meng-Lin Tsai and Chong Wei Ong and Cheng-Liang Chen},
keywords = {Engineering education, Industry 4.0 skill, Programming in chemical engineering, Problem-solving, Large language models (LLMs), Chat-GPT},
abstract = {This study highlights the potential benefits of integrating Large Language Models (LLMs) into chemical engineering education. In this study, Chat-GPT, a user-friendly LLM, is used as a problem-solving tool. Chemical engineering education has traditionally focused on fundamental knowledge in the classroom with limited opportunities for hands-on problem-solving. To address this issue, our study proposes an LLMs-assisted problem-solving procedure. This approach promotes critical thinking, enhances problem-solving abilities, and facilitates a deeper understanding of core subjects. Furthermore, incorporating programming into chemical engineering education prepares students with vital Industry 4.0 skills for contemporary industrial practices. During our experimental lecture, we introduced a simple example of building a model to calculate steam turbine cycle efficiency, and assigned projects to students for exploring the possible use of LLMs in solving various aspect of chemical engineering problems. Although it received mixed feedback from students, it was found to be an accessible and practical tool for improving problem-solving efficiency. Analyzing the student projects, we identified five common difficulties and misconceptions and provided helpful suggestions for overcoming them. Our course has limitations regarding using advanced tools and addressing complex problems. We further provide two additional examples to better demonstrate how to integrate LLMs into core courses. We emphasize the importance of universities, professors, and students actively embracing and utilizing LLMs as tools for chemical engineering education. Students must develop critical thinking skills and a thorough understanding of the principles behind LLMs, taking responsibility for their use and creations. This study provides valuable insights for enhancing chemical engineering education's learning experience and outcomes by integrating LLMs.}
}
@article{KLEIN2014437,
title = {Computation and Visualization of Patch Geometries for the Design of Carbon Fiber Reinforced Parts at Early Design Stages},
journal = {Procedia CIRP},
volume = {21},
pages = {437-442},
year = {2014},
note = {24th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2014.03.133},
url = {https://www.sciencedirect.com/science/article/pii/S2212827114006738},
author = {Daniel Klein and Kaja Scheler and Sandro Wartzack},
keywords = {Lightweight design, Early design stages, Endless fibre reinforced composites},
abstract = {The market for carbon fibers is forecast to experience a double-digit growth over the next years. The reason for this development can be found in the special characteristics of Carbon Fiber Reinforced Plastics (CFRP) like high stiffness and strength at very low weight which make this composite an ideal material for lightweight design. However, the design of parts made of CFRP is a tightrope walk between costs, mechanical characteristics and manufacturability for product developers. On the one hand, the mechanical properties are highly dependent on the ideal fiber orientation within the part and the unique material characteristics can only be exploited with a suitable fiber orientation, but on the other hand, the ideal fiber orientation is often not manufacturable or the required manufacturing technique is too expensive. Therefore, a novel algorithm to support product developers in finding a manufacturable fiber orientation or patch layout which is as close as possible to the ideal fiber orientation is introduced. This algorithm computes and highlights areas with constant fiber orientation (=cluster) based upon the ideal fiber alignment from the CAIO method. With the help of the visualization of the clusters, product developers can be supported in the decision for the best patch placement and geometry as well as in choosing the best manufacturing technique. It is important to point out that the algorithm is intended for endless fiber reinforced parts only.}
}
@article{LIU2019678,
title = {A review of the smart world},
journal = {Future Generation Computer Systems},
volume = {96},
pages = {678-691},
year = {2019},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17319532},
author = {Hong Liu and Huansheng Ning and Qitao Mu and Yumei Zheng and Jing Zeng and Laurence T. Yang and Runhe Huang and Jianhua Ma},
keywords = {Smart world, Ubiquitous computing, Ambient intelligence, Cyber–physical–social-thinking, Internet of Things},
abstract = {Smart world is an attractive prospect with comprehensive development of ubiquitous computing involving penetrative intelligence into ubiquitous things, including physical objects (e.g., wearable devices), cyber entities (e.g., cloud services), social people (e.g., social networking) and human thinking (e.g., brain cognition). This work systematically overviews related works in the field of the smart world, and explains prospects in emerging areas. The smart world evolutions are discussed through four progressive phases, and the representative projects are accordingly introduced. Meanwhile, smart world elements and the smart world driven applications are respectively analyzed in the contexts of cyber–physical–social-thinking hyperspace. Moreover, enabling technologies including ubiquitous intelligence, web intelligence, brain informatics, social computing, big data, and security and privacy are respectively discussed. Finally, perspectives referring to ubiquitous sensing, ubiquitous object modeling, smart services, and philosophical, ethical and legal issues, are presented for identifying trends and challenges in the smart world.}
}
@article{TESCH2001633,
title = {Applying optimal control theory for elements of quantum computation in molecular systems},
journal = {Chemical Physics Letters},
volume = {343},
number = {5},
pages = {633-641},
year = {2001},
issn = {0009-2614},
doi = {https://doi.org/10.1016/S0009-2614(01)00748-5},
url = {https://www.sciencedirect.com/science/article/pii/S0009261401007485},
author = {Carmen M. Tesch and Lukas Kurtz and Regina {de Vivie-Riedle}},
abstract = {Elements of quantum computation are implemented in a vibrationally excited molecule applying optimal control theory. The two different IR-active modes of acetylene are taken as a two-qubit-system. Optimal control theory is used to design laser pulses that allow transitions within each qubit separately. Calculations for initial state preparation and basic quantum gates are presented.}
}
@article{VELIZ2025115299,
title = {Modeling the interconnected drivers of power sector decarbonization in Chile},
journal = {Renewable and Sustainable Energy Reviews},
volume = {211},
pages = {115299},
year = {2025},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2024.115299},
url = {https://www.sciencedirect.com/science/article/pii/S1364032124010256},
author = {Karina D. Véliz and Jeffrey P. Walters and Carlos Fica and Carolina Busco},
keywords = {Decarbonization, Chile, Renewable energy, Systems thinking, Participatory modeling},
abstract = {This study sought to model the interconnected and multidimensional factors influencing the decarbonization of Chile's electricity sector. Factors were identified through a structured review of articles found in the Web of Science. Factor interactions were then characterized through a survey and participatory systems modeling workshop with stakeholders from various fields in the Chilean energy sector. The model emerging from the workshop was structurally analyzed to identify and evaluate system leverage points used to inform recommendations for future policy and practice. A key leverage point identified in this analysis underscores the importance of stakeholder awareness regarding the benefits of renewable energy projects, serving as a crucial catalyst towards decarbonization by fostering citizen support and driving the implementation of favorable public policies. Conversely, the model showed that public opposition to transmission line construction, stemming from health, environmental, and property value concerns, can potentially lead to project delays, increased costs, and challenges in modernizing electrical grids. These findings emphasize the need for public engagement and effective communication to prioritize decarbonization while balancing short-term impacts with long-term benefits. The systemic and process-oriented insights gained from the application of the participatory modeling approach presented in this study, highlight the value of utilizing systems thinking and modeling approaches to inform future decarbonization strategies on a global scale.}
}
@article{MYCKA2006103,
title = {Analog computation beyond the Turing limit},
journal = {Applied Mathematics and Computation},
volume = {178},
number = {1},
pages = {103-117},
year = {2006},
note = {Special Issue on Hypercomputation},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2005.09.074},
url = {https://www.sciencedirect.com/science/article/pii/S0096300305008386},
author = {Jerzy Mycka},
abstract = {The main purpose of this paper is quite uncontroversial. First, we recall some models of analog computations (including these allowed to perform Turing uncomputable tasks). Second, we support the suggestions that such hypercomputable capabilities of such systems can be explained by the use of infinite limits. Additionally, the inner restrictions of analog models of computations are indicated.}
}
@article{PAPAIOANNOU2021e07984,
title = {Complexity analysis of the brain activity in Autism Spectrum Disorder (ASD) and Attention Deficit Hyperactivity Disorder (ADHD) due to cognitive loads/demands induced by Aristotle's type of syllogism/reasoning. A Power Spectral Density and multiscale entropy (MSE) analysis},
journal = {Heliyon},
volume = {7},
number = {9},
pages = {e07984},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e07984},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021020879},
author = {Anastasia G. Papaioannou and Eva Kalantzi and Christos C. Papageorgiou and Kalliopi Korombili and Anastasia Βokou and Artemios Pehlivanidis and Charalabos C. Papageorgiou and George Papaioannou},
keywords = {Multiscale entropy, Power Spectral Density, Aristotle's syllogism, ASD-ADHD, Systems of thinking I&II, Cognitive load},
abstract = {Objective
We aim to investigate whether EEG dynamics differ in adults with ASD (Autism Spectrum Disorders), ADHD (attention-deficit/hyperactivity disorder), compared with healthy subjects during the performance of an innovative cognitive task: Aristotle's valid and invalid syllogisms. We follow the Neuroanatomical differences type of criterion in assessing the results of our study in supporting or not the dual-process theory of Kahneman, 2011) (Systems I & II of thinking).
Method
We recorded EEGs from 14 scalp electrodes in 30 adults with ADHD, 30 with ASD and 24 healthy, normal subjects. The subjects were exposed in a set of innovative cognitive tasks (inducing varying cognitive loads), the Aristotle's four types of syllogism mentioned above. The multiscale entropy (MSE), a nonlinear information-theoretic measure or tool was computed to extract features that quantify the complexity of the EEG.
Results
The dynamics of the curves of the grand average of MSE values of the ADHD and ASD participants was significantly in higher levels for the majority of time scales, than the healthy subjects over a number of brain regions (electrodes locations), during the performance of both valid and invalid types of syllogism. This result is seemingly not in accordance of the broadly accepted ‘theory’ of complexity loss in ‘pathological’ subjects, but actually this is not the case as explained in the text. ADHD subjects are engaged in System II of thinking, for both Valid and Invalid syllogism, ASD and Control in System I for valid and invalid syllogism, respectively. A surprising and ‘provocative’ result of this paper, as shown in the next sections, is that the Complexity-variability of ASD and ADHD subjects, when they face Aristotle's types of syllogisms, is higher than that of the control subjects. An explanation is suggested as described in the text. Also, in the case of invalid type of Aristotelian syllogisms, the linguistic and visuo-spatial systems are both engaged ONLY in the temporal and occipital regions of the brain, respectively, of ADHD subjects. In the case of valid type, both above systems are engaged in the temporal and occipital regions of the brain, respectively, of both ASD and ADHD subjects, while in the control subjects only the visuo-spatial type is engaged (Goel et al., 2000; Knauff, 2007).
Conclusion
Based on the results of the analysis described in this work, the differences in the EEG complexity between the three groups of participants lead to the conclusion that cortical information processing is changed in ASD and ADHD adults, therefore their level of cortical activation may be insufficient to meet the peculiar cognitive demand of Aristotle's reasoning.
Significance
The present paper suggest that MSE, is a powerful and efficient nonlinear measure in detecting neural dysfunctions in adults with ASD and ADHD characteristics, when they are called on to perform in a very demanding as well as innovative set of cognitive tasks, that can be considered as a new diagnostic ‘benchmark’ in helping detecting more effectively such type of disorders. A linear measure alone, as the typical PSD, is not capable in making such a distinction. The work contributes in shedding light on the neural mechanisms of syllogism/reasoning of Aristotelian type, as well as toward understanding how humans reason logically and why ‘pathological’ subjects deviate from the norms of formal logic.}
}
@article{ROBERTS201648,
title = {Mathematical and computational models of the retina in health, development and disease},
journal = {Progress in Retinal and Eye Research},
volume = {53},
pages = {48-69},
year = {2016},
issn = {1350-9462},
doi = {https://doi.org/10.1016/j.preteyeres.2016.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S1350946216300106},
author = {Paul A. Roberts and Eamonn A. Gaffney and Philip J. Luthert and Alexander J.E. Foss and Helen M. Byrne},
keywords = {Oxygen, Neuroglobin, Photoreceptors, Angiogenesis, Retinitis pigmentosa, Choroidal neovascularisation},
abstract = {The retina confers upon us the gift of vision, enabling us to perceive the world in a manner unparalleled by any other tissue. Experimental and clinical studies have provided great insight into the physiology and biochemistry of the retina; however, there are questions which cannot be answered using these methods alone. Mathematical and computational techniques can provide complementary insight into this inherently complex and nonlinear system. They allow us to characterise and predict the behaviour of the retina, as well as to test hypotheses which are experimentally intractable. In this review, we survey some of the key theoretical models of the retina in the healthy, developmental and diseased states. The main insights derived from each of these modelling studies are highlighted, as are model predictions which have yet to be tested, and data which need to be gathered to inform future modelling work. Possible directions for future research are also discussed. Whilst the present modelling studies have achieved great success in unravelling the workings of the retina, they have yet to achieve their full potential. For this to happen, greater involvement with the modelling community is required, and stronger collaborations forged between experimentalists, clinicians and theoreticians. It is hoped that, in addition to bringing the fruits of current modelling studies to the attention of the ophthalmological community, this review will encourage many such future collaborations.}
}
@article{AMEMIYA2024105836,
title = {Children use disagreement to infer what happened},
journal = {Cognition},
volume = {250},
pages = {105836},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105836},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724001227},
author = {Jamie Amemiya and Gail D. Heyman and Tobias Gerstenberg},
keywords = {Disagreement, Inference, Prediction, Theory of mind, Ambiguous speech},
abstract = {In a rapidly changing and diverse world, the ability to reason about conflicting perspectives is critical for effective communication, collaboration, and critical thinking. The current pre-registered experiments with children ages 7 to 11 years investigated the developmental foundations of this ability through a novel social reasoning paradigm and a computational approach. In the inference task, children were asked to figure out what happened based on whether two speakers agreed or disagreed in their interpretation. In the prediction task, children were provided information about what happened and asked to predict whether two speakers will agree or disagree. Together, these experiments assessed children's understanding that disagreement often results from ambiguity about what happened, and that ambiguity about what happened is often predictive of disagreement. Experiment 1 (N = 52) showed that children are more likely to infer that an ambiguous utterance occurred after learning that people disagreed (versus agreed) about what happened and found that these inferences become stronger with age. Experiment 2 (N = 110) similarly found age-related change in children's inferences and also showed that children could reason in the forward direction, predicting that an ambiguous utterance would lead to disagreement. A computational model indicated that although children's ability to predict when disagreements might arise may be critical for making the reverse inferences, it did not fully account for age-related change.}
}
@article{BLACKBURNE2025105969,
title = {Communicated priors tune the perception of control},
journal = {Cognition},
volume = {254},
pages = {105969},
year = {2025},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2024.105969},
url = {https://www.sciencedirect.com/science/article/pii/S0010027724002555},
author = {George Blackburne and Chris D. Frith and Daniel Yon},
keywords = {Agency, Control, Expectation, Prediction, Communication},
abstract = {Action allows us to shape the world around us. But to act effectively we need to accurately sense what we can and cannot control. Classic theories across cognitive science suppose that this ‘sense of agency’ is constructed from the sensorimotor signals we experience as we interact with our surroundings. But these sensorimotor signals are inherently ambiguous, and can provide us with a distorted picture of what we can and cannot influence. Here we investigate one way that agents like us might overcome the inherent ambiguity of these signals: by combining noisy sensorimotor evidence with prior beliefs about control acquired through explicit communication with others. Using novel tools to measure and model control decisions, we find that explicit beliefs about the controllability of the environment alter both the sensitivity and bias of agentic choices; meaning that we are both better at detecting and more biased to feel control when we are told to expect it. These seemingly paradoxical effects on agentic choices can be captured by a computational model where expecting to be in control exaggerates the sensitivity or ‘gain’ of the mechanisms we use to detect our influence over our surroundings – making us increasingly sensitised to both true and illusory signs of agency. In combination, these results reveal a cognitive and computational mechanism that allows public communication about what we can and cannot influence to reshape our private sense of control.}
}
@article{SCHULTEMECKLENBECK2013242,
title = {A lack of appetite for information and computation. Simple heuristics in food choice},
journal = {Appetite},
volume = {71},
pages = {242-251},
year = {2013},
issn = {0195-6663},
doi = {https://doi.org/10.1016/j.appet.2013.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0195666313003668},
author = {Michael Schulte-Mecklenbeck and Matthias Sohn and Emanuel {de Bellis} and Nathalie Martin and Ralph Hertwig},
keywords = {Food choice, Heuristics, Process tracing, Rational choice, MouselabWeb},
abstract = {The predominant, but largely untested, assumption in research on food choice is that people obey the classic commandments of rational behavior: they carefully look up every piece of relevant information, weight each piece according to subjective importance, and then combine them into a judgment or choice. In real world situations, however, the available time, motivation, and computational resources may simply not suffice to keep these commandments. Indeed, there is a large body of research suggesting that human choice is often better accommodated by heuristics—simple rules that enable decision making on the basis of a few, but important, pieces of information. We investigated the prevalence of such heuristics in a computerized experiment that engaged participants in a series of choices between two lunch dishes. Employing MouselabWeb, a process-tracing technique, we found that simple heuristics described an overwhelmingly large proportion of choices, whereas strategies traditionally deemed rational were barely apparent in our data. Replicating previous findings, we also observed that visual stimulus segments received a much larger proportion of attention than any nutritional values did. Our results suggest that, consistent with human behavior in other domains, people make their food choices on the basis of simple and informationally frugal heuristics.}
}
@article{RICHARDSON2022100935,
title = {Extending the two-component model of delusion to substance use disorder etiology and recovery},
journal = {New Ideas in Psychology},
volume = {66},
pages = {100935},
year = {2022},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2022.100935},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X22000058},
author = {George B. Richardson and Nathan McGee},
keywords = {Brain disease model of addiction, Two-component model of delusion, Bayes Theorem, Belief, Substance use disorder},
abstract = {The brain disease model (BMDA) and psychosocial models of addiction attend to phenomena at different levels of biological organization, and evidence suggests neither is sufficient to explain substance use disorder (SUD). Here, we extend a Bayesian model of the emergence and persistence of delusions to SUD etiology and recovery, building upon efforts to link lower-level impacts of psychoactive compounds to higher-level phenomena such as attitudes, beliefs, and self-control. According to the resulting two-component model of SUD, psychoactive substances interact with genetic and environmental factors to produce delusions about the biological importance of substance use and its contexts by perturbating basic human affective systems. These delusions are most often revised or rejected based on individuals’ existing belief systems. But in some individuals, factors explaining the persistence of an array of delusions (e.g., lower levels of executive functioning) prevent the evaluation and revision system from rejecting or revising beliefs that attribute high salience to substance-related stimuli. This theory provides novel hypotheses regarding the potential roles of factors such as dichotomous thinking, positive illusions and self-deception, and denial or lack of awareness in SUD etiology and recovery. Furthermore, it provides an account of SUD that may result in less stigma than the BDMA.}
}
@article{GUR2015207,
title = {Space reconstruction by primary visual cortex activity: a parallel, non-computational mechanism of object representation},
journal = {Trends in Neurosciences},
volume = {38},
number = {4},
pages = {207-216},
year = {2015},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2015.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0166223615000351},
author = {Moshe Gur},
keywords = {vision, object representation, recognition, conscious perception, parallel processing},
abstract = {The current view posits that objects, despite changes in appearance, are uniquely encoded by ‘expert’ cells. This view is untenable. First, even if cell ensemble responses are invariant and unique, we are consciously aware of all of the objects’ details. Second, in addition to detail preservation, data show that the current hypothesis fails to account for uniqueness and invariance. I present an alternative view whereby objects’ representation and recognition are based on parallel representation of space by primary visual cortex (V1) responses. Information necessary for invariance and other attributes is handled in series by other cortical areas through integration, interpolation, and hierarchical convergence. The parallel and serial mechanisms combine to enable our flexible space perception. Only in this alternative view is conscious perception consistent with the underlying architecture.}
}
@article{PLATZ2024e4563,
title = {Dichlorocarbene: From Jack Hine to Robert Moss},
journal = {Journal of Physical Organic Chemistry},
volume = {37},
number = {1},
pages = {e4563},
year = {2024},
issn = {0894-3230},
doi = {https://doi.org/10.1002/poc.4563},
url = {https://www.sciencedirect.com/science/article/pii/S089432302300259X},
author = {Matthew S. Platz},
keywords = {carbene, dichlorocarbene, Jack Hine, Robert Moss},
abstract = {A select history of dichlorocarbene chemistry between 1950 and 2010 will be presented. This is not a comprehensive review; rather, it is a personal perspective on the contributions of two respected colleagues, the reactive intermediate that spanned their research efforts, and their important contributions to organic synthesis and mechanistic thinking.}
}
@incollection{ROMO2020150,
title = {Metaphor},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {150-156},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23529-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245235293},
author = {Manuela Romo},
keywords = {Analogical thought, Combinatory process, Computational creativity, Constitutive metaphor, Darwin, Einstein, Lorca, Pedagogical metaphor, Poetry, Scientific discovery},
abstract = {The subject of metaphors is introduced with a definition, stressing its role as a universal process in the development of thinking and language in human beings. A discussion follows on the differences between metaphor and analogy in this thinking process. The classification of metaphors is then addressed, while the body of the text is dedicated to reviewing explanations given from the standpoint of Psychology of Creativity on the nature of this process and its role in creative output. Lastly, the usefulness of metaphors and their dependence on domain specificity is analysed.}
}
@article{MARCIALROMERO2008171,
title = {Sequential Real Number Computation and Recursive Relations},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {202},
pages = {171-189},
year = {2008},
note = {Proceedings of the Fourth International Conference on Computability and Complexity in Analysis (CCA 2007)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2008.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108001199},
author = {J. Raymundo Marcial-Romero and M. Andrew Moshier},
keywords = {exact real-number computation, sequential computation, recursive relations, semantics, non-determinism, PCF},
abstract = {In the first author's thesis [Marcial-Romero, J. R., “Semantics of a sequential language for exact real-number computation”, PhD thesis at the University of Birmingham, 2004)], a sequential language, LRT, for real number computation is investigated. The thesis includes a proof that all polynomials are programmable, but that work comes short of giving a complete characterization of the expressive power of the language even for first-order functions. The technical problem is that LRT is non-deterministic. So a natural characterization of its expressive power should be in terms of relations rather than functions. In [Brattka, V., Recursive characterization of computable real-valued functions and relations, Theoretical Computer Science 162 (1) (1996) 45–77], Brattka investigates a formalization of recursive relations in the style of Kleene's recursive functions on the natural numbers. This paper establishes the expressive power of LRTp, a variant of LRT, in terms of Brattka's recursive relations. Because Brattka already did the work of establishing the precise connection between his recursive relations and Type 2 Theory of Effectivity, we thus obtain a complete characterization of first-order definability in LRTp.}
}
@article{JONES2015e38,
title = {Complexity and forensic pathology},
journal = {Forensic Science International},
volume = {257},
pages = {e38-e43},
year = {2015},
issn = {0379-0738},
doi = {https://doi.org/10.1016/j.forsciint.2015.08.026},
url = {https://www.sciencedirect.com/science/article/pii/S0379073815003709},
author = {Richard Martin Jones},
keywords = {Complexity, Chaos, Nonlinear, Pathophysiology, Forensic pathology, Forensic medicine},
abstract = {It has become increasingly apparent that nonlinearity and complexity are the norm in human physiological systems, the relevance of which is informing an enhanced understanding of basic pathological processes such as inflammation, the host response to severe trauma, and critical illness. This article will explore how an understanding of nonlinear systems and complexity might inform the study of the pathophysiology of deaths of medicolegal interest, and how ‘complexity thinking’ might usefully be incorporated into modern forensic medicine and forensic pathology research, education and practice.}
}
@article{DALLAGO2016150,
title = {Computation by interaction for space-bounded functional programming},
journal = {Information and Computation},
volume = {248},
pages = {150-194},
year = {2016},
note = {Development on Implicit Computational Complexity (DICE 2013)},
issn = {0890-5401},
doi = {https://doi.org/10.1016/j.ic.2015.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S089054011500142X},
author = {Ugo {Dal Lago} and Ulrich Schöpp},
keywords = {Implicit computational complexity, Logarithmic space, Type system, Geometry of interaction, Functional programming},
abstract = {When programming with sublinear space constraints one often needs to use special implementation techniques even for simple tasks, such as function composition. In this paper, we study how such implementation techniques can be supported in a functional programming language. Our approach is based on modelling computation by interaction using the Int construction of Joyal, Street & Verity. We apply this construction to a term model of a first-order programming language and use the resulting structure to derive the functional programming language intml. Intml can be understood as a programming language simplification of Stratified Bounded Affine Logic. We formulate intml by means of a type system inspired by Baillot & Terui's Dual Light Affine Logic. We show that it captures the complexity classes flogspace and nflogspace. We illustrate its expressiveness by showing how typical graph algorithms, such a test for acyclicity in undirected graphs, can be represented.}
}
@article{CHUI201337,
title = {Simulation Method for Developing Multiple-Use Medical Devices from Re-using and Enhancing Design of Single-Use Device},
journal = {Procedia CIRP},
volume = {5},
pages = {37-41},
year = {2013},
note = {First CIRP Conference on BioManufacturing},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2013.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212827113000085},
author = {Chee-Kong Chui and Han-Tong Loh and Jun-Fung Yam},
keywords = {Medical device design, Simulation, Single port access surgery},
abstract = {Single port access surgery requires several specialized and one-time use devices to perform the surgery. By making the specialized devices suitable for multiple use may reduce surgical cost and increase the popularity of single port access surgery. However, this requires a new design thinking that emphasize on modular design and sterilization. We are exploiting simulation and computational intelligence methods to aid the design process that includes splitting an existing single use device design into modules and identifying the parts from the modules for manufacturing. Linking the design of the device with manufacturing can be achieved using feature graphs. This paper relates the development of a multiple use hand instrument for single port access surgery by re- using and enhancing the design of single-use devices with the proposed simulation-based methodology.}
}
@article{BARA2001839,
title = {Model theory of deduction: a unified computational approach},
journal = {Cognitive Science},
volume = {25},
number = {6},
pages = {839-901},
year = {2001},
issn = {0364-0213},
url = {https://www.sciencedirect.com/science/article/pii/S0364021301000568},
author = {Bruno G. Bara and Monica Bucciarelli and Vincenzo Lombardo},
keywords = {Mental models, Deduction, Computational model, Development},
abstract = {One of the most debated questions in psychology and cognitive science is the nature and the functioning of the mental processes involved in deductive reasoning. However, all existing theories refer to a specific deductive domain, like syllogistic, propositional or relational reasoning. Our goal is to unify the main types of deductive reasoning into a single set of basic procedures. In particular, we bring together the microtheories developed from a mental models perspective in a single theory, for which we provide a formal foundation. We validate the theory through a computational model (UNICORE) which allows fine-grained predictions of subjects’ performance in different reasoning domains. The performance of the model is tested against the performance of experimental subjects—as reported in the relevant literature—in the three areas of syllogistic, relational and propositional reasoning. The computational model proves to be a satisfactory artificial subject, reproducing both correct and erroneous performance of the human subjects. Moreover, we introduce a developmental trend in the program, in order to simulate the performance of subjects of different ages, ranging from children (3–6) to adolescents (8–12) to adults (>21). The simulation model performs similarly to the subjects of different ages. Our conclusion is that the validity of the mental model approach is confirmed for the deductive reasoning domain, and that it is possible to devise a unique mechanism able to deal with the specific subareas. The proposed computational model (UNICORE) represents such a unifying structure.}
}
@article{MENGOV20061636,
title = {Fast computation of a gated dipole field},
journal = {Neural Networks},
volume = {19},
number = {10},
pages = {1636-1647},
year = {2006},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2006.05.031},
url = {https://www.sciencedirect.com/science/article/pii/S0893608006001316},
author = {George Mengov and Kalin Georgiev and Stefan Pulov and Trifon Trifonov and Krassimir Atanassov},
keywords = {Gated dipole field, Adaptive resonance theory, Generalized net},
abstract = {We address the need to develop efficient algorithms for numerical simulation of models, based in part or entirely on adaptive resonance theory. We introduce modifications that speed up the computation of the gated dipole field (GDF) in the Exact ART neural network. The speed increase of our solution amounts to at least an order of magnitude for fields with more than 100 gated dipoles. We adopt a ‘divide and rule’ approach towards the original GDF differential equations by grouping them into three categories, and modify each category in a separate way. We decouple the slow-dynamics part — the neurotransmitters from the rest of system, solve their equations analytically, and adapt the solution to the remaining fast-dynamics processes. Part of the node activations are integrated by an unsophisticated numerical procedure switched on and off according to rules. The remaining activations are calculated at equilibrium. We implement this logic in a Generalized Net (GN) — a tool for parallel processes simulation which enables a fresh look at developing efficient models. Our software implementation of generalized nets appears to add little computational overhead.}
}
@article{MARINHO2021e06079,
title = {Quantum computational investigations and molecular docking studies on amentoflavone},
journal = {Heliyon},
volume = {7},
number = {1},
pages = {e06079},
year = {2021},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2021.e06079},
url = {https://www.sciencedirect.com/science/article/pii/S2405844021001845},
author = {Márcia M. Marinho and Francisco Wagner Q. Almeida-Neto and Emanuelle M. Marinho and Leonardo P. {da Silva} and Ramon R.P.P.B. Menezes and Ricardo P. {dos Santos} and Emmanuel S. Marinho and Pedro {de Lima-Neto} and Alice M.C. Martins},
keywords = {Antichagasic agent, Biflavonoid, DFT, Fukui analysis, NLO},
abstract = {Chagas disease is a neglected tropical disease caused by the protozoan parasite Trypanosoma cruzi, with approximately 6–7 million people infected worldwide, becoming a public health problem in tropical countries, thus generating an increasing demand for the development of more effective drugs, due to the low efficiency of the existing drugs. Aiming at the development of a new antichagasic pharmacological tool, the density functional theory was used to calculate the reactivity descriptors of amentoflavone, a biflavonoid with proven anti-trypanosomal activity in vitro, as well as to perform a study of interactions with the enzyme cruzain, an enzyme key in the evolutionary process of T-cruzi. Structural properties (in solvents with different values of dielectric constant), the infrared spectrum, the frontier orbitals, Fukui analysis, thermodynamic properties were the parameters calculated from DFT method with the monomeric structure of the apigenin used for comparison. Furthermore, molecular docking studies were performed to assess the potential use of this biflavonoid as a pharmacological antichagasic tool. The frontier orbitals (HOMO-LUMO) study to find the band gap of compound has been extended to calculate electron affinity, ionization energy, electronegativity electrophilicity index, chemical potential, global chemical hardness and global chemical softness to study the chemical behaviour of compound. The optimized structure was subjected to molecular Docking to characterize the interaction between amentoflavone and cruzain enzyme, a classic pharmacological target for substances with anti-gas activity, where significant interactions were observed with amino acid residues from each one's catalytic sites enzyme. These results suggest that amentoflavone has the potential to interfere with the enzymatic activity of cruzain, thus being an indicative of being a promising antichagasic agent.}
}
@article{MADHJA2020107068,
title = {Energy-aware tree network formation among computationally weak nodes},
journal = {Computer Networks},
volume = {168},
pages = {107068},
year = {2020},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2019.107068},
url = {https://www.sciencedirect.com/science/article/pii/S1389128619309533},
author = {Adelina Madhja and Sotiris Nikoletseas and Alexandros A. Voudouris},
keywords = {Wireless power transfer, Tree network formation, Energy balance},
abstract = {We study the fundamental problem of distributed network formation among mobile agents of limited computational power that aim to achieve energy balance by wirelessly transmitting and receiving energy in a peer-to-peer manner. Specifically, we design simple distributed protocols consisting of a small number of states and interaction rules for the formation of arbitrary and k-ary tree networks. Furthermore, we evaluate (theoretically and also using computer simulations) a plethora of energy redistribution protocols that exploit different levels of knowledge in order to achieve desired energy distributions among the agents which require that every agent has exactly or at least twice the energy of the agents of higher depth, according to the structure of the network. Our study shows that without using any knowledge about the network structure, such energy distributions cannot be achieved in a timely manner, meaning that there might be high energy loss during the redistribution process. On the other hand, only a few extra bits of information seem to be enough to guarantee quick convergence to energy distributions that satisfy particular properties, yielding low energy loss.}
}
@article{SHIVHARE2016243,
title = {On the Cognitive Process of Abstraction},
journal = {Procedia Computer Science},
volume = {89},
pages = {243-252},
year = {2016},
note = {Twelfth International Conference on Communication Networks, ICCN 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, ICDMW 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, ICISP 2016, August 19-21, 2016, Bangalore, India},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.06.051},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916311164},
author = {Radhika Shivhare and Ch. Aswani Kumar},
keywords = {Abstraction, Cognitive Informatics, Concept Algebra, Formal Concept Analysis.},
abstract = {Concepts are the basic elements of propositions. Concepts can be best understood as constituted by its subset of objects (Extent) and subset of attributes (Intent). Psychological capacities of human mind for example, learning, thinking, memorizing can be performed by concepts and their association. In this paper, we will explain how human will be able to generalize concrete concepts of Formal Concept Analysis into abstract concepts. In particular, we model the functionalities of concept algebra by making use of Formal Concept Analysis; we illustrate the proposed model with experiments on sample context. This model simulates the thinking process of human mind.}
}
@incollection{MEDINAFRANCO2015455,
title = {Chapter 21 - Discovery and Development of Lead Compounds from Natural Sources Using Computational Approaches},
editor = {Pulok K. Mukherjee},
booktitle = {Evidence-Based Validation of Herbal Medicine},
publisher = {Elsevier},
address = {Boston},
pages = {455-475},
year = {2015},
isbn = {978-0-12-800874-4},
doi = {https://doi.org/10.1016/B978-0-12-800874-4.00021-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128008744000210},
author = {José L. Medina-Franco},
keywords = {Chemical space, Chemoinformatics, Computer-aided drug design, Dietary components, Drug discovery, Molecular diversity, Pharmacological profiling, Structure–activity relationships, Target fishing, Virtual screening},
abstract = {This chapter discusses the synergy between natural product-based drug discovery and methods used in computer-aided drug design. For centuries, Nature has been the source of compounds that are currently in the clinic or that have been used as molecular probes to identify therapeutic targets. In addition, Nature has inspired the development of a significant number of pharmaceutical agents. In contrast, computational approaches applied to drug discovery date back to only a few decades. Nonetheless, computational methods are evolving at an impressive speed and are making significant contributions to identifying and developing bioactive compounds of therapeutic relevance. Computational methods have a broad range of applications in natural product research including the organization and comprehensive analysis of molecular databases, systematic screening of natural products libraries, computer-aided optimization of lead compounds, and identification of biological activities for natural products of dietary origin.}
}
@article{PEREZ2008755,
title = {A computational evaluation of the effect of intramedullary nail material properties on the stabilization of simulated femoral shaft fractures},
journal = {Medical Engineering & Physics},
volume = {30},
number = {6},
pages = {755-760},
year = {2008},
issn = {1350-4533},
doi = {https://doi.org/10.1016/j.medengphy.2007.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S1350453307001567},
author = {Angel Perez and Andrew Mahar and Charles Negus and Peter Newton and Tom Impelluso},
keywords = {Finite element method, Simulated pediatric femur fractures, Intramedullary nails, Biomechanical stability},
abstract = {Titanium flexible intramedullary nails have become far more prevalent for stabilization of pediatric femur fractures in recent years. While steel may be expected to have superior fracture stability due to its higher elastic modulus; titanium alloy has experimentally demonstrated improved biomechanical stability, as measured by gap closure and nail slippage. The purpose of this study was to verify these observations computationally, and thus, explain why titanium alloy may be better suited for surgical fixation of fractured femurs. A finite element model of a femur with complete mid-diaphyseal fracture and having two 3.5mm nails in a retrograde “C” pattern was created. Static analyses were run in which the nail material properties were titanium alloy or stainless steel, respectively. Gap closure for the stainless steel nails was 1.03mm; while the titanium alloy nails had 0.69mm of closure. Titanium alloy nails slipped slightly less at each loading increment than stainless steel nails. The titanium alloy nails distributed stress more evenly along the nail axis, resulting in lower peak magnitudes. These results agree with previously published clinical and biomechanical studies that reported increased gap closure and nail slippage with stainless steel nails. The increased deformation of the titanium alloy nail likely increases the contact area with the intramedullary canal wall, thus, increasing stability. Additionally, stainless steel nails had higher curve apex von Mises stresses, potentially inducing a stress-shielding effect which could hamper remodeling and consequently increase risk of re-fracture.}
}
@article{PAUSELLI201874,
title = {Computational linguistic analysis applied to a semantic fluency task to measure derailment and tangentiality in schizophrenia},
journal = {Psychiatry Research},
volume = {263},
pages = {74-79},
year = {2018},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2018.02.037},
url = {https://www.sciencedirect.com/science/article/pii/S0165178117309824},
author = {Luca Pauselli and Brooke Halpern and Sean D. Cleary and Benson S. Ku and Michael A. Covington and Michael T. Compton},
keywords = {Automatic Data Processing, Formal Thought Disorder, Psychosis, Schizophrenia, Semantics, Semantic Fluency Tasks},
abstract = {Although rating scales to assess formal thought disorder exist, there are no objective, high-reliability instruments that can quantify and track it. This proof-of-concept study shows that CoVec, a new automated tool, is able to differentiate between controls and patients with schizophrenia with derailment and tangentiality. According to ratings from the derailment and tangentiality items of the Scale for the Assessment of Positive Symptoms, we divided the sample into three groups: controls, patients without formal thought disorder, and patients with derailment/tangentiality. Their lists of animals produced during a one-minute semantic fluency task were processed using CoVec, a newly developed software that measures the semantic similarity of words based on vector semantic analysis. CoVec outputs were Mean Similarity, Coherence, Coherence-5, and Coherence-10. Patients with schizophrenia produced fewer words than controls. Patients with derailment had a significantly lower mean number of words and lower Coherence-5 than controls and patients without derailment. Patients with tangentiality had significantly lower Coherence-5 and Coherence-10 than controls and patients without tangentiality. Despite the small samples of patients with clinically apparent thought disorder, CoVec was able to detect subtle differences between controls and patients with either or both of the two forms of disorganization.}
}
@article{LU2024,
title = {Methods for Calculating Building-Embodied Carbon Emissions for the Whole Design Process},
journal = {Fundamental Research},
year = {2024},
issn = {2667-3258},
doi = {https://doi.org/10.1016/j.fmre.2022.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S266732582400092X},
author = {Mei Lu and Zhixing Luo and Yujie Cang and Nan Zhang and Liu Yang},
keywords = {Design process, embodied carbon emissions, calculation methods, conceptual design, scheme design, construction drawing design},
abstract = {Energy conservation and emissions reduction in the construction industry are important steps in achieving China's goals of peak carbon emissions by 2030 and carbon neutrality by 2060. The premise for building carbon emission (CE) reduction is to produce accurate CE calculations. Existing calculation methods for building CEs have many problems, such as complicated calculations, large data demands, time-consuming and laborious processes, weak design orientation of results, and poor feedback on emission reduction. At the same time, the calculation of CEs during the process of architectural design faces obstacles such as uncertainty of information, incomplete data, and difficulty in obtaining a bill of quantities based on design information. To resolve these obstacles, this study, based on a designer's vocabulary and thinking mode, describes the construction of a “design-oriented” calculation methods for building-embodied carbon emissions (ECEs). The prediction and assessment of the impact on the building environment during the architectural design process were helpful for identifying the key areas for carbon reduction, exploring potential emission reduction hotspots, and providing timely feedback for design optimization, which can have important theoretical value and practical significance in promoting the construction of low-carbon buildings.}
}
@article{HAN2020106264,
title = {A new computational model based on Archimedean copula for probabilistic unbalanced linguistic term set and its application to multiple attribute group decision making},
journal = {Computers & Industrial Engineering},
volume = {140},
pages = {106264},
year = {2020},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2019.106264},
url = {https://www.sciencedirect.com/science/article/pii/S0360835219307338},
author = {Bing Han and Zhifu Tao and Huayou Chen and Ligang Zhou and Jinpei Liu},
keywords = {Multiple attribute group decision making, Probabilistic unbalanced linguistic term set, Archimedean copula, Weighted average aggregation operator},
abstract = {This paper proposes the concept of the probabilistic unbalanced linguistic term set which considers not only the probability of linguistic variables but also the non-uniform and non-symmetric distribution of linguistic labels. A new computational model on basis of Archimedean copula and corresponding co-copula is developed to deal with probabilistic unbalanced linguistic information. The most advantage of the model is that it can keep the closure of the operation. Some operational properties and particular cases are further investigated. We present the concepts of Archimedean copula weighted probabilistic unbalanced linguistic arithmetic average aggregation operator and Archimedean copula weighted probabilistic unbalanced linguistic geometric average aggregation operator, some properties are also discussed. Finally, the effectiveness and universality of the developed approach are illustrated by a hospital selection and comparison analysis. A sensitivity analysis is also performed to test the robustness of proposed methods.}
}
@article{MINOZZI2020101498,
title = {Direct response and the strategy method in an experimental cheap talk game},
journal = {Journal of Behavioral and Experimental Economics},
volume = {85},
pages = {101498},
year = {2020},
issn = {2214-8043},
doi = {https://doi.org/10.1016/j.socec.2019.101498},
url = {https://www.sciencedirect.com/science/article/pii/S2214804319300230},
author = {William Minozzi and Jonathan Woon},
keywords = {Strategic information transmission, Sender-receiver games, Strategy method, Laboratory experiment},
abstract = {In cheap talk games, equilibrium analysis predicts extreme limits on the information that can be transmitted when senders and receivers have different goals. Yet experimental evidence suggests that senders overcommunicate relative to this baseline, revealing more information than predicted in equilibrium. We propose that overcommunication may be due in part to limited cognitive engagement by subjects, captured by level-k thinking. To test this conjecture, we compare two elicitation methods, direct response and the strategy method, holding other elements of the game fixed. Existing experimental studies of cheap talk games use the standard direct response method, while the strategy method—in which subjects make selections for all contingent choices—is believed to encourage more thoughtful decisionmaking. We therefore expect senders to transmit less information with the strategy method than with direct response. In contrast, we find the reverse: the strategy method increased overcommunication. Further examination suggests that this occurred because senders played more naïvely with the strategy method than with direct response. Our findings suggest that the strategy method and direct response do not elicit the same choices in cheap talk games.}
}
@article{CHARPENTIER20163365,
title = {Sensitivity computations in higher order continuation methods},
journal = {Applied Mathematical Modelling},
volume = {40},
number = {4},
pages = {3365-3380},
year = {2016},
issn = {0307-904X},
doi = {https://doi.org/10.1016/j.apm.2015.10.033},
url = {https://www.sciencedirect.com/science/article/pii/S0307904X15006952},
author = {Isabelle Charpentier and Komlanvi Lampoh},
keywords = {Continuation, Homotopy, Sensitivity, Automatic differentiation, Diamant, Complex nonlinear eigenvalue problem,},
abstract = {Sensitivity analysis is a key tool in the study of the relationships between the input parameters of a model and the output solution. Although sensitivity analysis is extensively addressed in the literature, little attention has been brought to the methodological aspects of the sensitivity of nonlinear parametric solutions computed through a continuation technique. This paper proposes four combinations of sensitivity analysis with continuation and homotopy methods, including sensitivity analysis along solution branches or at a particular point. Theoretical aspects are discussed in the higher order continuation framework Diamant. The sensitivity methods are applied to a thermal ignition problem and some free vibration problems. Remarkable eigenvalue maps are produced for the complex nonlinear eigenvalue problems.}
}
@article{WIECHERT20031363,
title = {The role of modeling in computational science education},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1363-1374},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00093-1},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X03000931},
author = {W. Wiechert},
keywords = {Computational science education, Modeling and simulation, Modeling education},
abstract = {Modeling and simulation skills are two core competences of computational science and thus should be a central part of any curriculum. While there is a well-founded methodology for the design of simulation algorithms today the teaching of modeling skills carries some intrinsic problems. The reason is that modeling is still partly an art and partly a science. As an important consequence for university education, the concepts for teaching modeling must be quite different from those for teaching simulation algorithms. Experiences made with the courses on ‘Modeling and Simulation’ at the University of Siegen are summarized and some general concepts for the teaching of modeling skills are presented. In particular, three practical approaches to modeling education are discussed with several examples.}
}
@article{MCCREADY2010274,
journal = {Journal of Pragmatics},
volume = {42},
number = {1},
pages = {274-278},
year = {2010},
issn = {0378-2166},
doi = {https://doi.org/10.1016/j.pragma.2009.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0378216609001532},
author = {Elin McCready}
}
@article{LOU2022100247,
title = {Two-additive fuzzy measure-based information integration approach to product design alternative evaluation},
journal = {Journal of Industrial Information Integration},
volume = {25},
pages = {100247},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100247},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000467},
author = {Shanhe Lou and Yixiong Feng and Zhiwu Li and Jianrong Tan},
keywords = {Multi-criteria decision-making, Two-additive fuzzy measure, Information integration, Intuitionistic linguistic number},
abstract = {Conceptual design is a pivotal stage of new product development in manufacturing industries. Since multiple design alternatives are put forward at this stage, developing advanced evaluation methods is of great importance. Existing methods adopt additive models to integrate evaluation data. They face some inconsistency issues, e.g. inconsistency in the independent assumption and interdependent data, since evaluation criteria are interactional. Fuzzy measure that replaces the additivity with monotonicity has enabled advances in addressing such issues. This work proposes a two-additive fuzzy measure-based information integration approach to product design alternative evaluation for the first time. The evaluation data given by experts are in the form of intuitionistic linguistic numbers. They are more in accordance with the thinking habits of experts because the hesitation degree in linguistic assessment can be revealed. In order to reduce the subjective bias, the decision-making trial and evaluation laboratory method combining with grey relational analysis is applied to adjust evaluation data. Then monotonous two-additive fuzzy measure is identified by nonlinear programming using these data. It makes a good trade-off between computational complexity and presentation capability. Hence, evaluation data can be integrated by non-additive Choquet integral for ranking design alternatives. In comparison to additive model-based methods, the extra effect on the simultaneous satisfaction of criteria can be effectively revealed by the proposed approach. And the robustness of it is demonstrated by the sensitivity analysis. A case study on an elevator's design alternative evaluation is conducted to illustrate the feasibility and practicability of the proposed approach.}
}
@article{MATSUDA2005275,
title = {Functional competency and cognitive ability in mild Alzheimer's Disease: relationship between ADL assessed by a relative/ carer-rated scale and neuropsychological performance},
journal = {International Psychogeriatrics},
volume = {17},
number = {2},
pages = {275-288},
year = {2005},
issn = {1041-6102},
doi = {https://doi.org/10.1017/S1041610205001304},
url = {https://www.sciencedirect.com/science/article/pii/S1041610224046805},
author = {Osamu Matsuda and Masahiko Saito},
keywords = {Alzheimer's disease, cognitive deficits, functional competency},
abstract = {ABSTRACT
Background: Alzheimer's disease (AD) is characterized by multiple cognitive deficits and affects functional competency to perform daily activities (ADL). As this may contribute to the patient's overall disability, it is important to identify factors that compromise competency. Objective: The relationship between different cognitive domains and functional activities in AD was studied. Methods: The functional competency of 73 Japanese AD patients, most with mild dementia, was assessed using a 27-item relative/carer-rating scale covering 7 ADL: managing finances, using transportation, taking precautions, self-care, housekeeping, communication and taking medicine. Cognitive assessment used 16 neuropsychological tests from the Japanese version of the WAIS-R and COGNISTAT, covering 9 cognitive domains: orientation, attention, episodic memory, semantic memory, language, visuoperceptual and construction abilities, computational ability, abstract thinking, and psychomotor speed. Results: Multiple regression analysis by the stepwise method indicated that functional competency could, for the most part, be predicted from test scores for orientation, abstract thinking and psychomotor speed. Discussion: The results of this study suggest that impairment of these three cognitive domains plays an important role in the functional deterioration of AD.}
}
@article{QUAN20196515,
title = {Smart Design for Sustainable Neighborhood Development},
journal = {Energy Procedia},
volume = {158},
pages = {6515-6520},
year = {2019},
note = {Innovative Solutions for Energy Transitions},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2019.01.108},
url = {https://www.sciencedirect.com/science/article/pii/S1876610219301183},
author = {Steven Jige Quan},
keywords = {Smart Design, Sustainable Neighborhood Development, Design Decision Making, Multi-objective Optimization, Genetic Algorithms, Pareto optimal},
abstract = {This study proposes the Smart Design method to support the design decision making in the sustainable neighborhood development with multiple objectives. Instead of the “creative design” approach in the scenario making in traditional PSS and recent Geodesign frameworks, the Smart Design method applies the optimization algorithms to search for optimal design solutions in the design space. It integrates the design thinking, computational performance modeling and optimization techniques to efficiently and effectively approximate optimal designs. This method is applied to a hypothetical residential neighborhood design case study with three sustainability objectives: to maximize FAR, to minimize building energy use, and to minimize outdoor human discomfort. Based on the form parameterization, the Nondominated Sorting Genetic Algorithm II (NSGA-II) algorithm is utilized to guide the evolution of the neighborhood design throughout 80 generations, with neighborhood performance modeling tools. The Smart Design method is able to identify 38 representative design solutions as Pareto optimal which are equally optimal. Those solutions set a basis for discussions and negotiations among stake holders to make design decisions with the three objectives. Further research will be focused on addressing the challenges such as recursive objective definitions, parametrization of complex forms, quantification of performances and optimization uncertainties, from simple cases to more realistic and complex designs for sustainable neighborhood development.}
}
@article{MEHRYAR2022155854,
title = {Investigating flood resilience perceptions and supporting collective decision-making through fuzzy cognitive mapping},
journal = {Science of The Total Environment},
volume = {837},
pages = {155854},
year = {2022},
issn = {0048-9697},
doi = {https://doi.org/10.1016/j.scitotenv.2022.155854},
url = {https://www.sciencedirect.com/science/article/pii/S0048969722029515},
author = {Sara Mehryar and Swenja Surminski},
keywords = {Flood resilience, Participatory decision making, Resilience measurement tool, Mind mapping, Fuzzy cognitive mapping},
abstract = {Improving flood resilience of communities requires a holistic understanding of risks and resilience options as well as the preferences and priorities of different stakeholders. Innovations in risk and resilience assessment have helped communities to identify gaps in their flood risk management strategy but selecting and implementing resilience solutions remains a big challenge for many decision-makers. In addition to traditional appraisals and cost-benefit assessments this also calls for a participatory process in which various stakeholders are encouraged to adopt a system-level approach in identifying interventions that can maximise a range of benefits and co-benefits. In this study, we investigate how a combination of modelling and measurement methods can help decision-makers with their flood resilience strategies. We apply a participatory system thinking approach combining Fuzzy Cognitive Mapping (FCM) with a flood resilience measurement framework called Flood Resilience Measurement for Communities (FRMC). We first investigate stakeholders' biases on flood resilience interventions, and then lead them through a system thinking exercise using FCM and FRMC to elicit mental models representing important aspects of flood resilience and their interrelation. These are then aggregated, representing the collective perceptions and knowledge of stakeholders, and used to identify the most beneficial resilience actions in terms of direct and indirect impacts on flood resilience. We apply this approach to the case of Lowestoft, a coastal town in England exposed to significant flood risk. Developed in close collaboration with the local authorities, the ambition is to support decision-making on flood resilience interventions. We find that this combination of methods enables system-level thinking and inclusive decision-making about flood resilience which can ultimately encourage transformative decisions on prioritization of actions and investments.}
}
@article{SWANSON201854,
title = {How failure is productive in the creative process: Refining student explanations through theory-building discussion},
journal = {Thinking Skills and Creativity},
volume = {30},
pages = {54-63},
year = {2018},
note = {The Role of Failure in Promoting Thinking Skills and Creativity},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2018.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S1871187117301785},
author = {Hillary Swanson and Allan Collins},
keywords = {Knowledge in pieces, Microgenetic learning analysis, Knowledge construction, Constructivist instruction, Science learning, Creative thinking, Critical thinking, Creative problem solving},
abstract = {We argue that failure can play a productive role in students’ creative knowledge-construction process. As evidence, we present a fine-grained analysis of a whole-class theory-building discussion with 8th grade students. The goal of the discussion was to construct a theoretical account for why a glass of cold milk warmed quickly at first and then more slowly as it approached room temperature. Though they initially produced scientifically non-normative explanations, by the end of the discussion the class had refined their ideas into an explanation of difference drives rate – a relationship at the heart of Newton’s law of heating and other equilibration phenomena. The students’ flawed initial explanations were productive in the knowledge-construction process, as the raw material they ultimately refined into a more scientific explanation. We argue that the theory-building discussion supported both creative and critical thinking and that this pedagogical approach has the power, more generally, to leverage failure productively for science learning.}
}
@article{CORBIN2023100645,
title = {A comparison of linguistic patterns between individuals with current major depressive disorder, past major depressive disorder, and controls in a virtual, psychiatric research interview},
journal = {Journal of Affective Disorders Reports},
volume = {14},
pages = {100645},
year = {2023},
issn = {2666-9153},
doi = {https://doi.org/10.1016/j.jadr.2023.100645},
url = {https://www.sciencedirect.com/science/article/pii/S266691532300183X},
author = {Lisette Corbin and Emily Griner and Salman Seyedi and Zifan Jiang and Kailey Roberts and Mina Boazak and Ali {Bahrami Rad} and Gari D. Clifford and Robert O. Cotes},
keywords = {Depression, LIWC, Psychiatric interview, Computational linguistics},
abstract = {Major Depressive Disorder (MDD) is a leading health burden worldwide. Previous research has demonstrated that linguistic analysis of depressed individuals’ written and oral speech has potential as a diagnostic and monitoring biomarker. We sought to determine if the semantic content of speech differs between individuals with current MDD, past MDD, and controls. We recruited 53 volunteers for a simulated telehealth psychiatric intake interview. The sample included 14 individuals with current MDD, 21 with past MDD, and 18controls, all confirmed using a semi-structured diagnostic interview. The manually-transcribed interview transcripts were analyzed utilizing the LIWC-22 dictionary and statistical tests were applied to identify differences in the linguistic patterns between each clinical categorization. When comparing depressed subjects (either current or past) versus controls, significant differences were found for emotional tone, total function words, auxiliary verbs, negative tone, negative emotion, anxiety, sadness, attention, and visual. Individuals with past MDD only differed from those with current MDD in use of analytical thinking and auxiliary verbs. These results indicate that LIWC categories could differentiate current or past depressed subjects from controls, but fewer differences emerged when comparing current and past MDD. Further prospective studies with larger sample sizes are needed to confirm these findings.}
}
@article{SHU2025117791,
title = {MSFPSO: Multi-algorithm integrated particle swarm optimization with novel strategies for solving complex engineering design problems},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {437},
pages = {117791},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.117791},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525000635},
author = {Bin Shu and Gang Hu and Mao Cheng and Cunxia Zhang},
keywords = {Particle swarm optimization, Cauchy variation, Joint adversarial selection, Differential creative search, Attraction-rejection, Algorithm fusion},
abstract = {Particle swarm optimization (PSO) is considered among the best seminal meta-heuristic algorithms,boasting merits of minimal parameter requirements, straightforward implementation, and highly accelerated convergence capacity, lower computational complexity, etc. Nevertheless, it also has drawbacks, for instance, it tends to converge prematurely at local optima, lack of diversity, and low accuracy. In order to effectively overcome these shortcomings, this paper presents a multi-strategy fusion enhanced PSO called MSFPSO algorithm. Firstly,It motivated by the black-winged kite algorithm, a migration mechanism based on Cauchy's variation is introduced. This mechanism contributes to the efficiency and effectiveness of the algorithm in exploiting the present search area. Also, it effectively balances the dynamics relationship between exploration and exploitation, boosting the algorithm's global and local search capabilities.Second, a joint-opposition selection strategy is introduced for expanding the solution search range. Our approach is designed to avoid getting stuck in local optima. Specifically, selective opposition obtains the proximity dimension of a candidate solution through a linearly decreasing threshold. Dynamic opposition further extends the process of investigating the solution space. The algorithm is fully incorporated with the differential creative search algorithm for dual-strategy scenarios to enhance the performance of the decision-making effectiveness, population diversity, exploitation capability of the PSO. Finally, an attraction-rejection optimization strategy is introduced to further obtain a good exploitation-exploration balance capability and avoid stagnation of the algorithm. In addition, the comparison results with eight advanced optimization algorithms and six improved particle swarm optimization algorithms on CEC2020 test sets, and the statistical analysis was conducted by Wilcoxon rank sum test. It illustrate the features of the MSFPSO developed within this research strong competitiveness. The convergence of the algorithm was verified at maximum iterations of 10000 on the CEC2017 test set. Meanwhile, the experimental outcomes of applying MSFPSO to 50 practical engineering design challenges prove its effectiveness and strong applicability. The test results and numerical computations manifest that the MSFPSO algorithm with strong competitiveness will become a preferred class of meta-heuristic algorithms to tackle issues within the realm of engineering optimization.}
}
@article{LIN20253,
title = {Multiple predictions of others’ actions in the human brain},
journal = {Trends in Neurosciences},
volume = {48},
number = {1},
pages = {3-4},
year = {2025},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2024.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0166223624002182},
author = {Yongling Lin and Marco K. Wittmann},
keywords = {social cognition, neuroimaging, decision making, prediction, theory of mind, computational modelling},
abstract = {The success of our actions often depends on what others are doing. How does the brain discern predictions of others’ actions when situations are ambiguous? Recent work by Ma and colleagues suggests that the brain solves this problem by entertaining multiple predictions of others’ actions, ranked by their likelihood.}
}
@article{SAMARASINGHE2013188,
title = {Mixed-method integration and advances in fuzzy cognitive maps for computational policy simulations for natural hazard mitigation},
journal = {Environmental Modelling & Software},
volume = {39},
pages = {188-200},
year = {2013},
note = {Thematic Issue on the Future of Integrated Modeling Science and Technology},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2012.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1364815212001909},
author = {Sandhya Samarasinghe and Graham Strickert},
keywords = {Fuzzy cognitive maps, Auto-Associative Neural Networks, Self-organizing maps, Natural hazard mitigation, Earthquakes, Mixed-method triangulation, Policy simulation},
abstract = {Human systems need to be adaptive to the consequences of natural hazards. Public policy decisions on natural hazard mitigation can benefit from computational models that embody a comprehensive view of the system. Such models need to be transparent and integrate both expert and lay expert knowledge and experience in an efficient manner. By integrating hard and soft sciences within an overall systems framework, scientists, policy makers and communities can better understand how to improve adaptive capacity. We present a fuzzy cognitive map based Auto-Associative Neural Networks framework generated from a development mixed method integration (triangulation) for adaptive policy formulations. The specific policies relate to preparation for, response to, and recovery from earthquakes in mountainous ski-field environments – a case study chosen to highlight the framework. Three different data collection techniques – expert geomorphic assessments, semi-structured qualitative interviews with three stakeholder groups (experts and lay experts), and fuzzy cognitive maps (FCM) (node and arc maps of stakeholder perceptions) were employed. FCM were first analysed using Graph theory indices to determine map structure. Special attention was paid to subsequent processing of fuzzy cognitive maps (e.g., condensation and aggregation) with qualitative followed by quantitative means to simplify the FCM from the original total of 300 variables to 5 high-level themes to improve the efficacy of subsequent policy simulations. Specifically, the use of Self Organising Maps (SOM) to group concepts (condensation) and individual stakeholders (aggregation) into social group FCMs is a novel contribution to advancing FCM. In the process, SOM also enabled the embedment of nonlinear relationships inherent in the system in the simplified FCM allowing a platform for realistic and meaningful policy simulations based on collective perceptions. Specifically, each of the three simplified stakeholder group FCM and a total social group FCM was represented by Auto-Associative Neural Networks (AANN) which converts an FCM into a dynamical system that allows policy scenario simulations based on input from both expert and lay expert stakeholders. A policy scenario is the level of importance given to a set of concepts and their effects on the system behaviour as revealed by the simulations. We present the results from one of several policy simulations to highlight the effectiveness of the mixed-method integration leading to simplified-FCM based ANNN simulations. Results revealed the similarities and differences between stakeholder group responses in relation to the scenario analysed and how these formed collective responses in the total social group map. Furthermore, outcomes of group and total social group simulations could be interpreted from individual and group stakeholder FCMs giving credibility to the mixed-method approach.}
}
@article{SAMUELSSON2023100173,
title = {A shape of play to come: Exploring children's play and imaginaries with robots and AI},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100173},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100173},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000528},
author = {Robin Samuelsson},
keywords = {Early childhood, Robots, AI, Play, Playful learning, Sociotechnical imaginaries},
abstract = {We are rapidly moving into an era where AI and robots are part of everyday interactions in society and education, and there are immense discussions today about current and future technologies. Still, children are often not included in this discussion, while there is much to learn from current uses and children's understandings of AI and robotics. The study is based on a seven-month ethnographical work that details the implementation of a robot in two preschool groups of children aged 1–2 and 3–5 (n = 38). The study descriptively combines a framework for children's play analysis with explorative qualitative child interviews (n = 6) with the 3-5-year-olds to examine how children play with the robot and their thinking about a future with robots and AI. The results show how children's play with robots spans all of Hughes's (2011) sixteen play types and integrates robots into play in ways specific to child-robot interaction. The interviews indicate that children have well-formed knowledge about the current uses of robots and AI and elaborate imaginaries about a future with them, including critical boundaries toward robots and AI agents. The evidence shows emerging ways children relate to these. The potential of including children's actions and voices in the ongoing societal and educational debates on AI is discussed.}
}
@article{MAIRAL202262,
title = {What should the university of the future look like?},
journal = {On the Horizon},
volume = {31},
number = {1},
pages = {62-70},
year = {2022},
issn = {1074-8121},
doi = {https://doi.org/10.1108/OTH-08-2022-0050},
url = {https://www.sciencedirect.com/science/article/pii/S1074812122000239},
author = {Ricardo Mairal},
keywords = {Employment, Internationalization, Higher education, Quality, Artificial intelligence, Online and distance education},
abstract = {Purpose
In this paper, the author has tried to outline the main ideas in connection with what the author conceives to be the university of the future, a university that should not only educate people within the university system but also prepare them to fill specific job positions at both local and global levels, apart from necessarily providing them with the critical thinking and competences in autonomous learning that will make them flexible and capable of adapting to the job market and to a fast-changing world in general.
Design/methodology/approach
The author has revised some of the major issues that are going to determine the direction of the university of the future, i.e. the employment opportunities of tomorrow; the role of new technologies, especially the impact of artificial intelligence (AI); quality in higher education; and internationalization.
Findings
The author has also pointed out the importance of the technologies and the great role they indisputably play in present and future education at all levels, a fact that has been particularly and hugely enhanced and promoted by the COVID-19 pandemic situation, thereby facilitating and fostering distance learning. This is very much connected to the application of AI to higher education, another unavoidable issue of utmost importance for the university of the future. While these technological advances present a challenge to universities, which must determine which are necessary and desirable and how to implement them, it is, ultimately, our responsibility to use them, in an ethical way, to the benefit of our students. The university of the future also has to be of high quality, and this involves carrying out important and decisive action having to do with matters of inclusion, hiring policies and the expansion of international opportunities for all parties involved.
Originality/value
This paper outlines the main ideas in connection with what the author conceives to be the university of the future, a university that should not only educate people within the university system but also prepare them to fill specific job positions at both local and global levels, apart from necessarily providing them with the critical thinking and competences in autonomous learning that will make them flexible and capable of adapting to the job market and to a fast-changing world in general. Moreover, the role of new technologies (especially the impact of AI), quality and internationalization are also discussed as relevant factors in this view of the university of the future.}
}
@article{KONOPKA200391,
title = {Selected dreams and nightmares about computational biology},
journal = {Computational Biology and Chemistry},
volume = {27},
number = {2},
pages = {91-92},
year = {2003},
issn = {1476-9271},
doi = {https://doi.org/10.1016/S1476-9271(03)00024-0},
url = {https://www.sciencedirect.com/science/article/pii/S1476927103000240},
author = {Andrzej K Konopka}
}
@article{TOUSSAINT20102,
title = {Computational geometric aspects of rhythm, melody, and voice-leading},
journal = {Computational Geometry},
volume = {43},
number = {1},
pages = {2-22},
year = {2010},
note = {Special Issue on the 14th Annual Fall Workshop},
issn = {0925-7721},
doi = {https://doi.org/10.1016/j.comgeo.2007.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S092577210900042X},
author = {Godfried Toussaint},
keywords = {Musical rhythm, Melody, Voice-leading, Evenness measures, Rhythm similarity, Sequence comparison, Necklaces, Convolution, Computational geometry, Music information retrieval, Algorithms, Computational music theory},
abstract = {Many problems concerning the theory and technology of rhythm, melody, and voice-leading are fundamentally geometric in nature. It is therefore not surprising that the field of computational geometry can contribute greatly to these problems. The interaction between computational geometry and music yields new insights into the theories of rhythm, melody, and voice-leading, as well as new problems for research in several areas, ranging from mathematics and computer science to music theory, music perception, and musicology. Recent results on the geometric and computational aspects of rhythm, melody, and voice-leading are reviewed, connections to established areas of computer science, mathematics, statistics, computational biology, and crystallography are pointed out, and new open problems are proposed.}
}
@article{SOTO2022100963,
title = {Undergraduates’ exploration of contour integration: What is Accumulated?},
journal = {The Journal of Mathematical Behavior},
volume = {66},
pages = {100963},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100963},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000311},
author = {Hortensia Soto and Michael Oehrtman},
keywords = {Complex functions, Contour integration, Emerging models},
abstract = {In this work we explored undergraduate students’ geometric and visual interpretations of the inscription for contour integrals, ∫Cfzdz, without them having any prior knowledge of integration of complex-valued functions. Our research participants drew from various sources of geometric and visual interpretations to productively investigate the components of contour integrals, which they conveyed with diagrams and gesture. Although this enabled significant progress, they were overwhelmed coordinating the multiple quantitative relationships and reverted to simplified interpretations such as summing values of z,fz, or ∆z. In other words, they were unable to maintain focus on what was accumulated. Our participants also engaged in the thinking real, doing complex phenomenon which sometimes provided productive feedback to assess their interpretations. We offer potential reasons for students’ struggles including various interpretations for integration of real-valued integration and the layering of inscriptions. We also provide potential instructional strategies based on the participants’ interpretations.}
}
@incollection{LEBARON20061187,
title = {Chapter 24 Agent-based Computational Finance},
editor = {L. Tesfatsion and K.L. Judd},
series = {Handbook of Computational Economics},
publisher = {Elsevier},
volume = {2},
pages = {1187-1233},
year = {2006},
issn = {1574-0021},
doi = {https://doi.org/10.1016/S1574-0021(05)02024-1},
url = {https://www.sciencedirect.com/science/article/pii/S1574002105020241},
author = {Blake LeBaron},
keywords = {learning, evolutionary finance, financial time series, asset pricing, efficient markets, behavioral finance, market microstructure, genetic algorithms, neural networks, artificial financial markets, evolutionary computation},
abstract = {This chapter surveys research on agent-based models used in finance. It will concentrate on models where the use of computational tools is critical for the process of crafting models which give insights into the importance and dynamics of investor heterogeneity in many financial settings.}
}
@article{XUE2024100156,
title = {Conceptual frameworks for the integration of genetic and social epidemiology in complex diseases},
journal = {Global Epidemiology},
volume = {8},
pages = {100156},
year = {2024},
issn = {2590-1133},
doi = {https://doi.org/10.1016/j.gloepi.2024.100156},
url = {https://www.sciencedirect.com/science/article/pii/S2590113324000221},
author = {Diane Xue and Anjum Hajat and Alison E. Fohner},
abstract = {Uncovering the root causes of complex diseases requires complex approaches, yet many studies continue to isolate the effects of genetic and social determinants of disease. Epidemiologic efforts that under-utilize genetic epidemiology methods and findings may lead to incomplete understanding of disease. Meanwhile, genetic epidemiology studies are often conducted without consideration of social and environmental context, limiting the public health impact of genomic discoveries. This divide endures despite shared goals and increases in interdisciplinary data due to a lack of shared theoretical frameworks and differing language. Here, we demonstrate that bridging epidemiological divides does not require entirely new ways of thinking. Existing social epidemiology frameworks including Ecosocial theory and Fundamental Cause Theory, can both be extended to incorporate principles from genetic epidemiology. We show that genetic epidemiology can strengthen, rather than detract from, efforts to understand the impact of social determinants of health. In addition to presenting theoretical synergies, we offer practical examples of how genetics can improve the public health impact of epidemiology studies across the field. Ultimately, we aim to provide a guiding framework for trainees and established epidemiologists to think about diseases and complex systems and foster more fruitful collaboration between genetic and traditional epidemiological disciplines.}
}
@article{BERGSTRA200855,
title = {Parallel Processes with Implicit Computational Capital},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {209},
pages = {55-81},
year = {2008},
note = {Proceedings of the LIX Colloquium on Emerging Trends in Concurrency Theory (LIX 2006)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2008.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S1571066108002193},
author = {J.A. Bergstra and C.A. Middelburg},
keywords = {Process algebra, Implicit computational capital, Preservation of computational money},
abstract = {We propose a process algebra which is concerned with processes that have an implicit computational capital. This process algebra is intended to be helpful when designing computer-based systems of which the behaviour is related to money handling. It goes along with the development that the behaviour of computer-based systems, organizations and persons is increasingly more related to money handling.}
}
@article{EVERS2025180,
title = {Preliminaries to artificial consciousness: A multidimensional heuristic approach},
journal = {Physics of Life Reviews},
volume = {52},
pages = {180-193},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S1571064525000028},
author = {K. Evers and M. Farisco and R. Chatila and B.D. Earp and I.T. Freire and F. Hamker and E. Nemeth and P.F.M.J. Verschure and M. Khamassi},
abstract = {The pursuit of artificial consciousness requires conceptual clarity to navigate its theoretical and empirical challenges. This paper introduces a composite, multilevel, and multidimensional model of consciousness as a heuristic framework to guide research in this field. Consciousness is treated as a complex phenomenon, with distinct constituents and dimensions that can be operationalized for study and for evaluating their replication. We argue that this model provides a balanced approach to artificial consciousness research by avoiding binary thinking (e.g., conscious vs. non-conscious) and offering a structured basis for testable hypotheses. To illustrate its utility, we focus on "awareness" as a case study, demonstrating how specific dimensions of consciousness can be pragmatically analyzed and targeted for potential artificial instantiation. By breaking down the conceptual intricacies of consciousness and aligning them with practical research goals, this paper lays the groundwork for a robust strategy to advance the scientific and technical understanding of artificial consciousness.}
}
@incollection{VALERIO201385,
title = {Chapter 6 - Computational Translation and Integration of Test Data to Meet Risk Assessment Goals},
editor = {Bruce A. Fowler},
booktitle = {Computational Toxicology},
publisher = {Academic Press},
address = {San Diego},
pages = {85-112},
year = {2013},
isbn = {978-0-12-396461-8},
doi = {https://doi.org/10.1016/B978-0-12-396461-8.00008-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780123964618000087},
author = {Luis G. Valerio},
keywords = { toxicology,  methods, translational research, QSAR, computational toxicology, drug safety, safety assessment},
abstract = {The remarkable advances of high-performance computing to facilitate and increase efficiency in helping to resolve or support assessments on the toxic effects of chemicals on tissues and genomic material have led to development of novel in silico methods. These methods can support risk assessment via integration of study data that can be translated into meaningful predictive information. This chapter describes some methods in computational toxicology and how to integrate experimental data with computational assessments for supporting risk assessment.}
}
@article{VAMVOUDAKIS20226,
title = {Nonequilibrium dynamical games: A control systems perspective},
journal = {Annual Reviews in Control},
volume = {53},
pages = {6-18},
year = {2022},
issn = {1367-5788},
doi = {https://doi.org/10.1016/j.arcontrol.2022.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S1367578822000128},
author = {Kyriakos G. Vamvoudakis and Filippos Fotiadis and Aris Kanellopoulos and Nick-Marios T. Kokolakis},
abstract = {Dynamical games model interactions between agents that take place in ever-shifting environments. Due to the increasing penetration of autonomous systems to society, understanding and predicting the outcomes of these games has become crucial. In this work, we highlight the importance of nonequilibrium solutions to dynamical games through the lens of bounded rationality. We describe the principles of level-k thinking and cognitive hierarchy – concepts developed in the field of economics – via mathematical tools and formulation of control theory. We describe the main principles of bounded rationality for nonequilibrium differential games in both nonlinear non-zero-sum and linear zero-sum settings. The importance of those approaches is highlighted in problems of pursuit evasion between Unmanned Aerial Vehicles, while the core of the bounded rationality principles that we employ are extended to discrete stochastic dynamical games. The versatility of the proposed approach is complemented by rigorous mathematical guarantees that enable predictability of the games’ outcomes.}
}
@article{GARFIELD198447,
title = {Artificial intelligence: Using computers to think about thinking, Part 2: Some practical applications of Al},
journal = {Computer Compacts},
volume = {2},
number = {2},
pages = {47-53},
year = {1984},
issn = {0167-7136},
doi = {https://doi.org/10.1016/0167-7136(84)90041-6},
url = {https://www.sciencedirect.com/science/article/pii/0167713684900416},
author = {Eugene Garfield}
}
@article{COLLINS2023101585,
title = {Generative linguistics: ‘Galilean style’},
journal = {Language Sciences},
volume = {100},
pages = {101585},
year = {2023},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2023.101585},
url = {https://www.sciencedirect.com/science/article/pii/S0388000123000505},
author = {John Collins},
keywords = {Chomsky, Centre-embedding, Competence/performance, Computation, Galilean style, Galileo},
abstract = {Generative linguistics is often claimed by Chomsky to have a 'Galilean style', which is intended to position linguistics as a science continuous with standard practise in the natural sciences. These claims, however, are more suggestive than explanatory. The paper will, first, explain just what a Galilean style is. It will then be argued that its application to two key notions in generative linguistics - the competence/performance distinction (with reference to centre-embedding) and the notion of computation - demands a departure from what we might expect of a Galilean style. In this sense, the epithet is misleading. It will also be shown, however, that the 'Galilean' label is appropriate once we factor in the difference between a science concerned with kinematics (the relations between objects in space and time) and one concerned with language.}
}
@article{ZENG2024123400,
title = {Research on the application of knowledge mapping and knowledge structure construction based on adaptive learning model},
journal = {Expert Systems with Applications},
volume = {249},
pages = {123400},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123400},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424002653},
author = {Xiyin Zeng and Shouqiang Liu},
keywords = {Personalized learing, Pedagogy, Interactive learning environments, Applications},
abstract = {This project has developed a geometry learning software that integrates multiple computer technologies to address the challenges of deep analysis of knowledge points and establishing connections in learning software. The software combines Long Short-Term Memory (LSTM) and Residual Neural Network (ResNet101) to encode text and image features. A self-attention mechanism is used to fuse information from both modalities, enabling decoding of geometric models and classification of corresponding knowledge points.This project uses LSTM and ResNet101 models to extract text and visual features for problem-solving using the Multi Mode Thinking Chain (CoT) method. Classification labels are utilized to generate text responses for problem-solving ideas. Furthermore, a recommendation module is proposed, which combines knowledge tracking and neural collaborative filtering algorithms to capture student behavior and knowledge point vectors. Implicit factors representing students' mastery of different knowledge points are used as inputs in neural collaborative filtering for personalized recommendations. The results demonstrate improvements in accuracy using the ResNet + LSTM multimodal algorithm, achieving a 13 % increase compared to single-modal classification. The multimodal CoT approach also outperforms language models like GPT3.5 and VisualBert by 10 %. Additionally, the combined algorithm of knowledge tracking and neural collaborative filtering shows a 13.3 % higher F1 value compared to ordinary algorithms, confirming the superiority of the adopted method in this project.}
}
@article{GUARINO2022559,
title = {Optimism and pessimism in strategic interactions under ignorance},
journal = {Games and Economic Behavior},
volume = {136},
pages = {559-585},
year = {2022},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2022.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S0899825622001506},
author = {Pierfrancesco Guarino and Gabriel Ziegler},
keywords = {Ignorance, Optimism/pessimism, Point/Wald Rationalizability, Interactive epistemology, Wishful thinking, Börgers dominance},
abstract = {We study players interacting under the veil of ignorance, who have—coarse—beliefs represented as subsets of opponents' actions. We analyze when these players follow max⁡min or max⁡max decision criteria, which we identify with pessimistic or optimistic attitudes, respectively. Explicitly formalizing these attitudes and how players reason interactively under ignorance, we characterize the behavioral implications related to common belief in these events: while optimism is related to Point Rationalizability, a new algorithm—Wald Rationalizability—captures pessimism. Our characterizations allow us to uncover novel results: (i) regarding optimism, we relate it to wishful thinking á la Yildiz (2007) and we prove that dropping the (implicit) “belief-implies-truth” assumption reverses an existence failure described therein; (ii) we shed light on the notion of rationality in ordinal games; (iii) we clarify the conceptual underpinnings behind a discontinuity in Rationalizability hinted in the analysis of Weinstein (2016).}
}
@incollection{SIEGLER20051,
title = {A computational model of conscious and unconscious strategy discovery},
editor = {Robert V. Kail},
series = {Advances in Child Development and Behavior},
publisher = {JAI},
volume = {33},
pages = {1-42},
year = {2005},
issn = {0065-2407},
doi = {https://doi.org/10.1016/S0065-2407(05)80003-5},
url = {https://www.sciencedirect.com/science/article/pii/S0065240705800035},
author = {Robert Siegler and Roberto Araya},
abstract = {Publisher Summary
This chapter deals with a computational model of conscious and conscious strategy discovery and advocates a triangulation strategy for attaining a better understanding of change mechanisms. This triangulation strategy involves going back and forth among traditional studies of age-related change, microgenetic studies of children's gleaming, and computer simulations that generate the changes documented in the other two approaches. The chapter describes a new computational model of conscious and unconscious strategy discovery. Apart from being a crucial component of one of the examples of the triangulation strategy, this simulation significantly extends previous models of strategy choice and discovery. A large majority of studies of cognitive development have been devoted to describe age-related changes. The studies of age-related change have succeeded in providing excellent descriptions of many aspects of cognitive growth. Each of these three approaches—descriptions of age-related change, descriptions of learning, and formal modeling—provides unique information critical to a well-grounded account of developmental change.}
}
@article{DIAS2007382,
title = {Philosophical grounding and computational formalization for practice based engineering knowledge},
journal = {Knowledge-Based Systems},
volume = {20},
number = {4},
pages = {382-387},
year = {2007},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2006.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0950705106001675},
author = {W.P.S. Dias},
keywords = {Practice based knowledge, Connectionist AI techniques, Tacit knowing, Shared practice},
abstract = {Michael Polanyi’s idea of tacit knowing and Martin Heidegger’s concept of pre-theoretical shared practice are presented as providing a strong rationale for the notion of practice based knowledge. Artificial Intelligence (AI) approaches such as Artificial Neural Networks (ANN), Case Based Reasoning (CBR) and Grounded Theory (with Interval Probability Theory) are able to model these philosophical concepts related to practice based knowledge. The AI techniques appropriate for modeling Polanyi’s and Heidegger’s ideas should be founded more on a connectionist rather than a cognitivist paradigm. Examples from engineering practice are used to demonstrate how the above techniques can capture, structure and make available such knowledge to practitioners.}
}
@article{TAILLANDIER2025105121,
title = {The dynamic sketch map to support reflection on urban flooding},
journal = {International Journal of Disaster Risk Reduction},
volume = {116},
pages = {105121},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.105121},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924008835},
author = {Franck Taillandier and Patrick Taillandier and Pénélope Brueder and Noé Brosse},
keywords = {Urban flood, Game, Sketch map, Agent-based simulation},
abstract = {Flood risk management is a significant concern for many regions. To reduce the flood impact, it is essential to increase residents' knowledge about this risk and in its management. Despite the many tools and methods available to raise awareness of flood risk, none of them fully meet the challenges of effective communication on flood and flood management by: integrating the perspective of local people, by providing information that is clear and easy to understand, by encouraging debate, discussion and reflection and by positioning flood mitigation measure at the center (positive vision on the risk). To answer this need, this article proposes an innovative approach that combines several methods, including sketch maps, agent-based simulation, and serious games. This combination enables to benefit from these three approaches: the expressiveness of sketch maps and the ability to analyze participants' spatial representations, the capacity of agent-based simulations to aid users in comprehending complex phenomena and dynamics, and the experimental and motivational environment provided by games. To implement this approach, we developed the DYSMA model, which bridges the gap between sketch maps and agent-based simulations by integrating drawn elements as agents, providing a dynamic sketch map. Additionally, we developed the Draw and Flood game, designed to engage the general public in thinking about flood management through the use of dynamic sketch maps. This approach is applied to an illustrative application dedicated to flooding in a small French city.}
}
@article{HODGENS2021102149,
title = {Solving the puzzle of Fe homeostasis by integrating molecular, mathematical, and societal models},
journal = {Current Opinion in Plant Biology},
volume = {64},
pages = {102149},
year = {2021},
note = {Cell biology},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2021.102149},
url = {https://www.sciencedirect.com/science/article/pii/S1369526621001503},
author = {Charles Hodgens and Belinda S. Akpa and Terri A. Long},
keywords = {Iron homeostasis, Simulation-based inference (SBI), Inclusivity},
abstract = {To ensure optimal utilization and bioavailability, iron uptake, transport, subcellular localization, and assimilation are tightly regulated in plants. Herein, we examine recent advances in our understanding of cellular responses to Fe deficiency. We then use intracellular mechanisms of Fe homeostasis to discuss how formalizing cell biology knowledge via a mathematical model can advance discovery even when quantitative data is limited. Using simulation-based inference to identify plausible systems mechanisms that conform to known emergent phenotypes can yield novel, testable hypotheses to guide targeted experiments. However, this approach relies on the accurate encoding of domain-expert knowledge in exploratory mathematical models. We argue that this would be facilitated by fostering more “systems thinking” life scientists and that diversifying your research team may be a practical path to achieve that goal.}
}
@article{LEOPOLD2024102913,
title = {The big mixup: Neural representation during natural modes of primate visual behavior},
journal = {Current Opinion in Neurobiology},
volume = {88},
pages = {102913},
year = {2024},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2024.102913},
url = {https://www.sciencedirect.com/science/article/pii/S0959438824000758},
author = {David A. Leopold},
abstract = {The primate brain has evolved specialized visual capacities to navigate complex physical and social environments. Researchers studying cortical circuits underlying these capacities have traditionally favored the use of simplified tasks and brief stimulus presentations in order to isolate cognitive variables with tight experimental control. As a result, operational theories about visual brain function have come to emphasize feature detection, hierarchical stimulus encoding, top-down task modulation, and functional segregation in distinct cortical areas. Recently, however, experimental paradigms combining natural behavior with electrophysiological recordings have begun to offer a distinctly different portrait of how the brain takes in and analyzes its visual surroundings. The present article reviews recent work in this area, highlighting some of the more surprising findings in domains of social vision and spatial navigation along with shifts in thinking that have begun to emanate from this approach.}
}
@article{KARTHIK2024106286,
title = {Improving brain tumor treatment with better imaging and real-time therapy using quantum dots},
journal = {Biomedical Signal Processing and Control},
volume = {95},
pages = {106286},
year = {2024},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.106286},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424003446},
author = {A. Karthik and S. {Shiek Aalam} and M. Sivakumar and M.V. {Rama Sundari} and J. {Dafni Rose} and Muniyandy Elangovan and A. Rajaram},
keywords = {NIR- quantum dots, Magnetic resonance imaging, Radiotherapy, Brain Tumor},
abstract = {Recent advancements in medical imaging and therapeutic technologies have propelled innovative strategies in brain tumor treatment. This study introduces a comprehensive methodology merging Quantum Dots (QDs) and Real-Time Imaging-Guided Therapeutics (RIGT) to refine the precision of brain tumor radiotherapy. Focusing on the synthesis of near-infrared quantum dots (NIR-QDs), the study emphasizes the critical role of meticulous surface functionalization in achieving biocompatibility and stability. The methodology integrates 3D brain MRI images into the ingeniously devised Real-Time Imaging-Guided Therapeutics (RIGT) system, facilitating precise tumor localization and adaptive treatment protocol adjustments. Novel hybrid architecture is introduced for real-time MRI data analysis, enabling intricate tumor segmentation, feature extraction, localization, and synthetic image generation. This fusion of technologies, empowered by artificial intelligence, equips healthcare professionals with comprehensive insights into tumor intricacies and potential treatment outcomes. The proposed methodology's transformative objective seeks to redefine brain tumor treatment by seamlessly integrating advanced imaging modalities, cutting-edge nanotechnology, and AI-driven precision therapeutics. It envisions establishing a new paradigm in brain tumor treatment, promising heightened efficacy and minimized risks for patients. The study's numerical findings showcase the AI-powered image analysis capabilities of the Hybrid CNN-GAN network. Demonstrating superior performance in tumor segmentation, the results exhibit an Intersection over Union (IoU) of 0.89, Dice Coefficient of 0.95, F1-score of 0.94, and Structural Similarity Index (SSI) of 0.91. Additionally, computational efficiency is evident, with a short processing time of 65 ms and balanced CPU and GPU usage at 80 % and 90 %, respectively. In summary, this study presents an innovative methodology for brain tumor treatment, underpinned by exceptional numerical results validating its efficacy and computational efficiency.}
}
@article{DECARVALHO2021107887,
title = {A process for designing innovative mechatronic products},
journal = {International Journal of Production Economics},
volume = {231},
pages = {107887},
year = {2021},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2020.107887},
url = {https://www.sciencedirect.com/science/article/pii/S0925527320302504},
author = {Rogerio Atem {de Carvalho} and Henrique {da Hora} and Rodrigo Fernandes},
keywords = {Mechatronics, Product design, Design thinking, Concurrent engineering, Agilism, Product life cycle, Intellectual property, Innovation management},
abstract = {This article presents a process for the design of innovative mechatronic products that integrates techniques of Design Thinking, Concurrent Engineering and Agilism to Intellectual Property Management activities. Design Thinking is employed in the early stages in order to better explore creativity, whereas Concurrent Engineering and Agilism are applied during the development of the product, in order to deal with emerging requirements and shrinking development times. The product development process is accompanied by Intellectual Property Management activities that address the protection of the project's intellectual assets. In this way, the proposed process represents an addition to theory and practice by smoothly integrating the three most influential product design philosophies of today, while, at the same time, introduces a direction for managing intellectual assets throughout the product lifecycle.}
}
@article{PATAHUDDIN2022100988,
title = {Subtleties in spatial visualization maneuvers: Insights from numerical solutions},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100988},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100988},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000566},
author = {Sitti Maesuri Patahuddin and Ajay Ramful and Tom Lowrie and Ajeevsing Bholoa},
keywords = {Spatial visualization, Spatial reasoning, Mathematics, Geometry, Measurement, Pre-service teacher},
abstract = {This study aimed to identify the role and nature of spatial visualization in the problem solutions of pre-service teachers solving school-mathematics tasks requiring measurement reasoning. The nuances in the pre-service teachers’ strategies were examined for the role of spatial visualization in the solution process. The findings suggest that inadequacies in visualizing the spatial configurations of the tasks led to incorrect numerical solutions despite the presence of conceptual knowledge. Furthermore, the tendency to rely on formula-based approaches appeared to have suppressed the preliminary spatial processing of the configurations. Theoretically, the paper offers insights into the mechanism that may be involved in the solution of spatially-related mathematical tasks. The findings imply that pre-service teachers need to be sufficiently engaged in spatial reasoning activities.}
}
@article{CAI2023101087,
title = {Impact of prompts on students’ mathematical problem posing},
journal = {The Journal of Mathematical Behavior},
volume = {72},
pages = {101087},
year = {2023},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2023.101087},
url = {https://www.sciencedirect.com/science/article/pii/S0732312323000573},
author = {Jinfa Cai and Hua Ran and Stephen Hwang and Yue Ma and Jaepil Han and Faith Muirhead},
keywords = {Problem posing, Problem-posing prompt, Problem-posing processes, Task variables, Task characteristics, Teaching mathematics through problem posing, P-PBL},
abstract = {This study used three pairs of problem-posing tasks to examine the impact of different prompts on students’ problem posing. Two kinds of prompts were involved. The first asked students to pose 2–3 different mathematical problems without specifying other requirements for the problems, whereas the second kind of prompt did specify additional requirements. A total of 2124 students’ responses were analyzed to examine the impact of the prompts along multiple dimensions. In response to problem-posing prompts with more specific requirements, students tended to engage in more in-depth mathematical thinking and posed much more linguistically and semantically complex problems with more relationships or steps required to solve them. The findings from this study not only contribute to our understanding of problem-posing processes but also have direct implications for teaching mathematics through problem posing.}
}
@article{YILMAZ2023100005,
title = {Augmented intelligence in programming learning: Examining student views on the use of ChatGPT for programming learning},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {1},
number = {2},
pages = {100005},
year = {2023},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2023.100005},
url = {https://www.sciencedirect.com/science/article/pii/S2949882123000051},
author = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
keywords = {Generative artificial intelligence, ChatGPT, Programming, Programming learning, Student opinions},
abstract = {With the diversification of generative artificial intelligence (AI) applications, the interest in their use in every segment and field of society in recent years has been increasing rapidly. One of these areas is programming learning and program writing processes. One of the generative AI tools used for this purpose is ChatGPT. The use of ChatGPT in program writing processes has become widespread, and this tool has a certain potential in the programming process. However, when the literature is examined, research results related to using ChatGPT for this purpose have yet to be found. The existing literature has a gap that requires exploration. This study aims to analyze the students' perspectives on using ChatGPT in the field of programming and programming learning. The study encompassed a cohort of 41 undergraduate students enrolled in a public university's Computer Technology and Information Systems department. The research was carried out within the scope of the Object-Oriented Programming II course for eight weeks. Throughout the research process, students were given project assignments related to the course every week, and they were asked to use ChatGPT while solving them. The research data was collected using a form consisting of open-ended questions and analyzed through content analysis. The research findings revealed both the advantages and disadvantages of ChatGPT usage, as perceived by the students. The students stated that the main benefits of using ChatGPT in programming learning are providing fast and mostly correct answers to questions, improving thinking skills, facilitating debugging, and increasing self-confidence. On the other hand, the main limitations of using ChatGPT in programming education were getting students used to laziness, being unable to answer some questions, or giving incomplete/incorrect answers, causing professional anxiety in students. Based on the results of the research, it can be said that it would be useful to integrate generative AI tools into programming courses considering the advantages they provide in programming teaching. However, appropriate measures should be taken regarding the limitations it brings. Based on the research findings, several recommendations were proposed regarding the integration of ChatGPT into lessons.}
}
@article{YANG2000103,
title = {Computational verb systems: a new paradigm for artificial intelligence},
journal = {Information Sciences},
volume = {124},
number = {1},
pages = {103-123},
year = {2000},
issn = {0020-0255},
doi = {https://doi.org/10.1016/S0020-0255(99)00135-8},
url = {https://www.sciencedirect.com/science/article/pii/S0020025599001358},
author = {Tao Yang},
keywords = {Verbs, Computational verbs, Computational verb systems, Chaos, Artificial intelligence, Reasoning, Knowledge representation},
abstract = {Computational verb systems can help machines to implement, understand and use verbs as human perception of dynamics. By using computational verbs we can embed dynamical experiences of human experts into artificial intelligence. Computational verbs, which are models of verbs in nature languages, are basic building blocks of computational verb systems. In this paper, computational verbs are used to represent dynamical knowledge embedded by verbs as a new framework of knowledge representation. BE-transformations are used to transform statements containing dynamical verbs into statements only containing static verb BE; namely, BE-propositions. Based on BE-transformations, the computational verb logic can be built. Furthermore, reasoning with computational verbs can be built based on BE-transformations and basic verb logic operations.}
}
@article{GILROY201643,
title = {Inherently irrational? A computational model of escalation of commitment as Bayesian Updating},
journal = {Behavioural Processes},
volume = {127},
pages = {43-51},
year = {2016},
note = {SQAB 2015: Choice and Consequences},
issn = {0376-6357},
doi = {https://doi.org/10.1016/j.beproc.2016.02.017},
url = {https://www.sciencedirect.com/science/article/pii/S0376635716300389},
author = {Shawn P. Gilroy and Donald A. Hantula},
keywords = {Escalation, Computer simulation, Decision-making, Bayes theorem},
abstract = {Monte Carlo simulations were performed to analyze the degree to which two-, three- and four-step learning histories of losses and gains correlated with escalation and persistence in extended extinction (continuous loss) conditions. Simulated learning histories were randomly generated at varying lengths and compositions and warranted probabilities were determined using Bayesian Updating methods. Bayesian Updating predicted instances where particular learning sequences were more likely to engender escalation and persistence under extinction conditions. All simulations revealed greater rates of escalation and persistence in the presence of heterogeneous (e.g., both Wins and Losses) lag sequences, with substantially increased rates of escalation when lags comprised predominantly of losses were followed by wins. These methods were then applied to human investment choices in earlier experiments. The Bayesian Updating models corresponded with data obtained from these experiments. These findings suggest that Bayesian Updating can be utilized as a model for understanding how and when individual commitment may escalate and persist despite continued failures.}
}
@article{LITTRELL2020109678,
title = {Not so fast: Individual differences in impulsiveness are only a modest predictor of cognitive reflection},
journal = {Personality and Individual Differences},
volume = {154},
pages = {109678},
year = {2020},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2019.109678},
url = {https://www.sciencedirect.com/science/article/pii/S0191886919306105},
author = {Shane Littrell and Jonathan Fugelsang and Evan F. Risko},
keywords = {Cognitive reflection, Impulsiveness, Intuitive thinking, Delay discounting dual process},
abstract = {The extent to which a person engages in reflective thinking while problem-solving is often measured using the Cognitive Reflection Test (CRT; Frederick, 2005). Some past research has attributed poorer performance on the CRT to impulsiveness, which is consistent with the close conceptual relation between Type I processing and dispositional impulsiveness (and the putative relation between a tendency to engage in Type I processing and poor performance on the CRT). However, existing research has been mixed on whether such a relation exists. To address this ambiguity, we report two large sample size studies examining the relation between impulsiveness and CRT performance. Unlike previous studies, we use a number of different measures of impulsiveness, as well as measures of cognitive ability and analytic thinking style. Overall, impulsiveness is clearly related to CRT performance at the bivariate level. However, once cognitive ability and analytic thinking style are controlled, these relations become small and, in some cases, non-significant. Thus, dispositional impulsiveness, in and of itself, is not a strong predictor of CRT performance.}
}
@article{DVIR20061233,
title = {Virtual Leashing: Creating a computational foundation for software protection},
journal = {Journal of Parallel and Distributed Computing},
volume = {66},
number = {9},
pages = {1233-1240},
year = {2006},
note = {Special Issue: Security in grid and distributed systems},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2006.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S074373150600092X},
author = {Ori Dvir and Maurice Herlihy and Nir N. Shavit},
keywords = {Digital rights management, Virtual leashing},
abstract = {We introduce Virtual Leashing,11The techniques described in this paper are protected by U.S. patents, both granted and pending. a new technique for software protection and control. The leashing process removes small fragments of code, pervasive throughout the application, and places them on a secure server. The secure server provides the missing functionality, but never the missing code. Reverse engineering the missing code, even with full tracing of the program's execution and its communication with the server, is computationally hard. Moreover, the server provides the missing functionality asynchronously: the application's performance is independent (within reason) of the secure server's speed. For example, the server might reside on a slow inexpensive chip or a remote Internet server. Leashing makes only modest demands on communication bandwidth, space, and computation.}
}
@article{MANSILHA2019190,
title = {Environmental externalities in broiler production: An analysis based on system dynamics},
journal = {Journal of Cleaner Production},
volume = {209},
pages = {190-199},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2018.10.179},
url = {https://www.sciencedirect.com/science/article/pii/S0959652618331950},
author = {Ricardo Brandão Mansilha and Dalila Cisco Collatto and Daniel Pacheco Lacerda and Maria Isabel {Wolf Motta Morandi} and Fabio Sartori Piran},
keywords = {Broiler, Environmental externalities, Energy sources, Systems thinking, System dynamics},
abstract = {Broiler represents approximately 1.5% of the Brazilian Gross Domestic Product (GDP). Brazil is one of the world's largest producers and exporters of chicken. Aiming to improve and sustain a competitive advantage, producers have invested in improvements in production systems in general, in particular aviary heating systems. However, producers need to choose the best among several alternatives of energy sources for heating. This decision impacts the environment to a greater or a lesser extent depending on the energy source chosen. The aim of this study is to develop a computational model to understand systemically and dynamically the environmental externalities based on the choice of energy source for aviary heating. The identification of criteria that influence the choice for heating systems was possible through a multiple case-study in the southern region of Brazil. By designing a computational model of system dynamics, it was possible to visualize scenarios using different energy sources and their respective negative environmental externalities. From the analysis of four scenarios, we sought to identify the one with the best relation to environmental and economic performance. It was evidenced that the scenario with the best relation was that using pellets as an energy source for aviary heating. The developed model may be applied to solve similar decision-making problems.}
}
@incollection{CLEMENTI200589,
title = {Chapter 6 - Computational chemistry: Attempting to simulate large molecular systems},
editor = {Clifford E. Dykstra and Gernot Frenking and Kwang S. Kim and Gustavo E. Scuseria},
booktitle = {Theory and Applications of Computational Chemistry},
publisher = {Elsevier},
address = {Amsterdam},
pages = {89-114},
year = {2005},
isbn = {978-0-444-51719-7},
doi = {https://doi.org/10.1016/B978-044451719-7/50049-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517197500494},
author = {Enrico Clementi},
abstract = {Publisher Summary
Computational chemistry is a very vast field dealing with atomic and molecular systems, considered at different complexity levels either as discretized quantum mechanical systems, or as statistical ensembles, amenable to Monte Carlo and Molecular Dynamic treatments, or as continuous matter fluid-dynamical distributions, modeled with Navier– Stokes equations. The mainstream computational chemistry was bent to fully solve the correlation problem with a single “technology.” Computational chemistry became a must for more and more chemists, even if the computer users had less and less awareness of the computational details of computer programs, and hardly understood that the computed answer could be incorrect, because of limitations of the selected method. In this computer generation and even more in the following years, internet, communications, commercial computer programs, computer servers, personal computers, desktop, graphics, Window, and Linux were common words, memory and disk space seemed unlimited, price/performance improved yearly, but faith in the computer replaced knowledge of the instrument and its software. Computational chemistry was becoming a part of the global economy.}
}
@article{TRUBA2024101496,
title = {Psycholinguistic underpinnings of image formation: Suggestion and manipulation in the educational network discourse},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101496},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101496},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000348},
author = {Hanna Truba and Sergii Khrapatyi and Kyrylo Harashchuk and Dmytro Shvets and Alina Proskurnia},
keywords = {Psycholinguistics, Image, Suggestion, Manipulation, Attraction, Fascination},
abstract = {This study delves into the intricate psycholinguistic mechanisms that underpin image formation within the educational network discourse, with a specific focus on the dynamics of suggestion and manipulation. In an era where digital communication reigns supreme, understanding how language shapes perceptions and influences behavior is paramount. This research seeks to unravel the complex interplay between suggestion, manipulation, and the formation of images within educational networks. Drawing from insights across disciplines such as psychology, linguistics, and communication studies, this study examines how linguistic cues and contextual factors interact to shape individuals' perceptions and responses within educational settings. Acknowledging the transformative power of language in shaping attitudes, beliefs, and actions, this study aims to shed light on the subtle yet profound ways in which educators employ linguistic strategies to influence discourse within educational networks. By employing a multifaceted approach that integrates theoretical frameworks with empirical analysis, this research endeavors to uncover the underlying mechanisms driving suggestion and manipulation within educational discourse. Through a meticulous examination of textual elements, discourse patterns, and communicative strategies employed by educators in digital environments, this study seeks to elucidate the intricate processes involved in image formation. By exploring the role of suggestion and manipulation in shaping perceptions, attitudes, and behaviors, this research contributes to a deeper understanding of the psycholinguistic underpinnings of educational network discourse. Furthermore, this study not only offers theoretical insights but also practical implications for educators, policymakers, and practitioners involved in educational communication. By highlighting the ethical considerations and implications of linguistic manipulation within educational networks, this research aims to empower stakeholders to navigate digital discourse with greater awareness and discernment. In conclusion, this study represents a significant contribution to the field of thinking skills and creativity by offering new insights into the psycholinguistic dynamics of image formation within educational networks. By unraveling the complexities of suggestion and manipulation, this research opens avenues for further inquiry and underscores the importance of critical thinking and creativity in navigating contemporary digital landscapes.}
}
@incollection{MOL2015158,
title = {Chapter 5 - Computational Design of Biological Systems: From Systems to Synthetic Biology},
editor = {Zaheer Ul-Haq and Jeffry D. Madura},
booktitle = {Frontiers in Computational Chemistry},
publisher = {Bentham Science Publishers},
pages = {158-196},
year = {2015},
isbn = {978-1-60805-865-5},
doi = {https://doi.org/10.1016/B978-1-60805-865-5.50005-8},
url = {https://www.sciencedirect.com/science/article/pii/B9781608058655500058},
author = {Milsee Mol and Shailza Singh},
keywords = {Abstraction, bioengineering, bioinspired, biological parts, computational modelling, computational tools, constructs, dynamic, infectious disease, interdisciplinary, linearization, mathematical framework, nextgen therapeutics, omics, ordinary differential equations, parameters, physical systems, reactions, regulatory circuits, simulation},
abstract = {Abstract:
Today biology is overwhelmed with ‘big data’, amassed from genomic projects carried out in various laboratories around the world using efficient high throughput technologies. Biologists are co-opting mathematical and computational techniques developed to address these data and derive meaningful interpretations. These developments have led to new disciplines: systems and synthetic biology. To explore these two evolving branches of biology one needs to be familiar with technologies such as genomics, bioinformatics and proteomics, mathematical and computational modeling techniques that help predict the dynamic behavior of the biological system, ruling out the trial-and-error methods of traditional genetic engineering. Systems and synthetic biology have developed hand-in-hand towards building artificial biological devices using engineered biological units as basic building blocks. Systems biology is an integrated approach for studying the dynamic and complex behaviors of biological components, which may be difficult to interpret and predict from properties of individual constituents making up the biological systems. While, synthetic biology aims to engineer biologically inspired devices, such as cellular regulatory circuits that do not exist in nature but are designed using well characterized genes, proteins and other biological components in appropriate combinations to perform a desired function. This is analogous to an electronic circuit board design that is fabricated using well characterized electrical components such as resistors, capacitors and so on. The in silico abstractions and predictions should be tightly linked to experimentation to be proved in vitro and in vivo systems for their successful applications in biotechnology. This chapter focuses on mathematical approaches and computational tools available to engineer biological regulatory circuits and how they can be implemented as next generation therapeutics in infectious disease.}
}
@article{ZHU2020102369,
title = {Sentiment and guest satisfaction with peer-to-peer accommodation: When are online ratings more trustworthy?},
journal = {International Journal of Hospitality Management},
volume = {86},
pages = {102369},
year = {2020},
issn = {0278-4319},
doi = {https://doi.org/10.1016/j.ijhm.2019.102369},
url = {https://www.sciencedirect.com/science/article/pii/S0278431918307333},
author = {Liang Zhu and Yan Lin and Mingming Cheng},
keywords = {Peer-to-peer accommodation, Guest satisfaction, Online ratings, Sentiment analysis, Analytical thinking, Authenticity},
abstract = {This study aims to decode guest satisfaction with peer-to-peer accommodations by analyzing the relationship between guests’ sentiment and online ratings and examining how analytical thinking and authenticity influence this relationship. Based on reviews of 4602 Airbnb listings in San Francisco, we empirically find that positive (negative) sentiment is linked to a high (low) rating. We further show that this link is stronger when guests manifest a higher extent of analytical thinking and authenticity. Both Tobit and ordered logit models yield consistent estimation results, showing the robustness of our findings. Our study contributes to the tourism and hospitality literature by theoretically explaining the association between sentiment and ratings. In addition, this paper enriches our knowledge regarding the trustworthiness of Airbnb ratings.}
}
@article{MATTHEWS2021100278,
title = {Reconceptualising feedback: Designing educational tangible technologies to be a creative material},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100278},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100278},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000210},
author = {Sarah Matthews and Ben Matthews},
keywords = {Tangible technologies, Feedback, Educational technologies, Creative material, Interaction design, Empirical studies},
abstract = {This paper investigates how children who are engaged in a creative project with tangible technology kits make sense of the system feedback the technology provides. A micro-analytic video study was conducted of primary school children designing their own technologies using existing educational microcontrollers. Our investigation reveals that the roles feedback plays in children’s interactions cannot easily be assimilated within the existing approaches to understand feedback that have been articulated in HCI literature. Our qualitative analysis shows how children do not make sense of feedback as semantic communication from the system, but make sense of it with respect to its embeddedness in a sequence of activities they are performing with the system and each other. The principal contribution to emerge from our study is a conception of feedback as a process, rather than as a semantic communicative event, nor a direct coupling of action and system response. Our discussion identifies how feedback participates in the institutional agendas of classrooms (e.g. discovery, computational thinking), and draws out initial implications for the design of feedback in educational tangible technologies, identifying possibilities for how feedback might be redesigned to better promote children’s diagnostic practices with open-ended technology kits.}
}
@incollection{ISMAIL2018165,
title = {Chapter 6 - High-Throughput Screening of Phytochemicals: Application of Computational Methods},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry},
publisher = {Elsevier},
pages = {165-192},
year = {2018},
isbn = {978-0-12-812364-5},
doi = {https://doi.org/10.1016/B978-0-12-812364-5.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128123645000067},
author = {Fyaz M.D. Ismail and Lutfun Nahar and Satyajit D. Sarker},
keywords = {High-throughput screening (HTS), Robotics, Dereplication, Liquid handling systems, Screening , Natural product prototypes, Drug discovery and development, , , },
abstract = {This chapter reviews the origin and evolution of high-throughput screening (HTS) through the experience of the authors, who have either consulted for and/or provided courses to various pharmaceutical companies. It focuses on the role of HTS in natural product (phytochemicals) drug screening and drug discovery. Application of computational methods in HTS for phytochemical is highlighted. Commonly encountered difficulties and solutions to some of the problems are discussed together with selected ‘how to’ protocols to ensure investigators can set up and productively use HTS in their own natural product research. Relevant failures and successes in identifying interesting natural products are also outlined.}
}
@article{GALITSKY201325,
title = {A computational simulation tool for training autistic reasoning about mental attitudes},
journal = {Knowledge-Based Systems},
volume = {50},
pages = {25-43},
year = {2013},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2013.04.018},
url = {https://www.sciencedirect.com/science/article/pii/S095070511300138X},
author = {Boris Galitsky},
keywords = {Autistic reasoning, Rehabilitation, Theory of mind},
abstract = {It has been discovered more than a decade ago that autistic people cannot properly understand and reproduce mental states and emotions. We hypothesize that people with autism suffer from difficulties in learning social rules from examples. Many remediation strategies have not taken this into account. Therefore an appropriate remediation strategy is to teach not simply via examples but to teach the rule along with it. In this study we suggest a reasoning rehabilitation strategy, based on playing with a computer based mental simulator that is capable of modeling mental and emotional states of the real world. A model of the mental world is presented in 12 steps. We describe our implementation of a natural language multiagent system that simulates this model. In addition we describe the system’s user interface for autistic rehabilitation. This system is subject to short-term and long-term evaluation of rehabilitation of autistic reasoning. Case studies with children who used it extensively are presented. Implications specifically in terms of autistic rehabilitation as well as generally in terms of reasoning about mental states are discussed.}
}
@article{LIU200548,
title = {A computational model for rare-earth ferrimagnets and antiferromagnets},
journal = {Physica B: Condensed Matter},
volume = {367},
number = {1},
pages = {48-52},
year = {2005},
issn = {0921-4526},
doi = {https://doi.org/10.1016/j.physb.2005.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S0921452605007982},
author = {Z.-S. Liu and M. Diviš and V. Sechovský},
keywords = {Intermetallic compounds, Crystal field},
abstract = {A computational model for the calculation of the bulk magnetic properties of rare-earth ferrimagnets and antiferromagnets was developed and justified theoretically in the framework of mean-field theory. To demonstrate its utility, the model was applied to calculate the anisotropic Heisenberg exchange constants of CeTe2 by fitting magnetization curves numerically, and to derive analytical expressions for the spontaneous magnetization as well as the Neél temperature by considering only the crystal-field (CF) ground-state doublet. It turns out that the temperature dependencies of the magnetization and the specific heat calculated with the formulas in absence of an external field are identical with the plots obtained directly with the full lowest CF J-multiplet, manifesting the strong role of the Kramers doublet in the magnetic process at low temperatures. Finally, the model was applied to investigate the effects of the quadrupolar and magneto-elastic (QM) interactions on the magnetic properties of the system.}
}
@article{LI2024101590,
title = {Transforming maker mindsets: A case study of elementary students in a maker education context during lesson study},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101590},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101590},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001287},
author = {Jiajia Li and Zhuang Li and Huixin Gao and Tianying Yun},
keywords = {Maker mindsets, STEM learning, Maker education, Lesson study},
abstract = {Utilizing a case study approach, this research investigates the transformation of elementary students' Maker mindsets within the context of Maker education through a lesson study cycle. The study focuses on the Maker mindsets transformation of three students with varying abilities, deliberately chosen as information-rich participants. A project-specific questionnaire, the Maker Mindsets Scale, was employed to facilitate self-assessment of Maker mindsets before and after intervention. Additionally, teachers' post-lesson discussion meetings were observed, and semi-structured interviews with participating teachers were conducted to gauge their perceptions of students' Maker mindsets transformation. The analysis encompassed students' semi-structured reflection logs and interviews to uncover the underlying factors driving Maker mindsets transformation. The results revealed distinct variations in how students of different abilities perceived their Maker mindsets transformation. Nonetheless, participant teachers consistently observed transformations in STEM (Science, Technology, Engineering, Mathematics) thinking skills, self-efficacy, motivation, and collaborative learning across all students. The study further identifies a collaborative convergence of multiple factors contributing to Maker mindsets transformation, spanning teacher, student, and pedagogical perspectives. These findings carry significant implications for educators, advocating for the implementation of customized strategies, authentic contextualization, structured methodologies, and collaborative frameworks to holistically nurture Maker mindsets evolution. Moreover, our study underscores the practicality of the LS approach in fostering collaborative development of innovative pedagogical strategies aimed at fostering Maker mindsets formation.}
}
@article{PALKOVICS2016144,
title = {Exploration of cognition–affect and Type 1–Type 2 dichotomies in a computational model of decision making},
journal = {Cognitive Systems Research},
volume = {40},
pages = {144-160},
year = {2016},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2016.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041715300115},
author = {Michael Anton Palkovics and Martin Takáč},
keywords = {Affective computing, Dual process theory, Decision-making},
abstract = {This paper studies the role of cognition and affect in decision-making as well as notions of Type 1 and 2 processes and behaviors typically used in dual process theories. In order to demonstrate that there is no 1:1 correspondence between types of observed behavior and internal processes causing them, and that Type 1 and Type 2 processes can be produced by a single system, we implemented a computational model integrating affective and cognitive processing. Our model is based on the model of Marinier, Laird, and Lewis (2009). We modified it by increasing the agent’s visual field, adding a GOFAI-style cognitive module (sub-goal management) and expanding the environment by a high-threat tile, to which the agent responds with a hard-wired automatic reaction. This allowed us to generate and observe different types of behavior and study interesting interactions between cognitive and affective control. By comparing our re-implementation to the modified agent, we demonstrated clear cases of Type 1 (fast, automatic) and Type 2 (slow, deliberative) behavior, providing further evidence for the “single-system, two processes” hypothesis.}
}
@incollection{DERINGER201359,
title = {9.02 - Computational Methods for Solids},
editor = {Jan Reedijk and Kenneth Poeppelmeier},
booktitle = {Comprehensive Inorganic Chemistry II (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Amsterdam},
pages = {59-87},
year = {2013},
isbn = {978-0-08-096529-1},
doi = {https://doi.org/10.1016/B978-0-08-097774-4.00902-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780080977744009025},
author = {V.L. Deringer and R. Dronskowski},
keywords = {Ab initio calculations, Band structure, Bonding indicators, Chemical bonding, Computational chemistry, Crystal orbitals, Density-functional theory, Electronic-structure calculations, Magnetism, Materials science, Plane-wave basis sets, Pseudopotentials, Quantum chemistry, Solid-state chemistry, Theoretical chemistry, Thermochemistry},
abstract = {Today's scientific progress would be unthinkable without theoretical and computational assistance. This holds true also for the solid-state sciences – which are without doubt a fundamental part of modern inorganic chemistry. This chapter is concerned mainly with first principles or ab initio quantum-chemical methods; the fundamental goal of solving Schrödinger's equation does not change upon going to extended systems, but there are some very important new ideas to consider. First, we describe these essential concepts; however, we do not, nor attempt to, provide an exhaustive overview of electronic-structure theory. Subsequently, we deal with simplifications, which are necessary to make quantum-chemical computations tractable and which possess special importance in the solid state. Simplifying ‘well’ is thus a vital part of any theorist's work. Finally, we describe applications – how chemists ‘see’ bonds in complicated structures, and how the computational toolkit may complement and enhance chemical concepts. They illustrate our most important message: how beautifully rock-solid theories and chemists' ingenious models blend in the solid state.}
}
@article{VARTIAINEN2021100281,
title = {Machine learning for middle schoolers: Learning through data-driven design},
journal = {International Journal of Child-Computer Interaction},
volume = {29},
pages = {100281},
year = {2021},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2021.100281},
url = {https://www.sciencedirect.com/science/article/pii/S2212868921000222},
author = {Henriikka Vartiainen and Tapani Toivonen and Ilkka Jormanainen and Juho Kahila and Matti Tedre and Teemu Valtonen},
keywords = {AI, Machine learning, K-12, Computational thinking, Design-oriented pedagogy, Design-based research},
abstract = {An entire generation of children is growing up with machine learning (ML) systems that are greatly disrupting job markets as well as changing people’s everyday lives. Yet, that development and its societal effects have been given minor attention in computing education in schools, which mainly focuses on rule-based programming. This article presents a pedagogical framework for supporting middle schoolers to become co-designers and makers of their own machine learning applications. It presents a case study conducted in the 6th grade of a Finnish elementary school and analyzes students’ (N=34) evolving ML ideas and explanations. Data consists of a children’s artwork, students’ design ideas and co-designed applications, and structured group interviews organized at the end of the ML project. The qualitative content analysis revealed how hands-on exploration with ML-based technologies supported students in developing various kinds of design ideas that harnessed face recognition, gestures, or voice recognition for solving real-life problems. The results of the study further indicated that co-designing ML applications provided a promising entry point for students to develop their conceptual understanding of ML principles, its workflows, and its role in their everyday practices. The article concludes with a discussion on how to support students to become innovators and software designers in the age of machine learning.}
}
@incollection{REIMERS2006119,
title = {[8] Bioconductor: An Open Source Framework for Bioinformatics and Computational Biology},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {411},
pages = {119-134},
year = {2006},
booktitle = {DNA Microarrays, Part B: Databases and Statistics},
issn = {0076-6879},
doi = {https://doi.org/10.1016/S0076-6879(06)11008-3},
url = {https://www.sciencedirect.com/science/article/pii/S0076687906110083},
author = {Mark Reimers and Vincent J. Carey},
abstract = {This chapter describes the Bioconductor project and details of its open source facilities for analysis of microarray and other high‐throughput biological experiments. Particular attention is paid to concepts of container and workflow design, connections of biological metadata to statistical analysis products, support for statistical quality assessment, and calibration of inference uncertainty measures when tens of thousands of simultaneous statistical tests are performed.}
}
@article{BJORNE2005193,
title = {A model of attentional impairments in autism: first steps toward a computational theory},
journal = {Cognitive Systems Research},
volume = {6},
number = {3},
pages = {193-204},
year = {2005},
note = {Epigenetic Robotics},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2004.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041704000749},
author = {Petra Björne and Christian Balkenius},
keywords = {Autism, Attention, Computational model},
abstract = {A computational model with three interacting components for context sensitive reinforcement learning, context processing and automation can autonomously learn a focus attention and a shift attention task. The performance of the model is similar to that of normal children, and when a single parameter is changed, the performance on the two tasks approaches that of autistic children.}
}
@article{REYNANTE2024102287,
title = {Reducing the cognitive abstractness of climate change through an “engineering fiction” learning experience: A natural language processing study},
journal = {Journal of Environmental Psychology},
volume = {95},
pages = {102287},
year = {2024},
issn = {0272-4944},
doi = {https://doi.org/10.1016/j.jenvp.2024.102287},
url = {https://www.sciencedirect.com/science/article/pii/S0272494424000604},
author = {Brandon Reynante and Nicole M. Ardoin and Roy Pea},
keywords = {Artificial intelligence, Climate change education, Climate fiction},
abstract = {The lackluster societal response to the climate crisis is partially attributed to the abstractness of people's mental construals of climate change given its vast spatial and temporal dimensions, which fail to evoke urgency to act. Prior efforts to measure mental construal levels of climate change are inconsistent, insufficient, and labor-intensive. This study developed and implemented learning experiences for integrating engineering design and climate fiction writing to engage 48 high school students in concrete climate change thinking. A novel measure of cognitive abstractness overcomes previous methodological shortcomings by automatically quantifying the linguistic abstractness of participant-authored stories using natural language processing. Comparing participant stories written at the beginning and end of the intervention reveals a significant decrease in linguistic abstractness (Cohen's d = 1.01, p = 0.03). This study contributes to the nascent movement for greater use of narratives as data sources in environmental psychology research, which may uncover new insights into human behavior and decision making.}
}