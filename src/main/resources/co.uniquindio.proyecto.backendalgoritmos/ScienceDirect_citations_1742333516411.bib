@article{MA201542,
title = {Towards computational models of animal cognition, an introduction for computer scientists},
journal = {Cognitive Systems Research},
volume = {33},
pages = {42-69},
year = {2015},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2014.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041714000357},
author = {Zhanshan (Sam) Ma},
keywords = {Animal cognition, Cognitive ecology, Social learning, Bioinspired computing and communication, Behavioral informatics, Computational behavior biology},
abstract = {The last few years of the twentieth century witnessed the emerging convergence of biology and computer science and this trend has been accelerating since then. The study of animal behavior or behavior biology has been one of the major contributors for this convergence. Behavior is fascinating because it is the response of an organism to internal and external signals and it is controlled by complex interactions among nerves, the sensory and the motor systems. To some extent, behavior is similar to the output (or response) of a computer system or a network node if we consider an animal brain as a computer node. This paper is the first in a two-part series in which I review the state-of-the-art research in behavior biology inspired computing and communication, with the first part focusing on animal cognition and the second part on animal communication (Ma, 2014). The present article also assumes the task of presenting a general introduction on behavior biology literature, which sets a foundation for synthesizing both parts of the series but the synthesis will be performed in the second part of the series. I sets three objectives in this ‘cognition’ part: (i) to present a brief overview on the literature of behavior biology for computer scientists; (ii) to summarize the state-of-the-art studies in several cognitive aspects of animal behavior: focusing on emerging research in cognitive ecology, social learning and innovation, as well as animal logics; (iii) to review some important existing studies inspired by animal behavior and further present a perspective on the future research. These cognition-related topics offer insights for research fields such as machine learning, human computer interactions (HCI), brain computer interfaces (BCIs), evolutionary computing, pervasive computing, etc. In perspective, I suggest that the interaction between behavioral biology and computer science should be bidirectional, and a new subject, behavioral informatics, or more general computational behavior biology, should be developed by the cooperative efforts between biologists and computer scientists.}
}
@incollection{GALLEGATI20173,
title = {Chapter 1 - An Introduction to Agent-Based Computational Macroeconomics},
editor = {Mauro Gallegati and Antonio Palestrini and Alberto Russo},
booktitle = {Introduction to Agent-Based Economics},
publisher = {Academic Press},
pages = {3-11},
year = {2017},
isbn = {978-0-12-803834-5},
doi = {https://doi.org/10.1016/B978-0-12-803834-5.00002-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128038345000023},
author = {Mauro Gallegati and Antonio Palestrini and Alberto Russo}
}
@article{LOONG2014237,
title = {Tourism and Simulacrum: The Computational Economy of Algorithmic Destinations},
journal = {Procedia - Social and Behavioral Sciences},
volume = {144},
pages = {237-246},
year = {2014},
note = {5th Asia-Euro Conference 2014 in Tourism, Hospitality & Gastronomy},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.07.292},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814042207},
author = {Bernard Lew Shian Loong},
keywords = {gamified tourism, algorithmic destinations, simulacrum, computational economics, tourism computability, reflexivity},
abstract = {The paper establishes a conceptual and methodological link between destinations and simulacrum through gamified tourism. As a paradigm, gamified tourism provides a rationale and a setting within which to apply computational economics to tourism, an approach amounting to tourism computability. Algorithmic destinations serve as “petri dishes” for real destinations. Utilizing rule sets that embody destination growth dynamics and visitor behavioural norms, seeding points in a cellular automata model (CA) were grown into algorithmic destinations. This is followed by a morphological transformation of geo-tagged satellite images into spatial points. The overlap of this additive and subtractive approach is at the core of tourism computability. Finally, the spatio-temporal dynamics of economic resilience was traced out through a visual phenomenology of algorithmic destinations. The gamification of tourism should be embraced as it holds up a flicker of hope for mature destinations, amidst the onset of museumification and increased commoditization of heritage sites. Gamification is treated as part of the reflexive cycle for destination authenticity; a notion that that Cohen (1988) alluded to in his discussion of emergent authenticity in destination image formation. Seen in this light, the museumification of Venice and the proliferation of its simulacrum, such as the Venetian Hotel in Macao and Venice-themed hotels across the globe, are prefigures and archetypes of a glorious age of gamified tourism.}
}
@article{OISHI2017327,
title = {Computational mechanics enhanced by deep learning},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {327},
pages = {327-351},
year = {2017},
note = {Advances in Computational Mechanics and Scientific Computation—the Cutting Edge},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2017.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S0045782517306199},
author = {Atsuya Oishi and Genki Yagawa},
keywords = {Deep learning, Artificial neural network, Numerical quadrature, Element stiffness matrix},
abstract = {The present paper describes a method to enhance the capability of, or to broaden the scope of computational mechanics by using deep learning, which is one of the machine learning methods and is based on the artificial neural network. The method utilizes deep learning to extract rules inherent in a computational mechanics application, which usually are implicit and sometimes too complicated to grasp from the large amount of available data A new method of numerical quadrature for the FEM stiffness matrices is developed by using the proposed method, where a kind of optimized quadrature rule superior in accuracy to the standard Gauss–Legendre quadrature is obtained on the element-by-element basis. The detailed formulation of the proposed method is given with the sample application above, and an acceleration technique for the proposed method is discussed}
}
@incollection{WARD201140,
title = {Analogies},
editor = {Mark A. Runco and Steven R. Pritzker},
booktitle = {Encyclopedia of Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {40-45},
year = {2011},
isbn = {978-0-12-375038-9},
doi = {https://doi.org/10.1016/B978-0-12-375038-9.00009-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780123750389000091},
author = {T.B. Ward},
keywords = {ACME, Analogy, Case study, Computational modeling,  study, Laboratory study, Mapping, Multiconstraint theory, One-to-one correspondence, Parallel connectivity, Retrieval, SME, Source domain, Structure-mapping theory, Systematicity, Target domain},
abstract = {Analogical thinking is a fundamental cognitive process underlying creativity. Analogies map structured knowledge from one domain to another and serve as information for understanding, explaining and creating. Analogy is studied through case study, laboratory, in vivo and computational modeling approaches. The use of analogy is often suggested to be a helpful technique in applied approaches to creativity.}
}
@article{ARDALAN2018170,
title = {Neurofinance versus the efficient markets hypothesis},
journal = {Global Finance Journal},
volume = {35},
pages = {170-176},
year = {2018},
issn = {1044-0283},
doi = {https://doi.org/10.1016/j.gfj.2017.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1044028317302715},
author = {Kavous Ardalan},
keywords = {Neurofinance, Behavioral finance, Costly thinking, Efficient markets hypothesis},
abstract = {This paper develops the implication of neurofinance with respect to the efficient markets hypothesis. Neurofinance informs us that thinking imposes strain on the mind, in the sense that thinking is a comparatively laborious, biologically costly, and neurologically expensive cognitive process. The paper shows that people balance the costs and benefits of thinking and demonstrates mathematically that such balancing makes financial markets inefficient.}
}
@article{WANG20241359,
title = {On Metaphor Translation into English Based on Artificial Intelligence},
journal = {Procedia Computer Science},
volume = {247},
pages = {1359-1365},
year = {2024},
note = {The 11th International Conference on Applications and Techniques in Cyber Intelligence},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.162},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924029636},
author = {Zikang Wang and Jinlian Chai},
keywords = {Artificial intelligence, English translation of metaphor, Machine translation},
abstract = {As a rhetorical device, metaphor plays an instrumental role in facilitating human thinking, cognition and communication. The translation of metaphors into English represents a significant challenge, involving cross-cultural, cross-linguistic and cross-domain considerations. In recent years, the rapid development of artificial intelligence has provided a new method and approach for English metaphor translation. This article mainly discusses the basic concept of artificial intelligence, puts forward the key technologies of metaphor translation in artificial intelligence, and then analyzes the difficulties and methods of metaphor translation with the purpose of providing a reference point and helpful insights.}
}
@article{TANG2024103266,
title = {A causal counterfactual graph neural network for arising-from-chair abnormality detection in parkinsonians},
journal = {Medical Image Analysis},
volume = {97},
pages = {103266},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103266},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524001919},
author = {Xinlu Tang and Rui Guo and Chencheng Zhang and Xiaohua Qian},
keywords = {Parkinson's disease, Arising-from-chair, Graph neural network, Causal inference, Counterfactual thinking},
abstract = {The arising-from-chair task assessment is a key aspect of the evaluation of movement disorders in Parkinson's disease (PD). However, common scale-based clinical assessment methods are highly subjective and dependent on the neurologist's expertise. Alternate automated methods for arising-from-chair assessment can be established based on quantitative susceptibility mapping (QSM) images with multiple-instance learning. However, performance stability for such methods can be typically undermined by the presence of irrelevant or spuriously-relevant features that mask the intrinsic causal features. Therefore, we propose a QSM-based arising-from-chair assessment method using a causal graph-neural-network framework, where counterfactual and debiasing strategies are developed and integrated into this framework for capturing causal features. Specifically, the counterfactual strategy is proposed to suppress irrelevant features caused by background noise, by producing incorrect predictions when dropping causal parts. The debiasing strategy is proposed to suppress spuriously relevant features caused by the sampling bias and it comprises a resampling guidance scheme for selecting stable instances and a causal invariance constraint for improving stability under various interferences. The results of extensive experiments demonstrated the superiority of the proposed method in detecting arising-from-chair abnormalities. Its clinical feasibility was further confirmed by the coincidence between the selected causal features and those reported in earlier medical studies. Additionally, the proposed method was extensible for another motion task of leg agility. Overall, this study provides a potential tool for automated arising-from-chair assessment in PD patients, and also introduces causal counterfactual thinking in medical image analysis. Our source code is publicly available at https://github.com/SJTUBME-QianLab/CFGNN-PDarising.}
}
@incollection{PERRI202255,
title = {Chapter 4 - High-performance computing and computational intelligence applications with a multi-chaos perspective},
editor = {Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis},
booktitle = {Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems},
publisher = {Academic Press},
pages = {55-76},
year = {2022},
isbn = {978-0-323-90032-4},
doi = {https://doi.org/10.1016/B978-0-323-90032-4.00010-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323900324000109},
author = {Damiano Perri and Marco Simonetti and Osvaldo Gervasi and Sergio Tasso},
keywords = {Cloud computing, Computational intelligence, Container, High performance computing, Machine learning, Multi-chaos, Neural networks, Privacy, Quantum computing},
abstract = {The experience of the COVID-19 pandemic, which has accelerated many chaotic processes in modern society, has highlighted in a very serious and urgent way the need to understand complex processes in order to achieve the common well-being. Modern high performance computing technologies, quantum computing, computational intelligence are shown to be extremely efficient and useful in safeguarding the fate of mankind. These technologies are the state-of-the-art of IT evolution and are fundamental to be competitive and efficient today. If a company is familiar with these techniques and technologies, it will be able to deal with any unexpected and complicated scenarios more efficiently and effectively. The main contribution of our work is a set of best practices and case studies that can help the researcher address computationally complex problems. We offer a range of software technologies, from high performance computing to machine learning and quantum computing, which represent today the state-of-the-art to deal with extremely complex computational issues, driven by chaotic events and not easily predictable. In this chapter we analyze the different technologies and applications that will lead mankind to overcome this difficult moment as well as to understand more and more deeply the profound aspects of very complex phenomena. In this environment of rising complexity, in terms of technology, algorithms, and changing lifestyles, it is critical to emphasize the importance of achieving maximum efficiency and outcomes while protecting the integrity of everyone's personal data and respecting the human being as a whole.}
}
@article{MATENCIO2021129639,
title = {A physicochemical, thermodynamical, structural and computational evaluation of kynurenic acid/cyclodextrin complexes},
journal = {Food Chemistry},
volume = {356},
pages = {129639},
year = {2021},
issn = {0308-8146},
doi = {https://doi.org/10.1016/j.foodchem.2021.129639},
url = {https://www.sciencedirect.com/science/article/pii/S0308814621006452},
author = {Adrián Matencio and Fabrizio Caldera and Alberto {Rubin Pedrazzo} and Yousef {Khazaei Monfared} and Nilesh {K. Dhakar} and Francesco Trotta},
keywords = {Kynurenic acid, Cyclodextrin, Inclusion complex, Physicochemical, Stability},
abstract = {In this work, the interaction between Kynurenic acid (KYNA) and several natural and modified cyclodextrins (CDs) is carried out. Among all the CD tested, HPβ-CD showed the strongest complexation constant (KF), with a value of 270.94 ± 29.80 M−1. Between natural (α- and β-) CDs, the complex of KYNA with β-CD was the most efficient. The inclusion complex of KYNA with CDs showed a strong influence of pH and temperature. The KF value decreased at high pH values, when the pKa was passed. Moreover, an increase of the temperature caused a decrease in the KF values. The thermodynamic parameters of the complexation (ΔH°, ΔS° and ΔG°) were studied with negative entropy, enthalpy and spontaneity of the process at 25 °C. Moreover, the inclusion complex was also characterized using FTIR and TGA. Finally, molecular docking calculations provided different interactions and their influence in the complexation constant.}
}
@article{WANG2007126,
title = {Nature-inspired Computation — Effective Realization of Artificial Intelligence},
journal = {Systems Engineering - Theory & Practice},
volume = {27},
number = {5},
pages = {126-134},
year = {2007},
issn = {1874-8651},
doi = {https://doi.org/10.1016/S1874-8651(08)60034-4},
url = {https://www.sciencedirect.com/science/article/pii/S1874865108600344},
author = {Lei WANG and Qi KANG and Qi-di WU},
keywords = {nature-inspired computation, general mode, uniform framework mode, neural networks, swarm intelligence},
abstract = {In nature-inspired computation, different intelligent computation modes of agents usually have different extrinsic forms; but can they take on some relative uniform characteristics? To validate this idea, further systematic study on nature-inspired computation from a more macroscopical angle is made in this article and the uniform framework mode of nature-inspired computation is consequently summarized and presented, as well as described with feedback neural network and swarm intelligence algorithms. On the basis of the defined general mode framework, agents of the algorithms in a nature-inspired computation field can show a type of uniform intelligent computation mode.}
}
@article{SU2021100862,
title = {Is the Text-Based Cognitive Tool More Effective Than the Concept Map on Improving the Pre-Service Teachers’ Argumentation Skills?},
journal = {Thinking Skills and Creativity},
volume = {41},
pages = {100862},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100862},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121000778},
author = {Guo Su and Taotao Long},
keywords = {Argumentation skills, cognitive tools, pre-service teachers},
abstract = {How to improve pre-service teachers’ argumentation skills has been receiving more and more attention from teacher educators. Visual cognitive tool refers to tools which users can learn with and creatively use to construct knowledge online. Current research revealed that it could help to improve learners’ higher-order thinking skills. This experimental study aimed to investigate the effect of two kinds of cognitive tools, the text-based online visual cognitive tool and the visual concept map, on improving the pre-service teachers’ skills on constructing and evaluating arguments. Post-test argumentation measurement scores and attitude questionnaire showed that the text-based cognitive tool was more effective than the concept map on improving pre-service teachers’ argumentation skills. However, the concept map was useful for externalizing the pre-service teachers’ thinking process as well as collaborative learning. This study also found that the pre-service teachers with teaching experience were inferior to the ones without any teaching experience in the ability on constructing arguments.}
}
@article{IBARRATORRES2024413,
title = {Use of basic programming tools to foster programming logic in university students with school preparation other than computer science},
journal = {Procedia Computer Science},
volume = {237},
pages = {413-419},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.122},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011384},
author = {Fernando Ibarra-Torres and Gustavo Caiza and Marcelo V. García and Valeria Barona-Pico},
keywords = {Programming logic, programming tools, software development, undergraduate student},
abstract = {Teaching programming logic to students who do not have a background in computer science is challenging, as the instructor has to awaken problem-solving, critical thinking, and logical reasoning skills Several programming tools have been created to teach coding concepts to computer science students of different ages. However, these tools are not well designed to meet the challenge of teaching programming to new developers who come with school training in other areas such as accounting, management, etc. Therefore, this research focused on analyzing the importance of the application of online programming tools to students starting college who come with a school background in an area other than technology. A pre/post experimental design was carried out with 82 first-level students of the Technical University of Ambato in the careers of Systems and Electronics. The results revealed that 45% of the students increased their levels of application and analysis in programming processes. In addition, the research revealed that students who come from a background other than computer science agree with the integration of online programming tools from the first level of university entrance since this method helps to improve their learning capacity.}
}
@article{KORIYAMA2021458,
title = {Inclusive cognitive hierarchy},
journal = {Journal of Economic Behavior & Organization},
volume = {186},
pages = {458-480},
year = {2021},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2021.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0167268121001578},
author = {Yukio Koriyama and Ali I. Ozkes},
keywords = {Cognitive hierarchy, Collective decision-making, Level- model, Strategic thinking},
abstract = {Cognitive hierarchy theory, a collection of structural models of non-equilibrium thinking, in which players’ best responses rely on heterogeneous beliefs on others’ strategies including naïve behavior, proved powerful in explaining observations from a wide range of games. We propose an inclusive cognitive hierarchy model, in which players do not rule out the possibility of facing opponents at their own thinking level. Our theoretical results show that inclusiveness is crucial for asymptotic properties of deviations from equilibrium behavior in expansive games. We show that the limiting behaviors are categorized in three distinct types: naïve, Savage rational with inconsistent beliefs, and sophisticated. We test the model in a laboratory experiment of collective decision-making. The data suggests that inclusiveness is indispensable with regard to explanatory power of the models of hierarchical thinking.}
}
@article{DALLACHIARA201894,
title = {A many-valued approach to quantum computational logics},
journal = {Fuzzy Sets and Systems},
volume = {335},
pages = {94-111},
year = {2018},
note = {Special Issue: Selected Papers from the 36th Linz Seminar on Fuzzy Set Theory},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2016.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0165011416304560},
author = {M.L. {Dalla Chiara} and R. Giuntini and G. Sergioli and R. Leporini},
keywords = {Quantum logics, Quantum tomography, Logical gates},
abstract = {Quantum computational logics are special examples of quantum logic where formulas are supposed to denote pieces of quantum information (qubit-systems or mixtures of qubit-systems), while logical connectives are interpreted as reversible quantum logical gates. Hence, any formula of the quantum computational language represents a synthetic logical description of a quantum circuit. We investigate a many-valued approach to quantum information, where the basic notion of qubit has been replaced by the more general notion of qudit. The qudit-semantics allows us to represent as reversible gates some basic logical operations of Łukasiewicz many-valued logics. In the final part of the article we discuss some problems that concern possible implementations of gates by means of optical devices.}
}
@incollection{LAWSON1990108,
title = {9 - Creative thinking},
editor = {Bryan Lawson},
booktitle = {How Designers Think (Second Edition)},
publisher = {Butterworth-Heinemann},
edition = {Second Edition},
pages = {108-120},
year = {1990},
isbn = {978-0-7506-0268-6},
doi = {https://doi.org/10.1016/B978-0-7506-0268-6.50013-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780750602686500139},
author = {Bryan Lawson},
abstract = {Publisher Summary
This chapter discusses creative thinking in design. Design is a creative occupation, and good designers are creative people. One of the most vexing and perennial questions in design education concerns the balance between the free, open-ended, and expressive work demanded of the student and attention to the acquisition of knowledge, discipline, and experience. The effects of experience on problem solving are not always beneficial. In industry, the need to improve already successful products provides the ultimate test of creative thinking. When using personal analogy, the problem solver identifies personally with some part of the problem or solution, thus acting out the situation. Fantasy analogy allows the designer to suspend the sense of credulity and to explore the seemingly fantastic or impossible. Creativity is not only skill or talent but is also related to context—the situation within which the person perceives the problem and performs the process.}
}
@article{MYERSCOUGH2014e143,
title = {Tracking the development of atherosclerosis in silico: a computational model for early inflammatory events},
journal = {Atherosclerosis},
volume = {235},
number = {2},
pages = {e143},
year = {2014},
issn = {0021-9150},
doi = {https://doi.org/10.1016/j.atherosclerosis.2014.05.404},
url = {https://www.sciencedirect.com/science/article/pii/S0021915014006406},
author = {M. Myerscough and A. Chalmers}
}
@article{PERFORS2012486,
title = {When do memory limitations lead to regularization? An experimental and computational investigation},
journal = {Journal of Memory and Language},
volume = {67},
number = {4},
pages = {486-506},
year = {2012},
issn = {0749-596X},
doi = {https://doi.org/10.1016/j.jml.2012.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X12000800},
author = {Amy Perfors},
keywords = {Regularization, Less is More, Computational modeling, Language acquisition},
abstract = {The Less is More hypothesis suggests that one reason adults and children differ in their ability to learn language is that they also differ in other cognitive capacities. According to one version of this hypothesis, children’s relatively poor memory may make them more likely to regularize inconsistent input (Hudson Kam and Newport, 2005, Hudson Kam and Newport, 2009). This paper reports the result of an experimental and computational investigation of one aspect of this version of the hypothesis. A series of seven experiments in which adults were placed under a high cognitive load during a language-learning task reveal that in adults, increased load during learning (as opposed to retrieval) does not result in increased regularization. A computational model offers a possible explanation for these results. It demonstrates that, unless memory limitations distort the data in a particular way, regularization should occur only in the presence of both memory limitations and a prior bias for regularization. Taken together, these findings suggest that the difference in regularization between adults and children may not be solely attributable to differences in memory limitations during learning.}
}
@article{KARPOVA2016v,
title = {Editorial overview: Neurobiology of cognitive behavior: Complexity of neural computation and cognition},
journal = {Current Opinion in Neurobiology},
volume = {37},
pages = {v-viii},
year = {2016},
note = {Neurobiology of cognitive behavior},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438816300125},
author = {Alla Karpova and Roozbeh Kiani}
}
@article{SUN200912529,
title = {A computational model of an intuitive reasoner for ecosystem control},
journal = {Expert Systems with Applications},
volume = {36},
number = {10},
pages = {12529-12536},
year = {2009},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2009.04.037},
url = {https://www.sciencedirect.com/science/article/pii/S0957417409003686},
author = {Yung-Chien Sun and Grant Clark},
keywords = {Artificial Intelligence, Intuition, Knowledge acquisition, Limited certainty},
abstract = {Intuition is the human capacity to make decisions under novel, complex situations where knowledge is incomplete and of variable levels of certainty. We take the view that intuition can be modeled as a rational and deductive mode of information processing which is suited to novel, complex situations. In this research, a computational algorithm, or “intuitive reasoner”, is proposed which mimics some aspects of human intuition by combining established mathematical tools, such as fuzzy set theory, and some novel innovations. A rule-based scheme is followed and a rule-learning module that allows rules to be learned from incomplete datasets is developed. The input and the rules drawn by the reasoner are allowed to be fuzzy, multi-valued, and low in certainty. A measure of the certainty level, Strength of Belief, is attached to each input as well as each rule. Solutions are formulated through iterations of consolidating intermediate reasoning results, during which the Strength of Belief of corroborating intermediate results is combined. An experimental implementation of the proposed intuitive reasoner is reported, in which the reasoner was used to solve a classification problem. The results showed that, when given increasingly sparse input data, the rule-learning module generated more rules of lower associated certainty than when presented with more complete data. The intuitive reasoner was able to make use of these low-certainty rules to solve the classification problems with an accuracy that compared favorably to that of traditional methods based on complete datasets.}
}
@article{DEHOLLANDER2016101,
title = {Different Ways of Linking Behavioral and Neural Data via Computational Cognitive Models},
journal = {Biological Psychiatry: Cognitive Neuroscience and Neuroimaging},
volume = {1},
number = {2},
pages = {101-109},
year = {2016},
issn = {2451-9022},
doi = {https://doi.org/10.1016/j.bpsc.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S2451902215000166},
author = {Gilles {de Hollander} and Birte U. Forstmann and Scott D. Brown},
keywords = {Cognition, Computational models, Functional neuroimaging, Joint modeling, Linking, Mathematical models},
abstract = {Cognitive neuroscientists sometimes apply formal models to investigate how the brain implements cognitive processes. These models describe behavioral data in terms of underlying, latent variables linked to hypothesized cognitive processes. A goal of model-based cognitive neuroscience is to link these variables to brain measurements, which can advance progress in both cognitive and neuroscientific research. However, the details and the philosophical approach for this linking problem can vary greatly. We propose a continuum of approaches that differ in the degree of tight, quantitative, and explicit hypothesizing. We describe this continuum using four points along it, which we dub qualitative structural, qualitative predictive, quantitative predictive, and single model linking approaches. We further illustrate by providing examples from three research fields (decision making, reinforcement learning, and symbolic reasoning) for the different linking approaches.}
}
@article{MARUYAMA1987437,
title = {New economic thinking: Morphogenetic causal loops and product adaptation strategy},
journal = {Futures},
volume = {19},
number = {4},
pages = {437-441},
year = {1987},
issn = {0016-3287},
doi = {https://doi.org/10.1016/0016-3287(87)90005-X},
url = {https://www.sciencedirect.com/science/article/pii/001632878790005X},
author = {Magoroh Maruyama},
abstract = {This article sets out to dispel two widespread economic superstitions—the belief in an inherent equilibrium of the economic system, and the perception of international trade as a zero-sum game. The author argues that morphogenetic causal loops disprove the first assumption, and should be used to aid policy making; and that positive-sum results could be obtained by lifting import restrictions and adapting products for foreign markets.}
}
@article{LEE2024107,
title = {Project-Based Learning Course Design for Multi-Agent Autonomy Using Quadrotors⁎⁎This group design project of academic year 2023/24 has been sponsored by Leonardo S.p.A.},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {16},
pages = {107-112},
year = {2024},
note = {2nd IFAC Workshop on Aerospace Control Education - WACE 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.08.470},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324012394},
author = {Hae-In Lee and Dmitry Ignatyev and Hyo-Sang Shin and Antonios Tsourdos},
keywords = {Project-Based Learning, Autonomous Multi-Agent System, Unmanned Aerial Vehicles, Quadrotor, Surveillance},
abstract = {This paper proposes a project-based learning course utilising multiple quadrotors, aiming to solidify and amplify technical knowledge and develop critical thinking capabilities. An engineering problem is provided as a surveillance mission with multiple quadrotors autonomously searching, detecting, and tracking ground vehicles. The course covers all stages of multi-agent autonomy development, from identiflying system requirements, designing software and hardware, to conducting demonstrations in a drone flying arena. During the course, students improve their ability to critically formulate, solve and evaluate engineering problems as well as gain and apply technical knowledge in all aspects of autonomy such as fight dynamics, control, navigation, guidance, task allocation, situational awareness and communication. The paper details the problem design, course timeline, outcomes, and key lessons learnt from the course.}
}
@article{SALAJ2024298,
title = {Competencies for Smart City Challenges},
journal = {IFAC-PapersOnLine},
volume = {58},
number = {3},
pages = {298-303},
year = {2024},
note = {22nd IFAC Conference on Technology, Culture and International Stability TECIS 2024},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2024.07.167},
url = {https://www.sciencedirect.com/science/article/pii/S2405896324002507},
author = {Alenka Temeljotov Salaj and Olav Torp and Elham Andalib},
keywords = {smart solutions, competencies, AI, education},
abstract = {It is acknowledged that technological innovation is needed in all sectors to cope with new demands. From social innovations, it introduces novel ideas, whether products, services, or models, to fulfil societal needs and foster new partnerships or collaborations. The aim is to enhance social interactions and elevate human well-being. Development of cutting-edge digital technologies is reality. The challenge is on human resource side, how quickly we can prepare employees to adapt to the requirements of Industry 4.0 and Society 5.0. In the paper, the new competencies were identified with the business stakeholders by conducting a survey among industry partners to recognize the requirements for the future labor market. The stakeholders in the construction field act as target groups for monitoring and development of the competencies. The focus of the result part is on the competencies companies mostly miss from their employees from digital perspectives, e.g. reason to hire highly educated people, training possibilities for digitally upskilling employees, lacking appropriate competencies (critical thinking, systems and analytical thinking, information management, advanced computer/IT skills (AI), ensuring security). Digital skills Advanced data/IT skills were the competencies in that companies defined as key competencies expected to be developed in 21st-century higher education employees. It is highly important to consider the job market needs for development and to adopt the engineering education system to be responsive to the needs of labor market.}
}
@article{DIAZ2021247,
title = {Evaluating Aspects of Usability in Video Game-Based Programming Learning Platforms},
journal = {Procedia Computer Science},
volume = {181},
pages = {247-254},
year = {2021},
note = {CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.141},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921001812},
author = {Jaime Díaz and Jeferson Arango López and Samuel Sepúlveda and Gabriel Mauricio {Ramírez Villegas} and Danay Ahumada and Fernando Moreira},
keywords = {Human-Computer Interaction, Usability, Video-games, Training, Computer Programming},
abstract = {Teaching computer programming is an important topic. Due to Science and Technology initiatives, these topics are considered in different training cycles. For higher education, students must cultivate fundamental concepts for the development of software applications, which not only contribute to the knowledge of programming languages but also to opening guidelines for computational thinking. However, selecting a proper tool can be complex. Especially for the diversity of alternatives on the web. Further, not all of them meet basic usability requirements. In this study, we present a set of platforms that seek to develop programming skills based on video games. The search consisted of 4 stages: (i) definition of the research questions, (ii) scope review, (iii) execution of search and (iv) platform selection. Finally, we employ a usability heuristic evaluation for a novice programming system to determine best practices.}
}
@article{READ2017237,
title = {Virtual personalities: Using computational modeling to understand within-person variability},
journal = {Journal of Research in Personality},
volume = {69},
pages = {237-249},
year = {2017},
note = {Within-Person Variability in Personality},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2016.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0092656616301738},
author = {Stephen J. Read and Benjamin J. Smith and Vitaliya Droutman and Lynn C. Miller},
keywords = {Virtual personalities, Within-person variability, Between-person variability, Social computational modeling},
abstract = {How can the same underlying psychological/neurobiological system result in both stable between-individual differences and high levels of within-individual variability in personality states over time and situations? We argue that both types of variability result from a psychological system based on structured, chronic motivations, where behavior at a specific point in time is a joint function of the current availability of motive affordances in the situation, current motivationally relevant bodily or interoceptive states, and the result of the competition among alternative active motives. Here we present a biologically-based theoretical framework, embodied in two different computational models, that shows how individuals with stable personality characteristics, can nevertheless exhibit considerable within-person variability in personality states across time and situations.}
}
@article{SHARMA2022132755,
title = {Conformational stability, quantum computational, spectroscopic, molecular docking and molecular dynamic simulation study of 2-hydroxy-1-naphthaldehyde},
journal = {Journal of Molecular Structure},
volume = {1259},
pages = {132755},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2022.132755},
url = {https://www.sciencedirect.com/science/article/pii/S0022286022004288},
author = {Arun Sharma and Ghazala Khanum and Anuj Kumar and Aysha Fatima and Meenakshi Singh and Khamael M. Abualnaja and Khaled Althubeiti and S. Muthu and Nazia Siddiqui and Saleem Javed},
keywords = {DFT studies, Fukui Function, MEP, ELF, Hirshfeld, Molecular docking},
abstract = {Experimental FTIR, NMR and UV-visible spectrum analyses were used to describe the title compound 2-Hydroxy-1-Naphthaldehyde. The optimized molecular geometry and vibrational wave numbers were determined by using the DFT approach and B3LYP/6-311++G(d, p) basis set. VEDA was used to determine the vibrational assignments. The GIAO technique was used to compute carbon and proton NMR chemical shifts in CDCl3. The most reactive location of the 2H1NA molecule, according to MEP map analysis, is the site containing the oxygen atom. TD-DFT approach was used to produce the theoretical UV-visible spectrum in MeOH and gas phase. HOMO-LUMO and Donor-Acceptor (NBO) interactions were investigated for the title compound. In addition, nonlinear optical characteristics, ELF and Fukui activity were investigated. Temperature-dependent thermodynamic characteristics were also computed. The 3D intermolecular interactions of the crystal surface were characterised using Hirshfeld surface analysis, whereas the 2D interactions were explained using fingerprint plots. 2H1NA was stabilized by the development of H—H/H—C/H—O contacts. The bioactive probability of the title molecule was theoretically demonstrated by computing the electrophilicity index. In a biological study six different receptors, molecular docking was performed to evaluate the best ligand-protein interactions and likeness to the active substance. Biomolecular stability was investigated using a molecular dynamics simulation.}
}
@article{MAITY2016152,
title = {A Computational Model to Predict Aesthetic Quality of Text Elements of GUI},
journal = {Procedia Computer Science},
volume = {84},
pages = {152-159},
year = {2016},
note = {Proceeding of the Seventh International Conference on Intelligent Human Computer Interaction (IHCI 2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.04.081},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916300965},
author = {Ranjan Maity and Akshay Madrosiya and Samit Bhattacharya},
keywords = {Aesthetics, web page, text elements, aesthetic score, categorization},
abstract = {The role of aesthetics in determining usability of interactive systems has come under focus in recent time. The issue is relevant for Graphical User Interfaces (GUI) containing elements of widely varying nature. It is important to evaluate GUI aesthetically to determine their acceptability to the users. Computational models have been reported in the literature to perform objective assessment of interface aesthetics. However, the existing models only consider geometric features at the highest level, without considering the content inside the geometry. To address this issue, we propose a computational model to evaluate aesthetics of textual contents present on a GUI. The proposed model is based on empirical data collected from user studies. The model is a weighted sum of six features characterizing text: chromatic contrast, luminance contrast, font size, letter spacing, line height and word spacing. A separate validation study demonstrates the feasibility and potential of the model (showing 87% accuracy in model prediction), which is expected to be useful in predicting usability of a web page in a more refined way. Such modeling has its obvious implications in the context of engineering interactive systems. The proposed model along with the user studies are presented in this paper.}
}
@article{NOWICKI2012324,
title = {Improving the computational efficiency of metric-based spares algorithms},
journal = {European Journal of Operational Research},
volume = {219},
number = {2},
pages = {324-334},
year = {2012},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2011.12.033},
url = {https://www.sciencedirect.com/science/article/pii/S0377221711011271},
author = {David R. Nowicki and Wesley S. Randall and Jose Emmanuel Ramirez-Marquez},
keywords = {Inventory, Performance based logistics, Logistics, Supply chain, Optimization, Outcome based contracting},
abstract = {We propose a new heuristic algorithm to improve the computational efficiency of the general class of Multi-Echelon Technique for Recoverable Item Control (METRIC) problems. The objective of a METRIC-based decision problem is to systematically determine the location and quantity of spares that either maximizes the operational availability of a system subject to a budget constraint or minimizes its cost subject to an operational availability target. This type of sparing analysis has proven essential when analyzing the sustainment policies of large-scale, complex repairable systems such as those prevalent in the defense and aerospace industries. Additionally, the frequency of these sparing studies has recently increased as the adoption of performance-based logistics (PBL) has increased. PBL represents a class of business strategies that converts the recurring cost associated with maintenance, repair, and overhaul (MRO) into cost avoidance streams. Central to a PBL contract is a requirement to perform a business case analysis (BCA) and central to a BCA is the frequent need to use METRIC-based approaches to evaluate how a supplier and customer will engage in a performance based logistics arrangement where spares decisions are critical. Due to the size and frequency of the problem there exists a need to improve the efficiency of the computationally intensive METRIC-based solutions. We develop and validate a practical algorithm for improving the computational efficiency of a METRIC-based approach. The accuracy and effectiveness of the proposed algorithm are analyzed through a numerical study. The algorithm shows a 94% improvement in computational efficiency while maintaining 99.9% accuracy.}
}
@article{MOUTOUSSIS20212025,
title = {Decision-making ability, psychopathology, and brain connectivity},
journal = {Neuron},
volume = {109},
number = {12},
pages = {2025-2040.e7},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321002853},
author = {Michael Moutoussis and Benjamín Garzón and Sharon Neufeld and Dominik R. Bach and Francesco Rigoli and Ian Goodyer and Edward Bullmore and Peter Fonagy and Peter Jones and Tobias Hauser and Rafael Romero-Garcia and Michelle {St Clair} and Petra Vértes and Kirstie Whitaker and Becky Inkster and Gita Prabhu and Cinly Ooi and Umar Toseeb and Barry Widmer and Junaid Bhatti and Laura Villis and Ayesha Alrumaithi and Sarah Birt and Aislinn Bowler and Kalia Cleridou and Hina Dadabhoy and Emma Davies and Ashlyn Firkins and Sian Granville and Elizabeth Harding and Alexandra Hopkins and Daniel Isaacs and Janchai King and Danae Kokorikou and Christina Maurice and Cleo McIntosh and Jessica Memarzia and Harriet Mills and Ciara O’Donnell and Sara Pantaleone and Jenny Scott and Pasco Fearon and John Suckling and Anne-Laura {van Harmelen} and Rogier Kievit and Marc Guitart-Masip and Raymond J. Dolan},
keywords = {decision acuity, computational psychiatry, functional connectivity, adolescence, development},
abstract = {Summary
Decision-making is a cognitive process of central importance for the quality of our lives. Here, we ask whether a common factor underpins our diverse decision-making abilities. We obtained 32 decision-making measures from 830 young people and identified a common factor that we call “decision acuity,” which was distinct from IQ and reflected a generic decision-making ability. Decision acuity was decreased in those with aberrant thinking and low general social functioning. Crucially, decision acuity and IQ had dissociable brain signatures, in terms of their associated neural networks of resting-state functional connectivity. Decision acuity was reliably measured, and its relationship with functional connectivity was also stable when measured in the same individuals 18 months later. Thus, our behavioral and brain data identify a new cognitive construct that underpins decision-making ability across multiple domains. This construct may be important for understanding mental health, particularly regarding poor social function and aberrant thought patterns.}
}
@article{KOTAGODAHETTI2024118926,
title = {Life cycle-based multi-objective model for optimal gaseous fuel generation and portfolio allocation in gas grids: A strategic decarbonization},
journal = {Energy Conversion and Management},
volume = {319},
pages = {118926},
year = {2024},
issn = {0196-8904},
doi = {https://doi.org/10.1016/j.enconman.2024.118926},
url = {https://www.sciencedirect.com/science/article/pii/S0196890424008677},
author = {Ravihari Kotagodahetti and Kasun Hewage and Ezzeddin Bakhtavar and Rehan Sadiq},
keywords = {Biomethane, Hydrogen, Environmental impacts, Economic impacts, Life cycle thinking, Multi-objective optimization},
abstract = {Biomethane and hydrogen are acknowledged as transformative opportunities for decarbonizing the conventional gas grid. Essential to this transformation is the modeling of the gaseous fuel supply chain, particularly with hydrogen and biomethane, offering crucial insights for decision-makers. This study introduces a life cycle thinking-based multi-objective optimization model for the integrated design of biomethane and hydrogen gaseous fuel supply chain networks. The model determines optimal resource allocation for the production of the two fuels, integrating them into the conventional gas network. Moreover, it allocates conventional natural gas, biomethane, and hydrogen optimally across building, industry, and transport sectors, considering the life cycle environmental and economic performance of fuel integration paths. Objective functions include minimization of life cycle emissions and levelized cost of energy while maximizing revenue from fuel sales. Integrating life cycle assessment and cost analysis tools, the optimization model quantifies emissions and life cycle costs for biomethane and hydrogen paths. Results identify Pareto-optimal fuel production paths and portfolios, revealing that integrating the alternative fuels into the current gas grid can significantly reduce emissions (up to 250 tonCO2eq/year) and generate substantial carbon tax savings (up to $16,250/year). This model is useful for gaseous fuel industry stakeholders, offering a comprehensive view of supply chain costs and detailed insights into emission benefits when integrating alternative fuels into existing gas networks.}
}
@incollection{KANELLOPOULOS2024111,
title = {Chapter Five - Adversarial modeling},
editor = {Aris Kanellopoulos and Lijing Zhai and Filippos Fotiadis and Kyriakos G. Vamvoudakis},
booktitle = {Control and Game Theoretic Methods for Cyber-Physical Security},
publisher = {Academic Press},
pages = {111-170},
year = {2024},
series = {Emerging Methodologies and Applications in Modelling, Identification and Control},
isbn = {978-0-443-15408-9},
doi = {https://doi.org/10.1016/B978-0-44-315408-9.00011-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443154089000117},
author = {Aris Kanellopoulos and Lijing Zhai and Filippos Fotiadis and Kyriakos G. Vamvoudakis},
keywords = {Bounded rationality, Differential games, Attack prediction},
abstract = {In this chapter we utilize results from game theory to model the interactions of the CPS operator with different types of adversarial agents. To approach accurate prediction of realistic attacks, we present and exploit results from behavioral game theory, namely level-k thinking and cognitive hierarchy. Finally, we propose a method of predicting future adversarial behavior of adapting, learning opponents.}
}
@article{SLOOT2010189,
title = {Computational science: A kaleidoscopic view into science},
journal = {Journal of Computational Science},
volume = {1},
number = {4},
pages = {189},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000694},
author = {Peter M.A. Sloot}
}
@article{MANTELERO2014643,
title = {The future of consumer data protection in the E.U. Re-thinking the “notice and consent” paradigm in the new era of predictive analytics},
journal = {Computer Law & Security Review},
volume = {30},
number = {6},
pages = {643-660},
year = {2014},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2014.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S026736491400154X},
author = {Alessandro Mantelero},
keywords = {Data protection, Consent, Data protection impact assessment, Big Data, Data protection authorities},
abstract = {The new E.U. proposal for a general data protection regulation has been introduced to give an answer to the challenges of the evolving digital environment. In some cases, these expectations could be disappointed, since the proposal is still based on the traditional main pillars of the last generation of data protection laws. In the field of consumer data protection, these pillars are the purpose specification principle, the use limitation principle and the “notice and consent” model. Nevertheless, the complexity of data processing, the power of modern analytics and the “transformative” use of personal information drastically limit the awareness of consumers, their capability to evaluate the various consequences of their choices and to give a free and informed consent. To respond to the above, it is necessary to clarify the rationale of the “notice and consent” paradigm, looking back to its origins and assessing its effectiveness in a world of predictive analytics. From this perspective, the paper considers the historical evolution of data protection and how the fundamental issues coming from the technological and socio-economic contexts have been addressed by regulations. On the basis of this analysis, the author suggests a revision of the “notice and consent” model focused on the opt-in and proposes the adoption of a different approach when, such as in Big Data collection, the data subject cannot be totally aware of the tools of analysis and their potential output. For this reason, the author sustains the provision of a subset of rules for Big Data analytics, which is based on a multiple impact assessment of data processing, on a deeper level of control by data protection authorities, and on the different opt-out model.}
}
@article{CHIASTRA20162102,
title = {Computational replication of the patient-specific stenting procedure for coronary artery bifurcations: From OCT and CT imaging to structural and hemodynamics analyses},
journal = {Journal of Biomechanics},
volume = {49},
number = {11},
pages = {2102-2111},
year = {2016},
note = {Selected Articles from the International Conference on CFD in Medicine and Biology (Albufeira, Portugal – August 30th - September 4th, 2015)},
issn = {0021-9290},
doi = {https://doi.org/10.1016/j.jbiomech.2015.11.024},
url = {https://www.sciencedirect.com/science/article/pii/S0021929015006661},
author = {Claudio Chiastra and Wei Wu and Benjamin Dickerhoff and Ali Aleiou and Gabriele Dubini and Hiromasa Otake and Francesco Migliavacca and John F. LaDisa},
keywords = {Mathematical model, Finite element analysis, Computational fluid dynamics, Coronary bifurcation, Stent},
abstract = {The optimal stenting technique for coronary artery bifurcations is still debated. With additional advances computational simulations can soon be used to compare stent designs or strategies based on verified structural and hemodynamics results in order to identify the optimal solution for each individual’s anatomy. In this study, patient-specific simulations of stent deployment were performed for 2 cases to replicate the complete procedure conducted by interventional cardiologists. Subsequent computational fluid dynamics (CFD) analyses were conducted to quantify hemodynamic quantities linked to restenosis. Patient-specific pre-operative models of coronary bifurcations were reconstructed from CT angiography and optical coherence tomography (OCT). Plaque location and composition were estimated from OCT and assigned to models, and structural simulations were performed in Abaqus. Artery geometries after virtual stent expansion of Xience Prime or Nobori stents created in SolidWorks were compared to post-operative geometry from OCT and CT before being extracted and used for CFD simulations in SimVascular. Inflow boundary conditions based on body surface area, and downstream vascular resistances and capacitances were applied at branches to mimic physiology. Artery geometries obtained after virtual expansion were in good agreement with those reconstructed from patient images. Quantitative comparison of the distance between reconstructed and post-stent geometries revealed a maximum difference in area of 20.4%. Adverse indices of wall shear stress were more pronounced for thicker Nobori stents in both patients. These findings verify structural analyses of stent expansion, introduce a workflow to combine software packages for solid and fluid mechanics analysis, and underscore important stent design features from prior idealized studies. The proposed approach may ultimately be useful in determining an optimal choice of stent and position for each patient.}
}
@article{HUANGHUANG2023315,
title = {Teacher educator learning to implement equitable mathematics teaching using technology through lesson study},
journal = {International Journal for Lesson and Learning Studies},
volume = {12},
number = {4},
pages = {315-329},
year = {2023},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-05-2023-0049},
url = {https://www.sciencedirect.com/science/article/pii/S2046825323000537},
author = {RongjinRongjin HuangHuang and Christopher T.Christopher T. BonnesenBonnesen and Amanda LakeAmanda Lake HeathHeath and Jennifer M.Jennifer M. SuhSuh},
keywords = {Equitable instruction, Technology, Teacher educator learning, Lesson study},
abstract = {Purpose
This paper examines how mathematics teacher educators (MTEs) learn to enact equitable mathematics instruction using technology through lesson study (LS).
Design/methodology/approach
A LS team with three MTEs conducted three iterations of LS on teaching the Pythagorean Theorem in an in-person, technology-mediated environment. Many forms of data were collected: Desmos activities, videos of research lessons (RLs), videos of MTE RL debriefings, artifacts of student learning in the Desmos Dashboard, and MTEs' written self-reflection. The authors investigate the teacher educators' learning through LS by analyzing the MTE debriefings of the RLs using Bannister’s (2015) framework for teacher learning in communities of practice.
Findings
The MTEs learned to enact equitable mathematics instruction using technology through addressing emerging issues related to intellectual authority and use of student thinking. Throughout the LS, the MTEs sought ways of promoting students' mathematical authority and using student thinking through features of the Desmos platform.
Research limitations/implications
This study focuses on MTEs' learning without examining participating preservice teachers' learning. It demonstrates the benefits of LS for MTEs' professional learning.
Practical implications
This study showcases how a research-based Desmos activity is used and refined to promote MTE learning how to implement equitable mathematics instruction.
Originality/value
The study contributes to better understanding of how LS could be used to develop MTEs' professional learning. Moreover, the dual process of participation and reification was concretized through diagnostic and prognostic frames in the LS context, which enriches the concept of community of practice.}
}
@article{BATINI2025101896,
title = {Shared reading aloud fosters intelligence: Three cluster-randomized control trials in elementary and middle school},
journal = {Intelligence},
volume = {108},
pages = {101896},
year = {2025},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2024.101896},
url = {https://www.sciencedirect.com/science/article/pii/S0160289624000904},
author = {Federico Batini and Marco Bartolucci and Giulia Toti and Emanuele Castano},
keywords = {Intelligence, Cognitive development, Narrative fiction, Storytelling, Reading},
abstract = {Storytelling played a crucial role in human evolution. To this day, through stories humans gain declarative and procedural knowledge, and learn the skills that support learning itself. Research shows that reading stories to children enhances their reading and language skills. Does it also enhance their intelligence? To answer this question, we conducted three (N = 626, 254, 195) longitudinal, cluster-randomized control trials in Italian elementary and middle schools. Over a 4-month period, for half of the participants 1 h/day of standard, active language instructional activities were substituted with reading-aloud of stories by a teacher. Compared to those who kept doing language instructional activities, read-aloud condition children showed a stronger increase on two measures of intelligence focusing on knowing things and thinking skills. This result, which emerged in three independent trials conducted in different regions of Italy, suggests avenues for easily scalable interventions to improve children's intelligence.}
}
@article{PRADIPA20241213,
title = {Malang Voyage: A sustainable digital landscape in Malang City},
journal = {Procedia Computer Science},
volume = {245},
pages = {1213-1224},
year = {2024},
note = {9th International Conference on Computer Science and Computational Intelligence 2024 (ICCSCI 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.351},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924031594},
author = {I Gede Cahya Pradipa and Yudhistya Ayu Kusumawati and Yongkie Angkawijaya},
keywords = {Sustainable tourism, Tourism development, Digital infrastructure, Malang City},
abstract = {In the scope of global tourism, Malang stands as a potential yet underutilized tourism city. Known as the "Paris of East Java," its captivating landscapes and pleasant climate offer a unique experience. Despite this, the city's tourism sector remains underdeveloped, evident from the low number of visitors compared to what it has to offer. Existing studies reveal the city's yet undiscovered potential, especially in city tourism, cultural experiences, and culinary. However, limited information and digital infrastructure pose significant challenges. This research addresses these gaps, proposing the development of a robust digital platform in the form of a dedicated social media travel hub for Malang's sustainable tourism. By utilizing design thinking methodology, the study aims to revolutionize how tourists access information and interact with local attractions. It hypothesizes that a well-designed digital infrastructure will enhance the city's tourism quality, attracting more visitors. Additionally, adopting sustainable tourism principles will further boost Malang's tourism industry. This research is not just a digital upgrade, it's a transformative journey, paving the way for Malang to emerge as a sustainable tourism hub. Through innovative design and a user-focused approach, this study is set to unlock Malang's full tourism potential of balanced growth with environmental and cultural preservation.}
}
@article{MARTINEZLEDESMA20203567,
title = {Computational methods for detecting cancer hotspots},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3567-3576},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304876},
author = {Emmanuel Martinez-Ledesma and David Flores and Victor Trevino},
keywords = {Mutations, Cancer, Hotspots, Recurrent mutations, Algorithms, Genomics, Sequencing, Exome, Whole genome sequencing},
abstract = {Cancer mutations that are recurrently observed among patients are known as hotspots. Hotspots are highly relevant because they are, presumably, likely functional. Known hotspots in BRAF, PIK3CA, TP53, KRAS, IDH1 support this idea. However, hundreds of hotspots have never been validated experimentally. The detection of hotspots nevertheless is challenging because background mutations obscure their statistical and computational identification. Although several algorithms have been applied to identify hotspots, they have not been reviewed before. Thus, in this mini-review, we summarize more than 40 computational methods applied to detect cancer hotspots in coding and non-coding DNA. We first organize the methods in cluster-based, 3D, position-specific, and miscellaneous to provide a general overview. Then, we describe their embed procedures, implementations, variations, and differences. Finally, we discuss some advantages, provide some ideas for future developments, and mention opportunities such as application to viral integrations, translocations, and epigenetics.}
}
@incollection{GEYER2020125,
title = {Chapter 6 - Physical meets digital: Blending reality and computational power with digital sticky notes},
editor = {Bo T. Christensen and Kim Halskov and Clemens N. Klokmose},
booktitle = {Sticky Creativity},
publisher = {Academic Press},
pages = {125-151},
year = {2020},
series = {Explorations in Creativity Research},
isbn = {978-0-12-816566-9},
doi = {https://doi.org/10.1016/B978-0-12-816566-9.00006-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128165669000069},
author = {Florian Geyer and Johannes Zagermann and Harald Reiterer},
keywords = {Affinity diagramming, Blended interaction, Post-WIMP user interface, Interaction design, Tangible user interface, User interface design framework, Creativity tool},
abstract = {The high utility and usability of paper sticky notes support workflows and social dynamics of collaborative design activities and methods like affinity diagramming. In this chapter, we show how these natural collaboration activities can be blended with computational power by applying our framework Blended Interaction for a case study on affinity diagramming. Based on four domains of design, we embed our design solutions in a specific physical environment, preserve workflows, and emphasize individual and social interaction. Our proposed design solution to augment sticky notes with digital power blends the benefits of physical materials with the digital power of interactive surfaces, tangibles, and digital pens in an outstanding way. We hope that our design solutions inspire other researchers and practitioners to find innovative solutions that carefully blend real-world practices with the power of digital computing.}
}
@article{BULLOCK2009757,
title = {Computational perspectives on forebrain microcircuits implicated in reinforcement learning, action selection, and cognitive control},
journal = {Neural Networks},
volume = {22},
number = {5},
pages = {757-765},
year = {2009},
note = {Advances in Neural Networks Research: IJCNN2009},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2009.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608009001117},
author = {Daniel Bullock and Can Ozan Tan and Yohan J. John},
keywords = {Basal ganglia, Acetylcholine, Dopamine, Striatum, Decision making},
abstract = {Abundant new information about signaling pathways in forebrain microcircuits presents many challenges, and opportunities for discovery, to computational neuroscientists who strive to bridge from microcircuits to flexible cognition and action. Accurate treatment of microcircuit pathways is especially critical for creating models that correctly predict the outcomes of candidate neurological therapies. Recent models are trying to specify how cortical circuits that enable planning and voluntary actions interact with adaptive subcortical microcircuits in the basal ganglia. The basal ganglia are strongly implicated in reinforcement learning, and in all behavior and cognition over which the frontal lobes exert flexible control. The persisting role of the basal ganglia shows that ancient vertebrate designs for motivated action selection proved adaptable enough to support many “modern” behavioral innovations, including fluent generation of language and speech. This paper summarizes how recent models have incorporated realistic representations of microcircuit features, and have begun to trace their computational implications. Also summarized are recent empirical discoveries that provide guidance regarding how to formulate the rules for synaptic modification that govern learning in cortico-striatal pathways. Such efforts are contributing to an emerging synthesis based on an interlocking set of computational hypotheses regarding cortical interactions with basal ganglia and thalamic nuclei. These hypotheses specify how specialized microcircuits solve learning and control problems inherent to the brain’s parallel design.}
}
@article{BROM20121,
title = {A computational model of the allocentric and egocentric spatial memory by means of virtual agents, or how simple virtual agents can help to build complex computational models},
journal = {Cognitive Systems Research},
volume = {17-18},
pages = {1-24},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000404},
author = {Cyril Brom and Jan Vyhnánek and Jiří Lukavský and David Waller and Rudolf Kadlec},
keywords = {Spatial cognition, Paradigm of pointing, Disorientation effect, Intelligent virtual agent},
abstract = {The ability to acquire, remember and use information about locations of objects in one’s proximal surrounding is a fundamental aspect of human spatial cognition. In this paper, we present a computational model of this ability. The model provides a possible explanation of contradictory results from experimental psychology related to this ability, namely explanation of why some experiments have reproduced the so-called “disorientation effect” while others have failed to do so. Additionally, in contrast to other computational models of various aspects of spatial cognition, our model is integrated within an intelligent virtual agent. Thus, on a more general level, this paper also demonstrates that it is possible to use intelligent virtual agents as a powerful research tool in computational cognitive sciences.}
}
@article{LIGOMENIDES200910,
title = {The reality of Mathematics},
journal = {Journal of Computational and Applied Mathematics},
volume = {227},
number = {1},
pages = {10-16},
year = {2009},
note = {Special Issue of Proceedings of NUMAN 2007 Conference: Recent Approaches to Numerical Analysis: Theory, Methods and Applications},
issn = {0377-0427},
doi = {https://doi.org/10.1016/j.cam.2008.07.029},
url = {https://www.sciencedirect.com/science/article/pii/S0377042708003257},
author = {Panos A. Ligomenides},
keywords = {Languages of mathematics, Mathematical reality, Information science, Cyber-world},
abstract = {The power of mathematics is discussed as a way of expressing reasoning, aesthetics and insight in symbolic non-verbal communication. The human culture of discovering mathematical ways of thinking in the enterprise of exploring the understanding of the nature and the evolution of our world through hypotheses, theories and experimental affirmation of the scientific notion of algorithmic and non-algorithmic ‘computation’, is examined and commended upon.}
}
@article{MAVRIDIS202311223,
title = {Attack Identification for Cyber-Physical Security in Dynamic Games under Cognitive Hierarchy},
journal = {IFAC-PapersOnLine},
volume = {56},
number = {2},
pages = {11223-11228},
year = {2023},
note = {22nd IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2023.10.851},
url = {https://www.sciencedirect.com/science/article/pii/S2405896323012314},
author = {Christos N. Mavridis and Aris Kanellopoulos and Kyriakos G. Vamvoudakis and John S. Baras and Karl Henrik Johansson},
abstract = {This paper considers the problem of identifying the profiles and capabilities of attackers injecting adversarial inputs to a cyber-physical system. The system in question interacts with attackers of different levels of intelligence, each employing different feedback controllers against the system. Principles of behavioral game theory – specifically the concept of level-k thinking – is employed to construct a database of potential attack vectors. By observing the state trajectories under sequential interactions with different adversaries, the defender adaptively estimates both the number and profiles of the different attack signals using an online deterministic annealing approach. This information is used to dynamically estimate the level of intelligence of the attackers. Simulation results showcase the efficacy of the proposed method.}
}
@article{RAZ2024101598,
title = {Open and closed-ended problem solving in humans and AI: The influence of question asking complexity},
journal = {Thinking Skills and Creativity},
volume = {53},
pages = {101598},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101598},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001366},
author = {Tuval Raz and Roni Reiter-Palmon and Yoed N. Kenett},
keywords = {Question asking, Problem-solving, AI, Creativity},
abstract = {Question-asking, an underexplored aspect of creativity, is integral to creative problem-solving and information-seeking. Previous research reveals that lower creativity correlates with asking simpler, closed questions, while higher creativity correlates with complex, open-ended inquiries. The present study explores the relation between question asking complexity and problem-solving tasks involving open- and close-ended thinking and how these abilities generalize and compare to AI. In Study 1, participants (N = 89) completed the alternative questions task (AQT), a close-ended riddles task (Stumpers), and the alternate uses task (AUT), a creativity measure. Our results show AQT question complexity wasn't correlated with stumpers performance, although it correlated with AUT originality (r = .3). In Study 2, participants (N = 100) completed the AQT, AUT, and open-ended creative problem-solving (CPS) task. CPS responses were evaluated for originality and quality. A positive correlation was observed between CPS quality and AQT complexity (r = .29) and originality (r = .34). In study 3, AI agents (N = 100) completed the AQT, AUT, stumpers, and CPS tasks. Like humans, AI's AQT originality and complexity were related with open, but not closed problem-solving. AI questions were also significantly more creative and complex, it solved more stumpers and gave higher quality CPS solutions. Surprisingly, human and AI CPS originality didn't differ. We find significant links between question complexity and open—but not closed-ended—problem-solving in humans, which generalize to AI. Our results highlight the significance of complex and creative question-asking in everyday life and as an integral part of our problem-solving toolkit.}
}
@article{LIN2021103944,
title = {Lessons learned from critical accidental fires in tunnels},
journal = {Tunnelling and Underground Space Technology},
volume = {113},
pages = {103944},
year = {2021},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2021.103944},
url = {https://www.sciencedirect.com/science/article/pii/S0886779821001358},
author = {Chien Liang Lin and Chao Fu Chien},
keywords = {Systems thinking, Lessons learned, Accidental tunnel fires, Causal loop diagram},
abstract = {Historical data indicate that tunnel fires often cause casualties and damage to both vehicles and tunnels. These severe consequences suggest that (1) humans seldom effectively learn from history, and (2) people lack optimal safety response strategies for tunnel fires. To investigate the root causes of accidental tunnel fires and learn from them, we first surveyed the literature on historical tunnel accidents and described the common timeline of accidental tunnel fires. We employed systems thinking, based on the past research, to depict a causal loop diagram of common accidental tunnel fires. We arrived at the following three findings: (1) the literature review proved that the causes of tunnel fires are far more complex than other types of fires, and the damage they generate is greater; (2) in the context of systems thinking, accidental tunnel fires involve many causal relationships which are both continuous and dynamic, including at least three systems, namely vehicles, tunnel control, and safety response; (3) the mental models “the experience of the operators at the tunnel operation control center is just as vital as the safety response” and “safety is more critical than the traffic volume in the tunnel”, can strengthen safety response systems and ensure safe driving in tunnels. Although the structure of each tunnel and the characteristics of each fire differ and present different causal relationships, this study elucidated lessons from accidental tunnel fires and provided required messages for establishing effective safety measures. The results of this study can be used to establish systems thinking models of tunnel fires and can serve as a reference for policy planning and establishing standard operating procedures for safety responses.}
}
@article{LIU20183231,
title = {Nickel catalyzed regio- and stereoselective arylation and methylation of allenamides via coupling reactions. An experimental and computational study11Electronic supplementary information (ESI) available. CCDC 1548725 and 1817608. For ESI and crystallographic data in CIF or other electronic format see DOI: 10.1039/c8qo00729b},
journal = {Organic Chemistry Frontiers},
volume = {5},
number = {22},
pages = {3231-3239},
year = {2018},
issn = {2052-4129},
doi = {https://doi.org/10.1039/c8qo00729b},
url = {https://www.sciencedirect.com/science/article/pii/S2052411022005156},
author = {Yang Liu and Alessandro Cerveri and Assunta {De Nisi} and Magda Monari and Olalla {Nieto Faza} and Carlos Silva Lopez and Marco Bandini},
abstract = {The nickel catalyzed regio- and stereoselective condensation of boronic acids to allenamides is documented as a novel synthetic route to stereochemically defined tri-substituted enamides. The protocol has been implemented into a three-component variant intercepting the in situ formed allyl-Ni intermediate with a range of aldehydes. Additionally, evidence for the effective extension of this methodology to Me2Zn is documented. Full rationale on the mechanism as well as its stereochemical outcome is provided by a synergistic experimental/computational approach.}
}
@article{STEPHENS2021100871,
title = {From “You have to have three numbers and a plus sign” to “It’s the exact same thing”: K–1 students learn to think relationally about equations},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100871},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100871},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000328},
author = {Ana Stephens and Ranza {Veltri Torres} and Yewon Sung and Susanne Strachota and Angela {Murphy Gardiner} and Maria Blanton and Rena Stroud and Eric Knuth},
keywords = {Equal sign, Equations, Elementary grades, Early algebra, Algebraic thinking},
abstract = {This research shares progressions in thinking about equations and the equal sign observed in ten students who took part in an early algebra classroom intervention across Kindergarten and first grade. We report on data from task-based interviews conducted prior to the intervention and at the conclusion of each school year that elicited students’ interpretations of the equal sign and equations of various forms. We found at the beginning of the intervention that most students viewed the equal sign as an operational symbol and did not accept many equations forms as valid. By the end of first grade, almost all students described the symbol as indicating the equivalence of two amounts and were much more successful interpreting and working with equations in a variety of forms. The progressions we observed align with those of other researchers and provide evidence that very young students can learn to reason flexibly about equations.}
}
@article{DEICHMANN2024105260,
title = {Contrasting philosophical and scientific views in the long history of studying the generation of form in development},
journal = {BioSystems},
volume = {242},
pages = {105260},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105260},
url = {https://www.sciencedirect.com/science/article/pii/S030326472400145X},
author = {Ute Deichmann},
keywords = {Genomic causality, Developmental gene regulatory networks, Physical-chemical selforganization in form generation, Preformation versus epigenesis, Morphogenesis, Stochastic fluctuations, Eric Davidson, Aristotle},
abstract = {Focusing on the opposing ways of thinking of philosophers and scientists to explain the generation of form in biological development, I show that today's controversies over explanations of early development bear fundamental similarities to the dichotomy of preformation theory versus epigenesis in Greek antiquity. They are related to the acceptance or rejection of the idea of a physical form of what today would be called information for the generating of the embryo as a necessary pre-requisite for specific development and heredity. As a recent example, I scrutinize the dichotomy of genomic causality versus self-organization in 20th and 21st century theories of the generation of form. On the one hand, the generation of patterns and form, as well as the constant outcome in development, are proposed to be causally related to something that is "preformed" in the germ cells, the nucleus of germ cells, or the genome. On the other hand, it is proposed that there is no pre-existing form or information, and development is seen as a process where genuinely new characters emerge from formless matter, either by immaterial "forces of life," or by physical-chemical processes of self-organization. I also argue that these different ways of thinking and the research practices associated with them are not equivalent, and maintain that it is impossible to explain the generation of form and constant outcome of development without the assumption of the transmission of pre-existing information in the form of DNA sequences in the genome. Only in this framework of "preformed" information can "epigenesis" in the form of physical and chemical processes of self-organization play an important role.}
}
@article{YEH2011794,
title = {Evaluation approach to stock trading system using evolutionary computation},
journal = {Expert Systems with Applications},
volume = {38},
number = {1},
pages = {794-803},
year = {2011},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2010.07.035},
url = {https://www.sciencedirect.com/science/article/pii/S0957417410006639},
author = {I-Cheng Yeh and Che-hui Lien and Yi-Chen Tsai},
keywords = {Genetic algorithms, Neural networks, Decision system, Stock market, Over-learning},
abstract = {The past researches emphasize merely the avoidance of over-learning at the system level and ignore the problem of over-learning at the model level, which lead to the poor performance of the evolutionary computation based stock trading decision-making system. This study presents a new evaluation approach to focus on evaluating the generalization capability at the model level. An empirical study was provided and the results reveal four important findings. First, the decision-making system generated at the model design stage outperforms the system generated at the model validation stage, which shows over-learning at the model level. Secondly, for the decision-making system generated either at the model design stage or at the model validation stage, the investment performance in the training period is much better than that in the testing period, exhibiting over-learning at the system level. Third, employing moving timeframe approach is unable to improve the investment performance at the model validation stage. Fourth, reducing the evolution generation and input variables are unable to avoid the over-learning at the model level. The major contribution of this study is to clarify the issue of over-learning at the model and the system level. For future research, this study developed a more reliable evaluation approach in examining the generalization capability of evolutionary computation based decision-making system.}
}
@article{VARMA2024101673,
title = {Recruitment of magnitude representations to understand graded words},
journal = {Cognitive Psychology},
volume = {153},
pages = {101673},
year = {2024},
issn = {0010-0285},
doi = {https://doi.org/10.1016/j.cogpsych.2024.101673},
url = {https://www.sciencedirect.com/science/article/pii/S0010028524000446},
author = {Sashank Varma and Emily M. Sanford and Vijay Marupudi and Olivia Shaffer and R. {Brooke Lea}},
keywords = {Magnitude representations, Numerical cognition, Graded words, Distributional word semantics, Multi-dimensional scaling, Machine learning},
abstract = {Language understanding and mathematics understanding are two fundamental forms of human thinking. Prior research has largely focused on the question of how language shapes mathematical thinking. The current study considers the converse question. Specifically, it investigates whether the magnitude representations that are thought to anchor understanding of number are also recruited to understand the meanings of graded words. These are words that come in scales (e.g., Anger) whose members can be ordered by the degree to which they possess the defining property (e.g., calm, annoyed, angry, furious). Experiment 1 uses the comparison paradigm to find evidence that the distance, ratio, and boundary effects that are taken as evidence of the recruitment of magnitude representations extend from numbers to words. Experiment 2 uses a similarity rating paradigm and multi-dimensional scaling to find converging evidence for these effects in graded word understanding. Experiment 3 evaluates an alternative hypothesis – that these effects for graded words simply reflect the statistical structure of the linguistic environment – by using machine learning models of distributional word semantics: LSA, word2vec, GloVe, counterfitted word vectors, BERT, RoBERTa, and GPT-2. These models fail to show the full pattern of effects observed of humans in Experiment 2, suggesting that more is needed than mere statistics. This research paves the way for further investigations of the role of magnitude representations in sentence and text comprehension, and of the question of whether language understanding and number understanding draw on shared or independent magnitude representations. It also informs the role of machine learning models in cognitive psychology research.}
}
@article{DROZDZEWSKI2024100086,
title = {Developing QualNotes: A collaborative and cross-disciplinary ethnography},
journal = {Digital Geography and Society},
volume = {6},
pages = {100086},
year = {2024},
issn = {2666-3783},
doi = {https://doi.org/10.1016/j.diggeo.2024.100086},
url = {https://www.sciencedirect.com/science/article/pii/S2666378324000084},
author = {Danielle Drozdzewski and Jose Oriol Lopez Berengueres},
keywords = {QualNotes, Collaborative ethnography, Cross-disciplinary, Mobile application, Digital},
abstract = {Rarely do academics reveal the ‘backend’ of their research; the hours of labour invested into question generation, ethics compliance, transcription, translation, and data analysis, and in our case, coding. Further, when working collaboratively, the conversations that occur between collaborators seldom appear in final publications either. The development of the mobile application QualNotes, provided a productive digital space for collaboration across disciplines. In this paper, we use three vignettes to explicate the ‘backend’ of the development of that mobile application. We chart howour collaborative cross-disciplinary ethnography revealed the generative potential of thinking-with the digital and across disciplinary divides. This paper's contribution is in revealing ‘how’ we work using our disciplinary expertise, but at the same time at the edges of those disciplines too, where we contest, argue, adapt, understand, and, where we learn.}
}
@article{TRAYLOR2024110895,
title = {Model-based experiments as epistemic evidence in paleoecology},
journal = {Ecological Modelling},
volume = {498},
pages = {110895},
year = {2024},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2024.110895},
url = {https://www.sciencedirect.com/science/article/pii/S0304380024002837},
author = {Wolfgang Traylor},
keywords = {Epistemology, Bayesian, Preregistration, Blinding, Uncertainty analysis},
abstract = {Where ordinary experiments are impossible and observational data scarce and indirect—particularly in paleoecosystems—computational experiments are often our only means to learn about reality. There are good arguments to count such model-based predictions as evidence, testing hypotheses and updating our beliefs about the world. However, the epistemic weight of computational experiments depends on an adequate model representation of the target system, transparency about predictive uncertainty, and the avoidance of confirmation bias. I argue that mechanistic models are particularly suited for paleoecological predictions but that iterative uncertainty analyses should guide their development. Using a Bayesian framework I propose preregistration and blinded analysis as tools to strengthen the epistemic value of computational experiments. Here, a preregistration marks the boundary between exploratory model development, which establishes credence in the model, and predictive model application, which tests hypotheses. As good modeling practice I suggest clarifying epistemic goals at the outset of a project and accordingly choose methods to maximize the epistemic weight of the computational experiment.}
}
@article{EGBERT2021104173,
title = {“It's a chance to make mistakes”: Processes and outcomes of coding in 2nd grade classrooms},
journal = {Computers & Education},
volume = {168},
pages = {104173},
year = {2021},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2021.104173},
url = {https://www.sciencedirect.com/science/article/pii/S0360131521000506},
author = {Joy Egbert and Seyed Abdollah Shahrokni and Reima Abobaker and Nataliia Borysenko},
keywords = {Elementary education, Robotics, Coding, Teacher learning, Computational thinking},
abstract = {Several gaps exist in the literature on coding. First, little exploration has focused on early elementary school students. In addition, close description of the overall context of coding tasks at this level is rare. Further, there is a need for both teacher and student voices around coding experiences to be heard. Moreover, a task engagement framework has not been used to evaluate the process or outcomes of early elementary coding tasks. Therefore, an exploratory holistic case study design was used to investigate student and teacher processes and outcomes of coding lessons in order to fill gaps in the literature. In this study, forty-six 2nd grade students, two teachers, and four researchers completed two one-week units on basic coding. Multiple descriptive and numeric data sources were employed to describe the process and outcomes of learning coding. Conclusions include: (1) teachers should start learning about coding first with short awareness sessions and then move to their own classrooms with knowledge brokers and other forms of assistance; (2) a focus on content and process, including problem-solving, is effective for coding with young children; (3) there can be a high level of engagement for teachers and students with the use of robots and welldesigned, age-appropriate coding tasks, and; (4) multiple data sources and the inclusion of both teacher and student data are essential in exploring coding in classrooms.}
}
@article{GUHE2011249,
title = {A computational account of conceptual blending in basic mathematics},
journal = {Cognitive Systems Research},
volume = {12},
number = {3},
pages = {249-265},
year = {2011},
note = {Special Issue on Complex Cognition},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000155},
author = {Markus Guhe and Alison Pease and Alan Smaill and Maricarmen Martinez and Martin Schmidt and Helmar Gust and Kai-Uwe Kühnberger and Ulf Krumnack},
keywords = {Mathematical cognition, Metaphor, Mathematical reasoning, Analogy, Anti-unification, Conceptual blending, HDTP},
abstract = {We present an account of a process by which different conceptualisations of number can be blended together to form new conceptualisations via recognition of common features, and judicious combination of their distinctive features. The accounts of number are based on Lakoff and Núñez’s cognitively-based grounding metaphors for arithmetic. The approach incorporates elements of analogical inference into a generalised framework of conceptual blending, using some ideas from the work of Goguen. The ideas are worked out using Heuristic-Driven Theory Projection (HDTP, a method based on higher-order anti-unification). HDTP provides generalisations between domains, giving a crucial step in the process of finding commonalities between theories. In addition to generalisations, HDTP can also transfer concepts from one domain to another, allowing the construction of new conceptual blends. Alongside the methods by which conceptual blends may be constructed, we provide heuristics to guide this process.}
}
@incollection{YONGSATIANCHOT2021651,
title = {Chapter 19 - Computational models of appraisal to understand the person-situation relation},
editor = {Dustin Wood and Stephen J. Read and P.D. Harms and Andrew Slaughter},
booktitle = {Measuring and Modeling Persons and Situations},
publisher = {Academic Press},
pages = {651-674},
year = {2021},
isbn = {978-0-12-819200-9},
doi = {https://doi.org/10.1016/B978-0-12-819200-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128192009000053},
author = {Nutchanon Yongsatianchot and Stacy Marsella},
abstract = {Appraisal theories of emotion argue that emotions arise from a process of comparing individual needs and concerns to external demands. That is, emotions cannot be explained by solely focusing on the environment or by solely focusing on the individual. Rather, they reflect an individual’s subjective assessment of their relation to the environment. Appraisal theories further posit this relationship is characterized by the individual (appraised) in terms of a set of criteria, variously called appraisal variables, checks, or dimensions; for example, Is an event congruent with a person’s goals or concerns?; Who or what caused it?; Was it unexpected?; and What control does the person have over its unfolding? The results of these appraisal checks are in turn mapped to emotion. In this chapter, we do not explore appraisal as a theory of emotion elicitation. Rather, we suggest appraisal theories, specifically the criteria that appraisal theories posit, provide a useful framework for characterizing how situations are perceived by a person and influence their behavior. We go on to suggest that computational models of appraisal can provide a clear specification of how these criteria are assessed. Furthermore, such models can help us explore the dynamics of the person-environment relation, specifically how changes in the environment as well as changes in the person’s perceptions and behavior arise and induce those dynamics.}
}
@article{DIFRANCO2019386,
title = {Information-gain computation in the Fifth system},
journal = {International Journal of Approximate Reasoning},
volume = {105},
pages = {386-395},
year = {2019},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18301610},
author = {Anthony {Di Franco}},
keywords = {Declarative programming, Probabilistic logic programming, , Adaptive evaluation strategy, Multi-armed bandits},
abstract = {Despite large incentives, correctness in software remains an elusive goal. Declarative programming techniques, where algorithms are derived from a specification of the desired behavior, offer hope to address this problem, since there is a combinatorial reduction in complexity in programming in terms of specifications instead of algorithms, and arbitrary desired properties can be expressed and enforced in specifications directly. However, limitations on performance have prevented programming with declarative specifications from becoming a mainstream technique for general-purpose programming, because a strategy which is both efficient and fully general to derive algorithms from specifications does not yet exist. To address this bottleneck, I propose information-gain computation, a framework where an adaptive evaluation strategy is used to efficiently perform a search which derives algorithms that provide information about a query via the most efficient routes. Within this framework, opportunities to compress the search space present themselves, which suggest that information-theoretic bounds on the performance of such a system might be articulated and a system might be designed to achieve them. The computation of the information measures that are the basis of this strategy crucially depends on a probabilistic semantics for the relations represented by predicates, which may either already be present in a probabilistic logic language, or may be superimposed on a pure logic language. I describe a prototype implementation of Fifth, a system that implements these techniques, and a preliminary empirical study of adaptive evaluation for a simple test program. In the test, the evaluation strategy adapts successfully to efficiently evaluate a query with pathological features that would prevent its evaluation by standard general-purpose strategies.}
}
@article{COTTAM2024105343,
title = {Intelligence: Natural, artificial, or what?},
journal = {BioSystems},
volume = {246},
pages = {105343},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105343},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002284},
author = {Ron Cottam and Roger Vounckx},
abstract = {We consider the competing attributes of natural intelligence (NI) and artificial intelligence (AI). Attention is paid to conceptual, theoretical, stylistic and structural aspects of both, and non-human intelligence. Intelligence is related to information processing and current views of physical structuring. Means of distinguishing between NI and AI are noted, and neural and digital structures are described. Pribram's bi-computational neural networks are introduced, and high-level Pribram computation is discussed. We describe the hierarchical Aquarium scheme, along with an AI implementation, and conclude with a proposition for future quantum-based artificial intelligence.}
}
@article{ISLAM2021104757,
title = {EEG Channel Correlation Based Model for Emotion Recognition},
journal = {Computers in Biology and Medicine},
volume = {136},
pages = {104757},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104757},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521005515},
author = {Md. Rabiul Islam and Md. Milon Islam and Md. Mustafizur Rahman and Chayan Mondal and Suvojit Kumar Singha and Mohiuddin Ahmad and Abdul Awal and Md. Saiful Islam and Mohammad Ali Moni},
keywords = {Emotion, Convolutional neural network, Feature extraction, EEG, Pearson's correlation coefficient, Complexity},
abstract = {Emotion recognition using Artificial Intelligence (AI) is a fundamental prerequisite to improve Human-Computer Interaction (HCI). Recognizing emotion from Electroencephalogram (EEG) has been globally accepted in many applications such as intelligent thinking, decision-making, social communication, feeling detection, affective computing, etc. Nevertheless, due to having too low amplitude variation related to time on EEG signal, the proper recognition of emotion from this signal has become too challenging. Usually, considerable effort is required to identify the proper feature or feature set for an effective feature-based emotion recognition system. To extenuate the manual human effort of feature extraction, we proposed a deep machine-learning-based model with Convolutional Neural Network (CNN). At first, the one-dimensional EEG data were converted to Pearson's Correlation Coefficient (PCC) featured images of channel correlation of EEG sub-bands. Then the images were fed into the CNN model to recognize emotion. Two protocols were conducted, namely, protocol-1 to identify two levels and protocol-2 to recognize three levels of valence and arousal that demonstrate emotion. We investigated that only the upper triangular portion of the PCC featured images reduced the computational complexity and size of memory without hampering the model accuracy. The maximum accuracy of 78.22% on valence and 74.92% on arousal were obtained using the internationally authorized DEAP dataset.}
}
@article{ASHTIANI201618,
title = {A hesitant fuzzy model of computational trust considering hesitancy, vagueness and uncertainty},
journal = {Applied Soft Computing},
volume = {42},
pages = {18-37},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.01.023},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616300102},
author = {Mehrdad Ashtiani and Mohammad Abdollahi Azgomi},
keywords = {Trust modeling, Hesitant fuzzy sets (HFS), Comparative linguistic expressions, Vagueness, Uncertainty, Multi-criteria decision making (MCDM)},
abstract = {The aim of this work is to introduce a trust model, which is highly consistent with the social nature of trust in computational domains. To this end, we propose a hesitant fuzzy multi-criteria decision making based computational trust model capable of taking into account the fundamental building blocks corresponding to the concept of trust. The proposed model is capable of considering the contextuality property of trust and the subjective priorities of the trustor regarding the chosen goal. This is due to viewing trust not as a single label or an integrated concept, but as a collection of trustworthiness facets that may form the trust decision in various contexts and toward different goals. The main benefit of the proposed model is the consideration of the hesitancy of recommenders and the trustor in the process of trust decision making which can create a more flexible mapping between the social and computational requirements of trust. This type of formulation also allows for taking into account the vagueness of the provided opinions. In addition to the vagueness of the provided opinions, the model is capable of considering the certainty of recommendations and its effect on the aggregation process of gathered opinions. In the proposed model, the taste of the recommenders and the similarity of opinions are also considered. This will allow the model to assign more weight to recommendations that have a similar taste compared to the trustor. Finally, taking into consideration the attitudes of the trustors toward change of personality that may occur for various entities in the environment is another advantage of the proposed model. A step-by-step illustrative example and the results of several experimental evaluations, which demonstrate the benefits of the proposed model, are also presented in this paper.}
}
@article{KINLEY2022105843,
title = {Pathologies of precision: A Bayesian account of goals, habits, and episodic foresight in addiction},
journal = {Brain and Cognition},
volume = {158},
pages = {105843},
year = {2022},
issn = {0278-2626},
doi = {https://doi.org/10.1016/j.bandc.2022.105843},
url = {https://www.sciencedirect.com/science/article/pii/S027826262200001X},
author = {Isaac Kinley and Michael Amlung and Suzanna Becker},
keywords = {Addiction, Goals, Habits, Free energy, Bayesian statistics, Episodic future thinking},
abstract = {The brain is thought to implement two decision-making systems: a goal-directed system in which decisions are made through planning on the basis of action–outcome relationships, and a habitual system in which behaviour reflects stimulus–response associations. A prominent theory of addiction sees it as arising due to an extreme dominance of habit over goal-directed action. The balance between these systems is thought to be arbitrated by the relative precision of their separate predictions of reward. In this paper, we argue that various factors in addiction create hyper-precise reward predictions in the habitual system and hypo-precise reward predictions in the goal-directed system, shifting the balance of behavioural control in favour of habit. Based on this, we offer a theoretical account of the utility of episodic future thinking in addiction, interpreting it as increasing the precision of reward estimates in the goal-directed system, thereby enhancing the control of this system over behaviour.}
}
@article{ZHAO2015194,
title = {Bring CS2013 Recommendations into c Programming Course},
journal = {Procedia - Social and Behavioral Sciences},
volume = {176},
pages = {194-199},
year = {2015},
note = {International Educational Technology Conference, IETC 2014, 3-5 September 2014, Chicago, IL, USA},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.01.461},
url = {https://www.sciencedirect.com/science/article/pii/S187704281500498X},
author = {Lingling Zhao and Xiaohong Su and Tiantian Wang},
keywords = {CS2013, C programming course, CS curriculum planning, CS major ;},
abstract = {Computer Science Curriculum 2013 has become the guidance of computing education since it was released in 2013by the ACM/IEEE-Computer Society. This paper analyzes the CS curriculum development trend, trying to dig the programming-related core from CS2013 with respect to the knowledge areas, topics, organization of teaching, and the building of students’ capability. Considering the characteristic of our local institution and undergraduates, we present an updated teaching curriculum and lab curriculum for C Programming Language course in relation to CS2013 recommendations, which highlight the development of the students’ abilities on programming, problem-solving, self-regulated learning, and computational thinking. Finally, we present and assess the implementation of the resulting curriculum.}
}
@article{KLEINSCHMIDT2004842,
title = {Thinking Big: Many Modules or Much Cortex?},
journal = {Neuron},
volume = {41},
number = {6},
pages = {842-844},
year = {2004},
issn = {0896-6273},
doi = {https://doi.org/10.1016/S0896-6273(04)00154-0},
url = {https://www.sciencedirect.com/science/article/pii/S0896627304001540},
author = {Andreas Kleinschmidt},
abstract = {Is there a neural system dedicated to generic magnitude judgments? In this issue of Neuron, Pinel et al. report qualitative spatial overlap of fMRI responses during judgments of luminance, size, and numerical magnitude but also quantitative response differences in intraparietal cortex that mirror behavioral interference between perceptual and symbolic magnitude.}
}
@article{CARLEY2002253,
title = {Computational organizational science and organizational engineering},
journal = {Simulation Modelling Practice and Theory},
volume = {10},
number = {5},
pages = {253-269},
year = {2002},
note = {Organisational Processes},
issn = {1569-190X},
doi = {https://doi.org/10.1016/S1569-190X(02)00119-3},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X02001193},
author = {Kathleen M Carley},
keywords = {Computational modeling, Simulation, Organization science, Organizational design, Organizational learning},
abstract = {The past decade has witnessed the emergence of a new scientific discipline––computational social and organizational science. Within organization science in particular, and social science more generally, scientists and practitioners are turning to computational analysis to address fundamental socio-technical problems that are so complex and dynamic that they cannot be fully addressed by traditional techniques. Consequently, there is an explosion of computational models, computationally generated findings, interest in doing simulation, and a dearth of support for this enterprise. This paper contains discussions of the underlying fundamental perspective, the relation of models to empirical data and characteristics of necessary infrastructure.}
}
@article{HUMPHREYS1991315,
title = {Vol. 3: Thinking: edited by Daniel N. Osherson and Edward E. Smith (x + 308 pages) ISBN 0 262 65035 5},
journal = {Trends in Neurosciences},
volume = {14},
number = {7},
pages = {315},
year = {1991},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(91)90148-N},
url = {https://www.sciencedirect.com/science/article/pii/016622369190148N},
author = {Glyn W. Humphreys}
}
@article{CROLLEN2020290,
title = {How visual is the « number sense »? Insights from the blind},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {118},
pages = {290-297},
year = {2020},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2020.07.022},
url = {https://www.sciencedirect.com/science/article/pii/S0149763420304851},
author = {Virginie Crollen and Olivier Collignon},
keywords = {Blindness, Mathematical cognition, Brain plasticity},
abstract = {Is vision a necessary building block for the foundations of mathematical cognition? A straightforward model to test the causal role visual experience plays in the development of numerical abilities is to study people born without sight. In this review we will demonstrate that congenitally blind people can develop numerical abilities that equal or even surpass those of sighted individuals, despite representing numbers using a qualitatively different representational format. We will also show that numerical thinking in blind people maps onto regions typically involved in visuo-spatial processing in the sighted, highlighting how intrinsic computational biases may constrain the reorganization of numerical networks in case of early visual deprivation. More generally, we will illustrate how the study of arithmetic abilities in congenitally blind people represents a compelling model to understand how sensory experience scaffolds the development of higher-level cognitive representations.}
}
@article{BATEMAN2021100502,
title = {What are digital media?},
journal = {Discourse, Context & Media},
volume = {41},
pages = {100502},
year = {2021},
issn = {2211-6958},
doi = {https://doi.org/10.1016/j.dcm.2021.100502},
url = {https://www.sciencedirect.com/science/article/pii/S2211695821000386},
author = {John A. Bateman},
keywords = {Digital media, Digital information, Literacy, Models of communication, Multimodality, Medium, Development of media, Computational media},
abstract = {This essay addresses the nature of so–called ‘digital media’ in a literacy context from the perspectives of semiotics, theories of the ‘medium’, and computation. It argues that most accounts that attempt to work with some notion of ‘digital media’ anchor themselves insufficiently in semiotics and computation and the essential combination of these that is necessary when discussing digital media as an object of study. This weakens approaches, particularly when the concern is to develop ways of teaching engagement with contemporary communication practices at any level, i.e., improving ‘digital literacies’ of various kinds. Achieving more robust foundations is important for interventions which are not only more effective but also sustainable, minimizing the danger of obsolescence with each new technological turn of the screw. Foundations are also essential for a more balanced perspective on learning situations that does not dichotomize allegedly ‘digital’ and ‘non–digital’ practices and skills. Many such boundaries are deeply misleading and so unnecessarily compartmentalize thinking and restrict the application of relevant research results and methods. The focus of this essay is therefore to consider how a closer examination of media and their development, combined with the contributions made by information technologies, may help articulate notions of digital media that are more supportive of productive engagements with research and issues of literacy.}
}
@article{ZHANG202524,
title = {Farmers’ decisions on crop residues utilization, greenhouse gases reduction and subsidy of crop residue-based bioenergy: An agent-based life cycle model},
journal = {Sustainable Production and Consumption},
volume = {55},
pages = {24-36},
year = {2025},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2025.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2352550925000235},
author = {Jiaqi Zhang and Chengxiang Zhuge and Qitong Huang and Bin Wang and Yu'e Li and Peter Oosterveer},
keywords = {Agent-based model, Crop residue-based bioenergy, Life cycle thinking, Environmental and economic impacts, Farmer decision making},
abstract = {To further advance the crop residue-based bioenergy (CRB) industry for climate change mitigation, it is crucial to better understand the influence of stakeholders' behaviours on greenhouse gases (GHG) mitigation potentials. However, the heterogeneity and social dynamics of stakeholders, particularly farmers, have received less attention. This study develops an Agent-based Environmental and Economic assessment (AEE) model that integrates agent-based model and life cycle thinking methods to simulate the CRB system. The AEE model was applied in Heilongjiang Province of China, to investigate how stakeholder decisions affect CRB's GHG reduction potential and government subsidies. Scenario analyses explore the effects of grain markets, subsidies, and collection distance on environmental and economic outcomes. The findings indicate that more farmers are willing to adopt crop residues collection than those currently practicing it, primarily due to logistical constraints. Key factors influencing adoption include farming income, age, farm size and crop types. CRB contributed to 70.6 % of overall GHG reductions with only 41.6 % of the subsidy, demonstrating higher mitigation efficiency. In conclusion, the government must address the deficiency in crop residues logistics to promote CRB development. Additionally, agricultural policies play a crucial role in ensuring CRB feedstock availability by guiding crop types selection. The results suggest that AEE model is adequate in simulating both micro and macro dynamics in the context of CRB, highlighting the robustness of integrating agent-based model and life cycle thinking methods to study complex issues.}
}
@article{MARTI2025345,
title = {Fifty years of metaheuristics},
journal = {European Journal of Operational Research},
volume = {321},
number = {2},
pages = {345-362},
year = {2025},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2024.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0377221724002637},
author = {Rafael Martí and Marc Sevaux and Kenneth Sörensen},
keywords = {Heuristics, Combinatorial optimization, Critical review, Metaheuristics},
abstract = {In this paper, we review the milestones in the development of heuristic methods for optimization over the last 50 years. We propose a critical analysis of the main findings and contributions, mainly from a European perspective. Starting with the roots of the area that can be traced back to the classical philosophers, we follow the historical path of heuristics and metaheuristics in the field of operations research and list the main milestones, up to the latest proposals to hybridize metaheuristics with machine learning. We pay special attention to the theories that changed our way of thinking about problem solving, and to the role played by the European Journal of Operational Research in the development of these theories. Our approach emphasizes methodologies and their connections with related areas, which permits to identify potential lines of future research.}
}
@article{JONES2020100801,
title = {Scalar and vector line integrals: A conceptual analysis and an initial investigation of student understanding},
journal = {The Journal of Mathematical Behavior},
volume = {59},
pages = {100801},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100801},
url = {https://www.sciencedirect.com/science/article/pii/S0732312320300651},
author = {Steven R. Jones},
keywords = {Multivariable calculus, Definite integrals, Line integrals, Conceptual analysis, Student understanding},
abstract = {This paper adds to the growing body of research happening in multivariable calculus by examining scalar and vector line integrals. This paper contributes in two ways. First, this paper provides a conceptual analysis for both types of line integrals in terms of how theoretical ways of thinking about definite integrals summarized from the research literature might be applied to understanding line integrals specifically. Second, this paper provides an initial investigation of students’ understandings of line integral expressions, and connects these understanding to the theoretical ways of thinking drawn from the literature. One key finding from the empirical part is that several students appeared to understand individual pieces of the integral expression based on one way of thinking, such as adding up pieces or anti-derivatives, while trying to understand the overall integral expression through a different way of thinking, such as area under a curve.}
}
@article{EYSENCK19921359,
title = {Thinking clearly about psychology volume 2: Personality and psychopathology: William M. Grove and Dante Cicchetti: Minneapolis: University of Minnesota Press (1991). pp. v–vi, 3–467. Cloth, ISBN 0-8166-1892-5 v. 2.$45.00.},
journal = {Personality and Individual Differences},
volume = {13},
number = {12},
pages = {1359-1360},
year = {1992},
issn = {0191-8869},
doi = {https://doi.org/10.1016/0191-8869(92)90185-R},
url = {https://www.sciencedirect.com/science/article/pii/019188699290185R},
author = {H.J. Eysenck}
}
@article{JUHOLA2021106367,
title = {On computational classification of genetic cardiac diseases applying iPSC cardiomyocytes},
journal = {Computer Methods and Programs in Biomedicine},
volume = {210},
pages = {106367},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2021.106367},
url = {https://www.sciencedirect.com/science/article/pii/S0169260721004417},
author = {Martti Juhola and Henry Joutsijoki and Kirsi Penttinen and Disheet Shah and Katriina Aalto-Setälä},
keywords = {Genetic cardiac diseases, Induced pluripotent stem cells, Cardiomyocytes, Transient profiles, Machine learning, Classification, Leave-one-out, -fold cross-validation},
abstract = {Background
Cardiomyocytes differentiated from human induced pluripotent stem cells (iPSC-CMs) can be used to study genetic cardiac diseases. In patients these diseases are manifested e.g. with impaired contractility and fatal cardiac arrhythmias, and both of these can be due to abnormal calcium transients in cardiomyocytes. Here we classify different genetic cardiac diseases using Ca2+ transient data and different machine learning algorithms.
Methods
By studying calcium cycling of disease-specific iPSC-CMs and by using calcium transients measured from these cells it is possible to classify diseases from each other and also from healthy controls by applying machine learning computation on the basis of peak attributes detected from calcium transient signals.
Results
In the current research we extend our previous study having Ca-transient data from four different genetic diseases by adding data from two additional diseases (dilated cardiomyopathy and long QT Syndrome 2). We also study, in the light of the current data, possible differences and relations when machine learning modelling and classification accuracies were computed by using either leave-one-out test or 10-fold cross-validation.
Conclusions
Despite more complex classification tasks compared to our earlier research and having more different genetic cardiac diseases in the analysis, it is still possible to attain good disease classification results. As excepted, leave-one-out test and 10-fold cross-validation achieved virtually equal results.}
}
@article{CATENACCIVOLPI20141,
title = {How active perception and attractor dynamics shape perceptual categorization: A computational model},
journal = {Neural Networks},
volume = {60},
pages = {1-16},
year = {2014},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2014.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0893608014001440},
author = {Nicola {Catenacci Volpi} and Jean Charles Quinton and Giovanni Pezzulo},
keywords = {Hopfield networks, Perceptual categorization, Prediction, Active vision, Dynamic choice},
abstract = {We propose a computational model of perceptual categorization that fuses elements of grounded and sensorimotor theories of cognition with dynamic models of decision-making. We assume that category information consists in anticipated patterns of agent–environment interactions that can be elicited through overt or covert (simulated) eye movements, object manipulation, etc. This information is firstly encoded when category information is acquired, and then re-enacted during perceptual categorization. The perceptual categorization consists in a dynamic competition between attractors that encode the sensorimotor patterns typical of each category; action prediction success counts as “evidence” for a given category and contributes to falling into the corresponding attractor. The evidence accumulation process is guided by an active perception loop, and the active exploration of objects (e.g., visual exploration) aims at eliciting expected sensorimotor patterns that count as evidence for the object category. We present a computational model incorporating these elements and describing action prediction, active perception, and attractor dynamics as key elements of perceptual categorizations. We test the model in three simulated perceptual categorization tasks, and we discuss its relevance for grounded and sensorimotor theories of cognition.}
}
@article{OCAMPO2024111111,
title = {An integrated three-way decision methodology for sustainability of wastewater circularity in thermal power plants},
journal = {Applied Soft Computing},
volume = {151},
pages = {111111},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.111111},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623011298},
author = {Lanndon Ocampo and Jenebyb Cabigas and Dylan Jones and Ashraf Labib},
keywords = {Water circularity, Wastewater, Water reuse, MARCOS, Three-way decision},
abstract = {The presence of multiple criteria for evaluating wastewater reuse applications indicates the potential usage of Multi-Criteria Decision-Making (MCDM) methods for this purpose. However, there is currently a scarcity of studies in the domain literature that utilize MCDM approaches in this application topic. This paper therefore advances the domain literature in two distinctive ways. Firstly, it analyzes and advances the reuse agenda of wastewater from thermal power plants, recognized as large-scale users of water, thus promoting greater water circularity. Secondly, it provides a methodological advance by integrating the notion of Three-Way Decision (3WD) into the computational structure of MCDM methods by introducing a middle reference point. Such an initiative results in a novel 3WD extension of the Measurement of Alternatives and Ranking according to COmpromise Solution (MARCOS) method. Additionally, this work provides a proof that the MARCOS method utilizes a compromise solution in identifying priority alternatives, along with the integration of a Weighted Aggregated Sum Product ASsessment (WASPAS) metric. An initial hypothetical example illustrates how the proposed approach augments the canonical MARCOS method, particularly in promoting the “thinking in threes” as a more natural information processing approach and the high degree of distinguishability of priorities between decision alternatives. An actual case study in a thermal power plant then demonstrates the contributions of this work. With the best-worst method used to determine the priorities of the decision attributes, the findings reveal that wastewater reuse applications achieving reduced costs for needed infrastructures, operational simplicity, technological compatibility, consumer safety and household savings are preferred by stakeholders. The 3WD-MARCOS approach identifies industrial and commercial use, municipal use, environmental restoration, and household use as the high-priority alternatives, with cooking and drinking as least preferred. These insights guide stakeholders in their design of initiatives that allocate resources for greater wastewater reuse. A comparative analysis yields high consistency of these findings with similar MCDM methods. In addition, the efficacy of the novel 3WD-MARCOS method highlights its potential in handling MCDM problems, including those promoting water circularity.}
}
@article{DESOUZA2024100042,
title = {The generative AI revolution, cognitive mediation networks theory and the emergence of a new mode of mental functioning: Introducing the Sophotechnic Mediation scale},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100042},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100042},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000021},
author = {Bruno Campello {de Souza} and Agostinho {Serrano de Andrade Neto} and Antonio Roazzi},
keywords = {ChatGPT, Chatbots, Artificial intelligence, Cognitive mediation networks theory, Hyperculture, Sophotechnic},
abstract = {This paper examines the recent emergence of AI-powered chatbots such as ChatGPT through the lens of the Cognitive Mediation Networks Theory (CMNT), deducing that the introduction of this radically new technology will likely create a new stage of collective cognitive functioning, called “Sophotechnic Mediation”, with characteristics that can be extrapolated from the way these new tools work and the dynamics of the sociocultural structures being created around them. From that description, the Sophotechnic Mediation Scale is proposed as a means to assess the extent of an individual's internalization of the new form of thinking. A preliminary empirical investigation with 132 higher education professors and students found the instrument to be statistically consistent, yielding a unidimensional and Gaussian score that behaves as a developmental trait emerging from the interaction with generative AIs, mediated by age and mastery of previous digital technologies and their cultural elements. It is concluded that the results are suggestive of the validity of the new scale and warrant further research.}
}
@article{BENTLEY20131240,
title = {Predicting the future: Towards symbiotic computational and experimental angiogenesis research},
journal = {Experimental Cell Research},
volume = {319},
number = {9},
pages = {1240-1246},
year = {2013},
note = {Special Issue: Endothelial Biology},
issn = {0014-4827},
doi = {https://doi.org/10.1016/j.yexcr.2013.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0014482713000426},
author = {Katie Bentley and Martin Jones and Bert Cruys},
keywords = {Computational modelling, Interdisciplinary, Angiogenesis, Prediction, Simulation},
abstract = {Understanding the fundamental organisational principles underlying the complex and multilayered process of angiogenesis is the mutual aim of both the experimental and theoretical angiogenesis communities. Surprisingly, these two fields have in the past developed in near total segregation, with neither fully benefiting from the other. However, times are changing and here we report on the new direction that angiogenesis research is taking, where from well-integrated collaborations spring new surprises, experimental predictions and research avenues. We show that several successful ongoing collaborations exist in the angiogenesis field and analyse what aspects of their approaches led them to achieve novel and impactful biological insight. We conclude that there are common elements we can learn from for the future, and provide a list of guidelines to building a successful collaborative venture. Specifically, we find that a near symbiosis of computation with experimentation reaps the most impactful results by close cyclical feedback and communication between the two disciplines resulting in continual refinement of models, experimental directions and our understanding. We discuss high impact examples of predictive modelling from the wider, more established integrated scientific domains and conclude that the angiogenesis community can do nothing but benefit from joining this brave new, integrated world.}
}
@article{DASH201640,
title = {An evolutionary hybrid Fuzzy Computationally Efficient EGARCH model for volatility prediction},
journal = {Applied Soft Computing},
volume = {45},
pages = {40-60},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616301624},
author = {Rajashree Dash and P.K. Dash},
keywords = {Volatility prediction, Stock markets, GARCH model variants, Fuzzy logic based hybrids, Fuzzy inference with nonlinear functions, Multistep prediction, Differential evolution, Super predictive ability test},
abstract = {Accurate modeling for forecasting of stock market volatility is a widely interesting research area both in academia as well as financial markets. This paper proposes an innovative Fuzzy Computationally Efficient EGARCH model to forecast the volatility of three stock market indexes. The proposed model represents a joint estimation of the membership function parameters of a TSK-type fuzzy inference system along with the leverage effect, asymmetric shock by leverage effect of EGARCH model in forecasting highly nonlinear and complicated financial time series model more accurately. Further unlike the conventional TSK type fuzzy neural network the proposed model uses a functional link neural network (FLANN) in the consequent part of the fuzzy rules to provide an improved mapping. Moreover, a differential evolution (DE) algorithm is suggested to solve the parameters estimation problem of Fuzzy Computationally Efficient EGARCH model. Being a parallel direct search algorithm, DE has the strength of finding global optimal solutions regardless of the initial values of its few control parameters. Furthermore, the DE based algorithm aims to achieve an optimal solution with a rapid convergence rate. The proposed model has been compared with some GARCH family models and hybrid fuzzy systems and GARCH models based on three performance metrics: MSFE, RMSFE, and MAFE. The results indicate that the proposed method offers significant improvements in volatility forecasting performance in comparison with all other specified models.}
}
@article{CABITZA201765,
title = {The semiotics of configurations for the immanent design of interactive computational systems},
journal = {Journal of Visual Languages & Computing},
volume = {40},
pages = {65-90},
year = {2017},
note = {Semiotics, Human-Computer Interaction and End-User Development},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2017.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X16300246},
author = {Federico Cabitza and Alvise Mattozzi},
keywords = {Semiotics of Configurations, Immanent design, End-User Development platforms, Document management systems, Electronic Health Record},
abstract = {In this paper the authors propose a novel semiotic approach to the design of interactive systems and computational systems, grounded in the most recent contributions within the debate around semiotic theory and analysis. This approach, that is here called Semiotics of Configurations (SoC), is proposed for its analytic power in describing material artifacts and settings with a purposely a-conceptualistic stance. The resulting analysis informs a kind of design that is aimed at reproducing and supporting the programs of action detected in the use of artifacts, as this use is “abducted” from the physical and material form of the artifacts themselves and from the observation of how content is transformed within and across them. This approach to design, called immanent design, has inspired a platform for the user-driven development and use of electronic documents and forms in cooperative and organizational domains. The framework is illustrated with a case drawn from a study performed in the domain of hospital work.}
}
@article{PRATT2023103217,
title = {Bringing advanced technology to strategic decision-making: The Decision Intelligence/Data Science (DI/DS) Integration framework},
journal = {Futures},
volume = {152},
pages = {103217},
year = {2023},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2023.103217},
url = {https://www.sciencedirect.com/science/article/pii/S0016328723001222},
author = {Lorien Pratt and Christophe Bisson and Thierry Warin},
keywords = {Strategic decision making, Decision intelligence, Corporate foresight, Artificial intelligence, Complexity, Kahneman’s systems thinking},
abstract = {There is a widespread stated desire amongst both public and private organizations worldwide to engage in more significant “evidence-based reasoning” and to be more “data-driven.” We argue that these two goals are proxies for the often-unstated goal of improving the exploration of possible futures as foresights that could lead to better strategic decisions and improved business outcomes. From this perspective, data and analytics hold great promise and are necessary—but not sufficient—for improving strategic decision-making. Something more is needed to realize this potential. We specify how to fill this gap using an integration framework between technology and decision-makers, which is especially appropriate in complex and/or volatile environments. Our solution—which comprises a methodology as well as a software architecture—therefore unifies not only human decision makers to technology but each other and also integrates several disciplines that have been hitherto unnecessarily separated. Thereby, it could help organizations to address increasing challenges better as well as improve the exploration of possible futures.}
}
@article{AALTO2019145,
title = {Modeling of biomass supply system by combining computational methods – A review article},
journal = {Applied Energy},
volume = {243},
pages = {145-154},
year = {2019},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2019.03.201},
url = {https://www.sciencedirect.com/science/article/pii/S0306261919306178},
author = {Mika Aalto and Raghu KC and Olli-Jussi Korpinen and Kalle Karttunen and Tapio Ranta},
keywords = {Biomass, Supply chain, Life cycle assessment, Geographical information system, Agent-based modeling and simulation, Discrete-event simulation},
abstract = {As computing power increases, more complex computational models are utilized for biomass supply system studies. The paper describes three commonly used modeling methods in this context, geographic information systems, life-cycle assessment, and discrete-time simulation and presents bibliometric analysis of work using these three study methods. Of the 498 publications identified in searches of the Scopus and Web of Science databases, 17 reported on combinations of methods: 10 on life-cycle assessment and geographic information systems, six on joint use of life-cycle assessment and discrete-time simulation, and one on use of geographic information systems jointly with discrete-time simulation. While no articles dealt directly with simultaneous use of all three methods, several acknowledged the potential of this. The authors discuss numerous challenges identified in the review that arise in combining methods, among them computational load, the increasing number of assumptions, guaranteeing coherence between the models used, and the large quantities of data required. Discussion of issues such as the complexity of reporting and the need for standard procedures and terms becomes more critical as repositories bring together research materials, including entire models, from various sources. Efforts to mitigate many of modeling’s challenges have involved phase-specific modeling and use of such methods as expressions or uncertainty analysis in place of a complex secondary model. The authors conclude that combining modeling methods offer considerable potential for taking more variables into account; improving the results; and benefiting researchers, decision–makers, and operation managers by producing more reliable information.}
}
@article{KRZHIZHANOVSKAYA2015288,
title = {Russian-Dutch double-degree Master’s programme in computational science in the age of global education},
journal = {Journal of Computational Science},
volume = {10},
pages = {288-298},
year = {2015},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2015.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877750315000812},
author = {Valeria V. Krzhizhanovskaya and Alexey V. Dukhanov and Anna Bilyatdinova and Alexander V. Boukhanovsky and Peter M.A. Sloot},
keywords = {Computational science, Master’s programme, Graduate program, Double degree, Curriculum, Enrollment, Student research, Funding opportunities},
abstract = {We present a new double-degree graduate (Master’s) programme developed together by the ITMO University, Russia and University of Amsterdam, The Netherlands. First, we look into the global aspects of integration of different educational systems and list some funding opportunities. Then, we describe our double-degree program curriculum, suggest the timeline of enrollment and studies, and give some examples of student research topics. Finally, we discuss the issues of joint programs with Russia and suggest possible solutions, analyze the results of the first three student intakes and reflect on the lessons learnt, and share our thoughts and experiences that could be of interest to the international community expanding the educational markets to the vast countries like Russia, China or India. The paper is written for education professionals and contains useful information for potential students. This is an extended version of a conference paper (http://dx.doi.org/10.1016/j.procs.2014.05.130) invited to this special issue of the Journal of Computational Science.}
}
@incollection{MILLER201455,
title = {Chapter 5 - Managing and Integrating Exposome Data: Maps, Models, Computation, and Systems Biology},
editor = {Gary W. Miller},
booktitle = {The Exposome},
publisher = {Academic Press},
address = {San Diego},
pages = {55-69},
year = {2014},
isbn = {978-0-12-417217-3},
doi = {https://doi.org/10.1016/B978-0-12-417217-3.00005-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780124172173000057},
author = {Gary W. Miller},
keywords = {Bioinformatics, systems biology, computational biology, machine learning, Bayesian methods},
abstract = {Exposome-related data will come from a myriad of sources. The huge amounts of data must be organized in some manner that allows appropriate interpretations and associations to be drawn. Models and maps are often used to provide organization to complex data sets. Maps are quite appropriate for exposome research as the location of the sources and exposures is a critical component, and spatial statistics could play a major role in exposome data organization. The complex types of data will undoubtedly require mathematical approaches, including bioinformatics, computational, and systems biology-based techniques. This chapter reviews some of the possible strategies that can be used to keep track of the diverse and massive data sets that will result from exposome research.}
}
@article{FARAZI2024103661,
title = {Planning electric vertical takeoff and landing aircraft (eVTOL)-based package delivery with community noise impact considerations},
journal = {Transportation Research Part E: Logistics and Transportation Review},
volume = {189},
pages = {103661},
year = {2024},
issn = {1366-5545},
doi = {https://doi.org/10.1016/j.tre.2024.103661},
url = {https://www.sciencedirect.com/science/article/pii/S1366554524002527},
author = {Nahid Parvez Farazi and Bo Zou},
keywords = {Advanced air mobility (AAM), eVTOL, Package delivery, Community noise impact, Bi-objective integer programming model, Tailored solution algorithm},
abstract = {The rapid development of Advanced Air Mobility (AAM) in recent years suggests a promise to use electric vertical takeoff and landing aircraft (eVTOLs) for package delivery in metro areas. While eVTOL manufacturers and logistics service providers are actively developing prototype eVTOLs and exploring their potentials for moving freight, a system thinking about the suitability and ways to operate an eVTOL-based package delivery system remains scarce. A key aspect of the system thinking is the noise impact of eVTOL operations on surrounding communities. In this study, we provide an operation planning framework that aims to prepare AAM to be both economically efficient and community friendly for package delivery. We first develop a method to quantify the community noise impact of an eVTOL operation, using a “population exposure” measure which is based on the level of sound generated and accounts for both the number of people impacted and duration of the impact. Then, a bi-objective integer programming model is formulated which simultaneously optimizes total shipping cost and community noise impact of eVTOL operations. The optimization takes into consideration operational constraints including maximum distance for local delivery, latest package departure time from the warehouse, and eVTOL fleet size and carrying capacity. A tailored solution algorithm which augments non-dominated sorting genetic algorithm 2 (NSGA2) with compact solution representation, guided generation of initial population of solutions, and customized local search heuristics is devised. The model and the algorithm are implemented in a case study in the Chicago metro area. Numerical results reveal the trade-off between the minimization of shipping cost and community noise impact. Several operational insights about eVTOL-based package delivery are obtained. The computational efficiency and effectiveness of the proposed solution algorithm are also demonstrated in comparison with alternative solution methods.}
}
@article{MARRA2025102557,
title = {Bridging the gaps in sustainability assessment: A systematic literature review, 2014–2023},
journal = {Evaluation and Program Planning},
volume = {110},
pages = {102557},
year = {2025},
issn = {0149-7189},
doi = {https://doi.org/10.1016/j.evalprogplan.2025.102557},
url = {https://www.sciencedirect.com/science/article/pii/S0149718925000242},
author = {Mita Marra},
keywords = {Sustainability Assessment (SA), Sustainability, Bibliometric analysis, Evaluation Journals},
abstract = {This article highlights recurrent themes and research communities in Sustainability Assessment (SA), a rapidly growing trans-disciplinary area particularly relevant to the global evaluation community. This bibliometric analysis signals the emergence of a substantial research community based in Asia and the Middle East, whose production is distinct from North American and European-centric evaluation studies. While the latter primarily address methodological challenges related to sustainability issues in social policy, organizational capacity building, and public health, the broader SA literature centers on life-cycle assessments to integrate the analysis of environmental and socioeconomic effects in such domains as biodiversity, energy efficiency, urban planning, alternative agriculture, and supply chain management. This mapping exercise highlights the global distribution of research output and identifies existing gaps and potential future cross-fertilization. The transdisciplinary SA literature can draw from theory-based designs attuned to complexity and systems thinking. Policy analysts and evaluators can gain insights from diverse SA perspectives and policy approaches to tackle sustainability challenges more systematically.}
}
@article{VALTON2017631,
title = {Comprehensive review: Computational modelling of schizophrenia},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {83},
pages = {631-646},
year = {2017},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2017.08.022},
url = {https://www.sciencedirect.com/science/article/pii/S0149763416307357},
author = {Vincent Valton and Liana Romaniuk and J. {Douglas Steele} and Stephen Lawrie and Peggy Seriès},
keywords = {Psychotic symptoms, Schizophrenia, Computational models, Computational psychiatry},
abstract = {Computational modelling has been used to address: (1) the variety of symptoms observed in schizophrenia using abstract models of behavior (e.g. Bayesian models – top-down descriptive models of psychopathology); (2) the causes of these symptoms using biologically realistic models involving abnormal neuromodulation and/or receptor imbalance (e.g. connectionist and neural networks – bottom-up realistic models of neural processes). These different levels of analysis have been used to answer different questions (i.e. understanding behavioral vs. neurobiological anomalies) about the nature of the disorder. As such, these computational studies have mostly supported diverging hypotheses of schizophrenia's pathophysiology, resulting in a literature that is not always expanding coherently. Some of these hypotheses are however ripe for revision using novel empirical evidence. Here we present a review that first synthesizes the literature of computational modelling for schizophrenia and psychotic symptoms into categories supporting the dopamine, glutamate, GABA, dysconnection and Bayesian inference hypotheses respectively. Secondly, we compare model predictions against the accumulated empirical evidence and finally we identify specific hypotheses that have been left relatively under-investigated.}
}
@article{POSTAN2018111,
title = {Dioids for Computational Effects},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {339},
pages = {111-134},
year = {2018},
note = {The XLII Latin American Computing Conference},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2018.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1571066118300525},
author = {Ezequiel Postan and Exequiel Rivas and Mauro Jaskelioff},
keywords = {dioid, monad, Haskell, computational effect},
abstract = {There are different algebraic structures that one can use to model notions of computation. The most well- known are monads, but lately, applicative functors have been gaining popularity. These two structures can be understood as instances of the unifying notion of monoid in a monoidal category. When dealing with non-determinism, it is usual to extend monads and applicative functors with additional structure. However, depending on the desired non-determinism, there are different options of interaction between the existing and the additional structure. This article studies one of those options, which is captured algebraically by dioids. We generalise dioids to dioid categories and show how dioids in such a category model non- determinism in monads and applicative functors. Moreover, we study the construction of free dioids in a programming context.}
}
@article{YONG2024322,
title = {Students’ perception of non-placement work-integrated learning in chemical engineering: Work-related skills towards the post-pandemic future},
journal = {South African Journal of Chemical Engineering},
volume = {47},
pages = {322-332},
year = {2024},
issn = {1026-9185},
doi = {https://doi.org/10.1016/j.sajce.2023.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S1026918523001270},
author = {Su Ting Yong and Nishanth G. Chemmangattuvalappil and Dominic C.Y. Foo},
keywords = {Non-placement, Work-integrated learning, Virtual communication, Technology usage, Critical thinking, Problem solving},
abstract = {Work-integrated learning (WIL) is a pedagogical activity designed to enhance the integration of theoretical knowledge and practical skills in an authentic context. WIL is typically accomplished through work placement, but a non-placement WIL is potentially promising. In this study, a non-placement WIL programme was incorporated into chemical engineering final year projects. The students worked on industrial problems without a work placement. The purpose of the study was to investigate work-related skills learned in a non-placement WIL programme. A qualitative dominant mixed-methods research approach was adopted. Data was collected using a quantitative questionnaire (n = 69) and a qualitative interview (n = 15). Quantitative findings revealed no significant difference between students working on non-placement WIL and academic projects. However, qualitative findings revealed seven insightful work-related skills in the non-placement WIL: (1) professional relationship with industrial experts and academic supervisors, (2) virtual communication and collaboration, (3) technology skills in the latest industrial software and tools, (4) motivation to undertake novel and challenging industrial problems, (5) creative and innovative strategies, (6) application of higher order thinking skills to model authentic problems, (7) inductive and deductive reasoning. The COVID-19 pandemic has changed how engineers work. Today, it is a necessity to embrace creative problem-solving skills and adopt various types of modern technologies to work effectively and remotely.}
}
@article{BAUTISTA2023109,
title = {Acceptance and commitment therapy in parents of children with cancer at psychosocial risk: A randomized multiple baseline evaluation},
journal = {Journal of Contextual Behavioral Science},
volume = {29},
pages = {109-121},
year = {2023},
issn = {2212-1447},
doi = {https://doi.org/10.1016/j.jcbs.2023.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212144723000789},
author = {Ana B. Bautista and Francisco J. Ruiz and Juan C. Suárez-Falcón},
keywords = {Acceptance and commitment therapy, Repetitive negative thinking, Childhood cancer, Parents, Single-case experimental design, Psychosocial risk},
abstract = {Developing and testing psychological interventions for primary caregivers of children with cancer at significant psychosocial risk is still needed. One psychological factor contributing to their emotional distress is repetitive negative thinking (RNT). This study conducted a randomized, multiple-baseline evaluation of the effect of an individual, online, 2-session, RNT-focused ACT intervention in 12 parents. Participants responded to daily measures of emotional symptoms, RNT, and progress in values during baseline, intervention, and the 2-month follow-up. These measures have shown adequate psychometric properties at the individual level in this study. All 12 participants completed the intervention. A Bayesian hierarchical model indicated that most participants showed reductions in emotional symptoms and RNT (10 of 11), and 8 of 12 participants showed increases in valued living. The design-comparable standardized mean difference was computed to estimate the intervention effect overall. The effect sizes were large for all variables (PHQ-4: d = 0.83, 95% CI [0.27, 1.40]; RNTQ-3: d = 0.81, 95% CI [0.34, 1.28]; VQ-3: d = 1.07, 95% CI [0.22, 1.91]). Participants evaluated the intervention as useful at the 2-month follow-up. In conclusion, a brief and online RNT-focused intervention showed promising results in parents of children with cancer at significant psychosocial risk.}
}
@article{RICHARD2019136,
title = {CastLab: an object-oriented finite element toolbox within the Matlab environment for educational and research purposes in computational solid mechanics},
journal = {Advances in Engineering Software},
volume = {128},
pages = {136-151},
year = {2019},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2018.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0965997818301303},
author = {Benjamin Richard and Giuseppe Rastiello and Cédric Giry and Francesco Riccardi and Romili Paredes and Eliass Zafati and Santosh Kakarla and Chaymaa Lejouad},
keywords = {Matlab toolbox, Nonlinear solid mechanics, Computational mechanics, Educational tools, Finite elements},
abstract = {The Matlab environment has become widely used among the computational mechanics community, not only for research purposes but also to teach either undergraduate or graduate classes. This paper aims to present a new toolbox devoted to computational mechanics and in particular to solid mechanics. Both recent and well-established numerical formulations have been implemented in it. One of its strengths resides in the fact that it was developed within an object-oriented framework. This key feature makes the CastLab toolbox easy-to-use and with extensive capabilities for customized user developments. After a brief description of the theoretical background related to the problems that can be solved by means of the toolbox, several representative case-studies are presented. These examples have been selected to illustrate not only the numerical efficiency of the toolbox, which is of primary importance for research purposes, but also its strong educational and pedagogic potential.}
}
@article{KUMAR2006806,
title = {Applying computational modeling to drug discovery and development},
journal = {Drug Discovery Today},
volume = {11},
number = {17},
pages = {806-811},
year = {2006},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2006.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S1359644606002868},
author = {Neil Kumar and Bart S. Hendriks and Kevin A. Janes and David {de Graaf} and Douglas A. Lauffenburger},
abstract = {Computational models of cells, tissues and organisms are necessary for increased understanding of biological systems. In particular, modeling approaches will be crucial for moving biology from a descriptive to a predictive science. Pharmaceutical companies identify molecular interventions that they predict will lead to therapies at the organism level, suggesting that computational biology can play a key role in the pharmaceutical industry. We discuss pharmaceutically-relevant computational modeling approaches currently used as predictive tools. Specific examples demonstrate how companies can employ these computational models to improve the efficiency of transforming targets into therapies.}
}
@incollection{VAMVOUDAKIS2024,
title = {Multi Agent Q-Learning With Adversaries in Nash Equilibrium and Non Equilibrium Settings},
booktitle = {Reference Module in Materials Science and Materials Engineering},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-12-803581-8},
doi = {https://doi.org/10.1016/B978-0-443-14081-5.00082-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443140815000829},
author = {Kyriakos G. Vamvoudakis},
keywords = {Adaptive control, Adaptive learning, Bounded rationality, Cyber-physical systems, Game theory, Model-free, Multi-agent systems, Nash games, Networked systems, Optimal control, Q-learning, Reinforcement learning},
abstract = {The purpose of this chapter is to demonstrate how to solve optimal control problems, both for single-player games and multiplayer games with intermittent and continuous feedback in centralized and multi agent settings. We achieve this by using Q-learning, leveraging data measured along the trajectories. Importantly, our approaches do not require any prior knowledge of the system dynamics. This model-free and dynamic framework allows learning agents to adapt their objectives or optimality criteria on the fly. In addressing nonequilibrium results in shifting, dynamical environments, a control-oriented multi agent formulation of the interactions between different thinking agents is also shown.}
}
@article{MATSUMURA2023100689,
title = {Tasks and feedback: An exploration of students’ opportunity to develop adaptive expertise for analytic text-based writing},
journal = {Assessing Writing},
volume = {55},
pages = {100689},
year = {2023},
issn = {1075-2935},
doi = {https://doi.org/10.1016/j.asw.2022.100689},
url = {https://www.sciencedirect.com/science/article/pii/S107529352200085X},
author = {Lindsay Clare Matsumura and Elaine Lin Wang and Richard Correnti and Diane Litman},
keywords = {Feedback, Instruction, Tasks, Text-based writing},
abstract = {In this study, we apply a cognitive theoretical lens to investigate students’ opportunity to develop their analytic text-based writing skills (N = 35 fifth and sixth grade classrooms). Specifically, we examine the thinking demands of classroom text-based writing tasks and teachers’ written feedback on associated student work. Four text-based writing tasks with drafts of associated student work were collected from teachers across a school year. Results of qualitative analyses showed that about half of the classroom text-based writing tasks considered by teachers to be challenging guided students to express analytic thinking about what they read (n = 73). A minority of student work received written feedback focused on students’ use of evidence, expression of thinking, and text comprehension; or received feedback that provided guidance for strategies students could take to meet genre goals. Most teachers provided content-related, instructive, and/or localized feedback on at least one piece of student work. Only a small number of teachers, however, consistently provided content-related, instructive or localized feedback on their students’ essays. Overall, results suggest that students have few opportunities to practice analytic text-based writing and receive feedback that would be expected to advance their conceptual understanding and adaptive expertise for writing in this genre.}
}
@article{ATSALAKIS2016107,
title = {Using computational intelligence to forecast carbon prices},
journal = {Applied Soft Computing},
volume = {43},
pages = {107-116},
year = {2016},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2016.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S1568494616300801},
author = {George S. Atsalakis},
keywords = {ANFIS forecasting, Carbon allowance, Carbon price forecasting, Computational intelligent forecasting, Neuro-fuzzy forecasting, PATSOS forecasting},
abstract = {European Union has introduced the European Trading System (ETS) as a tool for developing and implementing international treaties related to climate changes and to identify the most cost-effective methods for reducing greenhouse gas emissions, in particular carbon dioxide (CO2), which is the most substantial. Companies producing carbon emissions must effectively manage associated costs by buying or selling carbon emission futures. Viewed from this perspective, this paper provides a model for managing the risk by buying and selling carbon emission futures by implementing techniques that leverage computational intelligence. Three computational intelligence techniques are proposed to provide accurate and timely forecasts for changes in the price of carbon: a novel hybrid neuro-fuzzy controller that forms a closed-loop feedback mechanism called PATSOS; an artificial neural network (ANN) based system; an adaptive neuro-fuzzy inference system (ANFIS). Results are based on 1074 daily carbon price observations collected to comprise a useful time-series dataset and for evaluation of the proposed techniques. The extra-sample performance of the proposed techniques is calculated. Analysis results are compared with those produced by other models. Comparison studies reveal that PATSOS is the most accurate and promising methodology for predicting the price of carbon. It is stated that this paper registers a first attempt to apply a hybrid neuro-fuzzy controller to forecasting carbon prices.}
}
@article{SHARMA20221,
title = {The design and evaluation of an AR-based serious game to teach programming},
journal = {Computers & Graphics},
volume = {103},
pages = {1-18},
year = {2022},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2022.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0097849322000024},
author = {Vandit Sharma and Kaushal Kumar Bhagat and Huai-Hsuan Huang and Nian-Shing Chen},
keywords = {Augmented Reality, Computational thinking, Learning Analytics, Gamification, Feedback design, System usability},
abstract = {The ubiquity of smartphone and tablet devices, combined with the increasing availability of serious games, has enabled students to learn various abstract concepts in an appealing and convenient manner. While several researchers have explored the use of Augmented Reality (AR) in serious games, many of these games have not been critically explained or evaluated. To that end, we employed game-based learning methodologies and Game Learning Analytics (GLA) to systematize the design and evaluation of an AR-based serious game to teach programming. We evaluated our game for usability and effectiveness by conducting a user study on twenty-seven undergraduate students. The evaluation primarily consisted of a learning test conducted twice – before and after playing the game – along with a usability questionnaire that players completed after playing the game. Our results showed that players made significant progress after playing the game. The game helped players improve their basic programming skills, especially for the group having lower prior programming skills. The results highlighted various ways in which GLA can be used to benefit different stakeholders in the game. Based on players’ qualitative responses, we also identified several areas of improvement, most prominently the trade-off between ease of use and game complexity. We provide suggestions and discuss implications for future work.}
}
@article{SINGH20212537,
title = {Resources and computational strategies to advance small molecule SARS-CoV-2 discovery: Lessons from the pandemic and preparing for future health crises},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {2537-2548},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.04.059},
url = {https://www.sciencedirect.com/science/article/pii/S2001037021001719},
author = {Natesh Singh and Bruno O. Villoutreix},
abstract = {There is an urgent need to identify new therapies that prevent SARS-CoV-2 infection and improve the outcome of COVID-19 patients. This pandemic has thus spurred intensive research in most scientific areas and in a short period of time, several vaccines have been developed. But, while the race to find vaccines for COVID-19 has dominated the headlines, other types of therapeutic agents are being developed. In this mini-review, we report several databases and online tools that could assist the discovery of anti-SARS-CoV-2 small chemical compounds and peptides. We then give examples of studies that combined in silico and in vitro screening, either for drug repositioning purposes or to search for novel bioactive compounds. Finally, we question the overall lack of discussion and plan observed in academic research in many countries during this crisis and suggest that there is room for improvement.}
}
@article{CAMACHOLIE202435,
title = {Development of basic thermodynamics workshops integrating a cubic equations of state simulator and MATLAB Grader courses},
journal = {Education for Chemical Engineers},
volume = {49},
pages = {35-54},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000228},
author = {Mariola Camacho-Lie and Rodrigo Alberto Hernández-Ochoa and Adriana Palacios},
keywords = {Teaching of thermodynamics, Digital tools in education, Deep learning, Constructive Alignment, Preparation for Future Learning, Productive Failure},
abstract = {This paper describes the development of EoS Simulator, a cubic equations of state simulator created in the MATLAB R2022b App Designer platform, which aims to be a practical digital tool for chemical engineering students that facilitates the solution, analysis, and critical thinking about thermodynamic problems. In the simulator, numerical algorithms were implemented based on a theoretical framework, such as fugacity test, bracketing methods, and the calculation of residual properties. EoS Simulator can estimate two-phase envelopes, isobars, isotherms, and surfaces related to PTVHS properties. MATLAB Grader courses were proposed to test student learning using the software in two different workshops. The evaluation was based on the achievement of tasks related to intended learning outcomes. Survey responses about the simulator and learning environment were collected, concluding that most students improved their skills in understanding thermodynamics phenomena, but some improvements are necessary for future versions of the software and online courses.}
}
@article{LASO2018428,
title = {Finding an economic and environmental balance in value chains based on circular economy thinking: An eco-efficiency methodology applied to the fish canning industry},
journal = {Resources, Conservation and Recycling},
volume = {133},
pages = {428-437},
year = {2018},
issn = {0921-3449},
doi = {https://doi.org/10.1016/j.resconrec.2018.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0921344918300429},
author = {Jara Laso and Isabel García-Herrero and María Margallo and Ian Vázquez-Rowe and Pére Fullana and Alba Bala and Cristina Gazulla and Ángel Irabien and Rubén Aldaco},
keywords = {Life cycle assessment, Life cycle costing, Eco-efficiency, Engraulis encrasicolus, Linear programming},
abstract = {The production of food that is environmentally friendly and presents a high economic return is one of the current concerns for the food industry. Eco-efficiency links the environmental performance of a product to its economic value. In this context, this study combines Life Cycle Assessment (LCA) and Life Cycle Costing (LCC) to propose a two-step eco-efficiency methodology assessment for the fish canning industry. An eco-label rating system based on a descriptive weighting of environmental (Global Warming Potential, Acidification Potential, Eutrophication Potential and the ReCiPe Single Score Endpoint) and economic (Value Added) indicators was applied to the canned anchovy. Secondly, LCA-LCC results were coupled to linear programming (LP) tools in order to define a composite eco-efficiency index. This approach enables translation into economic terms of the environmental damage caused when a given alternative is chosen. In particular, different origins for anchovy species (South American vs. Cantabrian) and related waste management alternatives (landfill, incineration and valorization) were evaluated under this cradle to gate approach. Results indicated that substantial differences can be observed depending on the origin of the fish. Anchovies landed in Cantabria show a higher value added score at the expense of larger environmental impacts, mainly due to fuel use intensity. Moreover, its environmental scores are lowered when fish residues are valorized into marketable products, while increasing the value added. This study demonstrates the environmental and economic benefits of applying circular economy. According to this, it is possible to introduce the cradle-to-cradle concept in the fish canned industry. The methodology proposed is intended to be useful to decision-makers in the anchovy canning sector and can be applied to other regions and industrial sectors.}
}
@article{ANGELAKI2009452,
title = {Multisensory integration: psychophysics, neurophysiology, and computation},
journal = {Current Opinion in Neurobiology},
volume = {19},
number = {4},
pages = {452-458},
year = {2009},
note = {Sensory systems},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2009.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S0959438809000725},
author = {Dora E Angelaki and Yong Gu and Gregory C DeAngelis},
abstract = {Fundamental observations and principles derived from traditional physiological studies of multisensory integration have been difficult to reconcile with computational and psychophysical studies that share the foundation of probabilistic (Bayesian) inference. We review recent work on multisensory integration, focusing on experiments that bridge single-cell electrophysiology, psychophysics, and computational principles. These studies show that multisensory (visual–vestibular) neurons can account for near-optimal cue integration during the perception of self-motion. Unlike the nonlinear (superadditive) interactions emphasized in some previous studies, visual–vestibular neurons accomplish near-optimal cue integration through subadditive linear summation of their inputs, consistent with recent computational theories. Important issues remain to be resolved, including the observation that variations in cue reliability appear to change the weights that neurons apply to their different sensory inputs.}
}
@article{DELOERA20161,
title = {Random sampling in computational algebra: Helly numbers and violator spaces},
journal = {Journal of Symbolic Computation},
volume = {77},
pages = {1-15},
year = {2016},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2016.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S074771711600002X},
author = {Jesús A. {De Loera} and Sonja Petrović and Despina Stasi},
keywords = {Violator spaces, Ideal generators, Solving polynomial systems, Randomized algorithm in algebra, Large sparse systems of equations},
abstract = {This paper transfers a randomized algorithm, originally used in geometric optimization, to computational problems in commutative algebra. We show that Clarkson's sampling algorithm can be applied to two problems in computational algebra: solving large-scale polynomial systems and finding small generating sets of graded ideals. The cornerstone of our work is showing that the theory of violator spaces of Gärtner et al. applies to polynomial ideal problems. To show this, one utilizes a Helly-type result for algebraic varieties. The resulting algorithms have expected runtime linear in the number of input polynomials, making the ideas interesting for handling systems with very large numbers of polynomials, but whose rank in the vector space of polynomials is small (e.g., when the number of variables and degree is constant).}
}
@incollection{THIEL2005559,
title = {Chapter 21 - Semiempirical quantum-chemical methods in computational chemistry},
editor = {Clifford E. Dykstra and Gernot Frenking and Kwang S. Kim and Gustavo E. Scuseria},
booktitle = {Theory and Applications of Computational Chemistry},
publisher = {Elsevier},
address = {Amsterdam},
pages = {559-580},
year = {2005},
isbn = {978-0-444-51719-7},
doi = {https://doi.org/10.1016/B978-044451719-7/50064-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517197500640},
author = {Walter Thiel},
abstract = {Publisher Summary
This chapter focuses on semiempirical quantum-chemical methods describing their development over the past 40 years. One of the first semiempirical approaches in quantum chemistry was the p-electron method proposed by Hǖckel (1931) that generates molecular orbitals (MOs) essentially from the connectivity matrix of a molecule and provides valuable qualitative insights into the structure, stability, and spectroscopy of unsaturated molecules. Hoffmann extended this approach to include all valence electrons and applied in many qualitative studies of inorganic and organometallic compounds. These early semiempirical methods had a lasting impact on chemical thinking as they guided the development of qualitative MO theory that is commonly employed for rationalizing chemical phenomena in terms of orbitals interactions. They are normally not used any longer as computational tools. After a survey of the established methods such as MNDO, AM1, and PM3, recent methodological advances are described including the development of improved semiempirical models, new general-purpose and special-purpose parametrizations, and linear scaling approaches.}
}