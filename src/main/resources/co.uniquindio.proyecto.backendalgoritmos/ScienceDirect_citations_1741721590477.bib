@article{STAVERT2023432,
title = {Unlocking the holy grail of sustainable and scalable mesoporous silica using computational modelling},
journal = {RSC Sustainability},
volume = {1},
number = {3},
pages = {432-438},
year = {2023},
issn = {2753-8125},
doi = {https://doi.org/10.1039/d3su00019b},
url = {https://www.sciencedirect.com/science/article/pii/S2753812523000952},
author = {Tom Stavert and Siddharth V. Patwardhan and Robert Pilling and Miguel Jorge},
abstract = {ABSTRACT
Bio-inspired methods offer a great alternative to design high-value mesoporous silica under more environmentally friendly conditions, allowing for an economical and sustainable scale-up. However, the synthesis of bio-inspired silica (BIS) is currently poorly understood, creating barriers to achieving products with comparable quality to traditional mesoporous silica. This perspective summarizes the key findings in the development of ordered mesoporous silica (OMS) and BIS synthesis, highlighting in particular the challenges faced in the development of scalable processing routes for these materials. Recent successes in improving mechanistic understanding of these syntheses using computational modelling are then presented, followed by suggestions as to how modelling may be used for predictive design of BIS with desired quality attributes. A multi-scale computational model, utilizing a combination of both ‘top-down’ and ‘bottom-up’ approaches, is argued to be critical for achieving a unified description of both BIS and OMS synthesis, allowing the potential of these materials to be fully realised.}
}
@article{DU2023108546,
title = {OSSCAR, an open platform for collaborative development of computational tools for education in science},
journal = {Computer Physics Communications},
volume = {282},
pages = {108546},
year = {2023},
issn = {0010-4655},
doi = {https://doi.org/10.1016/j.cpc.2022.108546},
url = {https://www.sciencedirect.com/science/article/pii/S001046552200265X},
author = {Dou Du and Taylor J. Baird and Sara Bonella and Giovanni Pizzi},
keywords = {Jupyter, Notebooks, Computational physics, Computational chemistry, Computational materials science, Education},
abstract = {In this paper we present the Open Software Services for Classrooms and Research (OSSCAR) platform. OSSCAR provides an open collaborative environment to develop and access educational resources in the form of web applications, for which various deployment methods are discussed and compared. To minimize efforts in the creation and use of new educational material, OSSCAR combines software tools that have emerged as standards with custom domain-specific ones. The technical solutions adopted to create and distribute content are described and motivated on the basis of reliability, sustainability, ease of uptake and use. Examples from courses in the domains of physics, chemistry, and materials science are shown to demonstrate the style and level of interactivity of typical applications. The tools presented are easy to use, and create a uniform and open environment exploitable by a large community of teachers, students, and researchers with the goal of facilitating learning and avoiding, when possible, duplication of efforts in creating teaching material. Contributions to expand the educational content of the OSSCAR project are welcome.
Program summary
Program Title: OSSCAR Interactive Notebooks for Quantum Mechanics and Computational Materials Science CPC Library link to program files: https://doi.org/10.17632/26py5zz9f8.1 Developer's repository link: https://github.com/osscar-org/quantum-mechanics Licensing provisions: MIT Programming language: Python Nature of problem: Among others, computational courses (e.g. on quantum mechanics) can benefit from advanced interactive visualizations of the content. However, on the one hand it might be complicated for teachers to develop such interactive content; on the other hand, students need to be able to access very quickly and efficiently the content, reducing the time needed to install libraries and dependencies that might differ between courses. Solution method: Here, we developed interactive web applications to complement teaching and encourage computational thinking for courses in computational physics, chemistry and materials science, using Jupyter notebooks and their rendering as interactive web applications. The latter is powered by a combination of Voila, to hide code and convert notebooks into live web applications, and (existing or custom) Jupyter widgets to enable interactiveness. The code is ready to be deployed via a number of open approaches.}
}
@article{GOBL2023100604,
title = {Situating computational empowerment in formal education: A multi-perspective view},
journal = {International Journal of Child-Computer Interaction},
volume = {38},
pages = {100604},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100604},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000417},
author = {Barbara Göbl and Elisabeth Anna Guenther and Fares Kayali and Christopher Frauenberger},
keywords = {Computational empowerment, Digital competences, Digital literacy, Empowerment, Participatory design},
abstract = {Digital literacy and respective education are of growing interest in our increasingly digitalized world. Recent works stress the importance of aiming beyond the acquisition of corresponding technical competences and call for fostering children’s empowerment and participation in digitalization. Computational Empowerment (CE) pursues that goal through a creative and reflexive participatory design approach. However, remaining conceptual vagueness with regard to what CE entails may hinder its implementation in formal education. This paper addresses this gap, with the aim to demonstrate what is needed to advance CE’s position in this context. To this end, we elaborate on our understanding of CE’s vision, approach and impact. We then examine CE in the context of formal education, and contrast it with selected contemporary educational theory and practice. Specifically, we position CE in relation to an established learning framework (Bloom’s revised taxonomy), educational policy (DigComp) and practices in the classroom. This is complemented by an analysis of four different projects: we present lessons learned in the context of pedagogical interventions and take a closer look at the accompanying empowerment processes. As a result, this paper provides a foundation to make CE’s ideas more tangible and, thus, actionable, for researchers, policy makers and educators.}
}
@article{MARMION201345,
title = {The Drosophila BMPRII, wishful thinking, is required for eggshell patterning},
journal = {Developmental Biology},
volume = {375},
number = {1},
pages = {45-53},
year = {2013},
issn = {0012-1606},
doi = {https://doi.org/10.1016/j.ydbio.2012.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S001216061200677X},
author = {Robert A. Marmion and Milica Jevtic and Alexander Springhorn and George Pyrowolakis and Nir Yakoby},
keywords = {Tissue patterning, Oogenesis, TGF-beta signaling},
abstract = {The Drosophila eggshell is an elaborate structure that is derived from a monolayer of follicular epithelium surrounding the developing oocyte within the female ovary. The bone morphogenetic protein (BMP) signaling pathway is essential for controlling the patterning and morphogenesis of the eggshell. During oogenesis, the roles of patterning and morphogenesis by the BMP type I receptor thickveins (tkv) have been studied extensively. However, signaling through this pathway requires both type I and II receptors, and the latter has yet to be established in oogenesis. We focus on wishful thinking (wit), the Drosophila homolog to the mammalian BMP type II receptor, BMPRII. We found that wit is expressed dynamically in the FCs of D. melanogaster in an evolutionary conserved pattern. The expression patterns are highly correlated with the dynamics of the BMP signaling, which is consistent with our finding that wit is a target of BMP signaling. Furthermore, we established that WIT is necessary for BMP signaling, and loss of WIT is associated with cell autonomous loss of BMP responses. Of importance, we demonstrated that perturbations in WIT led to changes in eggshell morphologies in domains that are patterned by BMP signaling. Previous studies have shown a role for WIT in BMP signaling during neurogenesis; however, our results reveal a role for WIT in epithelial cells' development.}
}
@incollection{ALLAHVIRANLOO2024407,
title = {Chapter 23 - Computations with words},
editor = {Tofigh Allahviranloo and Witold Pedrycz and Amir Seyyedabbasi},
booktitle = {Decision-Making Models},
publisher = {Academic Press},
pages = {407-415},
year = {2024},
series = {Uncertainty, Computational Techniques, and Decision Intelligence},
isbn = {978-0-443-16147-6},
doi = {https://doi.org/10.1016/B978-0-443-16147-6.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443161476000128},
author = {Tofigh Allahviranloo},
keywords = {Computation, Fuzzy, Application},
abstract = {In fact, computing with words is a method in which the objects are words, and the computations are propositions extracted from ordinary conversation. For example, small, large, far, and heavy, not very likely, the price of gas in Iran is low and increasing a lot. Computing with words is inspired by the remarkable ability of humans to perform various types of physical and mental activities without any measurement or calculation. Familiar examples of these activities are parking a car, driving in heavy traffic, riding a bicycle, understanding speech, etc.}
}
@article{IIVARI2023100600,
title = {Computational empowerment of children: Design research on empowering and impactful designs by children},
journal = {International Journal of Child-Computer Interaction},
volume = {37},
pages = {100600},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100600},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000375},
author = {Netta Iivari and Leena Ventä-Olkkonen and Heidi Hartikainen and Sumita Sharma and Essi Lehto and Jenni Holappa and Tonja Molin-Juustila},
keywords = {Children, Empowerment, Impact, Critical design, Critical making, Bullying, Design research},
abstract = {Prioritizing children’s empowerment in and through design has been on the agenda of child–computer interaction (CCI) research for a long time. Recently, the notion of the computational empowerment of children has received attention. However, there are still open issues in our understanding and advocacy of it. A related development is the recent interest in the longer-term impacts of our work. Fast and furious participation of children in design sessions is considered inadequate. We should advocate for longer-term trajectories and possibilities for children to make changes that will influence our world. However, the literature is limited in addressing longer-term impacts. This study taps into these two research gaps and showcases how we have addressed the computational empowerment of children in a project tackling bullying at school through critical design and making. In this paper, we examine in detail the children’s designs and their trajectories from the viewpoint of empowerment and impact: whether and how these children’s designs show potential for the empowerment of those bullied and whether and how their designs have had an impact in the realm of digital technology development. Our study has interesting conceptual and methodological implications for CCI research and practice on the computational empowerment of children and on our design research practice.}
}
@article{MAMMINO2022100743,
title = {Computational chemistry and green chemistry: Familiarizing chemistry students with the modes and benefits of promising synergies},
journal = {Sustainable Chemistry and Pharmacy},
volume = {29},
pages = {100743},
year = {2022},
issn = {2352-5541},
doi = {https://doi.org/10.1016/j.scp.2022.100743},
url = {https://www.sciencedirect.com/science/article/pii/S2352554122001474},
author = {Liliana Mammino},
keywords = {Computational modelling of molecules, Cross-area synergies for green chemistry, Green chemistry education, Molecular design for green chemistry, Student-friendly introduction to the bases of molecular studies},
abstract = {Because of its nature as the science of substances, chemistry is bound to play major roles in the pursuit of sustainable development. Green chemistry outlines the framework of this role and its 12 principles express objectives simultaneously constituting implementation guidelines. Tackling the challenges posed by the pursuit of sustainability is likely to become an increasingly permeating component of chemists' professional activities, and future chemists need to be adequately prepared for it. The principles of green chemistry entail the design of substances and processes that are inherently benign to human health and to the environment (benign-by-design concept). Computational chemistry constitutes a major resource for the design of molecules having desired properties. However, students’ exposure to the potentialities and practices of this type of cross-area synergies remains largely inadequate. The paper discusses the importance of adequate exposure and outlines possible routes to facilitate it in a student-friendly and constructive way.}
}
@article{CAI2002401,
title = {Generalized and generative thinking in US and Chinese students’ mathematical problem solving and problem posing},
journal = {The Journal of Mathematical Behavior},
volume = {21},
number = {4},
pages = {401-421},
year = {2002},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00142-6},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302001426},
author = {Jinfa Cai and Stephen Hwang},
keywords = {Generalized thinking, Generative thinking, Problem solving, Problem posing, Cross-national study},
abstract = {This study examined US and Chinese 6th grade students’ generalization skills in solving pattern-based problems, their generative thinking in problem posing, and the relationships between students’ performance on problem solving and problem posing tasks. Across the problem solving tasks, Chinese students had higher success rates than US students. The disparities appear to be related to students’ use of differing strategies. Chinese students tend to choose abstract strategies and symbolic representations while US students favor concrete strategies and drawing representations. If the analysis is limited to those students who used concrete strategies, the success rates between the two samples become almost identical. With regard to problem posing, the US and Chinese samples both produce problems of various types, though the types occur in differing sequences. Finally, this study revealed differential relationships between problem posing and problem solving for US and Chinese students. There was a much stronger link between problem solving and problem posing for the Chinese sample than there was for the US sample.}
}
@article{WORKMAN200213,
title = {The state of multivariate thinking for scientists in industry: 1980–2000},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {60},
number = {1},
pages = {13-23},
year = {2002},
note = {Fourth International Conference on Environ metrics and Chemometrics held in Las Vegas, NV, USA, 18-20 September 2000},
issn = {0169-7439},
doi = {https://doi.org/10.1016/S0169-7439(01)00182-4},
url = {https://www.sciencedirect.com/science/article/pii/S0169743901001824},
author = {Jerry Workman},
keywords = {Multivariate thinking, Spectrometer calibration, Spectroscopy-based measurements},
abstract = {Chemometrics has enjoyed tremendous success in the areas related to calibration of spectrometers and spectroscopy-based measurements. These chemometric-based spectrometers have been widely applied for process monitoring and quality assurance. However, chemometrics has the potential to revolutionize the very intellectual roots of problem solving. Are there barriers to a more rapid proliferation of chemometric-based thinking, particularly in industry? What are the potential effects of chemometrics technology and the New Network Economy (NNE) working in concert? Who will be the winners in the race for faster, better, cheaper systems and products? These questions are reviewed in terms of the principles of the NNE and in the promise of chemometrics for industry. What then is the state of multivariate thinking in industry? Several powerful principles are derived from an evaluation of the NNE and chemometrics which could allow chemometrics to proliferate much more rapidly as a key general problem-solving tool.}
}
@article{ATANCE2001533,
title = {Episodic future thinking},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {12},
pages = {533-539},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01804-0},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300018040},
author = {Cristina M. Atance and Daniela K. O'Neill},
keywords = {episodic future thinking, planning, future orientation, self, time, episodic memory, semantic memory},
abstract = {Thinking about the future is an integral component of human cognition – one that has been claimed to distinguish us from other species. Building on the construct of episodic memory, we introduce the concept of ‘episodic future thinking’: a projection of the self into the future to pre-experience an event. We argue that episodic future thinking has explanatory value when considering recent work in many areas of psychology: cognitive, social and personality, developmental, clinical and neuropsychology. Episodic future thinking can serve as a unifying concept, connecting aspects of diverse research findings and identifying key questions requiring further reflection and study.}
}
@article{KOSTERHALE201465,
title = {Thinking about seeing: Perceptual sources of knowledge are encoded in the theory of mind brain regions of sighted and blind adults},
journal = {Cognition},
volume = {133},
number = {1},
pages = {65-78},
year = {2014},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2014.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010027714000675},
author = {Jorie Koster-Hale and Marina Bedny and Rebecca Saxe},
keywords = {Blindness, Theory of mind, Experience, Representation, fMRI, Multivoxel pattern analysis (MVPA)},
abstract = {Blind people’s inferences about how other people see provide a window into fundamental questions about the human capacity to think about one another’s thoughts. By working with blind individuals, we can ask both what kinds of representations people form about others’ minds, and how much these representations depend on the observer having had similar mental states themselves. Thinking about others’ mental states depends on a specific group of brain regions, including the right temporo-parietal junction (RTPJ). We investigated the representations of others’ mental states in these brain regions, using multivoxel pattern analyses (MVPA). We found that, first, in the RTPJ of sighted adults, the pattern of neural response distinguished the source of the mental state (did the protagonist see or hear something?) but not the valence (did the protagonist feel good or bad?). Second, these neural representations were preserved in congenitally blind adults. These results suggest that the temporo-parietal junction contains explicit, abstract representations of features of others’ mental states, including the perceptual source. The persistence of these representations in congenitally blind adults, who have no first-person experience with sight, provides evidence that these representations emerge even in the absence of relevant first-person perceptual experiences.}
}
@article{YANG2025101808,
title = {Cross-domain analogical reasoning ability links functional connectome to creativity},
journal = {Thinking Skills and Creativity},
volume = {57},
pages = {101808},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101808},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000574},
author = {Lin Yang and Rongcan Zeng and Xueyang Wang and Jing Chen and Jing Gu and Jiaxin Fan and Jiang Qiu and Guikang Cao},
keywords = {Cross-domain analogical reasoning, Creativity, CPM, Natural language processing},
abstract = {Cross-domain analogical reasoning (CAR) is a potent cognitive tool that links seemingly unrelated knowledge domains, fostering creative thinking by identifying similarities across different fields. This study aimed to identify functional connectomes encoding individual variations in CAR abilities and assess their role in creativity. Participants included 69 typical university students who underwent resting-state brain MRI scans and behavioral tests. These tests assessed both CAR and within-domain analogical reasoning (WAR) abilities using verbal analogy tasks in the A:B::C:D format and measured individual creativity levels using the Alternative Uses Test (AUT). We employed a connectome-based predictive modeling (CPM) approach, utilizing the Power264 brain atlas to identify functional connectomes supporting CAR abilities. The CPM analysis indicated that the positive network model could reliably predict individual CAR scores. Functional anatomy and lesion analysis revealed that functional connectivity was broadly distributed across the brain. However, the default mode network, along with specific internetwork connections—such as between the salience and sensory/somatomotor mouth networks, and between the fronto-parietal task control and cingulo-opercular task control networks—showed preferential involvement. Moreover, mediation analysis suggested that CAR mediates the influence of brain functional connectomes on creativity. Our research provides evidence for functional neural markers of CAR and reveals a potential neuropsychological pathway for predicting creativity, whereby brain functional connectomes support creativity through CAR.}
}
@article{HUANG201244,
title = {Protocol analysis of designers using an interactive evolutionary computation},
journal = {Frontiers of Architectural Research},
volume = {1},
number = {1},
pages = {44-50},
year = {2012},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2095263512000040},
author = {Weixin Huang and Daisuke Matsushita and Junzo Munemoto},
keywords = {Interior color, Problem-solving behavior, Protocol analysis, Interactive evolutionary computation (IEC)},
abstract = {This paper explores the problem-solving behavior of people in design activities through a protocol analysis of verbal reports on the interior work design process simulated by an interactive evolutionary computation (IEC). The protocol analysis method was used to explore the ways of thinking of the participants throughout the process. The analysis reveals that different parts of the interior scene have different effects on the evaluations, and people tend to use the same evaluation criteria continuously on several images. This kind of behavior is consistent with that of professional designers in past studies and is revealed applicable to non-professionals in the current research.}
}
@article{JOHNSON2025101757,
title = {Shifting pedagogically: Incorporating the social, cultural, and emotional dimensions of student learning to develop STEM-identities in computer science},
journal = {Journal of Applied Developmental Psychology},
volume = {97},
pages = {101757},
year = {2025},
issn = {0193-3973},
doi = {https://doi.org/10.1016/j.appdev.2025.101757},
url = {https://www.sciencedirect.com/science/article/pii/S0193397325000048},
author = {Stanley L. Johnson and Joseph P. Bishop and Kirk D. Rogers},
keywords = {Stem-identity development, Social and emotional learning, Learning sciences, Pedagogy, Computational thinking, Educational equity},
abstract = {Through qualitative inquiry of a 9th-grade computer science (CS) classroom, this paper examines how teachers' pedagogical approaches can help prioritize the social and emotional dimensions of student learning to foster STEM identity and development. Findings from an ethnographic study of the delivery of the Exploring Computer Science curriculum in a high school setting of majority of students of color, and low-income youth identify five high-leverage instructional strategies. These strategies include 1) teacher mindsets towards specific subject areas like computer science; 2) creating conditions for affirming students culturally; 3) intentionally prioritizing student autonomy for social and emotional development; 4) co-constructing knowledge to increase student engagement; and 5) helping students create their own STEM identity by exposing them to STEM professionals of similar racial and cultural characteristics as students. Collectively, these practices offer critical windows into how educators can act as intermediaries in helping students see themselves in the CS field and STEM/CS career pathways. Findings from this study can inform strategies for teacher education and policy efforts seeking to close learning gaps for historically marginalized groups and to improve racial and gender diversity in opportunities for growing STEM fields.}
}
@article{CZAKON202399,
title = {Re-thinking strategic myopia: A necessary condition analysis of heuristic and firm's performance},
journal = {Industrial Marketing Management},
volume = {115},
pages = {99-109},
year = {2023},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2023.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0019850123001864},
author = {Wojciech Czakon and Patrycja Klimas and Arkadiusz Kawa},
keywords = {Myopia, Managers, Heuristic, Performance, NCA},
abstract = {At times of fast paced technology progress and global disruptions strategic myopia can be particularly harmful to firms. A narrow view of actors, events and tendencies is a firm's environment, combined with short-term preferences is widely recognized in the literature as leading to belated or inadequate responses to challenges. Manager's myopia is typically portrayed as a systematic bias, inducing underperformance. However, empirical evidence is more than nuanced in this respect. In this study, we view strategic myopia as an effective heuristic triggered in uncertain environments and specific task conditions. We use the necessary condition analysis (NCA) to examine the association between strategic myopia and firm performance through a necessity logic lens. This innovative method provides insights into the relationship between low levels of strategic myopia dimensions and firm performance in both the short- and long term. We measure strategic myopia and firm performance as multidimensional constructs on a representative sample of 658 Polish managers. Our results challenge the conventional wisdom that low strategic myopia is necessary for high performance. We highlight the nuanced role of myopia across its dimensions (i.e., competitive, cooperative, temporal, and learning) and shed light on its implications for both short- and long-term performance.}
}
@article{GOLDSCHMIDT1994158,
title = {On visual design thinking: the vis kids of architecture},
journal = {Design Studies},
volume = {15},
number = {2},
pages = {158-174},
year = {1994},
issn = {0142-694X},
doi = {https://doi.org/10.1016/0142-694X(94)90022-1},
url = {https://www.sciencedirect.com/science/article/pii/0142694X94900221},
author = {Gabriela Goldschmidt},
keywords = {visual thinking, designing, imagery, sketching, architecture},
abstract = {Designers invariably use imagery to generate new form combinations which they represent through sketching. But they also do the reverse: they sketch to generate images of forms in their minds. Common belief regards such activity as non-rational. In contrast, we assert that interactive imagery through sketching is a rational mode of reasoning, characterized by systematic exchanges between conceptual and figural arguments. Cognitive science, strongly dominated by a linguistic paradigm, has yet to recognize the paramount role of visual reasoning in many instances of problem solving; and in design tool-making, computational and otherwise, we must learn to optimize rather than bypass intuitive visuality.}
}
@article{PICKLO2024112790,
title = {Denoising Particle-In-Cell data via Smoothness-Increasing Accuracy-Conserving filters with application to Bohm speed computation},
journal = {Journal of Computational Physics},
volume = {502},
pages = {112790},
year = {2024},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2024.112790},
url = {https://www.sciencedirect.com/science/article/pii/S0021999124000391},
author = {Matthew J. Picklo and Qi Tang and Yanzeng Zhang and Jennifer K. Ryan and Xian-Zhu Tang},
keywords = {Particle-In-Cell, SIAC filters, Denoising},
abstract = {The simulation of plasma physics is computationally expensive because the underlying physical system is of high dimensions, requiring three spatial dimensions and three velocity dimensions. One popular numerical approach is Particle-In-Cell (PIC) methods owing to its ease of implementation and favorable scalability in high-dimensional problems. An unfortunate drawback of the method is the introduction of statistical noise resulting from the use of finitely many particles. In this paper we examine the application of the Smoothness-Increasing Accuracy-Conserving (SIAC) family of convolution kernel filters as denoisers for moment data arising from PIC simulations. We show that SIAC filtering is a promising tool to denoise PIC data in the physical space as well as capture the appropriate scales in the Fourier space. Furthermore, we demonstrate how the application of the SIAC technique reduces the amount of information necessary in the computation of quantities of interest in plasma physics such as the Bohm speed.}
}
@article{SCHAPER2023100617,
title = {Computational Empowerment and children: Expanding empowerment, agency and participation in computation},
journal = {International Journal of Child-Computer Interaction},
volume = {38},
pages = {100617},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2023.100617},
url = {https://www.sciencedirect.com/science/article/pii/S2212868923000545},
author = {Marie-Monique Schaper and Rachel Charlotte Smith and Ole Sejer Iversen and Christopher Frauenberger and Netta Iivari and Anja Zeising and Mike Tissenbaum and Elizabeth Marie Bonsignore and Jason Yip}
}
@article{LIU2024117403,
title = {Towards quantum computational mechanics},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {432},
pages = {117403},
year = {2024},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2024.117403},
url = {https://www.sciencedirect.com/science/article/pii/S0045782524006583},
author = {Burigede Liu and Michael Ortiz and Fehmi Cirak},
keywords = {Quantum computing, Multiscale analysis, Quantum Fourier transform, Quantum polynomial encoding, Gate-based quantum computing},
abstract = {The advent of quantum computers, operating on entirely different physical principles and abstractions from those of classical digital computers, sets forth a new computing paradigm that can potentially result in game-changing efficiencies and computational performance. Specifically, the ability to simultaneously evolve the state of an entire quantum system leads to quantum parallelism and interference. Despite these prospects, opportunities to bring quantum computing to bear on problems of computational mechanics remain largely unexplored. In this work, we demonstrate how quantum computing can indeed be used to solve representative volume element (RVE) problems in computational homogenisation with polylogarithmic complexity of O((logN)c), compared to O(Nc) in classical computing. Thus, our quantum RVE solver attains exponential acceleration with respect to classical solvers, bringing concurrent multiscale computing closer to practicality. The proposed quantum RVE solver combines conventional algorithms such as a fixed-point iteration for a homogeneous reference material and the Fast Fourier Transform (FFT). However, the quantum computing reformulation of these algorithms requires a fundamental paradigm shift and a complete rethinking and overhaul of the classical implementation. We employ or develop several techniques, including the Quantum Fourier Transform (QFT), quantum encoding of polynomials, classical piecewise Chebyshev approximation of functions and an auxiliary algorithm for implementing the fixed-point iteration and show that, indeed, an efficient implementation of RVE solvers on quantum computers is possible. We additionally provide theoretical proofs and numerical evidence confirming the anticipated O(logN)c complexity of the proposed solver.}
}
@article{LOWALEKAR201789,
title = {Revolutionizing blood bank inventory management using the TOC thinking process: An Indian case study},
journal = {International Journal of Production Economics},
volume = {186},
pages = {89-122},
year = {2017},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2017.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0925527317300336},
author = {Harshal Lowalekar and R. Raghavendra Ravi},
keywords = {Inventory management, Blood banks, Theory of Constraints (TOC), Thinking Process},
abstract = {The purpose of this research is to demonstrate an application of TOC's thinking process (TP) in a blood bank environment. We take an example of a real-life blood bank which is struggling with the problems of high shortage and wastage of blood products, large inventory levels, poor and erratic blood collection, limited product variety, high error rate, high turnover of technicians, high operating expenses and low revenue levels. We show using the TOC approach how these seemingly unrelated problems faced by the bank are in fact highly inter-related and how they all originate from a single root-cause. A current reality tree (CRT) is used to identify the root cause responsible for all the major blood bank problems. A conflict resolution diagram (CRD) is constructed to identify the core-conflict(s) responsible for the blood bank's poor performance. A simple yet powerful solution is generated for the given bank by breaking the core-conflict resulting from a paradigm constraint in blood banking. A future reality tree (FRT) is then constructed to show how the TOC approach will help the blood bank in lowering its shortage and wastage levels in spite of collecting lesser number of units in blood donation camps. The bank will be able to significantly cut down its inventories and can issue fresher units to the patients. Blood bank's revenue levels will increase while its operating expense will decrease due to the TOC approach. The error rate as well as the turnover of technicians in the blood bank laboratory will also reduce considerably. A simulation model shows that the proposed TOC solution will reduce the annual shortage of red blood cells by 66% and platelets by 82% at the bank. Similarly, the wastage of red blood cells will decrease by 93%, plasma by 99% and platelets by 98%. The average inventory level of the red blood cells will drop by 41%, plasma by 95% and platelets by 10%. The major contribution of this research is to show that TP tools can be extremely powerful in constructing win-win solutions for complex systems like blood banks by addressing their major problems in an integrated fashion. The TOC approach reveals how one widely-held belief in the blood banking world is the main reason behind the blood banks' poor state of affairs. The solutions presented in this research should be readily applicable to other blood banks which are struggling to improve their operational and financial performance.}
}
@article{MENG2025105053,
title = {Time-variant response computation of flexible multibody systems with imprecise random fields},
journal = {International Journal of Non-Linear Mechanics},
volume = {173},
pages = {105053},
year = {2025},
issn = {0020-7462},
doi = {https://doi.org/10.1016/j.ijnonlinmec.2025.105053},
url = {https://www.sciencedirect.com/science/article/pii/S0020746225000411},
author = {Jingwei Meng and Yanfei Jin},
keywords = {Hybrid uncertain analysis, Flexible multibody systems, Imprecise random fields, Interval parameters, Polynomial chaos-Legendre metamodel},
abstract = {This paper proposes a new uncertain modelling and analysis method for flexible multibody systems with imprecise random field uncertainties. The standard random field is expanded to the imprecise random field model containing the behavior of imprecise randomness with bounded statistical moments more appropriately for real engineering problems. The imprecise random field is further discretized to independent standard Gaussian random variables by using the Karhunen-Loève expansion method. The flexible multibody system is modeled by using a unified mesh of the absolute node coordinate formula. Mathematical expressions and solution procedure based on the Polynomial chaos-Legendre metamodel are developed to solve the dynamic equations of systems involving imprecise random field. Two types of evaluation indexes are effectively established by constructing the second layer polynomial chaos expansion, namely interval mean value, interval variance, mean of the upper bound, variance of the lower bound. Finally, the effectiveness of the presented method is illustrated by two numerical examples of flexible multibody systems. Especially, for complicated multibody systems, it is necessary to calculate two uncertainty evaluation indexes to study the complete dynamic behavior.}
}
@article{BAGO2018483,
title = {Fast and slow thinking: Electrophysiological evidence for early conflict sensitivity},
journal = {Neuropsychologia},
volume = {117},
pages = {483-490},
year = {2018},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2018.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S0028393218303440},
author = {Bence Bago and Darren Frey and Julie Vidal and Olivier Houdé and Gregoire Borst and Wim {De Neys}},
keywords = {EEG, Dual process theory},
abstract = {Popular dual process models have characterized reasoning as an interplay between fast, intuitive (System 1) and slow, deliberate (System 2) processes, but the precise nature of the interaction between the two systems is much debated. Here we relied on the temporal resolution of electroencephalogram (EEG) recordings to decide between different models. We adopted base-rate problems in which an intuitively cued stereotypical response was either congruent or incongruent with the correct response that was cued by the base-rates. Results showed that solving problems in which the base-rates and stereotypical description cued conflicting responses resulted in an increased centro-parietal N2 and frontal P3. This early conflict sensitivity suggests that the critical base-rates can be processed fast without slow and deliberate System 2 reflection. Findings validate prior EEG work and support recent hybrid dual process models in which the fast System 1 is processing both heuristic belief-based responses (e.g., stereotypes) and elementary logico-mathematical principles (e.g., base-rates).}
}
@article{BROWNING2023104031,
title = {Language, common sense, and the Winograd schema challenge},
journal = {Artificial Intelligence},
volume = {325},
pages = {104031},
year = {2023},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.104031},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223001777},
author = {Jacob Browning and Yann LeCun},
keywords = {Winograd schema challenge, Artificial intelligence, Common-sense, Disambiguation, Symbolic AI, Large language models},
abstract = {Since the 1950s, philosophers and AI researchers have held that disambiguating natural language sentences depended on common sense. In 2012, the Winograd Schema Challenge was established to evaluate the common-sense reasoning abilities of a machine by testing its ability to disambiguate sentences. The designers argued only a system capable of “thinking in the full-bodied sense” would be able to pass the test. However, by 2023, the original authors concede the test has been soundly defeated by large language models which still seem to lack common sense of full-bodied thinking. In this paper, we argue that disambiguating sentences only seemed like a good test of common-sense based on a certain picture of the relationship between linguistic comprehension and semantic knowledge—one typically associated with the early computational theory of mind and Symbolic AI. If this picture is rejected, as it is by most LLM researchers, then disambiguation ceases to look like a comprehensive test of common-sense and instead appear only to test linguistic competence. The upshot is that any linguistic test, not just disambiguation, is unlikely to tell us much about common sense or genuine intelligence.}
}
@article{KOVALCHUK2024102379,
title = {Computation at the Cutting Edge of Science},
journal = {Journal of Computational Science},
volume = {81},
pages = {102379},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102379},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324001728},
author = {Sergey V. Kovalchuk and Clélia {de Mulatier} and Valeria V. Krzhizhanovskaya and Jiří Mikyška and Maciej Paszyński and Jack Dongarra and Peter M.A. Sloot}
}
@article{AZIZ2013679,
title = {Applying lean thinking in construction and performance improvement},
journal = {Alexandria Engineering Journal},
volume = {52},
number = {4},
pages = {679-695},
year = {2013},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2013.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S111001681300046X},
author = {Remon Fayek Aziz and Sherif Mohamed Hafez},
keywords = {Lean production, Lean thinking, Lean construction, Construction industry, Performance and, Improvement theories},
abstract = {The productivity of the construction industry worldwide has been declining over the past 40years. One approach for improving the situation is using lean construction. Lean construction results from the application of a new form of production management to construction. Essential features of lean construction include a clear set of objectives for the delivery process, aimed at maximizing performance for the customer at the project level, concurrent design, construction, and the application of project control throughout the life cycle of the project from design to delivery. An increasing number of construction academics and professionals have been storming the ramparts of conventional construction management in an effort to deliver better value to owners while making real profits. As a result, lean-based tools have emerged and have been successfully applied to simple and complex construction projects. In general, lean construction projects are easier to manage, safer, completed sooner, and cost less and are of better quality. Significant research remains to complete the translation to construction of lean thinking in Egypt. This research will discuss principles, methods, and implementation phases of lean construction showing the waste in construction and how it could be minimized. The Last Planner System technique, which is an important application of the lean construction concepts and methodologies and is more prevalent, proved that it could enhance the construction management practices in various aspects. Also, it is intended to develop methodology for process evaluation and define areas for improvement based on lean approach principles.}
}
@incollection{PARASHAR2024275,
title = {Chapter ten - Computational techniques for sustainable green procurement and production},
editor = {Sanjoy Kumar Paul and Sandeep Kautish},
booktitle = {Computational Intelligence Techniques for Sustainable Supply Chain Management},
publisher = {Academic Press},
pages = {275-300},
year = {2024},
series = {Uncertainty, Computational Techniques, and Decision Intelligence},
isbn = {978-0-443-18464-2},
doi = {https://doi.org/10.1016/B978-0-443-18464-2.00004-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184642000042},
author = {Bhakti Parashar and Sandeep Kautish and Amrita Chaurasia},
keywords = {Computational techniques, computing, green procurement, procurement},
abstract = {Computational techniques are used to generate, solve, analyze, explain, or manage any simple or complex task. The use of environmentally responsible techniques to meet demand for resources, commodities, utilities, and services is known as green procurement. Computational technique in green procurement and production is one of the components of sustainable procurement, along with a commitment to social responsibility and good corporate behavior. Some solutions for this kind of issue are low-maintenance, energy-efficient, and long-lasting. Several experts and researchers provided their findings on the environmental impact of ICT with the use of computational techniques. Also, the importance of energy-efficient information technology for environmentally conscious and feasible information technology is a hot topic because a computer faces environmental challenges at every stage of its life, from development to use to disposal. Due to changing environmental conditions, corporations have prioritized carbon emissions in procurement and transportation, which have the highest carbon impact. To encourage potential suppliers to adopt environmentally friendly practices, green criteria should be introduced into public procurement. Environmentally friendly corporate practices and environmental conservation are considered significant tools through public procurement. Techniques for green procurement and production procedures have recently been correlated with the concept of computational techniques of green procurement and production, owing to the increased emphasis on the concept of computational approaches. For eco-friendly procurement and production operations, computational approaches are inculcated and presented in the same way that they are for green procurement and manufacturing. From this perspective, this chapter presents a methodology for merging computational techniques into green procurement and production in public procurement in the form of green computing.}
}
@article{ZHANG2015201,
title = {Thinking of data protection law's subject matter as a complex adaptive system: A heuristic display},
journal = {Computer Law & Security Review},
volume = {31},
number = {2},
pages = {201-220},
year = {2015},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2015.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0267364915000084},
author = {Kunbei Zhang and Aernout H.J. Schmidt},
keywords = {Data protection law, Complex adaptive system, Dynamics of innovation, Self-organization, Emergence},
abstract = {According to both whistle blowers and public reports, some commercial and governmental practices concerning personal data do not even appear to notice the law as a regulatory force. We are not satisfied by what mainstream legal scholarship has on offer in this context. Positivists consider the issue outside their domain. Realists (including their critical branch) focus on the behavior of legal institutions, ignoring many of the diverse institutions that have regulatory force. We need an additional, complementary perspective to help us, legal scholars, earn and hold serious positions in the diverse disciplinary teams that we need to participate in, in order to adequately investigate (and inform on) persistent problems concerning personal-data protection as faced by legislators. In this article we investigate whether the subject matter of data protection law, identified as Personal Data Community (hereinafter PDC), can be treated as a complex adaptive system (hereinafter CAS). This proposition is premised on the argument that the PDC exhibits key traits of CAS, including systemic, dynamic and complex characteristics. And we further show how complexity theory can help legal scholarship (without losing its identity) to join and add value to diverse disciplinary research and advisory teams. In this article, we aim for a stepping-stone (establishing that data protection law addresses a complex adaptive system with all of its corollaries), rather than for final solutions.}
}
@article{LU2023100154,
title = {Developing a weather prediction project-based machine learning course in facilitating AI learning among high school students},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100154},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100154},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000334},
author = {Wen-Yen Lu and Szu-Chun Fan},
keywords = {Artificial intelligence, Machine learning, Computational thinking, Secondary education},
abstract = {The rapid growth of artificial intelligence (AI) technology has changed lifestyles, work patterns, and educational approaches. However, courses that can guide students through the practical applications of AI technology are still scarce in K-12 education. This study aimed to develop a project-based machine learning (ML) course for the implementation of AI technology. The core idea of this course, which focused on the supervised learning of AI ML technology, was designed based on the project of weather prediction. Furthermore, data collection and status display were realized using various hardware devices such as Arduino and sensors, whereas ML algorithms were implemented in Python programming language. A total of 68 eleventh-grade senior high school students from a public school in Southern Taiwan participated in this study. The main variables included understanding AI concepts, computational thinking (CT), and learning attitude. Data were analyzed using quantitative statistics, including descriptive statistics, t-test, and analysis of covariance, supplemented with qualitative data. Based on the findings, the following conclusions were drawn: (1) the proposed course on the implementation of ML helps students understand the basic concepts of AI; (2) students demonstrate a significant improvement in CT skills after attending this course; (3) although the students’ attitude toward learning AI shows no significant change after attending this course, their overall view for it is positive; (4) contrary to their learning attitude, the CT skills among the students with different capabilities of learning AI are significantly dissimilar. Overall, the machine-learning implementation course developed in this study can serve as a reference for promoting AI education in the future. However, considering learners’ prior knowledge in programming, setting up appropriate learning scaffolding for them, and providing them with more examples of the applications of AI in real-life scenarios is still necessary when conducting the course for improving the students’ attitude toward AI.}
}
@article{FLEMING2024896,
title = {Quality space computations for consciousness},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {10},
pages = {896-906},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001657},
author = {Stephen M. Fleming and Nicholas Shea},
keywords = {consciousness, sensory states, quality space, similarity, neural representation},
abstract = {The quality space hypothesis about conscious experience proposes that conscious sensory states are experienced in relation to other possible sensory states. For instance, the colour red is experienced as being more like orange, and less like green or blue. Recent empirical findings suggest that subjective similarity space can be explained in terms of similarities in neural activation patterns. Here, we consider how localist, workspace, and higher-order theories of consciousness can accommodate claims about the qualitative character of experience and functionally support a quality space. We review existing empirical evidence for each of these positions, and highlight novel experimental tools, such as altering local activation spaces via brain stimulation or behavioural training, that can distinguish these accounts.}
}
@article{KAVGA2023102837,
title = {Design and simulation of a greenhouse in a computational environment (ANSYS/FLUENT) and an automatic control system in a LABVIEW environment},
journal = {Simulation Modelling Practice and Theory},
volume = {129},
pages = {102837},
year = {2023},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2023.102837},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X23001144},
author = {Angeliki Kavga and Vasileios Thomopoulos and Evangelos Pischinas and Dimitris Tsipianitis and Pantelis Nikolakopoulos},
keywords = {Greenhouses, Digital twin, Control, Arduino, Fuzzy logic},
abstract = {Greenhouses have been used to increase agricultural production. With the development of technology, they can now be automated. Many studies have been done on the automatic control of their microclimate, from intelligent control systems to Computational Fluid Dynamics (CFD) analyses, with the main purpose of optimal control of the microclimate and at the same time saving energy. This research concerns the process of modeling, design, and simulation of an automatic control system in greenhouses. More specifically, a virtual greenhouse (digital twin) is designed, and in it, the natural phenomena that take place in a real greenhouse are simulated. The program used for the simulations is Ansys FLUENT, suitable for CFD analyses. A branch of artificial intelligence, fuzzy logic, which is a method of replicating human thinking was utilized. To find the optimal control system, four fuzzy controllers were tested, and the optimal control system that the simulations indicated was implemented on an Arduino board using the LabVIEW program. The control was done at the temperature inside the greenhouse, with real weather data from a real greenhouse.}
}
@article{BICER2024101652,
title = {Exploring creativity in mathematics assessment: An analysis of standardized tests},
journal = {Thinking Skills and Creativity},
volume = {54},
pages = {101652},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101652},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124001901},
author = {Ali Bicer and Tugce Aldemir and Geoff Krall and Fay Quiroz and Scott Chamberlin and Jana L. Nelson and Yujin Lee and Hyunkyung Kwon},
keywords = {Mathematical creativity, Assessment for creativity, Creativity-directed tasks},
abstract = {This paper aims to investigate whether US standardized tests provide opportunities for students to demonstrate their creative thinking abilities through the inclusion of creativity-directed problems in their mathematics assessments. Our results indicated that two commonly used standardized national tests (i.e., PARCC and SBAC) do offer students some opportunities to exhibit their creative thinking skills by incorporating creativity-directed problems (e.g., multiple solution tasks) in their assessments. However, not all creativity-directed tasks are present at every grade level. The findings of this paper are significant not only because they reveal the potential of these tests to include creativity-directed tasks but also because they underscore the importance of assessment materials in fostering students’ creative thinking skills in mathematics, as assessments significantly influence teachers’ instructional practices and curriculum materials.}
}
@article{DENEYS20081248,
title = {Conflict monitoring in dual process theories of thinking},
journal = {Cognition},
volume = {106},
number = {3},
pages = {1248-1299},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2007.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S0010027707001576},
author = {Wim {De Neys} and Tamara Glumicic},
keywords = {Reasoning, Decision making, Heuristics and biases, Conflict monitoring, Dual process theories},
abstract = {Popular dual process theories have characterized human thinking as an interplay between an intuitive-heuristic and demanding-analytic reasoning process. Although monitoring the output of the two systems for conflict is crucial to avoid decision making errors there are some widely different views on the efficiency of the process. Kahneman [Kahneman, D. (2002). Maps of bounded rationality: A perspective on intuitive judgement and choice. Nobel Prize Lecture. Retrieved January 11, 2006, from: http://nobelprize.org/nobel_prizes/economics/laureates/2002/kahnemann-lecture.pdf] and Evans [Evans, J. St. B. T. (1984). Heuristic and analytic processing in reasoning. British Journal of Psychology, 75, 451–468], for example, claim that the monitoring of the heuristic system is typically quite lax whereas others such as Sloman [Sloman, S. A. (1996). The empirical case for two systems of reasoning. Psychological Bulletin, 119, 3–22] and Epstein [Epstein, S. (1994). Integration of the cognitive and psychodynamic unconscious. American Psychologists, 49, 709–724] claim it is flawless and people typically experience a struggle between what they “know” and “feel” in case of a conflict. The present study contrasted these views. Participants solved classic base rate neglect problems while thinking aloud. In these problems a stereotypical description cues a response that conflicts with the response based on the analytic base rate information. Verbal protocols showed no direct evidence for an explicitly experienced conflict. As Kahneman and Evans predicted, participants hardly ever mentioned the base rates and seemed to base their judgment exclusively on heuristic reasoning. However, more implicit measures of conflict detection such as participants’ retrieval of the base rate information in an unannounced recall test, decision making latencies, and the tendency to review the base rates indicated that the base rates had been thoroughly processed. On control problems where base rates and description did not conflict this was not the case. Results suggest that whereas the popular characterization of conflict detection as an actively experienced struggle can be questioned there is nevertheless evidence for Sloman’s and Epstein’s basic claim about the flawless operation of the monitoring. Whenever the base rates and description disagree people will detect this conflict and consequently redirect attention towards a deeper processing of the base rates. Implications for the dual process framework and the rationality debate are discussed.}
}
@article{HELVACIOZACAR2023100560,
title = {Centering and decentering children in computing through joint activity at a computational science exhibit},
journal = {International Journal of Child-Computer Interaction},
volume = {35},
pages = {100560},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100560},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000782},
author = {Basak {Helvaci Ozacar} and Stephanie Hladik},
keywords = {Public computing, Joint activity, Science museums, Facilitation, Computer science education, Adult–child interactions},
abstract = {In this paper, we offer an investigation of the nuances of adult–child interactions at a computational science exhibit in a Canadian science museum. The theoretical lens of joint activity allows us to understand learning to code as a collaborative, intergenerational activity distributed between learners, educators, exhibit hardware, and the computer code itself. Specifically, we attend to the ways in which children can be centered at the computational science exhibit (moments in which their goals, histories, and desires are driving the exhibit’s interaction) by the actions of parents and museum facilitators or be decentered by them. Through qualitative analysis of video-recorded interactions of adults and children at the exhibit, we present categories of centering or decentering interactions while preserving the nuance and ambiguity involved in sociocultural contexts of learning. We also highlight two cases that illustrate the complexity and heterogeneity involved in facilitating a computational science exhibit. We close with a discussion and a call to eschew technocentric views of computing education that focus solely on device-level engagement and instead attend to the complex human–human interactions involved in computing education.}
}
@article{TURNER2018782,
title = {Enterprise Thinking for Self-aware Systems},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {11},
pages = {782-789},
year = {2018},
note = {16th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.08.414},
url = {https://www.sciencedirect.com/science/article/pii/S2405896318315404},
author = {Pat Turner and Peter Bernus and Ovidiu Noran},
keywords = {Internet of Things, Systems of Systems, Self-aware systems, Service Oriented Enterprise Architectures, Enterprise System Engineering, Self-organization},
abstract = {The paper aims to provide high-level guidance for architects of cyber-physical enterprises. We propose that interactions within such systems should be largely self-determined, based on system self-awareness and dynamic re-configuration, with the architecture evolving based on a set of foundational principles, rather than being pre-defined by an external designer. We investigate the suitability of typical development life cycles and identify architectural challenges in the context of dynamic cyber-physical systems that utilize the power of the Internet of Things. Desired systemic attributes are defined, which are necessary for making suitable core architectural choices. The application of the findings is exemplified through a case study, a synthesis of issues, and implications for further research.}
}
@incollection{PREISIG20121682,
title = {Thinking Ontologies},
editor = {Iftekhar A. Karimi and Rajagopalan Srinivasan},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {31},
pages = {1682-1686},
year = {2012},
booktitle = {11th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-444-59506-5.50167-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044459506550167X},
author = {Heinz A. Preisig},
keywords = {computer-aided modelling, software tools, process engineering},
abstract = {Ontologies are a means of abstraction and concentrating information. Whilst it has mostly found acceptance in the computer and information technology domain, it is an excellent thinking pattern promoting a more structural approach to chemical engineering problems on all levels, starting with the representation of functionalities, their combination to form processing units and combined again as whole plants. The concepts helps in constructing models that adhere to basic concepts as they are the foundation for physical processes: the conservation principles and the description of transport phenomena. The material models, the interaction between different chemical species or biological species form a knowledge framework suitable in in case of biological processes also intensively mapped into ontologies. When properly used, The high density of information, makes it easy to check consistency and the consistent use in all applications yields a framework that produces reliable, checkable results quickly and efficiently and consistency across applications that in the past have been without any information link.}
}
@article{WEST20121551,
title = {The importance of quantitative systemic thinking in medicine},
journal = {The Lancet},
volume = {379},
number = {9825},
pages = {1551-1559},
year = {2012},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(12)60281-5},
url = {https://www.sciencedirect.com/science/article/pii/S0140673612602815},
author = {Geoffrey B West},
abstract = {Summary
The study and practice of medicine could benefit from an enhanced engagement with the new perspectives provided by the emerging areas of complexity science and systems biology. A more integrated, systemic approach is needed to fully understand the processes of health, disease, and dysfunction, and the many challenges in medical research and education. Integral to this approach is the search for a quantitative, predictive, multilevel, theoretical conceptual framework that both complements the present approaches and stimulates a more integrated research agenda that will lead to novel questions and experimental programmes. As examples, the importance of network structures and scaling laws are discussed for the development of a broad, quantitative, mathematical understanding of issues that are important in health, including ageing and mortality, sleep, growth, circulatory systems, and drug doses. A common theme is the importance of understanding the quantifiable determinants of the baseline scale of life, and developing corresponding parameters that define the average, idealised, healthy individual.}
}
@article{DELUCA2021101553,
title = {The development of machine intelligence in a computational universe},
journal = {Technology in Society},
volume = {65},
pages = {101553},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101553},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21000282},
author = {Gabriele {De Luca}},
keywords = {Machine intelligence, Computational universe, Bohmian mechanics, History of AI, Mechanical rationalism},
abstract = {The paper is dedicated to the study of the theoretical and technological development that occurred, in particular in the XX century, in the sector of Artificial Intelligence. According to the theoretical framework of mechanical rationalism, we study how the development of machine intelligence is a continuation, through different means, of the old process of outsourcing of cognitive activities by humans onto parts of their physical environments. Because of this process, an increasingly larger portion of the non-human environment performs perceptive and cognitive activities. From this follows that machine systems, not necessarily humans anymore, are the components of the physical environment that perform measurements on the universe of which the humans are also components. We suggest that the scientific discussion on the topic of AI development could be framed in the context of a more general phenomenon of an increase in the computational and perceptual capabilities of the physical universe, as opposed to a merely human and technological problem. This is because, ever so slightly, humans are being removed from the cognitive processes of technological systems they created, which continue to perceive and think autonomously. The act of machine cognition, or rather, of machine measurements, causes an effect on the environment in which humans live, and ever more so than the human measurements. Finally, we discuss the current approach to the development of viable AI systems that aim at increasing the reciprocal intelligence of humans and machines, rather than the replacement of the former's cognitive faculties by the latter.}
}
@article{KERN2000341,
title = {Structuring financial statement analysis projects to enhance critical thinking skills development},
journal = {Journal of Accounting Education},
volume = {18},
number = {4},
pages = {341-353},
year = {2000},
issn = {0748-5751},
doi = {https://doi.org/10.1016/S0748-5751(01)00005-7},
url = {https://www.sciencedirect.com/science/article/pii/S0748575101000057},
author = {Beth B. Kern},
keywords = {Financial statement analysis, Critical thinking},
abstract = {This paper documents a method of structuring financial statement analysis projects to enhance the development of students’ critical thinking skills. The project is structured in a cooperative learning framework in which a student accesses financial statement information from the World Wide Web, performs a financial statement analysis, and then engages in an exercise with other students who have analyzed firms in the same industry. Both the individual and team phases of the project offer opportunities for students to develop several important critical thinking skills.}
}
@incollection{HARTSON2012251,
title = {Chapter 7 - Design Thinking, Ideation, and Sketching},
editor = {Rex Hartson and Partha S. Pyla},
booktitle = {The UX Book},
publisher = {Morgan Kaufmann},
address = {Boston},
pages = {251-297},
year = {2012},
isbn = {978-0-12-385241-0},
doi = {https://doi.org/10.1016/B978-0-12-385241-0.00007-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123852410000075},
author = {Rex Hartson and Partha S. Pyla}
}
@article{SELICATI2021124932,
title = {The interoperability of exergy and Life Cycle Thinking in assessing manufacturing sustainability: A review of hybrid approaches},
journal = {Journal of Cleaner Production},
volume = {286},
pages = {124932},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2020.124932},
url = {https://www.sciencedirect.com/science/article/pii/S0959652620349763},
author = {Valeria Selicati and Nicola Cardinale and Michele Dassisti},
keywords = {Exergy, Hybrid methods, Integration modelling, Life cycle assessment, Process reversibility, Sustainable manufacturing},
abstract = {Today, the Life Cycle Assessment (LCA) is the most employed tool for assessing the sustainability of products and processes, both from an environmental, social and economic point of view. Exergy is defined by literature as the amount of useful work that can be derived from a real system when it is brought into equilibrium with its environment. In the literature, it is considered an outstanding concept that can be applied to enhance the effectiveness of ordinary evaluation models such as LCA. The literature proposes a variety of hybrid approaches that combine Exergetic Analysis (EA) and LCA with different combination frameworks. The aim of this paper is to describe the potential of each hybrid method and to characterize the degree of interoperability between EA and LCA that each of them can provide. Nevertheless, there are drawbacks that seem to be too challenging to overcome: a variety of inconsistencies in the interpretation of the results due to the difficulty of the inventory phase and the ambiguity in the choice of the correct alternative in the standard databases; the link with old techniques that refers to obsolete approaches in finding data that suit to the updated goals and scopes; the difficulty in conducting an assessment affected by the least possible uncertainty. Following a theoretical overview of the principles of each hybrid method that binds EA and LCA, the authors want to provide a review from a completely different point of view than the state-of-the-art literature, on how effectively EA and LCA can interact with each other in order to provide a more holistic view of the system/process to be assessed. The fascinating circumstance that emerges from the review is that any exergy approach would be more effective if joined (not replaced) to the standard LCA, because it turned out to be complementary. This theory has long been developed by many authors in their case studies as a confirmation of what Gutowski wrote years ago: no single alternative criteria or subsidiary model, independently of how well aggregated, may offer a suitable answer for all conditions. Specifically, through this review, the practitioners would be able to choose the best suited hybrid methodology, according to their aims, join the outcomes together and achieve a transdisciplinary knowledge of the behavior of the study case system, in order to design the best improvement strategies.}
}
@article{LAMBERT202132,
title = {From creative thinking to scientific principles in clinical practice},
journal = {Injury},
volume = {52},
number = {1},
pages = {32-36},
year = {2021},
note = {In Tribute To Professor Dr med Stephan Perren},
issn = {0020-1383},
doi = {https://doi.org/10.1016/j.injury.2020.09.036},
url = {https://www.sciencedirect.com/science/article/pii/S0020138320307397},
author = {Simon Lambert and Dominic Mischler and Markus Windolf and Pietro Regazzoni and Alberto Fernandez Dell'Oca and Boyko Gueorguiev and Peter Varga},
keywords = {Stephan Perren, AO Foundation, Strain theory, Education, Surgical skills, ICUC, OSAPP},
abstract = {Stephan Perren's contributions to the understanding and application of the principles of bone pathobiology, healing, and fracture fixation to clinical care remain as a lasting legacy of a great creative mind. Less well appreciated perhaps were his important contributions to the dissemination and practical application of those principles through the use of technology as applied to the learning environment. This paper describes and pays tribute to a series of initiatives in which Perren was a leading mentor and collaborator in the development of methods and instruments through which the principles of bone mechano-pathobiology could be translated through active learning environments into the practical world of clinical musculoskeletal traumatology.}
}
@article{PROULX2005345,
title = {Network thinking in ecology and evolution},
journal = {Trends in Ecology & Evolution},
volume = {20},
number = {6},
pages = {345-353},
year = {2005},
note = {SPECIAL ISSUE: BUMPER BOOK REVIEW},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2005.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0169534705000881},
author = {Stephen R. Proulx and Daniel E.L. Promislow and Patrick C. Phillips},
abstract = {Although pairwise interactions have always had a key role in ecology and evolutionary biology, the recent increase in the amount and availability of biological data has placed a new focus on the complex networks embedded in biological systems. The increased availability of computational tools to store and retrieve biological data has facilitated wide access to these data, not just by biologists but also by specialists from the social sciences, computer science, physics and mathematics. This fusion of interests has led to a burst of research on the properties and consequences of network structure in biological systems. Although traditional measures of network structure and function have started us off on the right foot, an important next step is to create biologically realistic models of network formation, evolution, and function. Here, we review recent applications of network thinking to the evolution of networks at the gene and protein level and to the dynamics and stability of communities. These studies have provided new insights into the organization and function of biological systems by applying existing techniques of network analysis. The current challenge is to recognize the commonalities in evolutionary and ecological applications of network thinking to create a predictive science of biological networks.}
}
@article{SUMMERER2014242,
title = {Thinking tomorrows' space – Research trends of the ESA advanced concepts team 2002–2012},
journal = {Acta Astronautica},
volume = {95},
pages = {242-259},
year = {2014},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2013.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0094576513003949},
author = {L. Summerer},
keywords = {Future, Technology trends, Advanced research topics, Disruptive innovation},
abstract = {This paper presents technological and conceptual visions beyond the traditional planning horizon of space agencies. It relies on the research and reflections within the larger advanced concepts research community created by and around the European Space Agency's Advanced Concepts Team as well as the results of a two-day long symposium in July 2012, including Europe's first space ‘un-conference’, focussed on re-thinking the future of space beyond the traditional thought boundaries of the space sector. For this purpose it reviews visions and expectations formulated at the creation of the ACT, results obtained and fundamental changes that are expected to shape space activities and the space sector in a 10–15+ years time frame, while relaying these to specific ongoing research activities.}
}
@article{SHOVLIN20253,
title = {When “loss-of-function” means proteostasis burden: Thinking again about coding DNA variants},
journal = {The American Journal of Human Genetics},
volume = {112},
number = {1},
pages = {3-10},
year = {2025},
issn = {0002-9297},
doi = {https://doi.org/10.1016/j.ajhg.2024.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0002929724004440},
author = {Claire L. Shovlin and Micheala A. Aldred},
abstract = {Each human genome has approximately 5 million DNA variants. Even for complete loss-of-function variants causing inherited, monogenic diseases, current understanding based on gene-specific molecular function does not adequately predict variability observed between people with identical mutations or fluctuating disease trajectories. We present a parallel paradigm for loss-of-function variants based on broader consequences to the cell when aberrant polypeptide chains of amino acids are translated from mutant RNA to generate mutated proteins. Missense variants that modify primary amino acid sequence, and nonsense/frameshift variants that generate premature termination codons (PTCs), are placed in context alongside emergent themes of chaperone binding, protein quality control capacity, and cellular adaptation to stress. Relatively stable proteostasis burdens are contrasted with rapid changes after induction of gene expression, or stress responses that suppress nonsense mediated decay (NMD) leading to higher PTC transcript levels where mutant proteins can augment cellular stress. For known disease-causal mutations, an adjunctive variant categorization system enhances clinical predictive power and precision therapeutic opportunities. Additionally, with typically more than 100 nonsense and frameshift variants, and ∼10,000 missense variants per human DNA, the paradigm focuses attention on all protein-coding DNA variants, and their potential contributions to multimorbid states beyond classically designated inherited diseases. Experimental testing in clinically relevant systems is encouraged to augment current atlases of protein expression at single-cell resolution, and high-throughput experimental data and deep-learning models that predict which amino acid substitutions generate enhanced degradative burdens. Incorporating additional dimensions such as pan-proteome competition for chaperones, and age-related loss of proteostasis capacity, should further accelerate health impacts.}
}
@article{CHAMPAGNE201912,
title = {Diagrams and alien ways of thinking},
journal = {Studies in History and Philosophy of Science Part A},
volume = {75},
pages = {12-22},
year = {2019},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2018.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S0039368118300281},
author = {Marc Champagne},
keywords = {Inference, Astrobiology, Messaging, Diagrams, Diagrammatic reasoning, C. S. Peirce},
abstract = {The recent wave of data on exoplanets lends support to METI ventures (Messaging to Extra-Terrestrial Intelligence), insofar as the more exoplanets we find, the more likely it is that “exominds” await our messages. Yet, despite these astronomical advances, there are presently no well-confirmed tests against which to check the design of interstellar messages. In the meantime, the best we can do is distance ourselves from terracentric assumptions. There is no reason, for example, to assume that all inferential abilities are language-like. With that in mind, I argue that logical reasoning does not have to be couched in symbolic notation. In diagrammatic reasoning, inferences are underwritten, not by rules, but by transformations of self-same qualitative signs. I use the Existential Graphs of C. S. Peirce to show this. Since diagrams are less dependent on convention and might even be generalized to cover non-visual senses, I argue that METI researchers should add some form of diagrammatic representations to their repertoire. Doing so can shed light, not just on alien minds, but on the deepest structures of reasoning itself.}
}
@incollection{ESTES2011249,
title = {Chapter eight - Thematic Thinking: The Apprehension and Consequences of Thematic Relations},
editor = {Brian H. Ross},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {54},
pages = {249-294},
year = {2011},
booktitle = {Advances in Research and Theory},
issn = {0079-7421},
doi = {https://doi.org/10.1016/B978-0-12-385527-5.00008-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123855275000085},
author = {Zachary Estes and Sabrina Golonka and Lara L. Jones},
keywords = {Categorization, Language, Similarity, Taxonomic relations, Thematic integration, Thematic relations},
abstract = {A thematic relation is a temporal, spatial, causal, or functional relation between things that perform complementary roles in the same scenario or event. For example, cows and milk are related by a production theme, and sails and anchors are related via a boating theme. Thematic relations are distinct from mere associations, scripts, and ad hoc categories. They also contrast and complement taxonomic (categorical) relations such as “fruits” and “furniture.” Thematic relations and taxonomic relations arise from distinct processes, as evidenced by numerous neuropsychological and behavioral dissociations. Thematic relations may be apprehended uncontrollably and rapidly according to how frequently and recently they have been encountered. They exert profound effects on many core cognitive processes, including similarity, categorization, memory, language, inference, and analogy, and they exhibit robust processing differences across individuals and cultures. In sum, without such thematic thinking, models of cognition will remain categorically limited.}
}
@article{SLEZAK2002353,
title = {Thinking about thinking: language, thought and introspection},
journal = {Language & Communication},
volume = {22},
number = {3},
pages = {353-373},
year = {2002},
issn = {0271-5309},
doi = {https://doi.org/10.1016/S0271-5309(02)00012-5},
url = {https://www.sciencedirect.com/science/article/pii/S0271530902000125},
author = {Peter Slezak},
keywords = {Language, Thought, Mentalese, Introspection, Imagery, Homunculus},
abstract = {I do not think that the world or the sciences would ever have suggested to me any philosophical problems. What has suggested philosophical problems to me is things which other philosophers have said about the world or the sciences.(G.E. Moore, 1942, p. 14) Peter Carruthers has made a vigorous attempt to defend the admittedly unfashionable doctrine that we think ‘in' language, despite its displacement by something like Fodor's ‘language of thought'. The idea that we think in language has considerable intuitive persuasiveness, but I suggest that this is not the force of good argument and evidence, but a familiar kind of introspective illusion. In this regard, the question of language and thought derives a more general interest, since the illusion is independently familiar from other notorious disputes in cognitive science such as the ‘imagery debate’.}
}
@article{CHOPARD2024102115,
title = {Preface—From the modeling of social behavior to computational diplomacy},
journal = {Journal of Computational Science},
volume = {77},
pages = {102115},
year = {2024},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102115},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001758},
author = {Bastien Chopard and Stephan Davishofer and Dirk Helbing and Nicolas Levrat and Peter Sloot}
}
@article{MARUPAKA2012147,
title = {Connectivity and thought: The influence of semantic network structure in a neurodynamical model of thinking},
journal = {Neural Networks},
volume = {32},
pages = {147-158},
year = {2012},
note = {Selected Papers from IJCNN 2011},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2012.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S0893608012000330},
author = {Nagendra Marupaka and Laxmi R. Iyer and Ali A. Minai},
keywords = {Semantic networks, Semantic cognition, Creativity, Cognitive dynamics, Itinerant dynamics, Attractor networks},
abstract = {Understanding cognition has been a central focus for psychologists, neuroscientists and philosophers for thousands of years, but many of its most fundamental processes remain very poorly understood. Chief among these is the process of thought itself: the spontaneous emergence of specific ideas within the stream of consciousness. It is widely accepted that ideas, both familiar and novel, arise from the combination of existing concepts. From this perspective, thought is an emergent attribute of memory, arising from the intrinsic dynamics of the neural substrate in which information is embedded. An important issue in any understanding of this process is the relationship between the emergence of conceptual combinations and the dynamics of the underlying neural networks. Virtually all theories of ideation hypothesize that ideas arise during the thought process through association, each one triggering the next through some type of linkage, e.g., structural analogy, semantic similarity, polysemy, etc. In particular, it has been suggested that the creativity of ideation in individuals reflects the qualitative structure of conceptual associations in their minds. Interestingly, psycholinguistic studies have shown that semantic networks across many languages have a particular type of structure with small-world, scale free connectivity. So far, however, these related insights have not been brought together, in part because there has been no explicitly neural model for the dynamics of spontaneous thought. Recently, we have developed such a model. Though simplistic and abstract, this model attempts to capture the most basic aspects of the process hypothesized by theoretical models within a neurodynamical framework. It represents semantic memory as a recurrent semantic neural network with itinerant dynamics. Conceptual combinations arise through this dynamics as co-active groups of neural units, and either dissolve quickly or persist for a time as emergent metastable attractors and are recognized consciously as ideas. The work presented in this paper describes this model in detail, and uses it to systematically study the relationship between the structure of conceptual associations in the neural substrate and the ideas arising from this system’s dynamics. In particular, we consider how the small-world and scale-free characteristics influence the effectiveness of the thought process under several metrics, and show that networks with both attributes indeed provide significant advantages in generating unique conceptual combinations.}
}
@article{KHALIL2022104656,
title = {A neurocomputational model of creative processes},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {137},
pages = {104656},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104656},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422001452},
author = {Radwa Khalil and Ahmed A. Moustafa},
keywords = {Divergent Thinking, Convergent Thinking, Abstraction, Improvisation, Novelty, Computational Model, Prefrontal Cortex, Hippocampus, Basal Ganglia, Cerebellum, Dopamine, Usefulness, Surprise},
abstract = {Creativity is associated with finding novel, surprising, and useful solutions. We argue that creative cognitive processes, divergent thinking, abstraction, and improvisation are constructed on different novelty-based processes. The prefrontal cortex plays a role in creative ideation by providing a control mechanism. Moreover, thinking about novel solutions activates the distant or loosely connected neurons of a semantic network that involves the hippocampus. Novelty can also be interpreted as different combinations of earlier learned processes, such as the motor sequencing mechanism of the basal ganglia. In addition, the cerebellum is responsible for the precise control of movements, which is particularly important in improvisation. Our neurocomputational perspective is based on three creative processes centered on novelty seeking, subserved by the prefrontal cortex, hippocampus, cerebellum, basal ganglia, and dopamine. The algorithmic implementation of our model would enable us to describe commonalities and differences between these creative processes based on the proposed neural circuitry. Given that most previous studies have mainly provided theoretical and conceptual models of creativity, this article presents the first brain-inspired neural network model of creative cognition.}
}
@article{ELLIOTT2024307a,
title = {Utilizing a structured undergraduate research framework to improve student success and mentoring capacity in a computational biophysics lab},
journal = {Biophysical Journal},
volume = {123},
number = {3, Supplement 1},
pages = {307a},
year = {2024},
issn = {0006-3495},
doi = {https://doi.org/10.1016/j.bpj.2023.11.1898},
url = {https://www.sciencedirect.com/science/article/pii/S0006349523025985},
author = {Truitt J. Elliott and Jonathan Briganti and Anne M. Brown}
}
@article{WOLFENGAGEN2024101183,
title = {Building a cognitive system based on process interaction},
journal = {Cognitive Systems Research},
volume = {83},
pages = {101183},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101183},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723001171},
author = {Viacheslav E. Wolfengagen and Larisa Ismailova and Sergey Kosikov},
keywords = {Computational thinking, Applicative prestructure, Theory of combinators, Cognitive modeling, Computation process, Interaction, Semantic modeling},
abstract = {According to modern notions, computing is not separable from cognitive modeling and activity. This paper continues the tradition of the uniform approach and proposes a small number of general mechanisms that cope with the main known effects of computing as a science — the interaction of objects-as-processes, the interaction of processes with the environment, generalized interaction. As shown, the applicative prestructure (objects-as-processes, application) generates an applicative structure (processes, application, values), which ensures the generation of the result — the value of interactions, enabling the process of evaluation. The theory of combinators is used as the main (meta)mathematical means. A diagram mechanism has been developed that implements the emerging applicative computational system of object interaction and reflects the arity of accompanying the induced information processes. The processes are bidirectional in nature, both with a decrease in arity – reduction, and with an increase in arity – expansion.}
}
@article{FLACH2017612,
title = {Supporting productive thinking: The semiotic context for Cognitive Systems Engineering (CSE)},
journal = {Applied Ergonomics},
volume = {59},
pages = {612-624},
year = {2017},
note = {The Legacy of Jens Rasmussen},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2015.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0003687015300739},
author = {John Flach},
keywords = {Cognitive Systems Engineering, Abstraction Hierarchy, Work domain analysis, Decision Ladder, Skills-Rules-Knowledge Model, Ecological Interface Design, Proactive Risk Management},
abstract = {The central thesis of this paper is that Rasmussen framed his approach to Cognitive Systems Engineering from the perspective of a Triadic Semiotic Model. This frame became the context for integrating multiple intellectual threads including Control Theory, Information Theory, Ecological Psychology, and Gestalt Psychology into a coherent theoretical framework. The case is made that the triadic semiotic framework is essential for a complete appreciation of the constructs that were central to Rasmussen's approach: Abstraction Hierarchy, Skill-Rules-Knowledge Model, Ecological Interface Design, and Proactive Risk Management.}
}
@article{BAYAGA2024100491,
title = {Enhancing M Enhancing mathematics problem-solving skills in AI-driven environment: Integrated SEM-neural network approach},
journal = {Computers in Human Behavior Reports},
volume = {16},
pages = {100491},
year = {2024},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100491},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824001246},
author = {Anass Bayaga},
keywords = {Gamification, AI, Digitisation, Education, Higher-order thinking, Game-based learning},
abstract = {This study explores the nexus of gamification, artificial intelligence (AI), and mathematics cognition. Sample size of 71 responded in an intervention using game-based learning (GBL) approach. The purpose of designing the GBL was to enhance computational thinking and mathematical skills. The research employed multigroup partial least squares structural equation modelling (MGA-PLS-SEM) and artificial neural networks (ANN) through multilayer perceptron (MLP) as data analysis technique. The findings showed significant positive influence on class engagement, attitudes toward mathematics, as well as student performance. The analysis also revealed gender-related variations, which affirmed the model's consistency across diverse groups. The study validated the hypothesis and consequently advocated for the transformative potential of gamification, in preparation of 21st-century learners for AI-driven digital landscape. The implications are to ensure the integration of gamified elements into educational strategies, benefiting educators, curriculum developers, and policymakers resonating strongly for educators, curriculum developers, and policymakers.}
}
@article{HENRIQUE2023100546,
title = {Who creates our computational worlds? A review of Critically Conscious Computing: Methods for secondary education},
journal = {International Journal of Child-Computer Interaction},
volume = {35},
pages = {100546},
year = {2023},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100546},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000642},
author = {Brendan Henrique and Collette Roberto and Michelle Hoda Wilkerson},
keywords = {Computational thinking, Computational literacy, Computer science education, Critical computing, Critical computational literacy, Critical computer science education},
abstract = {Despite growing attention to the social and ethical dimensions of Computer Science (CS), few practical resources exist to teach and learn CS through the lens of social responsibility. In Critically Conscious Computing, Ko and colleagues provide a comprehensive overview of foundational computing concepts with a sharp and needed critical perspective. In this review, we attend not only to the content of the book, but also to its format as a free, online, “living” text. The book is commendable for its tight integration of technical and socio-critical aspects of computing, approachable conversational style, and collection of flexible and practical resources for teachers. It would benefit from refinement of the integration chapters and a more explicit model for how educators themselves can approach new or different CS concepts through a critical frame. Overall, we strongly recommend this book for CS Educators at all levels for its balance of depth and practicality.}
}
@article{HEMERY2024114432,
title = {On a model of online analog computation in the cell with absolute functional robustness: Algebraic characterization, function compiler and error control},
journal = {Theoretical Computer Science},
volume = {991},
pages = {114432},
year = {2024},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2024.114432},
url = {https://www.sciencedirect.com/science/article/pii/S0304397524000471},
author = {Mathieu Hemery and François Fages},
keywords = {Analog computation, Online computation, Robustness, Stabilization, Algebraic functions, Chemical reaction networks, Chemical computation},
abstract = {The Turing completeness of continuous Chemical Reaction Networks (CRNs) states that any computable real function can be computed by a continuous CRN on a finite set of molecular species, possibly restricted to elementary reactions, i.e. with at most two reactants and mass action law kinetics. In this paper, we introduce a more stringent notion of robust online analog computation, called Absolute Functional Robustness (AFR), for the CRNs that stabilize the concentration values of some output species to the result of one function of the input species concentrations, while allowing arbitrary perturbations for intermediate and output species throughout the attraction basin. We prove that the set of real functions stabilized by a CRN with mass action law kinetics is precisely the set of real algebraic functions. Based on this result, we present a compiler which takes as input any algebraic function (defined by one polynomial and one point for selecting one branch of the algebraic curve defined by the polynomial) and generates an abstract CRN to stabilize it. Furthermore, we provide error bounds to estimate and control the error of an unperturbed system, under the assumption that the environment inputs are driven by k-Lipschitz functions.}
}
@article{NA202250,
title = {Computational mechanisms underlying illusion of control in delusional individuals},
journal = {Schizophrenia Research},
volume = {245},
pages = {50-58},
year = {2022},
note = {Computational Approaches to Understanding Psychosis},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.01.054},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422000652},
author = {Soojung Na and Sylvia Blackmore and Dongil Chung and Madeline O'Brien and Sarah M. Banker and Matthew Heflin and Vincenzo G. Fiore and Xiaosi Gu},
keywords = {Delusion, Social controllability, Illusion of control, Beliefs, Schizophrenia, Computational psychiatry},
abstract = {Humans navigate complex situations that require the accurate estimation of the controllability of the environment. Aberrant controllability computation might lead to maladaptive behaviors and poor mental health outcomes. Illusion of control, which refers to a heightened sense of control while the environment is uncontrollable, is one such manifestation and has been conceptually associated with delusional ideation. Nevertheless, this association has not yet been formally characterized in a computational framework. To address this, we used a computational psychiatry approach to quantify illusion of control in human participants with high (n = 125) or low (n = 126) trait delusion. Participants played a two-party exchange game in which their choices either did (“Controllable condition”) or did not (“Uncontrollable condition”) influence the future monetary offers made by simulated partners. We found that the two groups behaved similarly in model-agnostic measures (i.e., offer size, rejection rate). However, computational modeling revealed that compared to the low trait delusion group, the high delusion group overestimated their influence (“expected influence” parameter) over the offers made by their partners under the Uncontrollable condition. Highly delusional individuals also reported a stronger sense of control than those with low trait delusion in the Uncontrollable condition. Furthermore, the expected influence parameter and self-reported beliefs about controllability were significantly correlated in the Controllable condition in individuals with low trait delusion, whereas this relationship was diminished in those with high trait delusion. Collectively, these findings demonstrate that delusional ideation is associated with aberrant computation of and belief about environmental controllability, as well as a belief-behavior disconnect.}
}
@incollection{DUNN2023461,
title = {17 - Thinking in systems: sustainable design of nano-enabled agriculture informed by life cycle assessment},
editor = {Peng Zhang and Iseult Lynch and Jason C. White and Richard D. Handy},
booktitle = {Nano-Enabled Sustainable and Precision Agriculture},
publisher = {Academic Press},
pages = {461-491},
year = {2023},
isbn = {978-0-323-91233-4},
doi = {https://doi.org/10.1016/B978-0-323-91233-4.00019-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323912334000193},
author = {Patrick J. Dunn and Leila Pourzahedi and Thomas L. Theis and Leanne M. Gilbertson},
keywords = {Agriculture, food, environment, life cycle assessment, trade-off, production},
abstract = {Food systems are among the most complex systems devised by humankind with multiple stages involved in the production, marketing, and distribution, as well as the preparation and consumption of food.}
}
@article{KAHLE200053,
title = {Dialectical Thinking in Consumer Decision Making},
journal = {Journal of Consumer Psychology},
volume = {9},
number = {1},
pages = {53-58},
year = {2000},
issn = {1057-7408},
doi = {https://doi.org/10.1207/s15327663jcp0901_5},
url = {https://www.sciencedirect.com/science/article/pii/S1057740800703251},
author = {Lynn R. Kahle and Raymond R. Liu and Gregory M. Rose and Woo-Sung Kim},
abstract = {In this article, we examine the four processes of dialectical thinking: interconnection, development and change, transformation of quantitative into qualitative, and unity and struggle of opposites. We argue that the decisions of some consumers reflect dialectical thinking, at least some of the time.}
}
@article{HASTINGS2024103074,
title = {What's a parent to do? Measuring cultural logics of parenting with computational text analysis},
journal = {Social Science Research},
volume = {124},
pages = {103074},
year = {2024},
issn = {0049-089X},
doi = {https://doi.org/10.1016/j.ssresearch.2024.103074},
url = {https://www.sciencedirect.com/science/article/pii/S0049089X24000966},
author = {Orestes P. Hastings and Luca Maria Pesando},
keywords = {Family, Parenting, Socioeconomic status, Computational social science, Text as data, Topic modeling},
abstract = {Leading theories on parenting in the United States suggest that parenting varies widely by socioeconomic status, with middle-class parents practicing “concerted cultivation”—marked by parents' intensive efforts to foster their children's development—and working-class parents engaging in the “accomplishment of natural growth”—with children given more freedom to manage their own time. While frequently inferred that these parenting practices reflect different cultural logics of parenting, such logics are inherently hard to measure. Our paper proposes a new inductive way to study parenting logics using computational text analysis applied to a nationally representative survey where respondents provided parenting advice across three hypothetical parenting situations. Analyzing this advice using Biterm Topic Modeling we find that nearly all parenting logics reflect some form of intensive parenting, but within that are multiple nuanced versions varying across two dimensions: (1) assertive vs negotiated parenting, and (2) pedagogic vs pragmatic parenting. Using fractional multinomial logistic regression, we find little difference in how parenting logics vary by race/ethnicity, education, and income, suggesting more similarity across groups and more variability within groups than commonly understood. These findings also demonstrate how computational techniques may provide complementary tools to enrich the study of long-standing questions in social science research, at times offering an analytical naïveté that human coding cannot offer.}
}
@article{CHOU2024105940,
title = {The influence of anxiety on exploration: A review of computational modeling studies},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {167},
pages = {105940},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105940},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424004093},
author = {Ko-Ping Chou and Robert C. Wilson and Ryan Smith},
keywords = {Directed exploration, Random exploration, Foraging, Anxiety, Information-seeking},
abstract = {Exploratory behaviors can serve an adaptive role within novel or changing environments. Namely, they facilitate information gain, allowing an organism to maintain accurate beliefs about the environment and select actions that better maximize reward. However, finding the optimal balance between exploration and reward-seeking behavior – the so-called explore-exploit dilemma – can be challenging, as it requires sensitivity to one’s own uncertainty and to the predictability of one’s surroundings. Given the close relationship between uncertainty and anxiety, a body of work has now also emerged identifying associated effects on exploration. In particular, the field of computational psychiatry has begun to use cognitive computational models to characterize how anxiety may modulate underlying information processing mechanisms, such as estimation of uncertainty and the value of information, and how this might contribute to psychopathology. Here, we review computational modeling studies investigating how exploration is influenced by anxiety. While some apparent inconsistencies remain to be resolved, studies using reinforcement learning tasks suggest that directed (but not random) forms of exploration may be elevated by trait and/or cognitive anxiety, but reduced by state and/or somatic anxiety. Anxiety is also consistently associated with less exploration in foraging tasks. Some differences in exploration may further stem from how anxiety modulates changes in uncertainty over time (learning rates). Jointly, these results highlight important directions for future work in refining choice of tasks and anxiety measures and maintaining consistent methodology across studies.}
}
@article{HALES2023105083,
title = {Computational approaches to modeling gambling behaviour: Opportunities for understanding disordered gambling},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {147},
pages = {105083},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105083},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423000520},
author = {C.A. Hales and L. Clark and C.A. Winstanley},
keywords = {Gambling disorder, Reinforcement learning, Drift diffusion modeling, Bayesian, Computational psychiatry},
abstract = {Computational modeling has become an important tool in neuroscience and psychiatry research to provide insight into the cognitive processes underlying normal and pathological behavior. There are two modeling frameworks, reinforcement learning (RL) and drift diffusion modeling (DDM), that are well-developed in cognitive science, and have begun to be applied to Gambling Disorder. RL models focus on explaining how an agent uses reward to learn about the environment and make decisions based on outcomes. The DDM is a binary choice framework that breaks down decision making into psychologically meaningful components based on choice reaction time analyses. Both approaches have begun to yield insight into aspects of cognition that are important for, but not unique to, gambling, and thus relevant to the development of Gambling Disorder. However, these approaches also oversimplify or neglect various aspects of decision making seen in real-world gambling behavior. Gambling Disorder presents an opportunity for ‘bespoke’ modeling approaches to consider these neglected components. In this review, we discuss studies that have used RL and DDM frameworks to investigate some of the key cognitive components in gambling and Gambling Disorder. We also include an overview of Bayesian models, a methodology that could be useful for more tailored modeling approaches. We highlight areas in which computational modeling could enable progression in the investigation of the cognitive mechanisms relevant to gambling.}
}
@incollection{DELLAVERSANA201337,
title = {2 - Circular thinking in geophysics},
editor = {Paolo Dell'Aversana},
booktitle = {Cognition in Geosciences},
publisher = {EAGE},
address = {Oxford},
pages = {37-55},
year = {2013},
isbn = {978-90-73834-41-5},
url = {https://www.sciencedirect.com/science/article/pii/B9789073834415500098},
author = {Paolo Dell'Aversana}
}
@article{HE2024115752,
title = {Navigating the semantic space: Unraveling the structure of meaning in psychosis using different computational language models},
journal = {Psychiatry Research},
volume = {333},
pages = {115752},
year = {2024},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2024.115752},
url = {https://www.sciencedirect.com/science/article/pii/S0165178124000398},
author = {Rui He and Claudio Palominos and Han Zhang and Maria Francisca Alonso-Sánchez and Lena Palaniyappan and Wolfram Hinzen},
keywords = {Connected speech, Incoherence, Semantic similarity, Semantic perplexity, Language model, Loosening of associations, Schizophrenia},
abstract = {Speech in psychosis has long been ascribed as involving ‘loosening of associations’. We pursued the aim to elucidate its underlying cognitive mechanisms by analysing picture descriptions from 94 subjects (29 healthy controls, 18 participants at clinical high risk, 29 with first-episode psychosis, and 18 with chronic schizophrenia), using five language models with different computational architectures: FastText, which represents meaning non-contextually/statically; BERT, which represents contextual meaning sensitive to grammar and context; Infersent and SBERT, which provide sentential representations; and CLIP, which evaluates speech relative to a visual stimulus. These models were used to quantify semantic distances crossed between successive tokens/sentences, and semantic perplexity indicating unexpectedness in continuations. Results showed that, among patients, semantic similarity increased when measured with FastText, Infersent, and SBERT, while it decreased with CLIP and BERT. Higher perplexity was observed in first-episode psychosis. Static semantic measures were associated with clinically measured impoverishment of thought and referential semantic measures with disorganization. These patterns indicate a shrinking conceptual semantic space as represented by static language models, which co-occurs with a widening in the referential semantic space as represented by contextual models. This duality underlines the need to separate these two forms of meaning for understanding mechanisms involved in semantic change in psychosis.}
}
@article{TIEJUN2021120322,
title = {Implementation Status and Development Thinking on “Cloud National Examination” in China under the situation of “Online Anti-COVID-19 Epidemic”},
journal = {Technological Forecasting and Social Change},
volume = {162},
pages = {120322},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2020.120322},
url = {https://www.sciencedirect.com/science/article/pii/S0040162520311483},
author = {Zhu Tiejun},
keywords = {Cloud National Examination, Online Anti-COVID-19 Epidemic, Implementation Status, Analysis and discussion, Thinking and enlightenment, Empirical Research},
abstract = {At the beginning of 2020, China was first hit by the COVID-19 epidemic. In order to effectively prevent the spread of the virus, the Chinese people work online, teach online, study online and shop online from home, the whole country rapidly entered the era of “Cloud Anti-COVID-19 Epidemic”. With the passage of time, the Chinese relevant national examinations such as postgraduate second round examination, the senior high school and college entrance examination gradually approach. In response, some regions have launched the “Cloud National Examination” model. Based on this background, through the actual situation commentary and case proof of adaptive mock test of the “Cloud National Examination” that has been carried out in some areas and schools, this article analyzes, discusses, summarizes and deeply reflects the epidemic prevention and control, policy formulation, education care, scientific and technological progress, and social problems hidden behind the hot phenomenon of “Cloud National Examination”, so as to offer advice and suggestions for online education in such a special period. Also, to provide reference for the rapid deployment, preparation and implementation of “Cloud National Examination” by relevant education administrative departments, schools, candidates and their families, and supply the evaluation viewpoint and theoretical contribution for similar global problems and phenomena.}
}
@article{FOURNY2020102332,
title = {Perfect Prediction in normal form: Superrational thinking extended to non-symmetric games},
journal = {Journal of Mathematical Psychology},
volume = {96},
pages = {102332},
year = {2020},
issn = {0022-2496},
doi = {https://doi.org/10.1016/j.jmp.2020.102332},
url = {https://www.sciencedirect.com/science/article/pii/S0022249620300183},
author = {Ghislain Fourny},
keywords = {Counterfactual dependence, Necessary Rationality, Necessary Knowledge of Strategies, Perfect Prediction, Transparency, Non-cooperative game theory, Non-Nashian game theory, Strategic games, Superrationality},
abstract = {This paper introduces a new solution concept for non-cooperative games in normal form with no ties and pure strategies: the Perfectly Transparent Equilibrium. The players are rational in all possible worlds and know each other’s strategies in all possible worlds — which, together, we refer to as Perfect Prediction. The anticipation of a player’s decision by their opponents is counterfactually dependent on the decision, unlike in Nash Equilibria where the decisions are made independently. The equilibrium, when it exists, is unique and is Pareto optimal. This equilibrium is the normal-form counterpart of the Perfect Prediction Equilibrium; the prediction happens “in another room” rather than in the past. The equilibrium can also be seen as a natural extension of Hofstadter’s superrationality to non-symmetric games. Algorithmically, an iterated elimination of non-individually-rational strategy profiles is performed until at most one remains. An equilibrium is a strategy profile that is immune against knowledge of strategies in all possible worlds and rationality in all possible worlds, a stronger concept than common knowledge of rationality but also stronger than common counterfactual belief of rationality. We formalize and contrast the Non-Nashian Decision Theory paradigm, common to this and several other papers, with Causal Decision Theory and Evidential Decision Theory. We define the Perfectly Transparent Equilibrium algorithmically and prove (when it exists) that it is unique, that it is Pareto-optimal, and that it coincides with Hofstadter’s Superrationality on symmetric games. We relate the finding to concepts found in the literature such as Individual Rationality, Rationalizability, Minimax-Rationalizability, Second-Order Nash Equilibria, the Program Equilibrium, the Perfect Prediction Equilibrium, Shiffrin’s Joint-Selfish-Rational Equilibrium, the Stalnaker–Bonanno Equilibrium, the Perfect Cooperation Equilibrium, the Translucent Equilibrium, the Correlated Equilibrium, and Quantum Games. Finally, we specifically discuss inclusion relationships on the special case of symmetric games between Individual Rationality, Minimax-Rationalizability, Superrationality, and the Perfectly Transparent Equilibrium, and contrast them with asymmetric games.}
}
@article{KARUNATHILAKE201970,
title = {Optimal renewable energy supply choices for net-zero ready buildings: A life cycle thinking approach under uncertainty},
journal = {Energy and Buildings},
volume = {201},
pages = {70-89},
year = {2019},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2019.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S0378778819309582},
author = {Hirushie Karunathilake and Kasun Hewage and Joshua Brinkerhoff and Rehan Sadiq},
keywords = {Hybrid renewable energy systems, Net-zero buildings, Optimisation, Fuzzy logic, Life cycle assessment},
abstract = {The increasing concerns about the environmental and economic impacts of conventional centralised energy generation and fossil fuel usage have prompted an interest in renewable-based decentralised energy systems. Implementing such systems at building level can facilitate the development of net-zero energy buildings. Energy system planning is a multi-faceted problem that involves technical, economic, environmental, and social dimensions, and affects multiple stakeholders at different levels. A multi-objective optimisation approach is needed to identify the optimal energy choices at building level, while paying attention to stakeholder priorities and other constraints. The objective of this study is to develop a model to identify the optimal mix of renewable energy (RE) while also accounting for uncertainties, which can be integrated at building level with life cycle thinking. A framework was proposed for planning an optimised hybrid RE system at building level to support the net-zero development goals. The optimisation model was developed considering the objectives of minimising energy system cost, maximising operational cost savings, minimising the life cycle environmental impacts, and maximising the RE fraction. A combinatorial optimisation approach was adopted to reflect the practical engineering aspects of energy planning problems based on technologies available in the market. The developed framework was demonstrated through a case study conducted for an average multi-unit residential buildings (MURB) located in British Columbia, Canada. The results indicated that under the defined stakeholder priorities and constraints, ground source heat pumps and solar photovoltaics (PV) are the optimal energy choices for MURB, and the optimal energy system combination supplied 44% of the building's energy demand through RE. The findings will inform and guide community developers and other stakeholders with an interest in residential buildings, on the most suitable clean energy options for their building project during the pre-project planning stage.}
}
@article{SALEEM2024100124,
title = {Understanding 21st century skills needed in response to industry 4.0: Exploring scholarly insights using bibliometric analysis},
journal = {Telematics and Informatics Reports},
volume = {13},
pages = {100124},
year = {2024},
issn = {2772-5030},
doi = {https://doi.org/10.1016/j.teler.2024.100124},
url = {https://www.sciencedirect.com/science/article/pii/S2772503024000100},
author = {Sumayya Saleem and Elizabeth Dhuey and Linda White and Michal Perlman},
keywords = {21st century skills, Industry 4.0, Bibliometric analysis, Co-citation, Bibliographic coupling},
abstract = {International policy agendas are increasingly focusing on the 21st century skills needed by future workers in response to Industry 4.0. In this study, we conduct a bibliometric analysis of 2662 articles published by 6579 authors in the last two decades to understand the structure of the scholarly knowledge in this field. We first identify influential articles, documents, journals and trends in this literature. We use co-citation analysis to identify foundational themes in the development of 21st century skills literature, then using bibliometric coupling, we identify communities in the current research front. We then use co-word analysis to identify future directions in the field. Overall, we find that research on 21st century skills has grown exponentially in the past two decades, however, few researchers focus primarily on this topic. The existing research is primarily dominated by psychologists, education researchers and technology researchers. We also find that specific disciplines such as industrial engineering and nursing are prominent contributors in the field, and that critical thinking and computational thinking are key areas of focus.}
}
@article{MIAO2024117850,
title = {Progress toward adsorption mechanism exploration method for capacitive deionization: Experimental, mathematical model, computational chemistry and machine learning},
journal = {Desalination},
volume = {586},
pages = {117850},
year = {2024},
issn = {0011-9164},
doi = {https://doi.org/10.1016/j.desal.2024.117850},
url = {https://www.sciencedirect.com/science/article/pii/S0011916424005617},
author = {Luwei Miao and Ming Gao and Weilong Xiao and Yuchen Kang and Ran Li and Hao Kong and Haiyan Mou and Wenqing Chen and Tianqi Ao},
keywords = {Capacitive deionization mechanism, Experimental, Mathematical model, Computational chemistry, Machine learning},
abstract = {Capacitive deionization (CDI) is a novel and prospective technique mainly for desalination, featuring low-cost, easy maintenance, and environmental-friendly. As CDI develops by leaps and bounds, the electrode materials, the cell architectures, and the application fields have gained a lot of progress as reported. In order to optimize electrode materials, innovate cell architectures, broaden application fields, CDI adsorption mechanism exploration, as a necessary and important approach, have aroused enormous interest by researchers. This work provides a review of the strategies for investigating CDI adsorption mechanism form four aspects: experimental, mathematical model, computational chemistry, and machine learning, accompanied by discussing the prospects of these methods. Through a fine-grained summarization of the correlative reports from initial studies to the publications of late, it is expected that the meticulous statement of the characteristics, progress, and challenges of these exploration methods in this review can provide a fundamental support to facilitate prospective development of CDI.}
}
@article{LECORCHICK2020655,
title = {Problem Solving Archetype - Computer Science},
journal = {Procedia Computer Science},
volume = {172},
pages = {655-659},
year = {2020},
note = {9th World Engineering Education Forum (WEEF 2019) Proceedings : Disruptive Engineering Education for Sustainable Development},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.05.085},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920314149},
author = {Douglas Lecorchick and Scott Nichols and Lauren Tabor},
keywords = {problem formulation, computational thinking, problem solving archetype},
abstract = {Problems that are carefully formulated lead students to develop more sufficient and realistic solutions. By front-loading the process of problem solving through problem formulation, students are able to reduce the amount of time spent on solution development, and thus increase their efficiency towards meeting their main objective. By teaching students problem formulation, especially in computer science related activities, foundational skills in computational thinking are introduced, used, and refined. Using a problem solving archetype as a means for this formulation is an effective tool for students to leverage. As computational thinking skills are honed, these concepts can translate across barriers into other content areas.}
}
@article{ARASTOOPOURIRGENS2022100541,
title = {Characterizing children’s conceptual knowledge and computational practices in a critical machine learning educational program},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100541},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100541},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000599},
author = {Golnaz {Arastoopour Irgens} and Hazel Vega and Ibrahim Adisa and Cinamon Bailey},
keywords = {Critical pedagogies, Machine learning education, Elementary education, Design-based research, Robotics, Informal education},
abstract = {In this study, we describe the design and implementation of a CML (critical machine learning) education program for children between the ages of 9 and 13 at an after-school center. In this participatory design-based research, we collected learner artifacts, recordings of interactions, and pre/post drawings and written responses to model children’s developing knowledge and practices related to critical machine learning. Drawing from constructionist and critical pedagogical perspectives, our research questions are: (1) How do children develop machine learning knowledge grounded in social, ethical, and political orientations in a CML education program? and (2) What computational practices do children engage in when developing robots for social good in a CML education program? We found that (1) children made more sophisticated connections with socio-political orientations and ML content as they progressed through the program, and (2) they engaged in computational practices, such as experimenting and iterating, testing and debugging, reusing and remixing, and abstracting and modularizing. Further, our findings indicate that a critical lens to ML education can be characterized by posing and answering questions about the roles of AI technologies producers and consumers and identifying how these technologies are designed to apply this knowledge to build applications for marginalized populations. This study suggests that a critical lens is an effective approach towards engaging young children in designing their own machine learning tools in socially responsible ways.}
}
@article{PANG2025102852,
title = {Towards cognition-augmented human-centric assembly: A visual computation perspective},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {91},
pages = {102852},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102852},
url = {https://www.sciencedirect.com/science/article/pii/S073658452400139X},
author = {Jiazhen Pang and Pai Zheng and Junming Fan and Tianyuan Liu},
keywords = {Cognitive assistance, Human-centric assembly, Computer vision, Metaverse, Cloud service, Large language model, Brain computer interface},
abstract = {Human-centric assembly is emerging as a promising paradigm for achieving mass personalization in the context of Industry 5.0, as it fully capitalizes on the advantages of human flexibility with robot assistance. However, in small-batch and highly customized assembly tasks, frequently changes in production procedures pose significant cognition challenges. To address this, leveraging computer vision technology to enhance human cognition becomes a feasible solution. Therefore, this review aims to explore the cognitive characteristics of human beings and classify existing computer vision technologies in a manner that discusses the future development of cognition-augmented human-centric assembly. The concept of cognition-augmented assembly is first proposed based on the brain's functional structure - the frontal, parietal, temporal, and occipital lobes. Corresponding to these brain regions, cognitive issues in spatiality, memory, knowledge, and decision-making are summarized. Recent studies conducted between 2014 and 2023 on visual computation of assembly are categorized into four groups: position registration, multi-layer recognition, contextual perception, and mixed-reality fusion, all aimed at addressing these cognitive challenges. The applications and limitations of current computer vision technology are discussed. Furthermore, considering the rapidly evolving technologies such as the metaverse, cloud services, large language models, and brain-computer interfaces, future trends on computer vision are prospected to augment human cognition corresponding to the cognitive issues.}
}
@article{KARVELIS2023105137,
title = {Individual differences in computational psychiatry: A review of current challenges},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {148},
pages = {105137},
year = {2023},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2023.105137},
url = {https://www.sciencedirect.com/science/article/pii/S0149763423001069},
author = {Povilas Karvelis and Martin P. Paulus and Andreea O. Diaconescu},
keywords = {Computational psychiatry, Reliability, Validity, Computational modelling, Individual differences},
abstract = {Bringing precision to the understanding and treatment of mental disorders requires instruments for studying clinically relevant individual differences. One promising approach is the development of computational assays: integrating computational models with cognitive tasks to infer latent patient-specific disease processes in brain computations. While recent years have seen many methodological advancements in computational modelling and many cross-sectional patient studies, much less attention has been paid to basic psychometric properties (reliability and construct validity) of the computational measures provided by the assays. In this review, we assess the extent of this issue by examining emerging empirical evidence. We find that many computational measures suffer from poor psychometric properties, which poses a risk of invalidating previous findings and undermining ongoing research efforts using computational assays to study individual (and even group) differences. We provide recommendations for how to address these problems and, crucially, embed them within a broader perspective on key developments that are needed for translating computational assays to clinical practice.}
}
@article{YAN2024107454,
title = {A computational social science approach to understanding predictors of Chafee service receipt},
journal = {Children and Youth Services Review},
volume = {158},
pages = {107454},
year = {2024},
issn = {0190-7409},
doi = {https://doi.org/10.1016/j.childyouth.2024.107454},
url = {https://www.sciencedirect.com/science/article/pii/S0190740924000264},
author = {Jason Yan and Seventy F. Hall and Melanie Sage and Yuhao Du and Kenneth Joseph},
keywords = {Chafee services, Computational social science, Predictive modeling, National Youth in Transition Database},
abstract = {The John H. Chafee Foster Care Program for Successful Transition to Adulthood (CFCIP) allocates funding to provide services to youth who are likely to age out of foster care. These services, covering everything from mentoring to financial aid, are expected to be distributed in ways that prepare youth for life after care. One natural question to ask is, which youth receive Chafee services? The present work makes use of the National Youth in Transition Database (NYTD), a large-scale administrative dataset that tracks services allocated to youth that use CFCIP funds to answer this question. Specifically, we conduct a forensic social science analysis of the NYTD data. To do so, we first use computational methods to help us uncover the factors that best predict which youth will receive services associated with service receipt. We find that the majority of variables in the Adoption and Foster Care Analysis and Reporting System (AFCARS) and NYTD have limited or no utility in predicting Chafee service receipt, and that a subset of three variables—youth age, youth time in care, and the state in which a youth is in care—explain almost all variability in service receipt. We conclude with a discussion of the implications of these and other findings on future research on Chafee service allocation, and the utility of predictive modeling in child welfare, with a particular focus on the utility of the NYTD in this context.}
}
@incollection{DEWOSKIN2024779,
title = {Virtual models (aka: in silico or computational models)},
editor = {Philip Wexler},
booktitle = {Encyclopedia of Toxicology (Fourth Edition)},
publisher = {Academic Press},
edition = {Fourth Edition},
address = {Oxford},
pages = {779-793},
year = {2024},
isbn = {978-0-323-85434-4},
doi = {https://doi.org/10.1016/B978-0-12-824315-2.00094-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128243152000944},
author = {Robert S. DeWoskin and Thomas B. Knudsen and Imran Shah},
keywords = {Adverse outcome pathways, Computational model, Emergent properties, In silico models, Microphysiological systems (MPS), PBPK models, Physiome project, Systems biology, Virtual embryo, Virtual liver, Virtual model (vM), Virtual physiological human},
abstract = {Virtual models (vM) are mathematical representations of biological processes that are numerically solved computationally, and are used to investigate and predict system behaviors that cannot be predicted solely from studying the nature of the individual parts, or from the domain of the available data. Computational power is now available to develop advanced vMs capable of supporting predictive toxicology and drug efficacy, and of reducing the dependence on in vivo animal studies for basic research and risk assessment purposes. The ultimate goal is to simulate in vivo responses of biological organisms to environmental change, drugs, toxins, or human activities, and to predict the effects of defined perturbations on system behaviors. Examples of virtual models are presented from research in the fields of physiology, pharmacology, toxicology and risk assessment.}
}
@article{EPPE2018105,
title = {A computational framework for conceptual blending},
journal = {Artificial Intelligence},
volume = {256},
pages = {105-129},
year = {2018},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2017.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S000437021730142X},
author = {Manfred Eppe and Ewen Maclean and Roberto Confalonieri and Oliver Kutz and Marco Schorlemmer and Enric Plaza and Kai-Uwe Kühnberger},
keywords = {Computational creativity, Conceptual blending, Cognitive science, Answer set programming},
abstract = {We present a computational framework for conceptual blending, a concept invention method that is advocated in cognitive science as a fundamental and uniquely human engine for creative thinking. Our framework treats a crucial part of the blending process, namely the generalisation of input concepts, as a search problem that is solved by means of modern answer set programming methods to find commonalities among input concepts. We also address the problem of pruning the space of possible blends by introducing metrics that capture most of the so-called optimality principles, described in the cognitive science literature as guidelines to produce meaningful and serendipitous blends. As a proof of concept, we demonstrate how our system invents novel concepts and theories in domains where creativity is crucial, namely mathematics and music.}
}
@article{FANG2025103716,
title = {Functional connectivity profiles in remitted depression and their relation to ruminative thinking},
journal = {NeuroImage: Clinical},
volume = {45},
pages = {103716},
year = {2025},
issn = {2213-1582},
doi = {https://doi.org/10.1016/j.nicl.2024.103716},
url = {https://www.sciencedirect.com/science/article/pii/S2213158224001578},
author = {Zhuo Fang and Emma Lynn and Verner J. Knott and Natalia Jaworska},
keywords = {Remitted depression, Default mode network, Central executive network, Salience network, Hopeless rumination, Emotional processing},
abstract = {The triple network model suggests that dysfunction in three major brain networks – the default mode network (DMN), central executive network (CEN), and salience network (SN) – might contribute to cognitive impairments in various psychiatric disorders, including major depressive disorder (MDD). While hyperconnectivity in the DMN, hypoconnectivity in the CEN, and abnormal SN connectivity have been observed in acutely depressed patients, evidence for network alterations during remission is limited. Further, there are few studies examining connectivity in people in remission from MDD (rMDD) during emotional processing tasks, including during affective cognition (i.e., tasks that encompass affective processing in the context of cognitive processes, such as inhibition). To address these literature gaps, this study compared functional connectivity (FC) between resting and task conditions, specifically during the emotional Stroop (eStroop) task, as well as between rMDD and healthy volunteers (HVs), within and between nodes of the three networks. We also explored how FC relates to rumination in the rMDD group, given that rumination tends to persist in rMDD and involves affective and cognitive networks. We unexpectedly found greater FC during the task vs. rest condition within the DMN, and decreased FC during the task vs. rest conditions within the CEN and SN across the groups. Greater FC during the task vs. rest condition between DMN and SN nodes, as well as between CEN and SN nodes were also observed. These effects were more pronounced in the rMDD group as per our exploratory analyses. Additionally, the rMDD vs. HV group showed higher FC between DMN-CEN nodes, regardless of condition. Higher hopeless rumination scores were associated with decreased resting FC within the DMN, while higher active problem-solving scores were associated with increased task FC within the DMN in the rMDD group. These findings suggest that tasks engaging affective cognition processes influence FC within and among the three networks, with this effect more pronounced in the rMDD group. This might indicate potential protective and compensatory mechanisms in rMDD and expands our understanding of large-scale intrinsic network connectivity alterations during remission from depression. However, given the limited sample and the exploratory nature of some of our analyses, replication is necessary.}
}
@article{BONHAGE2016203,
title = {Thinking about thinking: Neural mechanisms and effects on memory},
journal = {NeuroImage},
volume = {127},
pages = {203-214},
year = {2016},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2015.11.067},
url = {https://www.sciencedirect.com/science/article/pii/S1053811915011040},
author = {Corinna Bonhage and Friederike Weber and Cornelia Exner and Philipp Kanske},
keywords = {Attention, Cognitive self-consciousness, Default mode network, Proactive interference/ memory, Salience network, fMRI},
abstract = {It is a well-established finding that memory encoding is impaired if an external secondary task (e.g. tone discrimination) is performed simultaneously. Yet, while studying we are also often engaged in internal secondary tasks such as planning, ruminating, or daydreaming. It remains unclear whether such a secondary internal task has similar effects on memory and what the neural mechanisms underlying such an influence are. We therefore measured participants' blood oxygenation level dependent responses while they learned word-pairs and simultaneously performed different types of secondary tasks (i.e., internal, external, and control). Memory performance decreased in both internal and external secondary tasks compared to the easy control condition. However, while the external task reduced activity in memory-encoding related regions (hippocampus), the internal task increased neural activity in brain regions associated with self-reflection (anterior medial prefrontal cortex), as well as in regions associated with performance monitoring and the perception of salience (anterior insula, dorsal anterior cingulate cortex). Resting-state functional connectivity analyses confirmed that anterior medial prefrontal cortex and anterior insula/dorsal anterior cingulate cortex are part of the default mode network and salience network, respectively. In sum, a secondary internal task impairs memory performance just as a secondary external task, but operates through different neural mechanisms.}
}
@article{ACKERMAN2017607,
title = {Meta-Reasoning: Monitoring and Control of Thinking and Reasoning},
journal = {Trends in Cognitive Sciences},
volume = {21},
number = {8},
pages = {607-617},
year = {2017},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2017.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S1364661317301055},
author = {Rakefet Ackerman and Valerie A. Thompson},
keywords = {reasoning, problem solving, metacognition, effort regulation, monitoring and control},
abstract = {Meta-Reasoning refers to the processes that monitor the progress of our reasoning and problem-solving activities and regulate the time and effort devoted to them. Monitoring processes are usually experienced as feelings of certainty or uncertainty about how well a process has, or will, unfold. These feelings are based on heuristic cues, which are not necessarily reliable. Nevertheless, we rely on these feelings of (un)certainty to regulate our mental effort. Most metacognitive research has focused on memorization and knowledge retrieval, with little attention paid to more complex processes, such as reasoning and problem solving. In that context, we recently developed a Meta-Reasoning framework, used here to review existing findings, consider their consequences, and frame questions for future research.}
}
@article{ANTONIOU2022,
title = {Predicting Mental Health Status in Remote and Rural Farming Communities: Computational Analysis of Text-Based Counseling},
journal = {JMIR Formative Research},
volume = {6},
number = {6},
year = {2022},
issn = {2561-326X},
doi = {https://doi.org/10.2196/33036},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X22006187},
author = {Mark Antoniou and Dominique Estival and Christa Lam-Cassettari and Weicong Li and Anne Dwyer and Abìlio de Almeida Neto},
keywords = {e-mental health, text-based, counseling, Linguistic Inquiry and Word Count, LIWC, depression, anxiety, stress},
abstract = {Background
Australians living in rural and remote areas are at elevated risk of mental health problems and must overcome barriers to help seeking, such as poor access, stigma, and entrenched stoicism. e-Mental health services circumvent such barriers using technology, and text-based services are particularly well suited to clients concerned with privacy and self-presentation. They allow the client to reflect on the therapy session after it has ended as the chat log is stored on their device. The text also offers researchers an opportunity to analyze language use patterns and explore how these relate to mental health status.
Objective
In this project, we investigated whether computational linguistic techniques can be applied to text-based communications with the goal of identifying a client’s mental health status.
Methods
Client-therapist text messages were analyzed using the Linguistic Inquiry and Word Count tool. We examined whether the resulting word counts related to the participants’ presenting problems or their self-ratings of mental health at the completion of counseling.
Results
The results confirmed that word use patterns could be used to differentiate whether a client had one of the top 3 presenting problems (depression, anxiety, or stress) and, prospectively, to predict their self-rated mental health after counseling had been completed.
Conclusions
These findings suggest that language use patterns are useful for both researchers and clinicians trying to identify individuals at risk of mental health problems, with potential applications in screening and targeted intervention.}
}
@incollection{RAAB202129,
title = {Chapter Four - How the body and the environment affect our thinking?},
editor = {Markus Raab},
booktitle = {Judgment, Decision-Making, and Embodied Choices},
publisher = {Academic Press},
pages = {29-46},
year = {2021},
isbn = {978-0-12-823523-2},
doi = {https://doi.org/10.1016/B978-0-12-823523-2.00004-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128235232000040},
author = {Markus Raab},
keywords = {Facial feedback, Court decision, Gut decision, Gesture, Emotional decision},
abstract = {This chapter deals with the question, why body conditions and the environment influence our choices. Therefore this chapter summarizes plenty of research and combines it with own experiences. One famous study cited is the one by Strack and colleagues [12] concerning the facial feedback effect: Subjects had to rate the funniness of cartoons which either a pen between their lips or their teeth. Depending on the condition, the movement facilitated either a smile or a neutral expression which transferred to the ratings of the cartoons. Also, the role of gut feelings is discussed again, as research shows that the state of hunger may influence judges’ decisions at the court and this connection therefore should not the neglected. Talking about the bacteria-brain-behavior relationship, research on probiotics is very promising, although the exact mechanism of action is not completely discovered yet. A last aspect covered in this chapter is the influence of the gut on risky behavior, which has not been fully explored neurophysiological, maybe due to the deficient distinction between risk and uncertainty.}
}
@article{KRASICH2024105624,
title = {A computational modeling approach to investigating mind wandering-related adjustments to gaze behavior during scene viewing},
journal = {Cognition},
volume = {242},
pages = {105624},
year = {2024},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105624},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723002585},
author = {Kristina Krasich and Kevin O'Neill and Samuel Murray and James R. Brockmole and Felipe {De Brigard} and Antje Nuthmann},
keywords = {Visual-cognitive processing, Mind wandering, Fixation duration, Computational modeling, Scene viewing},
abstract = {Research on gaze control has long shown that increased visual-cognitive processing demands in scene viewing are associated with longer fixation durations. More recently, though, longer durations have also been linked to mind wandering, a perceptually decoupled state of attention marked by decreased visual-cognitive processing. Toward better understanding the relationship between fixation durations and visual-cognitive processing, we ran simulations using an established random-walk model for saccade timing and programming and assessed which model parameters best predicted modulations in fixation durations associated with mind wandering compared to attentive viewing. Mind wandering-related fixation durations were best described as an increase in the variability of the fixation-generating process, leading to more variable—sometimes very long—durations. In contrast, past research showed that increased processing demands increased the mean duration of the fixation-generating process. The findings thus illustrate that mind wandering and processing demands modulate fixation durations through different mechanisms in scene viewing. This suggests that processing demands cannot be inferred from changes in fixation durations without understanding the underlying mechanism by which these changes were generated.}
}
@article{CHEN2022307,
title = {Computational markers of experience- but not description-based decision-making are associated with future depressive symptoms in young adults},
journal = {Journal of Psychiatric Research},
volume = {154},
pages = {307-314},
year = {2022},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2022.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0022395622004484},
author = {Chong Chen and Yasuhiro Mochizuki and Kosuke Hagiwara and Masako Hirotsu and Toshio Matsubara and Shin Nakagawa},
keywords = {Decision-making, Description-experience gap, Risk preference, Probability weighting, Reinforcement learning, Computational psychiatry},
abstract = {Background
Early prediction of high depressive symptoms is crucial for selective intervention and the minimization of functional impairment. Recent cross-sectional studies indicated decision-making deficits in depression, which may be an important contributor to the disorder. Our goal was to test whether description- and experience-based decision making, two major neuroeconomic paradigms of decision-making under uncertainty, predict future depressive symptoms in young adults.
Methods
One hundred young adults performed two decision-making tasks, one description-based, in which subjects chose between two gambling options given explicitly stated rewards and their probabilities, and the other experience-based, in which subjects were shown rewards but had to learn the probability of those rewards (or cue-outcome contingencies) via trial-and-error experience. We evaluated subjects' depressive symptoms with BDI-II at baseline (T1) and half a year later (T2).
Results
Comparing subjects with low versus high levels of depressive symptoms at T2 showed that the latter performed worse on the experience- but not description-based task at T1. Computational modeling of the decision-making process suggested that subjects with high levels of depressive symptoms had a more concave utility function, indicating enhanced risk aversion. Furthermore, a more concave utility function at T1 increased the odds of high depressive symptoms at T2, even after controlling depressive symptoms at T1, perceived stress at T2, and several covariates (OR = 0.251, 95% CI [0.085, 0.741]).
Conclusions
This is the first study to demonstrate a prospective link between experience-based decision-making and depressive symptoms. Our results suggest that enhanced risk aversion in experience-based decision-making may be an important contributor to the development of depressive symptoms.}
}
@article{CEDERMAN2023102112,
title = {Computational approaches to conflict research from modeling and data to computational diplomacy},
journal = {Journal of Computational Science},
volume = {72},
pages = {102112},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102112},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001722},
author = {Lars-Erik Cederman and Luc Girardin},
keywords = {Computational diplomacy, Agent-based modeling, Simulation, Conflict research},
abstract = {This paper offers an account of our own efforts to draw on computational methods to study conflict processes at the macro level. During a first phase, we relied on agent-based modeling in order to capture the complexity of system-level processes. This research yielded a number of publications, but less by way of influence on substantive research and policy making. Therefore, we decided to shift our main focus away from agent-based modeling to spatial computation, which allow for a more direct empirical validation of our results. This second phase of research includes the collection and integration of large amounts of spatiotemporally structured data, which we analyze with more conventional econometric tools. To advance the field of computational diplomacy, we recommend that future search combines agent-based modeling with rigorous empirical validation through the utilization of spatial computation.}
}
@article{RZEPA2023725,
title = {Teaching FAIR in computational chemistry: managing and publishing data using the twin tools of compute portals and repositories},
journal = {Canadian Journal of Chemistry},
volume = {101},
number = {9},
pages = {725-733},
year = {2023},
issn = {0008-4042},
doi = {https://doi.org/10.1139/cjc-2022-0255},
url = {https://www.sciencedirect.com/science/article/pii/S0008404223000724},
author = {Henry S. Rzepa},
keywords = {repository, FAIR data, knowledge graphs, emerging areas, teaching tools},
abstract = {The history of the emerging area of tools for managing research resources and the data produced from them is summarised from the perspective of two decades of use in teaching and research at one institution. These tools are a portal or electronic laboratory notebook for computational chemistry interfaced in one direction to a high-performance computing resource and in the other direction to a modern research data repository. The essential features of both these tools are described over two generations of each, with examples of student work cited as examples using persistent identifiers or PIDs, better known as DOIs. Underpinning this is the metadata describing the data being processed. The article outlines the evolution of managing such metadata-rich data and its progress towards what can now be summarised by the acronym FAIR data, itself enabling future emerging areas such as knowledge graphs.}
}
@article{JOHANNING2004371,
title = {Supporting the development of algebraic thinking in middle school: a closer look at students’ informal strategies},
journal = {The Journal of Mathematical Behavior},
volume = {23},
number = {4},
pages = {371-388},
year = {2004},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2004.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312304000458},
author = {Debra I. Johanning},
keywords = {Algebra, Algebraic thinking, Middle school, Guess and check},
abstract = {This study investigated how 31 sixth-, seventh-, and eighth-grade middle school students who had not previously, nor were currently taking a formal Algebra course, approached word problems of an algebraic nature. Specifically, these algebraic word problems were of the form x + (x + a) + (x + b) = c or ax + bx + cx = d. An examination of students’ understanding of the relationships expressed in the problems and how they used this information to solve problems was conducted. Data included the students’ written responses to problems, field notes of researcher–student interactions while working on the problems, and follow-up interviews. Results showed that students had many informal strategies for solving the problems with systematic guess and check being the most common approach. Analysis of researcher–student interactions while working on the problems revealed ways in which students struggled to engage in the problems. Support mechanisms for students who struggle with these problems are suggested. Finally, implications are provided for drawing upon students’ informal and intuitive knowledge to support the development of algebraic thinking.}
}
@article{DEGIORGI2008470,
title = {The α-beauty contest: Choosing numbers, thinking intervals},
journal = {Games and Economic Behavior},
volume = {64},
number = {2},
pages = {470-486},
year = {2008},
note = {Special Issue in Honor of Michael B. Maschler},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2008.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0899825608000511},
author = {Enrico {De Giorgi} and Stefan Reimann},
keywords = {Experiments, -beauty contest, Beliefs, Cognitive hierarchy model},
abstract = {We present a model for the α-beauty contest that explains common patterns in experimental data of one-shot and iterative games. The approach is based on two basic assumptions. First, players iteratively update their recent guesses. Second, players estimate intervals rather than exact numbers to cope with incomplete knowledge of other players' rationality. Under these assumptions we extend the cognitive hierarchy model of Camerer et al. [Camerer, C., Ho, T., Chong, J., 2003b. A cognitive hierarchy model of one-shot games. Quart. J. Econ. 119, 861–898]. The extended model is estimated on experimental data from a newspaper experiment.}
}
@article{ALTUN2024e00312,
title = {Parametric modeling and fabrication as capturing knowledge: A design computation workflow for historical brick surfaces in Anatolia},
journal = {Digital Applications in Archaeology and Cultural Heritage},
volume = {32},
pages = {e00312},
year = {2024},
issn = {2212-0548},
doi = {https://doi.org/10.1016/j.daach.2023.e00312},
url = {https://www.sciencedirect.com/science/article/pii/S2212054823000577},
author = {Sevgi Altun and Mine Özkar},
keywords = {Historical bricklaying, Shape grammars, Architectural heritage documentation, Robotic fabrication},
abstract = {Using computational design tools to create meaningful digital representations of architectural heritage delivers both challenges and opportunities. On one hand, digital tools aid the fast and detailed three-dimensional modeling of architectural elements. On the other hand, these models do not sufficiently document the materials and techniques of making. This research proposes a workflow to use computational design tools to analyze historic Anatolian brick elements while integrating their geometry, construction, and part-whole relations in parametric modeling and robotic fabrication processes. Our approach demonstrates a correlation between the design of the surface pattern and material application in historical bricklaying. The proposed workflow can be applied to formalize implicit design knowledge, integrating it into the digital environment and numeric control production codes. This holistic approach to heritage prioritizes both the tangible aspects, such as form and material, and intangible aspects such as the knowledge base of applied techniques.}
}
@incollection{MEINKE201939,
title = {Chapter 3 - The role of modeling and systems thinking in contemporary agriculture},
editor = {Riccardo Accorsi and Riccardo Manzini},
booktitle = {Sustainable Food Supply Chains},
publisher = {Academic Press},
pages = {39-47},
year = {2019},
isbn = {978-0-12-813411-5},
doi = {https://doi.org/10.1016/B978-0-12-813411-5.00003-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012813411500003X},
author = {Holger Meinke},
keywords = {Agriculture, Systems thinking, Complexity, Adaptation, Risk management, Modeling, Bioeconomy, Value chains, Social license, Industry 4.0, Sustainability},
abstract = {The images and perceived roles of agriculture in our societies have changed over the last few decades. Today agriculture is regarded as an integral part of interconnected value chains that sit at the heart of our economies, providing invaluable services to society. In response, most governments around the world are now actively developing policies to support and grow their bio-economies. This increases the expectations that society and governments have in terms of agriculture’s services and performance: agriculture is not only expected to generate food for our growing populations and income for farmers, it must be part of value chains that provide raw materials that can be incorporated or converted into feed, fiber, fuel, pharmaceuticals, and other industrial products. Farmers are expected to be responsible custodians of our landscapes and their farming practices must be economically, environmentally, and socially sustainable and aligned with the broader and changing values of our societies. Often these three objectives conflict and consequently societal expectations are not met. In a world that is increasingly data rich, practicing agriculture in a way that lives up to these expectations requires tools that can help to foresee the consequences of complex interactions. Hence, this chapter explores the role of modeling and systems thinking to manage this complexity by explicitly considering three attributes of complex, adaptive systems, whereby (i) order emerges rather than being predetermined; (ii) the system’s future can only be assessed probabilistically rather than deterministically predicted; and (iii) the history of the system is largely irreversible. The chapter reflects on the contemporary use of models against these three systems characteristics and concludes that scientifically based and tested algorithms (i.e., models) are already a ubiquitous and indispensable management tool for modern farming. Countless apps are already in use for short-term, tactical decision making, while more complex modeling approaches are vital for strategic scenario planning and risk assessments for farmers, policymakers, and scientists.}
}
@article{ASMUSSEN2025103328,
title = {Distrusting cores by separating computation from isolation},
journal = {Journal of Systems Architecture},
volume = {159},
pages = {103328},
year = {2025},
issn = {1383-7621},
doi = {https://doi.org/10.1016/j.sysarc.2024.103328},
url = {https://www.sciencedirect.com/science/article/pii/S1383762124002650},
author = {Nils Asmussen and Till Miemietz and Sebastian Haas and Michael Roitzsch},
keywords = {Multicore architectures, Hardware security, Reliability, Operating systems},
abstract = {Security mechanisms such as address spaces rely on the assumption that processor cores can be fully trusted. But the steady influx of side-channel vulnerabilities in processors is challenging this assumption. To minimize the impact of security vulnerabilities in processors, we need a system architecture that can tolerate potentially exploitable cores. In this paper, we propose the untrusted core isolation model to protect critical computation on trusted cores from untrusted and potentially buggy cores. We survey how current architectural building blocks such as MMUs fall short of this goal and derive requirements for untrusted core isolation. To demonstrate its feasibility, we discuss both changes to commodity platforms and show how research works such as fulfill the requirements. We evaluate the security benefits via a qualitative comparison of current architectures in both industry and academia and study its costs by a quantitative comparison of the most promising approaches on off-the-shelf and FPGA-based platforms.}
}
@article{KASPERSEN2022100539,
title = {High school students exploring machine learning and its societal implications: Opportunities and challenges},
journal = {International Journal of Child-Computer Interaction},
volume = {34},
pages = {100539},
year = {2022},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2022.100539},
url = {https://www.sciencedirect.com/science/article/pii/S2212868922000575},
author = {Magnus Høholt Kaspersen and Karl-Emil Kjær Bilstrup and Maarten {Van Mechelen} and Arthur Hjort and Niels Olof Bouvin and Marianne Graves Petersen},
keywords = {Computational empowerment, Computational thinking, Machine learning, Learning tools, AI literacy},
abstract = {The increased use of AI and machine learning (ML) calls for a general AI literacy, in particular regarding understanding how ML works, the process behind creating ML models, and reflecting on its implications. Where existing learning tools focus on the first two, we explore opportunities and challenges for meaningfully engaging students in understanding and reflecting on ML in their everyday life. We designed VotestratesML, following a Constructive Design Research approach, as an ethics-first learning tool that allow students to explore implications of ML for democratic elections. Based on deployments of VotestratesML in two high school social studies classrooms, we found that safely exploring ML from a concrete starting point helped students reflect and form opinions about its use, that promoting iterative exploration through collaboration and competition motivated them to explore, and that foregrounding ethics in the design and grounding ML in a well-known subject area allowed them to engage with ML on a personal level.}
}
@article{BERS2019130,
title = {Coding as a playground: Promoting positive learning experiences in childhood classrooms},
journal = {Computers & Education},
volume = {138},
pages = {130-145},
year = {2019},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2019.04.013},
url = {https://www.sciencedirect.com/science/article/pii/S0360131519300995},
author = {Marina U. Bers and Carina González-González and Mª Belén Armas–Torres},
keywords = {Cooperative/collaborative learning, Teaching/learning strategies, Improving classroom teaching, Elementary education},
abstract = {In recent years, there has been a push to introduce coding and computational thinking in early childhood education, and robotics is an excellent tool to achieve this. However, the integration of these fundamental skills into formal and official curriculums is still a challenge and educators needs pedagogical perspectives to properly integrate robotics, coding and computational thinking concepts into their classrooms. Thus, this study evaluates a “coding as a playground” experience in keeping with the Positive Technological Development (PTD) framework with the KIBO robotics kit, specially designed for young children. The research was conducted with preschool children aged 3–5 years old (N = 172) from three Spanish early childhood centers with different socio-economic characteristics and teachers of 16 classes. Results confirm that it is possible to start teaching this new literacy very early (at 3 years old). Furthermore, the results show that the strategies used promoted communication, collaboration and creativity in the classroom settings. The teachers also exhibited autonomy and confidence to integrate coding and computational thinking into their formal curricular activities, connecting concepts with art, music and social studies. Through the evidence found in this study, this research contributes with examples of effective strategies to introduce robotics, coding and computational thinking into early childhood classrooms.}
}
@article{DEBNATH2023314,
title = {Opportunities and limitations of integrating computational and collaborative approaches to scenario planning},
journal = {Journal of Urban Management},
volume = {12},
number = {4},
pages = {314-326},
year = {2023},
issn = {2226-5856},
doi = {https://doi.org/10.1016/j.jum.2023.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2226585623000468},
author = {Ripan Debnath and Christopher Pettit and Simone Zarpelon Leao},
keywords = {Scenario planning, Computational approach, CA-Model, Collaborative planning, Geodesign},
abstract = {In the context of changing global trends and growing uncertainties, creating and evaluating alternative future scenarios is crucial for urban and regional planning. Computational and collaborative approaches are two contemporary options for scenario planning. They have distinct roles and are often applied independently. This study investigates the integration of these two approaches, addressing a knowledge gap by explicitly integrating a Cellular Automata-based model within the collaborative geodesign framework. It assesses the integration process and scenario planning outcomes through a resilience planning case study. The key finding from this experiment is that integrating the information generated by a computational approach with the transparency and reliability inherent in a collaborative approach can enhance the end-user's scenario planning experience. The integration is also perceived to have positive effects on scenario outcomes, which is particularly relevant for joint evidence-based and collaborative resilience planning in cities and regions. However, the study also highlights the need for further investigation into the options for integrating computational methods into collaborative approaches and into the utility of integration in real-world planning with practitioners and the community.}
}
@article{FUNK2015163,
title = {Thinking about the future of technology: Rates of improvement and economic feasibility},
journal = {Futures},
volume = {73},
pages = {163-175},
year = {2015},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2015.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0016328715001081},
author = {Jeffrey L. Funk},
keywords = {Technology change, Economic feasibility, Transportation, Information technology, Health, Care, Telecommunications, Future, Rates of improvement, Scaling, Creating materials},
abstract = {This paper uses data on rates of improvement to discuss when new technologies or systems composed from them might become economically feasible. Technologies must provide some level of performance and price for specific applications before they will begin to diffuse and technologies that experience rapid rates of improvement are more likely to become economically feasible for a growing number of applications than are other technologies. Drawing from a large data base on rates of improvement, this paper describes a set of plausible futures that are very different from ones that are presented in public forums.}
}
@article{MAMMINO2023101151,
title = {Green chemistry and computational chemistry: A wealth of promising synergies},
journal = {Sustainable Chemistry and Pharmacy},
volume = {34},
pages = {101151},
year = {2023},
issn = {2352-5541},
doi = {https://doi.org/10.1016/j.scp.2023.101151},
url = {https://www.sciencedirect.com/science/article/pii/S2352554123001857},
author = {Liliana Mammino},
keywords = {Design of new molecules, Education to cross-disciplinary attitudes, Prediction of, Molecular properties, Prediction of reaction mechanisms},
abstract = {The green chemistry principles envisage the design of substances and production processes that are benign for human health and the environment, where ‘benign’ refers to the entire life of a substance, from production through usage and to final disposal. The design of new substances entails the design of new molecules, and the design of more benign processes may entail the design of other substances (besides reactants and products) facilitating the process' ‘greenness’, from catalysts to green solvents. Designing molecules with specific properties requires the possibility of predicting their properties before the actual synthesis. Computational chemistry has made molecular design rational by being able to predict the properties of not-yet-synthesized molecules. The results of molecular calculations enable a preliminary selection singling out the promising molecules among a high number of possibilities; only the promising ones are then synthesized and experimentally tested. Synergies between computational chemistry and green chemistry would thus appear a natural outcome. The present work outlines them with reference to the main components of an industrial process and of their potential ‘greening’. The presentation follows a pattern that can be used within educational contexts. The conclusions stress the importance to familiarise students with the variety of possible synergies and the benefits of each of them, within a perspective viewing a ‘knowing each other’ criterion as the main key to nurture true cross-areas attitudes, that will be valuable for the students' future professional activities.}
}
@article{LOCKWOOD2021100857,
title = {Reinforcing key combinatorial ideas in a computational setting: A case of encoding outcomes in computer programming},
journal = {The Journal of Mathematical Behavior},
volume = {62},
pages = {100857},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100857},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000183},
author = {Elise Lockwood and Adaline {De Chenne}},
keywords = {Combinatorics, Encoding outcomes, Computation, Programming, Discrete mathematics},
abstract = {Counting problems are difficult for students to solve, and there is a perennial need to investigate ways to help students solve counting problems successfully. One promising avenue for students’ successful counting is for them to think judiciously about how they encode outcomes – that is, how they symbolize and represent the outcomes they are trying to count. We provide a detailed case study of two students as they encoded outcomes in their work on several related counting problems within a computational setting. We highlight the role that a computational environment may have played in this encoding activity. We illustrate ways in which by-hand work and computer programming worked together to facilitate the students’ successful encoding activity. This case demonstrates ways in which the activity of computation seemed to interact with by-hand work to facilitate sophisticated encoding of outcomes.}
}
@article{CIMPIAN2012161,
title = {Remembering kinds: New evidence that categories are privileged in children’s thinking},
journal = {Cognitive Psychology},
volume = {64},
number = {3},
pages = {161-185},
year = {2012},
issn = {0010-0285},
doi = {https://doi.org/10.1016/j.cogpsych.2011.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0010028511000909},
author = {Andrei Cimpian and Lucy C. Erickson},
keywords = {Conceptual development, Kinds, Generic language, Memory},
abstract = {What are the representations and learning mechanisms that underlie conceptual development? The present research provides evidence in favor of the claim that this process is guided by an early-emerging predisposition to think and learn about abstract kinds. Specifically, three studies (N=192) demonstrated that 4- to 7-year-old children have better recall for novel information about kinds (e.g., that dogs catch a bug called “fep”) than for similar information about individuals (e.g., that a particular dog catches a bug called “fep”). By showing that children are particularly likely to retain information about kinds, this work not only provides a first empirical demonstration of a phenomenon that may be key to conceptual development but also makes it apparent that young children’s thinking is suffused with abstractions rather than being perceptually-based and concrete.}
}
@article{XU2024100415,
title = {Measuring mutual engagement in the context of middle-school pair programming: Development and validation of a self-reported questionnaire},
journal = {Computers in Human Behavior Reports},
volume = {14},
pages = {100415},
year = {2024},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2024.100415},
url = {https://www.sciencedirect.com/science/article/pii/S2451958824000484},
author = {Fan Xu and Ana-Paula Correia},
keywords = {Mutual engagement, Engagement questionnaire, Dyadic collaborative learning, Pair programming, Computational thinking, Middle school},
abstract = {With the increasing importance of equipping young learners with computational thinking skills through learning to code, pair programming has emerged as a prevalent collaborative learning strategy in this context. Successful pair programming interventions necessitate mutual engagement between partners within a dyad. However, the measurement of mutual engagement in dyadic collaborative learning remains an under-researched area. This research represents a foundational stage in bridging this gap by developing a comprehensive 20-item Pair-Programming Mutual Engagement Questionnaire (PPME-Q) as a measure of mutual engagement in pair programming at the activity level. The questionnaire was validated through a sample of 86 eighth-grade students. Confirmatory factor analysis confirmed the existence of a four-factor structure comprising of the behavioral, cognitive, emotional, and social engagement factors. The findings demonstrate the validity (χ2/df = 1.32) and reliability (Cronbach's α = 0.888) of the PPME-Q, establishing it as an effective tool for assessing eighth graders' mutual engagement in pair programming activities. As this tool is in the nascent stages of development the measurement, we emphasize the need for further empirical studies to establish criterion validity. We also discuss the implications of these findings for future research and educational practices. This targeted instrument can then potentially be adapted or scaled to other age groups based on the insights gained.}
}
@article{AISH2017144,
title = {Comparative evaluation of parametric design systems for teaching design computation},
journal = {Design Studies},
volume = {52},
pages = {144-172},
year = {2017},
note = {Parametric Design Thinking},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2017.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X17300327},
author = {Robert Aish and Sean Hanna},
keywords = {architectural design, design education, human–computer interaction, parametric design, evaluation},
abstract = {Three parametric design systems were tested by the authors to assess their suitability for undergraduate teaching. We used criteria taken from the ‘cognitive dimensions’ literature and an exercise of typical geometric operations in ascending order of complexity. For each system the cognitive barriers associated with the sequence of operations were plotted to create a ‘learning curve’. Different parametric systems presented distinctly different learning curves. The test exercise had to be completed in its entirety to assess the potential challenges which students with different educational levels, skills and abilities might encounter, so a single expert user conducted the tests. This research is intended to develop methods, both design exercises and evaluative criteria that could be used in future empirical studies.}
}
@article{HALL2024541,
title = {The computational structure of consummatory anhedonia},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {6},
pages = {541-553},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324000068},
author = {Anna F. Hall and Michael Browning and Quentin J.M. Huys},
keywords = {anhedonia, reinforcement learning, reward, goals, stress response, emotion appraisal},
abstract = {Anhedonia is a reduction in enjoyment, motivation, or interest. It is common across mental health disorders and a harbinger of poor treatment outcomes. The enjoyment aspect, termed ‘consummatory anhedonia’, in particular poses fundamental questions about how the brain constructs rewards: what processes determine how intensely a reward is experienced? Here, we outline limitations of existing computational conceptualisations of consummatory anhedonia. We then suggest a richer reinforcement learning (RL) account of consummatory anhedonia with a reconceptualisation of subjective hedonic experience in terms of goal progress. This accounts qualitatively for the impact of stress, dysfunctional cognitions, and maladaptive beliefs on hedonic experience. The model also offers new views on the treatments for anhedonia.}
}