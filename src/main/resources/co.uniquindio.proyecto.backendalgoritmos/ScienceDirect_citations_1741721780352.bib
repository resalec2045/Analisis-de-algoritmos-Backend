@article{XU2024167,
title = {Towards carbon neutrality in China: A systematic identification of China's sustainable land-use pathways across multiple scales},
journal = {Sustainable Production and Consumption},
volume = {44},
pages = {167-178},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2023.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S235255092300283X},
author = {Zhenci Xu},
keywords = {Carbon neutrality, Land use, Multi-scales, System thinking, China},
abstract = {Sustainable land use is crucial for achieving Carbon Neutrality goals, which requires a scientific identification of optimized pathways for land use patterns across multiple scales. Yet, current land use studies predominantly focus on single scales but lack system thinking and fail to establish complementary cross-regional carbon neutrality collaboration schemes. Applying life-cycle thinking to analyze land use sustainability and carbon neutrality potential at multiple scales could address this challenge. This study aims to present China's first multi-scale spatiotemporal optimization pathway for sustainable land use to improve carbon neutrality potential. It systematically integrates the complex spatial coupling relationships between land use intensity and efficiency. We integrate multi-scale sustainable land use pathways, spanning grid, basin, and administrative levels, and unveil significant variations in land use sustainability and carbon neutrality potential across China. Sixty-three percent of China's land is in low sustainability, and the overall carbon neutrality potential in China is relatively low, with regions accounting for <30 % facing more carbon neutrality missions. Implementing sequential and partitioned governance modes can effectively support China in achieving sustainable land use and advancing Carbon Neutrality goals. Our sustainable land use pathways for China provide valuable insights for systematically undertaking carbon neutrality actions across different scales.}
}
@article{FRANCIS2022103521,
title = {A framework for dynamic life cycle sustainability assessment and policy analysis of built environment through a system dynamics approach},
journal = {Sustainable Cities and Society},
volume = {76},
pages = {103521},
year = {2022},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2021.103521},
url = {https://www.sciencedirect.com/science/article/pii/S2210670721007873},
author = {Ann Francis and Albert Thomas},
keywords = {Sustainability assessment, System dynamics, Dynamic life cycle sustainability assessment (D-LCSA), Computational modelling, Life cycle assessment},
abstract = {Sustainability is gaining attention, particularly in the building sector, owing to its significant influence on economy, society and environment. However, most assessment methods/frameworks available for this sector focus solely or dominantly on the environmental dimension of sustainability. Hence, a sustainability assessment framework for buildings that accounts for the interdependencies amongst social, economic and environmental aspects is essential. Further, buildings also undergo several time-induced changes in their characteristics, such as changes in electricity consumption, material properties, surrounding infrastructure and energy mix that can influence their sustainability. Therefore, this paper introduces a system dynamics-based methodological framework for Dynamic Life Cycle Sustainability Assessment (D-LCSA) capable of incorporating the dynamic changes in the building characteristics with time and capturing the interactions amongst different sustainability indicators. The usability and utility of the framework is demonstrated using a case study residential project in India. The case study results show that ignoring time-dependant dynamic aspects in sustainability assessment of buildings leads to underestimating the overall sustainability impacts by about 50 per cent and specific environmental impacts by about 12 per cent. Therefore, the study reinforces the need to adopt dynamic thinking through modelling and simulation to predict sustainability performance in the built environment.}
}
@article{KOVYRSHIN2025104323,
title = {Prioritizing quantum computing use cases in the drug discovery and development pipeline},
journal = {Drug Discovery Today},
pages = {104323},
year = {2025},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2025.104323},
url = {https://www.sciencedirect.com/science/article/pii/S1359644625000364},
author = {Arseny Kovyrshin and Lars Tornberg and Jason Crain and Stefano Mensa and Ivano Tavernelli and Anders Broo},
keywords = {drug discovery and development, quantum computing, quantum chemistry, molecular interactions},
abstract = {Recent innovations in quantum computing hardware and algorithms have raised expectations that practical, real-world applications are within reach. In this context, we explore the potential impact of quantum computing on the drug discovery and development pipeline. Specifically, we discuss use cases from our research programs and outline approaches for prioritizing them based on our assessment of potential benefit from quantum computation. We identify and discuss specific classes of quantum chemistry problems that present challenges for classical computing methods, and where we have made initial efforts to develop and apply quantum computing algorithms. Finally, we offer a perspective on opportunities that will become available as we enter the early-fault tolerant era.}
}
@article{CORCORAN2020158,
title = {Language as a biomarker for psychosis: A natural language processing approach},
journal = {Schizophrenia Research},
volume = {226},
pages = {158-166},
year = {2020},
note = {Biomarkers in the Attenuated Psychosis Syndrome},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2020.04.032},
url = {https://www.sciencedirect.com/science/article/pii/S0920996420302474},
author = {Cheryl M. Corcoran and Vijay A. Mittal and Carrie E. Bearden and Raquel {E. Gur} and Kasia Hitczenko and Zarina Bilgrami and Aleksandar Savic and Guillermo A. Cecchi and Phillip Wolff},
keywords = {Psychosis, Automated language analysis, Natural language processing, Machine learning, Semantic coherence, Discourse coherence, Referential coherence, Semantic density, Latent semantic analysis, Digital phenotyping, Psychosis risk, Clinical high risk, Ultra high risk, Schizophrenia},
abstract = {Human ratings of conceptual disorganization, poverty of content, referential cohesion and illogical thinking have been shown to predict psychosis onset in prospective clinical high risk (CHR) cohort studies. The potential value of linguistic biomarkers has been significantly magnified, however, by recent advances in natural language processing (NLP) and machine learning (ML). Such methodologies allow for the rapid and objective measurement of language features, many of which are not easily recognized by human raters. Here we review the key findings on language production disturbance in psychosis. We also describe recent advances in the computational methods used to analyze language data, including methods for the automatic measurement of discourse coherence, syntactic complexity, poverty of content, referential coherence, and metaphorical language. Linguistic biomarkers of psychosis risk are now undergoing cross-validation, with attention to harmonization of methods. Future directions in extended CHR networks include studies of sources of variance, and combination with other promising biomarkers of psychosis risk, such as cognitive and sensory processing impairments likely to be related to language. Implications for the broader study of social communication, including reciprocal prosody, face expression and gesture, are discussed.}
}
@article{MARTINEZMINGO2023101154,
title = {Quantum projections on conceptual subspaces},
journal = {Cognitive Systems Research},
volume = {82},
pages = {101154},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101154},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723000827},
author = {Alejandro Martínez-Mingo and Guillermo Jorge-Botana and José Ángel Martinez-Huertas and Ricardo {Olmos Albacete}},
keywords = {Quantum similarity model, Semantic-vector space models, Computational linguistics, Similarity},
abstract = {One of the main challenges of cognitive science is to explain the representation of conceptual knowledge and the mechanisms involved in evaluating the similarities between these representations. Theories that attempt to explain this phenomenon should account for the fact that conceptual knowledge is not static. In line with this thinking, many studies suggest that the representation of a concept changes depending on context. Traditionally, concepts have been studied as vectors within a geometric space, sometimes called Semantic-Vector Space Models (S-VSMs). However, S-VSMs have certain limitations in emulating human biases or context effects when the similarity of concepts is judged. Such limitations are related to the use of a classical geometric approach that represents a concept as a point in space. Recently, some theories have proposed the use of sequential projections of subspaces based on Quantum Probability Theory (Busemeyer and Bruza, 2012; Pothos et al., 2013). They argue that this theoretical approach may facilitate accounting for human similarity biases and context effects in a more natural way. More specifically, Pothos and Busemeyer (2011) proposed the Quantum Similarity Model (QSM) to determine expectation in conceptual spaces in a non-monotonic logic frame. To the best of our knowledge, previous data-driven studies have used the QSM subspaces in a unidimensional way. In this paper, we present a data-driven method to generate these conceptual subspaces in a multidimensional manner using a traditional S-VSM. We present an illustration of the method taking Tversky’s classical examples to explain the effects of Asymmetry, Triangular Inequality, and the Diagnosticity by means of sequential projections of those conceptual subspaces.}
}
@article{LIBEROS2019319,
title = {Phase singularity point tracking for the identification of typical and atypical flutter patients: A clinical-computational study},
journal = {Computers in Biology and Medicine},
volume = {104},
pages = {319-328},
year = {2019},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2018.11.020},
url = {https://www.sciencedirect.com/science/article/pii/S0010482518303901},
author = {A. Liberos and M. Rodrigo and I. Hernandez-Romero and A. Quesada and F. Fernandez-Aviles and F. Atienza and A.M. Climent and M.S. Guillem},
keywords = {Atrial flutter, Phase map, Cardiac model, Body surface potential mapping},
abstract = {Atrial Flutter (AFL) termination by ablating the path responsible for the arrhythmia maintenance is an extended practice. However, the difficulty associated with the identification of the circuit in the case of atypical AFL motivates the development of diagnostic techniques. We propose body surface phase map analysis as a noninvasive tool to identify AFL circuits. Sixty seven lead body surface recordings were acquired in 9 patients during AFL (i.e. 3 typical, 6 atypical). Computed body surface phase maps from simulations of 5 reentrant behaviors in a realistic atrial structure were also used. Surface representation of the macro-reentrant activity was analyzed by tracking the singularity points (SPs) in surface phase maps obtained from band-pass filtered body surface potential maps. Spatial distribution of SPs showed significant differences between typical and atypical AFL. Whereas for typical AFL patients 70.78 ± 16.17% of the maps presented two SPs simultaneously in the areas defined around the midaxialliary lines, this condition was only satisfied in 5.15 ± 10.99% (p < 0.05) maps corresponding to atypical AFL patients. Simulations confirmed these results. Surface phase maps highlights the reentrant mechanism maintaining the arrhythmia and appear as a promising tool for the noninvasive characterization of the circuit maintaining AFL. The potential of the technique as a diagnosis tool needs to be evaluated in larger populations and, if it is confirmed, may help in planning ablation procedures.}
}
@article{USMANI20241044,
title = {The Digital Age: Exploring the Intersection of AI/CI and Human Cognition and Social Interactions},
journal = {Procedia Computer Science},
volume = {239},
pages = {1044-1052},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.268},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924015114},
author = {Usman Ahmad Usmani and Ari Happonen and Junzo Watada},
keywords = {Artificial intelligence, Computational intelligence, Digitalization, Digital transformation, Human cognition, Social interaction, Industry 4.0, Digital capability, Social transformation, Human computer interaction},
abstract = {Although solutions based on artificial and computational intelligence have made life easier, the fast development of technology also raises questions about near future and log term human cognition and social interaction. Through a survey of the literature and qualitative analysis, our work examined current research on how the AI/CI affects human cognitive functions and social interactions. We discuss how AI and CI are influencing e.g. how we humans gather information, build relationships, and communicate with others, with and without the new frontline technologies. Additionally, proposals for future advances are discussed along with the ethical and societal ramifications these technologies have, could and might bring into our lives. We think that by developing a deeper knowledge of how AI/CI affects human cognition and social interaction, new contributions are made to a positive conversation and encourage a responsible approach to incorporating new technologies into our daily lives.}
}
@article{MARIS2022131391,
title = {Structure and dynamics of methacrylamide, a computational and free-jet rotational spectroscopic study},
journal = {Journal of Molecular Structure},
volume = {1248},
pages = {131391},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2021.131391},
url = {https://www.sciencedirect.com/science/article/pii/S0022286021015192},
author = {Assimo Maris and Sonia Melandri and Luca Evangelisti and Annalisa Vigorito and Silvia Sigismondi and Camilla Calabrese and Imanol Usabiaga},
keywords = {Amide, Gas-phase structure, Large amplitude motions, Nuclear quadrupole hyperfine structure, Rotational spectroscopy, Quantum mechanical calculations},
abstract = {The conformational space of methacrylamide was explored by quantum mechanical modeling and surveyed in the 59.6–104.0 GHz frequency range using a millimeter-wave Stark-modulated free-jet absorption spectrometer. According to the relative orientation of the two unsaturated bonds, two conformers were observed, namely s-trans (A=5234.360(1), B=3364.9717(8) and C=2173.099(1) MHz) and s-cis (A=5207.292(1), B=3470.930(1) and C=2113.496(1) MHz). The s-trans conformation is the global minimum, with relative energy 4(2) kJ mol−1 and calculated isomerization barrier 15 kJ mol−1. Except for the methyl hydrogen atoms, s-cis-methacrylamide is planar and its methyl internal rotation barrier is 10.2(1) kJ mol−1. In s-trans-methacrylamide the allyl and amino frames form a dihedral angle of about 30° and the methyl internal rotation barrier is 7.4 kJ mol−1. This different behaviour is explained in terms of attractive and repulsive intramolecular interactions between groups: CH2/CO and CH3/NH2 for s-cis, CH2/NH2 and CH3/CO for s-trans. The tunneling splitting related to the double-well potential describing the interconversion between the two equivalent s-trans forms is 837.97(2) MHz and was reproduced by a one-dimensional flexible model using a 3.6 kJ mol−1 interconversion barrier.}
}
@incollection{ALIPPI2019245,
title = {Chapter 12 - Computational Intelligence in the Time of Cyber-Physical Systems and the Internet of Things},
editor = {Robert Kozma and Cesare Alippi and Yoonsuck Choe and Francesco Carlo Morabito},
booktitle = {Artificial Intelligence in the Age of Neural Networks and Brain Computing},
publisher = {Academic Press},
pages = {245-263},
year = {2019},
isbn = {978-0-12-815480-9},
doi = {https://doi.org/10.1016/B978-0-12-815480-9.00012-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128154809000128},
author = {Cesare Alippi and Seiichi Ozawa},
keywords = {Brain computing, Cyber-physical systems, Cybersecurity, Embedded systems, Neurodynamics, IoT, Machine learning, Neural networks},
abstract = {The emergence of nontrivial embedded sensor units and cyber-physical systems and the Internet of Things has made possible the design and implementation of sophisticated applications where large amounts of real-time data are collected, possibly to constitute a big data picture as time passes. Within this framework, intelligence mechanisms based on machine learning, neural networks, and brain computing approaches play a key role to provide systems with advanced functionalities. Intelligent mechanisms are needed to guarantee appropriate performances within an evolving, time-variant environment, optimally harvest the available energy and manage the residual energy, reduce the energy consumption of the whole system, identify and mitigate occurrence of faults, and provide shields against cyberattacks. The chapter introduces the above aspects of intelligence, whose functionalities are needed to boost the next generation of cyber-physical and Internet of Things applications, and the smart world generation whose footprint is already around us.}
}
@article{LOURIDAS1999517,
title = {Design as bricolage: anthropology meets design thinking},
journal = {Design Studies},
volume = {20},
number = {6},
pages = {517-535},
year = {1999},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(98)00044-1},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X98000441},
author = {Panagiotis Louridas},
keywords = {aesthetics, design activity, design cognition, metaphor, psychology of design},
abstract = {We identify a metaphor for the design activity: we view design as bricolage. We start from describing bricolage, and we proceed to the relationship of design to art. We obtain a characterisation of design that enables us to show that both traditional and contemporary design are forms of bricolage. We examine the consequences of `design as bricolage' for the relationship between design and science and for the extent of the design activity.}
}
@article{HARTMANN2021112902,
title = {Model development for evidence-based prioritisation of policy action on emerging chemical and microbial drinking water risks},
journal = {Journal of Environmental Management},
volume = {295},
pages = {112902},
year = {2021},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2021.112902},
url = {https://www.sciencedirect.com/science/article/pii/S0301479721009646},
author = {Julia Hartmann and Juan Carlos Chacon-Hurtado and Eric Verbruggen and Jack Schijven and Emiel Rorije and Susanne Wuijts and Ana Maria {de Roda Husman} and Jan Peter {van der Hoek} and Lisa Scholten},
keywords = {Multi criteria analysis, MCA, Stakeholder consultation, Water contaminants, Pathogen},
abstract = {While the burden of disease from well-studied drinking water contaminants is declining, risks from emerging chemical and microbial contaminants arise because of social, technological, demographic and climatological developments. At present, emerging chemical and microbial drinking water contaminants are not assessed in a systematic way, but reactively and incidence based. Furthermore, they are assessed separately despite similar pollution sources. As a result, risks might be addressed ineffectively. Integrated risk assessment approaches are thus needed that elucidate the uncertainties in the risk evaluation of emerging drinking water contaminants, while considering risk assessors’ values. This study therefore aimed to (1) construct an assessment hierarchy for the integrated evaluation of the potential risks from emerging chemical and microbial contaminants in drinking water and (2) develop a decision support tool, based on the agreed assessment hierarchy, to quantify (uncertain) risk scores. A multi-actor approach was used to construct the assessment hierarchy, involving chemical and microbial risk assessors, drinking water experts and members of responsible authorities. The concept of value-focused thinking was applied to guide the problem-structuring and model-building process. The development of the decision support tool was done using Decisi-o-rama, an open-source Python library. With the developed decision support tool (uncertain) risk scores can be calculated for emerging chemical and microbial drinking water contaminants, which can be used for the evidence-based prioritisation of actions on emerging chemical and microbial drinking water risks. The decision support tool improves existing prioritisation approaches as it combines uncertain indicator levels with a multi-stakeholder approach and integrated the risk assessment of chemical and microbial contaminants. By applying the concept of value-focused thinking, this study addressed difficulties in evidence-based decision-making related to emerging drinking water contaminants. Suggestions to improve the model were made to guide future research in assisting policy makers to effectively protect public health from emerging drinking water risks.}
}
@article{WANG202428,
title = {Exploring the interplay between core and mood symptoms in schizophrenia: A network analysis},
journal = {Schizophrenia Research},
volume = {269},
pages = {28-35},
year = {2024},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2024.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S0920996424001695},
author = {Yucheng Wang and Yixiao Xu and Peiyi Wu and Yang Zhou and Huanrui Zhang and Zijia Li and Yanqing Tang},
keywords = {Schizophrenia, Core symptoms, Mood symptoms, Network analysis, Symptom interactions},
abstract = {Background
Schizophrenia is a complex neuropsychiatric disorder characterized by positive symptoms, negative symptoms, cognitive deficits, and co-occurring mood symptoms. Network analysis offers a novel approach to investigate the intricate relationships between these symptom dimensions, potentially informing personalized treatment strategies.
Methods
A cross-sectional study was conducted from November 2019 to October 2021, involving 1285 inpatients with schizophrenia in Liaoning Province, China. Symptom severity was assessed using the Positive and Negative Syndrome Scale (PANSS), Hamilton Depression Rating Scale (HAMD-17), Hamilton Anxiety Rating Scale (HAMA-14), and Montreal Cognitive Assessment (MoCA). Network analysis was conducted to investigate the network structure, central symptoms, and bridge symptoms.
Results
The network analysis uncovered profound interconnectivity between core symptoms and the anxiety-depression community. Central symptoms, such as psychic anxiety, poor rapport, delusions, and attention, were identified as potential therapeutic targets. Bridge symptoms, including insomnia, depressed mood, anxiety-somatic, conceptual disorganization, and stereotyped thinking, emerged as key nodes facilitating interactions between symptom communities. The stability and reliability of the networks were confirmed through bootstrapping procedures.
Discussion
The findings highlight the complex interplay between schizophrenia symptoms, emphasizing the importance of targeting affective symptoms and cognitive impairment in treatment. The identification of central and bridge symptoms suggests potential pathways for personalized interventions aimed at disrupting self-reinforcing symptom cycles. The study underscores the need for a transdiagnostic, personalized approach to schizophrenia treatment.}
}
@article{LIN2021103499,
title = {Informational cues or content? Examining project funding decisions by crowdfunders},
journal = {Information & Management},
volume = {58},
number = {7},
pages = {103499},
year = {2021},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2021.103499},
url = {https://www.sciencedirect.com/science/article/pii/S0378720621000732},
author = {Yan Lin and Wai Fong Boh},
keywords = {Experience, Elaboration Likelihood Model, Information Asymmetry, Crowdfunding},
abstract = {We examine how crowdfunder experience affects their reliance on information available on projects. Drawing on elaboration likelihood model and using data from Kickstarter, we apply machine learning techniques and choice modeling to examine the information provided by creators, investigating not only the descriptions, but also the pictures and the videos. We found that more experienced crowdfunders react positively to descriptions exhibiting higher analytical thinking, while less experienced crowdfunders rely more on cues that arouse attention (e.g., number of pictures and positive emotions in videos). We highlight the importance of considering how experience influences crowdfunders’ interpretation of different types of information.}
}
@incollection{PARRY2016255,
title = {Chapter Ten - Using Data Mining and Computational Approaches to Study Intermediate Filament Structure and Function},
editor = {M. Bishr Omary and Ronald K.H. Liem},
series = {Methods in Enzymology},
publisher = {Academic Press},
volume = {568},
pages = {255-276},
year = {2016},
booktitle = {Intermediate Filament Proteins},
issn = {0076-6879},
doi = {https://doi.org/10.1016/bs.mie.2015.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0076687915004152},
author = {David A.D. Parry},
keywords = {IF chain assembly, Sequence periodicities, Heptad and hendecad substructure, Interchain ionic interactions, IF secondary and tertiary structure, Structural/functional motifs, Mutations},
abstract = {Experimental and theoretical research aimed at determining the structure and function of the family of intermediate filament proteins has made significant advances over the past 20 years. Much of this has either contributed to or relied on the amino acid sequence databases that are now available online, and the data mining approaches that have been developed to analyze these sequences. As the quality of sequence data is generally high, it follows that it is the design of the computational and graphical methodologies that are of especial importance to researchers who aspire to gain a greater understanding of those sequence features that specify both function and structural hierarchy. However, these techniques are necessarily subject to limitations and it is important that these be recognized. In addition, no single method is likely to be successful in solving a particular problem, and a coordinated approach using a suite of methods is generally required. A final step in the process involves the interpretation of the results obtained and the construction of a working model or hypothesis that suggests further experimentation. While such methods allow meaningful progress to be made it is still important that the data are interpreted correctly and conservatively. New data mining methods are continually being developed, and it can be expected that even greater understanding of the relationship between structure and function will be gleaned from sequence data in the coming years.}
}
@article{LEWIS2018491,
title = {How Memory Replay in Sleep Boosts Creative Problem-Solving},
journal = {Trends in Cognitive Sciences},
volume = {22},
number = {6},
pages = {491-503},
year = {2018},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2018.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S1364661318300706},
author = {Penelope A. Lewis and Günther Knoblich and Gina Poe},
keywords = {sleep, memory, creativity, reactivation, replay, consolidation},
abstract = {Creative thought relies on the reorganisation of existing knowledge. Sleep is known to be important for creative thinking, but there is a debate about which sleep stage is most relevant, and why. We address this issue by proposing that rapid eye movement sleep, or ‘REM’, and non-REM sleep facilitate creativity in different ways. Memory replay mechanisms in non-REM can abstract rules from corpuses of learned information, while replay in REM may promote novel associations. We propose that the iterative interleaving of REM and non-REM across a night boosts the formation of complex knowledge frameworks, and allows these frameworks to be restructured, thus facilitating creative thought. We outline a hypothetical computational model which will allow explicit testing of these hypotheses.}
}
@article{GENT202336,
title = {Computing comes to life},
journal = {New Scientist},
volume = {258},
number = {3442},
pages = {36-39},
year = {2023},
issn = {0262-4079},
doi = {https://doi.org/10.1016/S0262-4079(23)01054-0},
url = {https://www.sciencedirect.com/science/article/pii/S0262407923010540},
author = {Edd Gent},
abstract = {Nature is capable of astonishing feats of computation. Now, we are re-engineering molecules, cells and even whole organisms into living processors, says Edd Gent}
}
@article{SONOBE2022101560,
title = {Development and validation of machine learning prediction model for post-rehabilitation functional outcome after intracerebral hemorrhage},
journal = {Interdisciplinary Neurosurgery},
volume = {29},
pages = {101560},
year = {2022},
issn = {2214-7519},
doi = {https://doi.org/10.1016/j.inat.2022.101560},
url = {https://www.sciencedirect.com/science/article/pii/S2214751922000743},
author = {Shinya Sonobe and Tetsuo Ishikawa and Kuniyasu Niizuma and Eiryo Kawakami and Takuya Ueda and Eichi Takaya and Carlos {Makoto Miyauchi} and Junya Iwazaki and Ryuzaburo Kochi and Toshiki Endo and Arun Shastry and Vijayananda Jagannatha and Ajay Seth and Atsuhiro Nakagawa and Masahiro Yoshida and Teiji Tominaga},
keywords = {Intracerebral hemorrhage, Machine learning prediction, Post-rehabilitation functional outcome, Design thinking},
abstract = {Objective
Predicting outcomes after intracerebral hemorrhage (ICH) may help improve patient outcomes. We developed and validated a machine learning prediction model for post-rehabilitation functional outcomes after ICH. Patient selection and explanatory variable settings were based on clinical significance. Functional outcomes were predicted using ternary classification.
Methods
The subjects were patients aged > 18 years without pre-onset severe disability who developed primary putaminal and/or thalamic hemorrhage and underwent an inpatient rehabilitation program. As explanatory variables, 43 values related to patient background, imaging-related findings, systemic conditions, neurological findings, and blood tests were acquired within 10 days of onset. As an objective variable, the functional outcome at discharge to home or nursing home was acquired using a ternary classification. The dataset consisting of the collected information was split into a training dataset and a test dataset with a ratio of 2:1. A predictive model using a balanced random forest algorithm was created using supervised learning from the training dataset. The predictive performance was validated using a test dataset.
Results
Between January 2018 and June 2019, 100 consecutive patients were included in the study. The areas under the receiver operating characteristic curves for predictions of good, moderate, and poor outcomes were 0.952, 0.790, and 0.921, respectively.
Conclusions
The predictive performance of the model was comparable to that of previous models. Patient selection and variable settings from a clinical perspective may contribute to accurate and detailed predictions. These study designs are based on design thinking and may meet the needs of clinical practice.}
}
@article{CIMIER2025100092,
title = {Multisensory objects’ role on creativity},
journal = {Journal of Creativity},
volume = {35},
number = {1},
pages = {100092},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2024.100092},
url = {https://www.sciencedirect.com/science/article/pii/S2713374524000189},
author = {Amandine Cimier and Beatrice Biancardi and Jérome Guegan and Frédéric Segonds and Fabrice Mantelet and Camille Jean and Claude Gazo and Stéphanie Buisine},
keywords = {Engineering, Manipulation, Embodied cognition, Kinesthesia, Creativity},
abstract = {In this research, we investigated the role of multisensorial manipulation on creativity, and the influence of inspirational objects on creative outcomes. Object manipulation may support embodied cognition during a generative creative phase (emergence of motor, spatial, emotional ideas, etc.) then exploratory phase (creative fixation, development of a functional creation, etc.). Our protocol involved 136 engineering students divided into 34 groups which were provided with inspirational cubes illustrating manufacturing inventive principles or basic volumes from the Creative Mental Synthesis Task. They could manipulate these objects either in a visuo-haptic condition, or in a visuo-imaginative condition. Our results highlighted a main effect of manipulation, showing that visual-haptic condition led to higher creativity than visual-imaginative condition. We also observed several effects in favor of inspirational cubes with regard to basic volumes: significantly higher creativity, more subjective and inter-subjective facilitation behaviors, more cognitive and emotional operations. Participants also showed at an individual level a better mobilization of the multisensorial senses. Creative thinking may be stimulated when an active manipulation phase is set up before the creative production. This could contribute to improving practice for engineers, particularly for using additive manufacturing and/or during their training at school.}
}
@article{MUZAFFAR20224912,
title = {Analysing the Causes of Design Generated Waste through System Dynamics},
journal = {KSCE Journal of Civil Engineering},
volume = {26},
number = {12},
pages = {4912-4925},
year = {2022},
issn = {1226-7988},
doi = {https://doi.org/10.1007/s12205-022-1896-1},
url = {https://www.sciencedirect.com/science/article/pii/S1226798824013461},
author = {Sidra Muzaffar and Khurram Iqbal Ahmad Khan and Muhammad Bilal Tahir and Hamna Bukhari},
keywords = {Construction & demolition waste, Design generated waste, Causal loop diagram, Systems thinking, System dynamics},
abstract = {A drastic rise in construction waste observed has elicited a radical impact on the environment and economy of the world. It is, therefore, necessary to come up with waste minimization management strategies that reflect in-depth review of sources of waste. This in depth review demands understanding the intricacy of causative factors triggering generation of “waste at source” which is the main motive of study and is done through System Dynamics for design phase in context of developing countries. 8 most important causative factors in design phase were shortlisted along with their interrelationships via literature and questionnaire survey. Followed by system thinking approach that addressed the complexities caused by those factors in 2 stages. Firstly, a Causal loop diagram was developed that illustated interrelationship between factors in the form of loops. Later SD model built, evaluated the combinatorial effect of 3 evolved stocks over the fourth stock Design Generated Waste-an emanating phenomenon. Simulation result revealed increasing trend of the stock DGW over a course of time. Therefore, increase in effect of complexities of behavior of design waste causes, will consequently lead to increase in DGW. Managing the complex behavior of these design causes will help control over the DGW w.r.t. time.}
}
@article{LLOYD2019167,
title = {You make it and you try it out: Seeds of design discipline futures},
journal = {Design Studies},
volume = {65},
pages = {167-181},
year = {2019},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2019.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X19300675},
author = {Peter Lloyd},
keywords = {design methods, design studies, design research, design process, design thinking},
abstract = {This paper takes a narrative seam through the design discipline, attempting to explain how design methodology, one of the three types of Nigel Cross' designerly ways of knowing, has changed over the 40 years of Design Studies. Specifically, the paper identifies the point when a ‘social turn’ in the discipline occurred, allowing more nuanced and critical studies of designing, and shifting the balance from an objective (‘scientific’) perspective to one more based on relativist approaches. The paper concludes by noting the plurality of present-day study, arguably enabled by design thinking, and sketches what this holds for the future of the discipline. The references in the paper are mainly restricted to those published in, or strongly relating to, Design Studies.}
}
@article{TESFATSION2001281,
title = {Introduction to the special issue on agent-based computational economics},
journal = {Journal of Economic Dynamics and Control},
volume = {25},
number = {3},
pages = {281-293},
year = {2001},
note = {Agent-based Computational Economics (ACE)},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(00)00027-0},
url = {https://www.sciencedirect.com/science/article/pii/S0165188900000270},
author = {Leigh Tesfatsion},
keywords = {Agent-based computational economics},
abstract = {A brief overview of agent-based computational economics (ACE) is given, followed by a synopsis of the articles included in this special issue on ACE and in a companion special issue on ACE scheduled to appear in Computational Economics.}
}
@article{MCDERMOTT20071183,
title = {Level-headed},
journal = {Artificial Intelligence},
volume = {171},
number = {18},
pages = {1183-1186},
year = {2007},
note = {Special Review Issue},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2007.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S0004370207001488},
author = {Drew McDermott},
keywords = {Speculation, Methodology, Natural language},
abstract = {I don't believe that human-level intelligence is a well defined goal. As the cognitive-science community learns more about thinking and computation, the mileposts will keep changing in ways that we can't predict, as will the esteem we assign to past accomplishments. It would be fun to have a computer that could solve brain teasers as well as the average scientist, but focusing on such things, besides being parochial, overlooks the crucial role language plays in everything humans do, a role we understand hardly at all on a computational level. I am optimistic that we will eventually figure language out, but not without new ideas. Plus, when we can talk to machines, will we understand each other?}
}
@article{PEREZLOPEZ2024105162,
title = {Cartographic analysis as spatial determinant for climate change adaptation in the Hunter River Estuary, Australia},
journal = {Cities},
volume = {152},
pages = {105162},
year = {2024},
issn = {0264-2751},
doi = {https://doi.org/10.1016/j.cities.2024.105162},
url = {https://www.sciencedirect.com/science/article/pii/S0264275124003767},
author = {Irene {Perez Lopez} and Sandra Carrasco and Cesar {Mariscal Madrigal}},
keywords = {Ecological design, Estuary urbanism, Climate adaptation, Living infrastructures, Hunter River Australia},
abstract = {This paper explores the hydrological history of the Hunter River and Estuary (Newcastle, Australia), to identify pathways for incorporating climate-sensitive adaptation approaches into urban development and planning. The research method utilises mapping as a methodological discovery tools to visually articulate the correlation of pre-colonial hydrological landscapes, the transformation of the estuary over two centuries, the areas identified as at risk, and the opportunities for developing a climate-resilient estuary. This research aims to contribute to the redefinition of the discourse on the role of estuary planning for changing climate, focusing on four critical aspects: identify the impacts of urbanisation and industrialisation on ecosystems and its correlation with climate hazard at the estuary; visualise such transformations over time and space to identify critical spatial and climate factors threatening inhabitation; propose strategic spatial practices towards adaptation and resilience; and synthesising the options to foster reflective thinking and establish a correlation with novel policies, governance and practices. The study highlights that adopting new urbanism aligned with cultural and ecological principles can mitigate future climate impacts through re-naturalisation and urban adaptation to sea-level rise by focusing on proactive approaches to building resilient communities. This paper also acknowledges the need for site-specific adaptive design and planning strategies at multiple scales and governance levels.}
}
@article{MACHKROL2023259,
title = {An ML-extended conceptual framework for implementing temporal big data analytics in organizations to support their agility},
journal = {Procedia Computer Science},
volume = {225},
pages = {259-268},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923011687},
author = {Maria Mach-Król and Bartłomiej Hadasik},
keywords = {temporal big data analytics, temporal knowledge, machine learning, organizational agility, feedback loop},
abstract = {The main aim of this paper is to present the machine learning (ML) extension to the authors’ original conceptual framework for implementing temporal big data analytics (TBDA) in organizations. The framework has been also supplemented with a ML-supported feedback loop aimed at ongoing verification of the organization's maturity for TBDA in light of changing needs, requirements, and the company's environment. Such extension is needed to make the TBDA more flexible and adaptable to market environment, thus augmenting organizational agility. The research has been carried following the Design Science Research in Information Systems (DSRIS) methodological approach with the addition of creative thinking. As a result, the extended framework is elaborated, and further improvements and research directions are identified.}
}
@article{ISLAM2025100417,
title = {DFT insights into the mechanical properties of NMs},
journal = {Results in Surfaces and Interfaces},
volume = {18},
pages = {100417},
year = {2025},
issn = {2666-8459},
doi = {https://doi.org/10.1016/j.rsurfi.2025.100417},
url = {https://www.sciencedirect.com/science/article/pii/S2666845925000042},
author = {Md. Aminul Islam and Nayem Hossain and Zahid Ahsan and Masud Rana and Mustafizur Rahman and Md. Abdullah},
keywords = {DFT, NMs, Elasticity, Mechanical properties, Quantum effects, Surface phenomena},
abstract = {NMs, whose dimensions are below 100 nm, provide unique mechanical properties from quantum effects, surface phenomena, and small-scale interactions that account for their importance in energy storage, biomedicine, nanoelectronics, etc. This review discusses computational prediction of mechanical properties (for example, elasticity, strength, and fracture behavior) in NMs, especially using Density Functional Theory as a central tool. By conducting DFT calculations, we can analyze how NMs will behave across different mechanical states, which is critical for designing properties for advanced applications. Problems related to the application of DFT (e.g., high computational cost and failure in modeling defects or exchange-correlation functionals) are discussed. Despite these challenges, DFT must provide insights that complement other tools and strategies. However, further development is essential for improving its quantitative predictability on temperature and multiscale models. Future work is needed to integrate ML with DFT further to refine the accuracy and computational efficiency, thereby extending the capability of DFT to accelerate the discovery of new NMs with superior mechanical properties.}
}
@article{SALMON2022105511,
title = {Bicycle crash contributory factors: A systematic review},
journal = {Safety Science},
volume = {145},
pages = {105511},
year = {2022},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2021.105511},
url = {https://www.sciencedirect.com/science/article/pii/S0925753521003544},
author = {Paul M. Salmon and Mitch Naughton and Adam Hulme and Scott McLean},
keywords = {Cyclists, Cyclist crashes, Systems thinking, Road safety, Crash causation},
abstract = {There is a growing body of road safety research that seeks to identify crash contributory factors beyond road users, their vehicles, and the immediate road environment. Although cyclist safety represents a critical research area, this ‘systems thinking’ approach has received less attention in bicycle crash analysis. This article presents the findings from a systematic literature review which aimed to synthesise the peer reviewed literature regarding bicycle crash contributory factors (defined as factors which play a contributory role in bicycle crashes, as opposed to risk factors which are factors which may increase the probability of crashes). Crash contributory factors were extracted from included articles and mapped onto a systems thinking framework comprising seven hierarchical road transport system levels. The findings show that a majority of the included studies identified contributory factors relating to the road environment, cycling infrastructure, and cyclist and driver behaviour. No studies identified contributory factors outside of cyclists and road users, bicycles and vehicles, and the road environment and few specifically examined causal relationships between contributory factors. It is concluded that there are gaps in the knowledge base regarding the broader transport system features that play a role in bicycle crashes and how contributory factors interact to create crashes. We argue that more expansive research into the systemic factors involved in bicycle crashes is required and that initial work should focus on the development of new data sources and analysis methods.}
}
@article{YIN2015655,
title = {Automating design with intelligent human–machine integration},
journal = {CIRP Annals},
volume = {64},
number = {2},
pages = {655-677},
year = {2015},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2015.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S000785061500147X},
author = {Yue H. Yin and Andrew Y.C. Nee and S.K. Ong and Jian Y. Zhu and Pei H. Gu and Lien J. Chen},
keywords = {Design automation, Human–machine integration, Intelligent design, Imaginal thinking, Ontology},
abstract = {This paper reviews the state-of-the-art methodologies for automating design with intelligent human–machine integration from the perspectives of ontology and epistemology. The human–machine integrated automating design paradigm is reviewed systematically based on a proposed prototype of human–machine integrated design, from the aspects of ontology-based knowledge management with local-to-global ontology transitions, and epistemology-based upward-spiral cognitive process of coupled design ideation. Particularly, imaginal thinking frame is proposed as the foundation of intelligent human–machine interaction that puts human and machine on an equal platform. Further, this paper presents implementations and applications of the automating design paradigm and concludes with the identification of future trend.}
}
@article{GEORGIEV20181,
title = {Enhancing user creativity: Semantic measures for idea generation},
journal = {Knowledge-Based Systems},
volume = {151},
pages = {1-15},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118301394},
author = {Georgi V. Georgiev and Danko D. Georgiev},
keywords = {Creativity, Divergence, Semantic networks, Similarity, WordNet},
abstract = {Human creativity generates novel ideas to solve real-world problems. This thereby grants us the power to transform the surrounding world and extend our human attributes beyond what is currently possible. Creative ideas are not just new and unexpected, but are also successful in providing solutions that are useful, efficient and valuable. Thus, creativity optimizes the use of available resources and increases wealth. The origin of human creativity, however, is poorly understood, and semantic measures that could predict the success of generated ideas are currently unknown. Here, we analyze a dataset of design problem-solving conversations in real-world settings by using 49 semantic measures based on WordNet 3.1 and demonstrate that a divergence of semantic similarity, an increased information content, and a decreased polysemy predict the success of generated ideas. The first feedback from clients also enhances information content and leads to a divergence of successful ideas in creative problem solving. These results advance cognitive science by identifying real-world processes in human problem solving that are relevant to the success of produced solutions and provide tools for real-time monitoring of problem solving, student training and skill acquisition. A selected subset of information content (IC Sánchez–Batet) and semantic similarity (Lin/Sánchez–Batet) measures, which are both statistically powerful and computationally fast, could support the development of technologies for computer-assisted enhancements of human creativity or for the implementation of creativity in machines endowed with general artificial intelligence.}
}
@article{RADU2023100008,
title = {Charting opportunities and guidelines for augmented reality in makerspaces through prototyping and co-design research},
journal = {Computers & Education: X Reality},
volume = {2},
pages = {100008},
year = {2023},
issn = {2949-6780},
doi = {https://doi.org/10.1016/j.cexr.2023.100008},
url = {https://www.sciencedirect.com/science/article/pii/S2949678023000028},
author = {Iulian Radu and Josia Yuan and Xiaomeng Huang and Bertrand Schneider},
keywords = {Augmented reality, Makerspaces, Co-design, STEM, Classroom integration},
abstract = {Makerspace environments are becoming popular project-based learning spaces where students interact with physical objects and peer collaboration, while developing 21st century skills and engaging with science, technology, engineering, and math (STEM) topics. At the same time, augmented reality (AR) technology, which combines physical objects with digital visualizations, is becoming increasingly applicable for makerspace activities and has potential to address challenges for student learning in makerspaces. However, there is a lack of understanding of how to use and integrate AR in real makerspace environments. In this research we use a co-design methodology to address the following questions: (1) How can AR be useful for education in makerspaces? (2) How are students impacted by the process of co-designing AR technology? and (3) What are practical considerations for integrating AR in makerspaces? We engaged in a co-design process in a semester-long makerspace course attended by 18 students in a graduate school of education. Through this process, we generated six prototypes with seven student co-designers, exploring AR use in design, fabrication, programming, electronics, and training. We also identified areas where AR technology can benefit makerspaces, such as teaching STEM skills, facilitating construction activities, enhancing contextualization of learning, and debugging. We observed that students participating in co-design demonstrated improved understanding of technology design, enthusiasm for engaging with makerspaces and AR, and increased critical thinking about AR technology. These results suggest considerations and guidelines for integrating AR technology into makerspace environments.}
}
@article{HASKOVA2025102515,
title = {Fuzzy calculator – A tool for management needs},
journal = {Journal of Computational Science},
volume = {85},
pages = {102515},
year = {2025},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102515},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324003089},
author = {Simona Hašková and Petr Šuleř and Martin Smrt},
keywords = {Fuzzy calculator, Computer program, Multi-criteria evaluation, Fuzzy logic},
abstract = {Fuzzy logic and fuzzy system models have become popular tools in the field of management as they enable efficient handling of uncertainty. We present a tool based on the authors´ original approach focused on solving complex managerial problems affected by the vagueness or uncertainty caused by the human factor. For this purpose, we show the connection between the functioning principle of the tool and processes occurring in the human mind including a description of its structure as perceived by an external observer. This is followed by an overview of selected fragments of fuzzy propositional logic, the theory of fuzzy sets, and the conclusions derived from it. The main part consists of formulating an algebraic description of the computational process of multi-criteria evaluation of the considered alternative performed by a fuzzy system, which serves as the executive unit of a Fuzzy calculator. This is supplemented by a flowchart diagram illustrating the algorithm of its functioning. The Fuzzy calculator distinguishes itself from other fuzzy systems by standardizing all linguistic variables, regardless of the number of linguistic values, into a unified framework comprising three terms L, M, and H, which are represented using trapezoidal fuzzy numbers, ensuring precise mathematical characterization. During the transformation, the original linguistic terms are preserved by incorporating the positions of their support intervals, thereby maintaining the specificity of the input information. This approach establishes the Fuzzy calculator as a universal and highly adaptable tool, capable of addressing a wide range of practical managerial problems with improved consistency and control.}
}
@article{RONG20121462,
title = {Computational performance of basic state reduction based dynamic programming algorithms for bi-objective 0–1 knapsack problems},
journal = {Computers & Mathematics with Applications},
volume = {63},
number = {10},
pages = {1462-1480},
year = {2012},
issn = {0898-1221},
doi = {https://doi.org/10.1016/j.camwa.2012.03.057},
url = {https://www.sciencedirect.com/science/article/pii/S0898122112002623},
author = {Aiying Rong and José Rui Figueira},
keywords = {Multi-objective optimization, Bi-objective knapsack problem, Dynamic programming, Basic state reduction techniques},
abstract = {This paper studies a group of basic state reduction based dynamic programming (DP) algorithms for the multi-objective 0–1 knapsack problem (MKP), which are related to the backward reduced-state DP space (BRDS) and forward reduced-state DP space (FRDS). The BRDS is widely ignored in the literature because it imposes disadvantage for the single objective knapsack problem (KP) in terms of memory requirements. The FRDS based DP algorithm in a general sense is related to state dominance checking, which can be time consuming for the MKP while it can be done efficiently for the KP. Consequently, no algorithm purely based on the FRDS with state dominance checking has ever been developed for the MKP. In this paper, we attempt to get some insights into the state reduction techniques efficient to the MKP. We first propose an FRDS based algorithm with a local state dominance checking for the MKP. Then we evaluate the relative advantage of the BRDS and FRDS based algorithms by analyzing their computational time and memory requirements for the MKP. Finally different combinations of the BRDS and FRDS based algorithms are developed on this basis. Numerical experiments based on the bi-objective KP instances are conducted to compare systematically between these algorithms and the recently developed BRDS based DP algorithm as well as the existing FRDS based DP algorithm without state dominance checking.}
}
@article{WOOD199740,
title = {Thinking about Networks in the Control of Male Hamster Sexual Behavior},
journal = {Hormones and Behavior},
volume = {32},
number = {1},
pages = {40-45},
year = {1997},
issn = {0018-506X},
doi = {https://doi.org/10.1006/hbeh.1997.1403},
url = {https://www.sciencedirect.com/science/article/pii/S0018506X97914033},
author = {Ruth I. Wood},
abstract = {Motivated social behaviors such as mating are controlled by a complex network of limbic nuclei. Concepts of network organization derived from computational neuroscience may aid our understanding of the links between the neuroanatomical circuitry and what is represented by the anatomy. Research in my laboratory uses mating behavior in the male Syrian hamster as a model to elucidate how chemosensory and steroid cues are integrated in the brain. An interaction of odors and hormones is required for mating in this species. These two essential stimuli are transmitted through separate parallel pathways in the limbic system. The functional organization of the hamster mating behavior circuit is characterized by distributed representation, divergent and convergent neural pathways, and recurrent feedback. Odors and hormones have different modes of action on this neural network. While chemosensory cues stimulate the input units of the network, steroids facilitate behavior through the hidden units. In this manner, steroids appear to create a permissive environment for subsequent activation by odor cues.}
}
@article{ZHOU2024108310,
title = {The neuroanatomical correlates of daily habitual tendencies and mediating effect on the association between daily habitual tendencies and symptoms of behavioral addictions},
journal = {Computers in Human Behavior},
volume = {158},
pages = {108310},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108310},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400178X},
author = {Xinqi Zhou and Qi Liu and Lan Wang and Xianyang Gan and Ran Zhang and Xiqin Liu and Guojuan Jiao and Christian Montag and Weihua Zhao and Benjamin Becker},
keywords = {Habit, Gray matter, vmPFC, Precuneus, Internet gaming disorder, Smartphone use},
abstract = {Habitual behaviors significantly shape our daily actions. Furthermore, habit formation is proposed as a key mechanism contributing to the development and maintenance of addiction. However, the neural substrates underlying daily habitual tendencies and their contribution to behavioral addiction symptoms in everyday life remain poorly understood. To explore these questions, we conducted a comprehensive analysis of data from 219 individuals who underwent neuroimaging (structural MRI) assessments alongside evaluations of their daily habitual tendencies and symptoms of Internet Gaming Disorder (IGD) and Problematic Smartphone Use (PSU). Using voxel-based morphometry, meta-analytic decoding, and mediation analysis, we found that daily habitual tendencies were positively correlated with larger gray matter volumes in the ventromedial prefrontal cortex (vmPFC), precuneus, superior frontal gyrus (SFG), inferior temporal gyrus (ITG), and supplementary motor area (SMA). Notably, the midline regions, including the vmPFC and precuneus, play a crucial role in value-based computation, emotional regulation, social cognition, and self-referential thinking. Individual variations in gray matter volumes within these regions served as mediators, influencing the bidirectional relationship between daily habitual tendencies and IGD symptoms. However, vmPFC variations were specifically found to mediate the pathway from PSU to daily habitual tendencies. Our findings suggest that the morphological architecture of the vmPFC and precuneus is associated with habitual tendencies in daily life and may mediate the development of addictive behaviors. This study contributes to a more nuanced understanding of the neuroanatomical basis of daily habitual tendencies and their role in addictive behaviors.}
}
@article{BUCKER20031309,
title = {Parallel programming in computational science: an introductory practical training course for computer science undergraduates at Aachen University},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1309-1319},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00089-X},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X0300089X},
author = {H.M. Bücker and B. Lang and C.H. Bischof},
keywords = {Parallel programming, Java, Computational science and engineering, Education},
abstract = {Parallel programming of high-performance computers has emerged as a key technology for the numerical solution of large-scale problems arising in computational science and engineering (CSE). The authors believe that principles and techniques of parallel programming are among the essential ingredients of any CSE as well as computer science curriculum. Today, opinions on the role and importance of parallel programming are diverse. Rather than seeing it as a marginal beneficial skill optionally taught at the graduate level, we understand parallel programming as crucial basic skill that should be taught as an integral part of the undergraduate computer science curriculum. A practical training course developed for computer science undergraduates at Aachen University is described. Its goal is to introduce young computer science students to different parallel programming paradigms for shared and distributed memory computers as well as to give a first exposition to the field of computational science by simple, yet carefully chosen sample problems.}
}
@article{ZHANG2024117045,
title = {A bidirectional collaborative method based on an improved artificial fish swarm algorithm for ship pipe and equipment layout design},
journal = {Ocean Engineering},
volume = {296},
pages = {117045},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.117045},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824003822},
author = {Hongshuo Zhang and Yanyun Yu and Qiaoyu Zhang and Yuansong Yang and Haiyang Liu and Yan Lin},
keywords = {Collaborative optimization, Ship engine room layout design, Multi-strategy heuristic algorithm, Hybrid-objective optimization, Coding technique, Automation design},
abstract = {Ship engine room layout design (SERLD) significantly impacts a ship's transportation efficiency and safety by focusing on the layouts of equipment and piping. However, owing to complex constraints, previous research has mainly focused on single-dimensional layout designs and has failed to provide comprehensive references for designers. To address this research gap, this study proposes a collaborative layout method based on a multistrategy hybrid-objective artificial fish swarm algorithm (HMSAFSA). In terms of the underlying mathematical representation, a more stable Manhattan trajectory-based coding method suitable for a collaborative layout is proposed. Building on this coding method, multiple strategies are incorporated into the heuristic AFSA to enhance its optimization and collaborative performance. Collaborative evaluation functions and methods are designed and refined to ensure effective layout results for multiple objectives. Furthermore, a layout procedure incorporating bidirectional guidance strategies and hierarchical thinking is proposed. This method achieves collaborative layouts through the mutual guidance of optimal objectives. Finally, the effectiveness of the proposed method is verified through representative cases of various types of ship engine rooms in practical engineering. The method demonstrates its capability to offer multiple optimal layout schemes, thus presenting substantial value for practical engineering designs.}
}
@article{EGUCHI2016692,
title = {RoboCupJunior for promoting STEM education, 21st century skills, and technological advancement through robotics competition},
journal = {Robotics and Autonomous Systems},
volume = {75},
pages = {692-699},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.05.013},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015001281},
author = {Amy Eguchi},
keywords = {Educational robotics, Robotics competitions, STEM education, Computational thinking, Engineering skills, 21st century skills},
abstract = {RoboCupJunior is an international educational robotics initiative, aiming to promote STEM content and skill learning among participating youth through educational robotics competition inaugurated in 2000. What makes RoboCupJunior quite unique is its relationship with RoboCup which aims to promote robotics and AI research, by offering a publicly appealing, but formidable challenge including development of soccer robots, search and rescue robots, and robots functions at home and at work. This paper introduces a case of RoboCupJunior and the effectiveness of its practice for enhancing learning of STEM contents and skills for innovation and creativity among participating students. It presents the survey results from one of the World Championships held in 2012, the anecdotal and personal account of participating US students on their learning experience from their participation in 2013 World Championship, and participating students’ technological and innovative contributions to highlight the impacts RoboCupJunior has had through over a decade of its practice.}
}
@article{HARVEY2025,
title = {Using Natural Language Processing Methods to Build the Hypersexuality in Bipolar Reddit Corpus: Infodemiology Study of Reddit},
journal = {JMIR Infodemiology},
volume = {5},
year = {2025},
issn = {2564-1891},
doi = {https://doi.org/10.2196/65632},
url = {https://www.sciencedirect.com/science/article/pii/S2564189125000118},
author = {Daisy Harvey and Paul Rayson and Fiona Lobban and Jasper Palmier-Claus and Clare Dolman and Anne Chataigné and Steven Jones},
keywords = {bipolar, hypersexuality, natural language processing, Linguistic Inquiry and Word Count, LIWC, BERTopic, topic modeling, computational linguistics},
abstract = {Background
Bipolar is a severe mental health condition affecting at least 2% of the global population, with clinical observations suggesting that individuals experiencing elevated mood states, such as mania or hypomania, may have an increased propensity for engaging in risk-taking behaviors, including hypersexuality. Hypersexuality has historically been stigmatized in society and in health care provision, which makes it more difficult for service users to talk about their behaviors. There is a need for greater understanding of hypersexuality to develop better evidence-based treatment, support, and training for health professionals.
Objective
This study aimed to develop and assess effective methodologies for identifying posts on Reddit related to hypersexuality posted by people with a self-reported bipolar diagnosis. Using natural language processing techniques, this research presents a specialized dataset, the Talking About Bipolar on Reddit Corpus (TABoRC). We used various computational tools to filter and categorize posts that mentioned hypersexuality, forming the Hypersexuality in Bipolar Reddit Corpus (HiB-RC). This paper introduces a novel methodology for detecting hypersexuality-related conversations on Reddit and offers both methodological insights and preliminary findings, laying the groundwork for further research in this emerging field.
Methods
A toolbox of computational linguistic methods was used to create the corpora and infer demographic variables for the Redditors in the dataset. The key psychological domains in the corpus were measured using Linguistic Inquiry and Word Count, and a topic model was built using BERTopic to identify salient language clusters. This paper also discusses ethical considerations associated with this type of analysis.
Results
The TABoRC is a corpus of 6,679,485 posts from 5177 Redditors, and the HiB-RC is a corpus totaling 2146 posts from 816 Redditors. The results demonstrate that, between 2012 and 2021, there was a 91.65% average yearly increase in posts in the HiB-RC (SD 119.6%) compared to 48.14% in the TABoRC (SD 51.2%) and an 86.97% average yearly increase in users (SD 93.8%) compared to 27.17% in the TABoRC (SD 38.7%). These statistics suggest that there was an increase in posting activity related to hypersexuality that exceeded the increase in general Reddit use over the same period. Several key psychological domains were identified as significant in the HiB-RC (P<.001), including more negative tone, more discussion of sex, and less discussion of wellness compared to the TABoRC. Finally, BERTopic was used to identify 9 key topics from the dataset.
Conclusions
Hypersexuality is an important symptom that is discussed by people with bipolar on Reddit and needs to be systematically recognized as a symptom of this illness. This research demonstrates the utility of a computational linguistic framework and offers a high-level overview of hypersexuality in bipolar, providing empirical evidence that paves the way for a deeper understanding of hypersexuality from a lived experience perspective.}
}
@article{ONTIVEROSARAIZA2025105361,
title = {The Neurobehavioral State hypothesis},
journal = {BioSystems},
volume = {247},
pages = {105361},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105361},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002466},
author = {Luis Fernando Ontiveros-Araiza},
keywords = {Brain networks, Neuronal dynamics, Neural code, Neurotransmitter, Electrophysiology, Neuronal computation, Behavior},
abstract = {Since the early attempts to understand the brain made by Greek philosophers more than 2000 years ago, one of the main questions in neuroscience has been how the brain perceives all the stimuli in the environment and uses this information to implement a response. Recent hypotheses of the neural code rely on the existence of an ideal observer, whether on specific areas of the cerebral cortex or distributed network composed of cortical and subcortical elements. The Neurobehavioral State hypothesis stipulates that neurons are in a quasi-stable state due to the dynamic interaction of their molecular components. This increases their computational capabilities and electrophysiological behavior further than a binary active/inactive state. Together, neuronal populations across the brain learn to identify and associate internal and external stimuli with actions and emotions. Furthermore, such associations can be stored through the regulation of neuronal components as new quasi-stable states. Using this framework, behavior arises as the result of the dynamic interaction between internal and external stimuli together with previously established quasi-stable states that delineate the behavioral response. Finally, the Neurobehavioral State hypothesis is firmly grounded on present evidence of the complex dynamics within the brain, from the molecular to the network level, and avoids the need for a central observer by proposing the brain configures itself through experience-driven associations.}
}
@article{ZHANG2023100528,
title = {Foreign language effect in accounting uncertainty expressions: Interpretation and probabilistic estimation},
journal = {Journal of International Accounting, Auditing and Taxation},
volume = {50},
pages = {100528},
year = {2023},
issn = {1061-9518},
doi = {https://doi.org/10.1016/j.intaccaudtax.2023.100528},
url = {https://www.sciencedirect.com/science/article/pii/S1061951823000071},
author = {Yuqian Zhang and Anura {De Zoysa} and Corinne Cortese},
keywords = {Foreign language effect, Uncertainty expressions, Probability estimation, Accounting judgement, Interpretation},
abstract = {The foreign language effect, or thinking in a foreign language, reduces judgment bias under uncertainty. This study investigates how language use (native versus foreign) affects accounting judgment on uncertainty expressions. We conducted two separate experiments: between-subjects and within-subjects, both of which included tasks requiring interpretations and probability estimations based on accounting standard uncertainty expressions. The results demonstrated that foreign language use affected the interpretation of uncertainty expressions and reduced judgment bias in probability estimation, particularly in the context of asset recognition. These findings have important implications for accounting research and reporting.}
}
@incollection{KARACA2022149,
title = {Chapter 9 - Computational fractional-order calculus and classical calculus AI for comparative differentiability prediction analyses of complex-systems-grounded paradigm},
editor = {Yeliz Karaca and Dumitru Baleanu and Yu-Dong Zhang and Osvaldo Gervasi and Majaz Moonis},
booktitle = {Multi-Chaos, Fractal and Multi-Fractional Artificial Intelligence of Different Complex Systems},
publisher = {Academic Press},
pages = {149-168},
year = {2022},
isbn = {978-0-323-90032-4},
doi = {https://doi.org/10.1016/B978-0-323-90032-4.00006-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323900324000067},
author = {Yeliz Karaca and Dumitru Baleanu},
keywords = {Complexity, Artificial neural network, Classical calculus, Computational complexity, Data-driven fractional modeling, Differentiability prediction analyses, Fractional calculus, Mathematical biology and neuroscience, Mittag-Leffler function, Optimized fractional-order calculus},
abstract = {Modern science having embarked on the thorough and accurate interpretation of natural and physical phenomena has proven to provide successful models for the analysis of complex systems and harnessing of control over the various processes therein. Computational complexity, in this regard, comes to the foreground by providing applicable sets of ideas or integrative paradigms to recognize and understand the complex systems' intricate properties. Thus, while making the appropriate, adaptable and evolutive decisions in complex dynamic systems, it is essential to acknowledge different degrees of acceptance of the problems and construct the model it to account for its inherent constraints or limits. In this respect, while hypothesis-driven research has its inherent limitations regarding the investigation of multifactorial and heterogeneous diseases, a data-driven approach enables the examination of the way variables impact one another, which paves the way for the interpretation of dynamic and heterogeneous mechanisms of diseases. Fractional Calculus (FC), in this scope characterized by complexity, provides the applicable means and methods to solve integral, differential and integro-differential equations so FC enables the generalization of integration and differentiation possible in a flexible and consistent manner owing to its capability of reflecting the systems' actual state properties, which exhibit unpredictable variations. The fractional integration and differentiation of fractional-order is capable of providing better characterization of nonstationary and locally self-similar attributes in contrast to constant-order fractional calculus. It becomes possible to model many complex systems by fractional-order derivatives based on fractional calculus so that related syntheses can be realized in a robust and effective way. To this end, our study aims at providing an intermediary facilitating function both for the physicians and individuals by establishing accurate and robust model based on the integration of fractional-order calculus and Artificial Neural Network (ANN) for the diagnostic and differentiability predictive purposes with the diseases which display highly complex properties. The integrative approach we have proposed in this study has a multistage quality the steps of which are stated as follows: first of all, the Caputo fractional-order derivative, one of the fractional-order derivatives, has been used with two-parametric Mittag-Leffler function on the stroke dataset and cancer cell dataset, manifesting biological and neurological attributes. In this way, new fractional models with varying degrees have been established. Mittag-Leffler function, with its distributions of extensive application domains, can address irregular and heterogeneous environments for the solution of dynamic problems; thus, Mittag-Leffler function has been opted for accordingly. Following this application, the new datasets (mlf_stroke dataset and mlf_cancer cell dataset) have been obtained by employing Caputo fractional-order derivative with the two-parametric Mittag-Leffler function (α,β). In addition, classical derivative (calculus) was applied to the raw datasets; and cd_stroke dataset and cd_cancer cell dataset were obtained. Secondly, the performance of the new datasets as obtained from the Caputo fractional derivative with the two-parametric Mittag-Leffler function, the datasets obtained from the classical derivative application and the raw datasets have been compared by using feed forward back propagation (FFBP) algorithm, one of the algorithms of ANN (along with accuracy rate, sensitivity, precision, specificity, F1-score, multiclass classification (MCC), ROC curve). Based on the accuracy rate results obtained from the application with FFBP, the Caputo fractional-order derivative model that is most suitable for the diseases has been generated. The experimental results obtained demonstrate the applicability of the complex-systems-grounded paradigm scheme as proposed through this study, which has no existing counterpart. The integrative multi-stage method based on mathematical-informed framework with comparative differentiability prediction analyses can point toward a new direction in the various areas of applied sciences to address formidable challenges of critical decision making and management of chaotic processes in different complex dynamic systems.}
}
@article{CHIEN2009965,
title = {An efficient computational procedure for determining the container-loading pattern},
journal = {Computers & Industrial Engineering},
volume = {56},
number = {3},
pages = {965-978},
year = {2009},
note = {Intelligent Manufacturing and Logistics},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2008.09.019},
url = {https://www.sciencedirect.com/science/article/pii/S036083520800226X},
author = {Chen-Fu Chien and Chia-Yen Lee and Yi-Chao Huang and Wen-Ting Wu},
keywords = {Global logistics, Container-loading, Cutting and packing, Three-dimension knapsack, Decision support system},
abstract = {Supply chain and global logistics are driven by strategically focusing on core competences, outsourcing manufacturing to pursue higher value proposition in the supply chain, radically improving the return of capital investments and providing total solutions to targeted customers. The container-loading research has important industrial and commercial application for global logistics. In practice, loading pooled shipment into containers is a complex procedure that has relied largely on the workers’ experience. We developed an efficient computational procedure involving three-dimensional cutting for determining near-optimal container-loading patterns to minimize the waste of container space. We used numerical examples from a motor company that imports key components from Japan, produces parts in Taiwan, and assembles cars in China to estimate its validity and discussed the effectiveness of the proposed solution. This study concludes with a discussion of future research.}
}
@incollection{HANSKORTELING2022610,
title = {Cognitive Biases},
editor = {Sergio {Della Sala}},
booktitle = {Encyclopedia of Behavioral Neuroscience, 2nd edition (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {610-619},
year = {2022},
isbn = {978-0-12-821636-1},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.24105-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245241059},
author = {J.E. {(Hans) Korteling} and Alexander Toet},
keywords = {Cognitive biases, Cognitive neuroscience, Decision making, Dual process theory, Expertise, Evolutionary psychology, Heuristics, Information processing capacity, Intuition, Neural networks, Rationality},
abstract = {Cognitive biases are systematic cognitive dispositions or inclinations in human thinking and reasoning that often do not comply with the tenets of logic, probability reasoning, and plausibility. These intuitive and subconscious tendencies are at the basis of human judgment, decision making, and the resulting behavior. Psychological frameworks consider biases as resulting from the use of (inappropriate) cognitive heuristics that people apply to deal with data-limitations, from information processing limitations, or from a lack of expertise. Neuro-evolutionary frameworks provide a more profound explanation of biases as originating from the inherent design characteristics of our brain as a neural network that was primarily developed to perform basic physical, perceptual and motor functions, and which also had to promote the survival of our hunter-gatherer ancestors.}
}
@article{TSENG2025106570,
title = {Exploring artificial intelligence literacy and the use of ChatGPT and copilot in instruction on nursing academic report writing},
journal = {Nurse Education Today},
volume = {147},
pages = {106570},
year = {2025},
issn = {0260-6917},
doi = {https://doi.org/10.1016/j.nedt.2025.106570},
url = {https://www.sciencedirect.com/science/article/pii/S026069172500005X},
author = {Li-Ping Tseng and Li-Ping Huang and Wei-Ru Chen},
keywords = {Artificial intelligence literacy, Nursing education, ChatGPT, Copilot, Academic report writing, Scaffolding teaching, Artificial intelligence},
abstract = {Background
Nursing education increasingly emphasizes academic writing and communication, critical for delivering quality patient care and professional advancement. Rapidly emerging artificial intelligence (AI) tools such as ChatGPT and Copilot are transforming educational methodologies, and a focus is being placed on embedding AI literacy to effectively bridge the gap between theoretical knowledge and clinical practice. These technologies have the potential to reshape nursing education in a technology-driven health-care landscape.
Aim
This study investigated the effectiveness of AI literacy and the application of ChatGPT and Copilot in academic nursing report writing. It assessed the level of AI literacy of nursing students, examined the integration of basic AI concepts into a curriculum, and analyzed the impact of these tools compared with traditional teaching methods.
Methods
The study adopted a sample of 203 senior nursing students from Southern Taiwan to compare an AI-enhanced teaching approach using ChatGPT and Copilot with conventional methods. The curriculum, centered on the “Writing Case Reports and Seminars” course, employed the Analyze, Design, Develop, Implement, Evaluate model and incorporated scaffolding techniques to synergistically integrate clinical skills with academic learning. AI literacy was measured using the Meta AI Literacy Scale (MAILS). Summative assessments, adhering to the Taiwan Nursing Association standards, focused on individual and group case report evaluations.
Findings
Following an 18-week AI intervention, the experimental group demonstrated significant improvements in all dimensions of the MAILS. A ChatGPT usage of 100 % was found, with a notable enhancement discovered in the “Nursing Plan” section of case reports. Although the experimental group outperformed the control group in overall case report evaluations, the connections between identified problems and proposed plans were weaker and nursing interventions tended to be less individualized for the experimental group.
Conclusions
The incorporation of AI tools such as ChatGPT and Copilot into a scaffolding teaching framework significantly boosted students' AI literacy and performance in summative assessments. Effective AI training for students, supervised use of these tools, and continuous professional development for educators are paramount to successful implementation. Addressing the current limitations of AI has the potential to further improve academic writing, foster critical thinking, and ensure responsible application in patient care, ultimately leading to higher-quality and more effective nursing education.}
}
@article{CEKMIS2014115,
title = {A computational model for accommodating spatial uncertainty: Predicting inhabitation patterns in open-planned spaces},
journal = {Building and Environment},
volume = {73},
pages = {115-126},
year = {2014},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2013.11.023},
url = {https://www.sciencedirect.com/science/article/pii/S0360132313003430},
author = {Aslı Çekmiş and Işıl Hacıhasanoğlu and Michael J. Ostwald},
keywords = {Fuzzy logic, Fuzzy set, Spatial uncertainty, Occupancy prediction, Open-planned spaces},
abstract = {In the past, a range of computational models have been developed for analysing the social implications of spatial patterns and types. While such models are typically focussed on macro-patterns, often in cellular or linearly-organised spaces, few models exist for predicting where people will cluster within complex environments. One reason for this relates to the inherent uncertainty associated with spatial attributes and consequently of human spatial behaviours. The present paper draws on the concept of fuzzy spatial objects to develop an approach to handle such uncertainty in architecture. Focussing on large, open plan spaces, where the configuration of space does not define strict patterns of usage, the paper proposes a computational model for predicting patterns of spatial inhabitation. This new model relies on the theory of fuzzy sets to propose the existence of a “fuzzy architectural spatial object, (FASO)” which is comprised of spatial units with degrees of membership that reflect the possibility of a person being present in a sub-space or involved in a sub-function within a larger space. This model calculates and visualises the FASOs using a fuzzy inference engine and represents the space as distributed possibilities of presence according to the given data. After describing the model the paper demonstrates its application in the prediction of patterns of usage within a major exhibition space, and then presents a check of the efficacy of this prediction against the actual inhabitation of the space.}
}
@article{STEPHENS200833,
title = {What “counts” as algebra in the eyes of preservice elementary teachers?},
journal = {The Journal of Mathematical Behavior},
volume = {27},
number = {1},
pages = {33-47},
year = {2008},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2007.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S0732312307000594},
author = {Ana C. Stephens},
keywords = {Algebra, Elementary mathematics, Teacher conceptions},
abstract = {This study examined conceptions of algebra held by 30 preservice elementary teachers. In addition to exploring participants’ general “definitions” of algebra, this study examined, in particular, their analyses of tasks designed to engage students in relational thinking or a deep understanding of the equal sign as well as student work on these tasks. Findings from this study suggest that preservice elementary teachers’ conceptions of algebra as subject matter are rather narrow. Most preservice teachers equated algebra with the manipulation of symbols. Very few identified other forms of reasoning – in particular, relational thinking – with the algebra label. Several participants made comments implying that student strategies that demonstrate traditional symbol manipulation might be valued more than those that demonstrate relational thinking, suggesting that what is viewed as algebra is what will be valued in the classroom. This possibility, along with implications for mathematics teacher education, will be discussed.}
}
@article{FERNANDEZCABALLERO2003341,
title = {Lateral interaction in accumulative computation: a model for motion detection},
journal = {Neurocomputing},
volume = {50},
pages = {341-364},
year = {2003},
issn = {0925-2312},
doi = {https://doi.org/10.1016/S0925-2312(02)00571-4},
url = {https://www.sciencedirect.com/science/article/pii/S0925231202005714},
author = {Antonio Fernández-Caballero and José Mira Mira and Ana E. Delgado and Miguel A. {Fernández Graciani}},
keywords = {Accumulative computation, Lateral interaction, Double time scale, Motion detection, Image sequences},
abstract = {Some of the major computer vision techniques make use of neural nets. In this paper we present a novel model based on neural networks denominated lateral interaction in accumulative computation (LIAC). This model is based on a series of neuronal models in one layer, namely the local accumulative computation model, the double time scale model and the recurrent lateral interaction model. The LIAC model usefulness in the general task of motion detection may be appreciated by means of some significant examples of object detection in indefinite sequences of synthetic and real images.}
}
@article{FORTHMANN201959,
title = {Creative ideation, broad retrieval ability, and processing speed: A confirmatory study of nested cognitive abilities},
journal = {Intelligence},
volume = {75},
pages = {59-72},
year = {2019},
issn = {0160-2896},
doi = {https://doi.org/10.1016/j.intell.2019.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0160289618301211},
author = {Boris Forthmann and David Jendryczko and Jana Scharfen and Ruben Kleinkorres and Mathias Benedek and Heinz Holling},
keywords = {Divergent thinking, Broad retrieval ability, Processing speed, Structural equation modeling},
abstract = {Divergent thinking (DT) ability (i.e., the ability to come up with creative ideas) is a complex cognitive construct that has been associated with several specific components of the Cattel-Horn-Carroll (CHC) model. In this study, we employed a nested latent variable approach to examine the specific role of mental speed (Gs) and general retrieval ability (Gr) in DT ability, which was assessed by DT tasks that instructed to be creative and were scored for creative quality. Specifically, Gs was assumed to facilitate both Gr and DT, and Gr was assumed to contribute to DT. Successive latent variable models with orthogonal factors were tested to reflect these nested cognitive basic abilities. The proposed model of nested factors fit the data well: Latent Gs accounted for variation in Gs, Gr, and DT creative quality scores, latent Gr predicted performance in Gr and DT scores beyond Gs, and latent DT explained variation in DT scores beyond Gs and Gr. In addition, we related the resulting orthogonal latent variables to the external criteria of school grades to illustrate the explanatory power of the modeling approach. This study provides evidence that divergent thinking performance relies on mental speed and retrieval ability, as well as cognitive abilities unique to divergent thinking. We discuss consequences for the understanding of divergent thinking ability in the context of the CHC model.}
}
@article{BEHARA2009195,
title = {Parallel finite element computation of incompressible flows},
journal = {Parallel Computing},
volume = {35},
number = {4},
pages = {195-212},
year = {2009},
issn = {0167-8191},
doi = {https://doi.org/10.1016/j.parco.2008.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167819108001348},
author = {Suresh Behara and Sanjay Mittal},
keywords = {Navier–Stokes equations, Parallel computing, Superlinear speedup, Wake, Transition, Wake instabilities},
abstract = {A stabilized finite element formulation for three-dimensional unsteady incompressible flows is implemented on a distributed memory parallel computer. A matrix-free version of the GMRES algorithm is utilized to solve the equation systems in an implicit manner. The scalability of the computations on a 64-processor Linux cluster is evaluated for moderate to large size problems. A method for estimating the speedup for large-scale problems, where computations on a single processor is not possible, is proposed. Superlinear speedup is observed, perhaps for the first time, for a large-scale problem that is associated with more than 44 million nodes and 176 million equations. The performance of the various subactivities of the program is monitored to investigate the cause. It is found that the formation of the RHS vector and the preconditioner achieves a very high level of superlinear speedup as the number of processors increase. As a result, even though the network time for interprocessor communication increases with increase in processors, an overall superlinear speedup is realized for large-scale problems. The superlinear speedup is attributed to cache related effects. A comparison between the performance of matrix and matrix-free versions of the GMRES algorithm is carried out. It is found that for large-scale applications the matrix-free version outperforms its counterpart for reasonable dimensions of the Kyrylov subspace. The effect of mesh partitioning on the scalability is also studied. A significant reduction in communication time is observed with partitioning that leads to an overall improvement of speedup. The parallel implementation is utilized to study the wake instabilities in flow past a stationary circular cylinder at Re=150, 200 and 300. The Re=150 flow is found to be two-dimensional while mode-A and mode-B instabilities are observed at Re=200 and 300, respectively. The Re=300 flow is associated with a low frequency modulation in addition to the vortex shedding frequency.}
}
@article{VAHDANJOO2025101287,
title = {Digital transformation of the agri-food system},
journal = {Current Opinion in Food Science},
pages = {101287},
year = {2025},
issn = {2214-7993},
doi = {https://doi.org/10.1016/j.cofs.2025.101287},
url = {https://www.sciencedirect.com/science/article/pii/S2214799325000177},
author = {Mahdi Vahdanjoo and Claus Grøn Sørensen and Michael Nørremark},
abstract = {The purpose of this paper is to examine the role of digital transformation in the agri-food sector. The study emphasizes digitalization as both an enabler of production efficiency and a radical innovator redesigning business models and agricultural practices. The study explores the development of applications and products that connect consumers, supply chain actors, and producers, leading to customized food products. It highlights the notion of circular agri-food systems for feedback loops in the value chain, minimizing waste and integrating environmental and social values. Also, the paper explores the challenges in digital adoption, including technical barriers, privacy, and security concerns. To overcome these challenges, an interdisciplinary approach is proposed, merging technological, ecological, economic, and governance insights. Key needs identified for successful digital transformation include enhanced data processing, technological convergence, sustainability awareness, interoperability, and user adoption. The conclusion stresses the importance of invoking systemic thinking, user-friendly designs, and interdisciplinary collaboration in making sure that digital innovations enable a sustainable and resilient food production system.}
}
@article{REGGIO2002459,
title = {Computational analysis of the process for manufacturing seamless tubes},
journal = {Applied Thermal Engineering},
volume = {22},
number = {4},
pages = {459-470},
year = {2002},
issn = {1359-4311},
doi = {https://doi.org/10.1016/S1359-4311(01)00093-X},
url = {https://www.sciencedirect.com/science/article/pii/S135943110100093X},
author = {M. Reggio and F. McKenty and Luc Gravel and J. Cortes and G. Morales and M.-A. {Ladron de Guevara}},
keywords = {Seamless tube, Heat transfer, Computational simulation, CFD},
abstract = {A computer simulation of the transient three-dimensional heat transfer process occurring during the manufacturing of seamless tubes carried out by TAMSA, Tubos de Acero de Mexico, is reported. The work was performed by a team which combines Canadian and Mexican researchers and comprises both experimental and computational aspects. The Mexican team concentrated its efforts on experimentally investigating the metallurgical pattern of the mandrel, while the Canadian team devoted its time to the computer simulation and analysis of heat transfer and flow processes. In this paper, only the latter part is presented. The numerical simulation uses the Star-CD commercial CFD software package which is based on the finite volume methodology. The results show the importance of the cooling water channel configuration in relation to the mandrel temperature distribution and resulting metallurgical structure.}
}
@incollection{ROZINAJOVA201823,
title = {Chapter 2 - Computational Intelligence in Smart Grid Environment},
editor = {Arun Kumar Sangaiah and Michael Sheng and Zhiyong Zhang},
booktitle = {Computational Intelligence for Multimedia Big Data on the Cloud with Engineering Applications},
publisher = {Academic Press},
pages = {23-59},
year = {2018},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-12-813314-9},
doi = {https://doi.org/10.1016/B978-0-12-813314-9.00002-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128133149000025},
author = {Viera Rozinajová and Anna Bou Ezzeddine and Marek Lóderer and Jaroslav Loebl and Róbert Magyar and Petra Vrablecová},
keywords = {Smart grid, Intelligent data analysis, Computational intelligence, Power load prediction, Optimization, Bio-inspired algorithms, Ensemble models, Support vector regression},
abstract = {This chapter presents one way of incorporating computational intelligence into smart grid environment. We introduce an energy ecosystem, where contemporary technologies are used and by involving advanced methods of data analysis and optimization, we aim to ensure its effective operation. In order to schedule reliable energy supply, the prediction models for power load consumption and for energy spot prices are inevitable. We provide an overview of forecasting and optimization methods and propose solutions, which deal with stream and online processing as well as adaptivity of the proposed solutions. Several different prediction methods including statistical methods and computational intelligence methods, as well as our proposed ensemble and online SVR method are compared. We take into account the current trends of distributed energy generation from renewable sources and anticipate massive usage of electro vehicles in the near future, where the optimization of the whole environment is needed.}
}
@article{TETEWSKY1986202,
title = {Conceptual and lexical determinants of nonentrenched thinking},
journal = {Journal of Memory and Language},
volume = {25},
number = {2},
pages = {202-225},
year = {1986},
issn = {0749-596X},
doi = {https://doi.org/10.1016/0749-596X(86)90030-6},
url = {https://www.sciencedirect.com/science/article/pii/0749596X86900306},
author = {Sheldon J Tetewsky and Robert J Sternberg},
abstract = {Two experiments investigating information-processing consequences of entrenched and nonentrenched concepts are reported. An attempt is made to distinguish between these two kinds of concepts by using two variables—the naturalness of the occurrence described by a concept and the familiarity of the name used to refer to that occurrence. In each experiment a given conceptual system was expressed in four alternative forms by crossing concept familiarity (naturalness) with lexical familiarity. The experiments used a concept-selection task in which subjects were required to characterize an event based on a preliminary piece of information and a final, confirmatory piece of information. The results indicated that the locus of nonentrenchment lies in using a familiar name to identify an unfamiliar occurrence or in using an unfamiliar name to identify a familiar occurrence. An information-processing model of task performance provided a very good account of the latency data and scores from the concept-selection task correlated with scores from a set of psychometric reasoning tests. The distinction between entrenched and nonentrenched concepts can be interpreted in terms of interference theory, and it also has implications for the way we think about induction and human intelligence.}
}
@article{SHAHID2019638,
title = {Computational intelligence techniques for medical diagnosis and prognosis: Problems and current developments},
journal = {Biocybernetics and Biomedical Engineering},
volume = {39},
number = {3},
pages = {638-672},
year = {2019},
issn = {0208-5216},
doi = {https://doi.org/10.1016/j.bbe.2019.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0208521619300452},
author = {Afzal Hussain Shahid and M.P. Singh},
keywords = {Computational intelligence, Disease diagnosis, Prediction, Detection, Uncertainty, Medical data},
abstract = {Diagnosis, being the first step in medical practice, is very crucial for clinical decision making. This paper investigates state-of-the-art computational intelligence (CI) techniques applied in the field of medical diagnosis and prognosis. The paper presents the performance of these techniques in diagnosing different diseases along with the detailed description of the data used. This paper includes basic as well as hybrid CI techniques that have been used in recent years so as to know the current trends in medical diagnosis domain. The paper presents the merits and demerits of different techniques in general as well as application specific context. This paper discusses some critical issues related to the medical diagnosis and prognosis such as uncertainties in the medical domain, problems in the medical data especially dealing with time-stamped (temporal) data, and knowledge acquisition. Moreover, this paper also discusses the features of good CI techniques in medical diagnosis. Overall, this review provides new insight for future research requirements in the medical diagnosis domain.}
}
@article{SHI2024e35268,
title = {3D dynamic landscape simulation of artificial intelligence in environmental landscape design},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e35268},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35268},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024112996},
author = {Binbin Shi},
keywords = {Artificial intelligence, Environmental landscape design, Fuzzy analytical hierarchical process, Geographical information system, 3D dynamic landscape, Interactive design system},
abstract = {Three-dimensional (3D) simulations and precise landscape visualizations are crucial for various applications, like landscape management and planning, computer and connection of the landscape, evaluation, and tracking of land use. The consequences of several plans and a large scene cannot be communicated using older methods of comprehensive environmental planning and development in a timely, rational, and coordinated manner. Architects have trouble incorporating ideas into other comprehensive planning implementation processes. Architects did not thoroughly investigate the neighbourhood's demographics and matching behavioural needs and lacked critical thinking. The 3D dynamic landscape simulation is a detailed computerized three-dimensional simulation of the environment that can be dynamically presented. With the aid of Artificial Intelligence (AI) technology, the system possesses a strong sense of reality, a user-friendly interface, and interactive features that can be tailored to the requirements of the contemporary urban environmental landscape. Regarding exterior publicity, domestic assistance, environmental land use planning, and information systems. The novelty of the proposed Interactive Design System based on AI (IDS-AI) is to create a 3D dynamic landscape model based on a real-life environmental scene, utilizing a Geographic Information System (GIS) to optimize landscape vision. Secondly, 3D environmental landscape design simulation was implemented using GIS spatial analysis in conjunction with the Fuzzy Analytical Hierarchical Process (FAHP) to reduce the data overlap rate and help make an accurate decision. Finally, the design incorporates the development of the interactive interface system application of landscape design and environmental resources for viewing the landscape, the factors that affect them, and the area coverage ratio of various land cover types. The experimental outcomes show that the suggested IDS model increases the gradient sensitivity level of 98.3 % and area coverage ratio of 93.4 % compared to other existing models.}
}
@article{MA2024103893,
title = {Secure outsourced decryption for FHE-based privacy-preserving cloud computing},
journal = {Journal of Information Security and Applications},
volume = {86},
pages = {103893},
year = {2024},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103893},
url = {https://www.sciencedirect.com/science/article/pii/S2214212624001959},
author = {Xirong Ma and Chuan Li and Yuchang Hu and Yunting Tao and Yali Jiang and Yanbin Li and Fanyu Kong and Chunpeng Ge},
keywords = {Privacy-preserving computation, Outsourced computing, Homomorphic encryption},
abstract = {The demand for processing vast volumes of data has surged dramatically due to the advancement of machine learning technology. Large-scale data processing necessitates substantial computational resources, prompting individuals and enterprises to turn to cloud services. Accompanying this trend is a growing concern regarding data leakage and misuse. Homomorphic encryption (HE) is one solution for safeguarding data privacy, enabling encrypted data to be processed securely in the cloud. However, the encryption and decryption routines of some HE schemes require considerable computational resources, presenting non-trivial work for clients. In this paper, we propose an outsourced decryption protocol for the prevailing RLWE-based fully homomorphic encryption schemes. The protocol splits the original decryption into two routines, with the computationally intensive part executed remotely by the cloud. Its security relies on an invariant of the NTRU-search problem with a newly designed blinding key distribution. Cryptographic analyses are conducted to configure protocol parameters across varying security levels. Our experiments demonstrate that the proposed protocol achieves up to a 67% acceleration in the client-side computation, accompanied by a 50% reduction in space usage.}
}
@article{RIZZI20131,
title = {Introduction: Core computational principles in natural language syntax},
journal = {Lingua},
volume = {130},
pages = {1-13},
year = {2013},
note = {SI: Syntax and cognition: core ideas and results in syntax},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2012.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0024384112002756},
author = {Luigi Rizzi}
}
@article{PANANGADEN201410,
title = {Causality in physics and computation},
journal = {Theoretical Computer Science},
volume = {546},
pages = {10-16},
year = {2014},
note = {Models of Interaction: Essays in Honour of Glynn Winskel},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2014.02.041},
url = {https://www.sciencedirect.com/science/article/pii/S0304397514001674},
author = {Prakash Panangaden},
keywords = {Causal structure, Event structure, Spacetime, Petri nets},
abstract = {Glynn Winskel has had enormous influence on the study of causal structure in computer science. In this brief note, I discuss analogous concepts in relativity where also causality plays a fundamental role. I discuss spacetime structure in a series of layers and emphasize the role of causal structure. I close with some comparisons between causality in relativity and in distributed computing systems.}
}
@article{SUTHAR202431,
title = {Practical exercises of computer-aided process synthesis for chemical engineering undergraduates},
journal = {Education for Chemical Engineers},
volume = {48},
pages = {31-43},
year = {2024},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2024.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1749772824000071},
author = {Krunal J. Suthar and Aesha Mehta and Swapna Rekha Panda and Hitesh Panchal and Rakesh Sinha},
keywords = {computational tools, lifelong learning, laboratory learning, process synthesis},
abstract = {The study presents ten different exercises covering various computational tools. These exercises are practical applications presented to improve the understanding and skills of students in important concepts of chemical-aided process synthesis. A few exercises aim to build a foundation in computational techniques for chemical engineering undergraduates. The exercises are based on a spreadsheet that covers the design of regression analysis to find the optimum Antoine constants, array calculation for multicomponent distillation material balance, and the generation of a Gantt chart to plan and study the activities of batch processes. The other exercises included an introduction to process simulation, simulation, and reactor rating, and a simulation of multicomponent shortcut distillation. These exercises provide students with hands-on experience in utilizing process simulation software essential for analysing and optimizing chemical processes in real-world scenarios. The exercises also included the design of a heat exchanger network and solving a linear programming problem. An anonymous survey was collected from the cohort that had undergone the exercises, and the practical grades were compared with the batch that did not study the proposed exercises. Additionally, student feedback on practical exercises was collected. Based on the experience of the course coordinator and the collected feedback from participants, it was clear that the exercises helped students to inculcate critical thinking and self-learning abilities. An article essentially sheds light on the computer-aided practical exercises that enable chemical engineering graduates to engage in lifelong learning.}
}
@incollection{JOHNSON2009137,
title = {Embodied cognition of movement decisions: a computational modeling approach},
editor = {Markus Raab and Joseph G. Johnson and Hauke R. Heekeren},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {174},
pages = {137-150},
year = {2009},
booktitle = {Mind and Motion: The Bidirectional Link between Thought and Action},
issn = {0079-6123},
doi = {https://doi.org/10.1016/S0079-6123(09)01312-0},
url = {https://www.sciencedirect.com/science/article/pii/S0079612309013120},
author = {Joseph G. Johnson},
keywords = {attention, decision making, motor system},
abstract = {This chapter presents a cognitive computational view of decision making as the search for, and accumulation of, evidence for options under consideration. It is based on existing models that have been successful in traditional decision tasks involving preferential choice. The model assumes shifting attention over time that determines momentary inputs to an evolving preference state. In this chapter, the cognitive model is extended to illustrate how links from the motor system may be incorporated. These links can basically be categorized into one of three influences: modifying the subjective evaluation of choice options, restricting attention, and altering the options that are to be found in the choice set. The implications for the formal model are introduced and preliminary evidence is drawn from the extant literature.}
}
@article{KUDARIYAWAR2016193,
title = {Computational study of instabilities in a rectangular natural circulation loop using 3D CFD simulation},
journal = {International Journal of Thermal Sciences},
volume = {101},
pages = {193-206},
year = {2016},
issn = {1290-0729},
doi = {https://doi.org/10.1016/j.ijthermalsci.2015.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1290072915003440},
author = {Jayaraj Yallappa Kudariyawar and Abhijeet Mohan Vaidya and Naresh Kumar Maheshwari and Polepalle Satyamurthy},
keywords = {Natural circulation loop, 3D CFD simulation, Instability},
abstract = {Steady state and transient characteristics of a natural circulation loop working with water are obtained. For this purpose, 3D steady state and transient CFD simulations are performed. The CFD model includes pipe thickness as well as secondary side coolant passage apart from primary side. Steady state and transient characteristics are computed for various configurations i.e. Vertical Heater Vertical Cooler (VHVC), Horizontal Heater Horizontal Cooler (HHHC), etc. Steady state data was compared with available correlations. Flow initiation transients were compared with experimental data. Both the steady state and transient results are found to be in good agreement with previously published data. The reason for formation of unidirectional and bi-directional pulsing in HHHC configuration at different powers is explained with the help of temperature fields at different instants of time. Effect of sudden power rise/power step back on instability in HHHC configuration is estimated using CFD simulations.}
}
@article{RAJAN2024R1221,
title = {Cellular cognition: How single cells learn using non-neural networks},
journal = {Current Biology},
volume = {34},
number = {24},
pages = {R1221-R1223},
year = {2024},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2024.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S0960982224015239},
author = {Deepa H. Rajan and Wallace F. Marshall},
abstract = {Summary
Single cells can perform surprisingly complex behaviors and computations, including primitive forms of learning like habituation. New work highlighted here uses mathematical modeling to show that relatively simple biochemical networks can recapitulate many features of habituation in animals.}
}
@article{THOMPSON1983161,
title = {Thinking about thinking},
journal = {Trends in Neurosciences},
volume = {6},
pages = {161-163},
year = {1983},
issn = {0166-2236},
doi = {https://doi.org/10.1016/0166-2236(83)90076-0},
url = {https://www.sciencedirect.com/science/article/pii/0166223683900760},
author = {I.D. Thompson},
abstract = {The Cognitive Neuroscience Institute held its first conference in September 1982, in Kusadasi, Turkey. The institute was recently established in New York to promote research in cognitive neuroscience, and in December 1982 it presented the Hermann von Helmholtz Award to Vernon Mountcastle (see TINS, January 1983, Vol. 6, p. 9). The meeting was attended by individuals whose specialities range from molecular biology to philosophy. Their common aim was to investigate the role of cognitive neuroscience in establishing a theory of mental processing which combines the knowledge derived from cognitive psychology and from neuroscience. How this synthesis is to be achieved, and indeed the extent to which it is possible, was the subject of wide-ranging and often vigorous debate. But, as many disciplines begin to converge on common problems, the prospects for cognitive neuroscience appear encouraging. Thus, as neuroscientists start to unravel the molecular mechanisms of learning and memory, it is interesting to consider what constraints such mechanisms might place on the operational rules for correlating single-neuron activity and behaviour in invertebrates, it has been argued that similar progress in understanding the mammalian brain will come from the application of models, derived from cognitive psychology, to neurophysiology. Artificial intelligence provides an opportunity to model many cognitive processes, but how close do the models come to reflecting underlying mental states? Indeed, the problem or non-problem of self-awareness dominated many conversations, tantalizing some participants by its intractability and accepted by others as a naturally emergent attribute of the mechanics of the mind.}
}
@incollection{JOHNSON201435,
title = {Chapter 3 - Computational and Process Models of Decision Making in Psychology and Behavioral Economics},
editor = {Paul W. Glimcher and Ernst Fehr},
booktitle = {Neuroeconomics (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {35-47},
year = {2014},
isbn = {978-0-12-416008-8},
doi = {https://doi.org/10.1016/B978-0-12-416008-8.00003-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780124160088000036},
author = {Eric J. Johnson and Roger Ratcliff},
keywords = {Computation Process Models, Decision Neuroscience, Drift-Diffusion Models, economic theory, Intertemporal Choice, Riskless Choice, Risky Choice},
abstract = {This chapter reviews models of choice on two levels: The first concerns the descriptions of choice and their evolution from normative models of how choices should be make to more behaviorally realistic models, more consistent with data showing that choice depends heavily on context. We present brief overviews of risky and riskless choice models and data and for choice over time. We then turn to computational process models, a more recent class of models that make prediction for multiple properties of the decision process beyond simply what is chosen, including predicting the distribution of errors and decision times.These models are typically applied to simpler choices, but have found great use in contemporary neuroscience.}
}
@article{MARTINRAMOS201751,
title = {First exposure to Arduino through peer-coaching: Impact on students' attitudes towards programming},
journal = {Computers in Human Behavior},
volume = {76},
pages = {51-58},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217304193},
author = {Pablo Martín-Ramos and Maria João Lopes and M. Margarida {Lima da Silva} and Pedro E.B. Gomes and Pedro S. {Pereira da Silva} and José P.P. Domingues and Manuela {Ramos Silva}},
keywords = {Attitudes survey, Arduino, High school, Programming, Peer coaching},
abstract = {In this paper we report the work that jeKnowledge (Júnior Empresa da Faculdade de Ciências e Tecnologias da Universidade de Coimbra), a student-led initiative, has done in the ‘jeKnowledge academy’ courses to actively engage Portuguese high-school students in STEM education through hands-on projects based on the low-cost Arduino platform. F2F activities, based on a peer-assisted learning strategy, were complemented with tutorials and more advanced project suggestions in a blog. Pre and post surveys on students' attitudes towards programming and peer-coaching were administered to pre-university and first year college participants, finding an overall increase in the Likert scale for all the programming-related constructs under study (confidence, interest, gender, usefulness and professional) after the introductory course. As regards the peer-based learning approach, younger students seemed to be more eager to be taught in a less formal way than their older counterparts. The course resulted in high degrees of satisfaction for both the student tutors and their tutees.}
}
@article{CRONIN2022100987,
title = {Analysis of tutors’ responses to students’ queries in a second linear algebra course at a mathematics support center},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100987},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100987},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000554},
author = {Anthony Cronin and Sepideh Stewart},
keywords = {Mathematics tutors, Second courses in linear algebra, Mathematics support center, Feedback, Tutors’ tactics, Advanced mathematical thinking},
abstract = {This paper analyses six years of tutor feedback produced after inquiries made by students in a second linear algebra course at a university mathematics support center (MSC). We utilized Mason’s (2002) pedagogical tactics to build a model to analyze MSC tutors' feedback responding to these students’ queries. The aim of this research was to investigate the nature of students’ difficulties with concepts in a second linear algebra course that emphasizes theories and proof, in addition to examining the tactics employed by tutors to resolve student difficulties. We analyzed 227 feedback comments from 44 tutors based on their interactions with 82 students over six years. Our findings indicated that the most common areas of difficulty were basis, vector space, subspace, span, and proof. Tutor tactics deployed included ‘being mathematical’, ‘simplifying and complexifying’, and ‘worked examples’. We also discuss some implications for linear algebra tutor training.}
}
@incollection{BARBAROSSA2018419,
title = {Chapter 16 - The Edge Cloud: A Holistic View of Communication, Computation, and Caching},
editor = {Petar M. Djurić and Cédric Richard},
booktitle = {Cooperative and Graph Signal Processing},
publisher = {Academic Press},
pages = {419-444},
year = {2018},
isbn = {978-0-12-813677-5},
doi = {https://doi.org/10.1016/B978-0-12-813677-5.00016-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012813677500016X},
author = {Sergio Barbarossa and Stefania Sardellitti and Elena Ceci and Mattia Merluzzi},
keywords = {5G networks, Wireless communications, Graph-based learning},
abstract = {The evolution of communication networks shows a clear shift of focus from just improving the communications aspects to enabling new important services, from Industry 4.0 to automated driving, virtual/augmented reality, the Internet of Things (IoT), and so on. This trend is evident in the roadmap planned for the deployment of the fifth-generation (5G) communication networks. This ambitious goal requires a paradigm shift toward a vision that looks at communication, computation, and caching (3C) resources as three components of a single holistic system. The further step is to bring these 3C resources closer to the mobile user, at the edge of the network, to enable very low latency and high reliability services. The scope of this chapter is to show that signal processing techniques can play a key role in this new vision. In particular, we motivate the joint optimization of 3C resources. Then we show how graph-based representations can play a key role in building effective learning methods and devising innovative resource allocation techniques.}
}
@article{CASTRO20242377,
title = {Product Customization based on Digital Twin and Cloud Manufacturing within a Decentralized Production System},
journal = {Procedia Computer Science},
volume = {239},
pages = {2377-2384},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.431},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924016752},
author = {Hélio Castro and Fernando Câmara and Paulo Ávila and Luís Ferreira and Manuela Cruz-Cunha},
keywords = {Industry 4.0, Digital Twin, Cyber-Physical System, Smart Factory, Product Customization, Cloud Manufacturing},
abstract = {Industry 4.0 represents a turning point in the thinking of the production model since it is based on digitalized production systems with the aim of improving productivity, product quality, and delivery time to the customer. The digitalization and evolution of information technology allowed the emulation of production system virtual models, namely in the concept of Digital Twin (DT), with the ability to simulate different scenarios providing support for better decision making. This concept not only represents a virtual copy of the physical world that obtains information about the state of the value chain but also illustrates a system capable of changing the development of the production activity according to the fulfillment of the intended business goals. In literature, the concept of the Digital Twin is exhaustively treated as a stand-alone factory (one digital factory represents one physical factory) and underestimates the possibility of a DT oriented to a customized product (a project) that requires decentralized production systems. This paper brings to discussion the relevance of product customized applying DT to smart customization, and the inclusion of decentralized production systems supported by Cloud Manufacturing.}
}
@article{JOHNSON1997721,
title = {Observations with regard to massively parallel computation for Monte Carlo simulation of stochastic dynamical systems},
journal = {International Journal of Non-Linear Mechanics},
volume = {32},
number = {4},
pages = {721-734},
year = {1997},
note = {Third International Stochastic Structural Dynamics Conference},
issn = {0020-7462},
doi = {https://doi.org/10.1016/S0020-7462(96)00097-2},
url = {https://www.sciencedirect.com/science/article/pii/S0020746296000972},
author = {E.A. Johnson and S.F. Wojtkiewicz and L.A. Bergman and B.F. Spencer},
abstract = {The evolution of stochastic dynamical systems is governed by Fokker-Planck equations if the response process is Markovian. Analytical solutions for the transient response of multidimensional systems exist only for the simplest dynamical systems. The evolution of the transition probability density function over the phase space has been solved numerically for various low dimensional systems subjected to additive and multiplicative white noise excitations using the finite element method. Systems of higher order, however, pose difficulty when using standard finite element formulations due to memory requirements and computational expense. Direct Monte Carlo simulation (MCS), while often regarded as less elegant than other methods, can be used to solve problems of significantly higher complexity. The number of realizations required to accurately produce the transition probability density function over the entire phase space, especially in the tails, is large, but since each realization is entirely independent of the others, the Monte Carlo simulation is easily and efficiently adapted to parallel computation. The advent of high-speed, massively-parallel computers permits a large number of realizations of a complex dynamical system to be simultaneously determined. Consequently, Monte Carlo simulation may be more efficient for higher-dimensional systems than other solution methods currently in use. This investigation will examine some of these observations and compare the performance of MCS on various platforms, in the context of a four-dimensional linear oscillator and a Duffing oscillator subjected to band-limited white noise.}
}
@incollection{RUFFONI2017169,
title = {3.10 Finite Element Analysis in Bone Research: A Computational Method Relating Structure to Mechanical Function☆},
editor = {Paul Ducheyne},
booktitle = {Comprehensive Biomaterials II},
publisher = {Elsevier},
address = {Oxford},
pages = {169-196},
year = {2017},
isbn = {978-0-08-100692-4},
doi = {https://doi.org/10.1016/B978-0-12-803581-8.09798-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128035818097988},
author = {D. Ruffoni and G.H. {van Lenthe}},
keywords = {Bone imaging, Bone research, Computational modeling, Femur, Finite element analysis, Fracture, Hierarchical structure, Micro-computed tomography, Osteoporosis, Radius, Strength, Vertebra},
abstract = {Bone is probably the most frequently investigated biological material and finite element analysis (FEA) is the computational tool most commonly used for the analysis of bone biomechanical function. FEA has been used in bone research for more than 30 years and has had a substantial impact on our understanding of the complex behavior of bone. Bone is structured in a hierarchical way covering many length scales and this chapter reflects this hierarchical organization. In particular, the focus is on the applications of FEA for understanding the relationship between bone structure and its mechanical function at specific hierarchical levels. Depending on the hierarchical level, different issues have been investigated with FEA ranging from more clinically oriented topics related to bone quality (eg, predicting bone strength and fracture risk) to more fundamental problems dealing with the mechanical aspects of biological processes (eg, stress and strain around osteocyte lacunae) as well as with the micromechanical behavior of bone at its ultrastructure. A better understanding of the relationship between structure and mechanical function is expected to be important for the current trends in (bio)materials design, where the structure of biological materials is considered as a possible source of inspiration, as well as for more successful approaches in the prevention and treatment of age- and disease-related fractures.}
}
@article{TEZDUYAR19992039,
title = {Methods for parallel computation of complex flow problems},
journal = {Parallel Computing},
volume = {25},
number = {13},
pages = {2039-2066},
year = {1999},
issn = {0167-8191},
doi = {https://doi.org/10.1016/S0167-8191(99)00080-0},
url = {https://www.sciencedirect.com/science/article/pii/S0167819199000800},
author = {Tayfun Tezduyar and Yasuo Osawa},
keywords = {Computational fluid dynamics, Flow simulation, Stabilization methods, Compressible flow, Incompressible flow, Multidomain computational methods},
abstract = {This paper is an overview of some of the methods developed by the Team for Advanced Flow Simulation and Modeling (T★AFSM) [http://www.mems.rice.edu/TAFSM/] to support flow simulation and modeling in a number of “Targeted Challenges”. The “Targeted Challenges” include unsteady flows with interfaces, fluid–object and fluid–structure interactions, airdrop systems, and air circulation and contaminant dispersion. The methods developed include special numerical stabilization methods for compressible and incompressible flows, methods for moving boundaries and interfaces, advanced mesh management methods, and multi-domain computational methods. We include in this paper a number of numerical examples from the simulation of complex flow problems.}
}
@article{MARTINRAMOS2018420,
title = {Reprint of ‘First exposure to Arduino through peer-coaching: Impact on students' attitudes towards programming’},
journal = {Computers in Human Behavior},
volume = {80},
pages = {420-427},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S074756321730691X},
author = {Pablo Martín-Ramos and Maria João Lopes and M. Margarida {Lima da Silva} and Pedro E.B. Gomes and Pedro S. {Pereira da Silva} and José P.P. Domingues and Manuela {Ramos Silva}},
keywords = {Attitudes survey, Arduino, High school, Programming, Peer coaching},
abstract = {In this paper we report the work that jeKnowledge (Júnior Empresa da Faculdade de Ciências e Tecnologias da Universidade de Coimbra), a student-led initiative, has done in the ‘jeKnowledge academy’ courses to actively engage Portuguese high-school students in STEM education through hands-on projects based on the low-cost Arduino platform. F2F activities, based on a peer-assisted learning strategy, were complemented with tutorials and more advanced project suggestions in a blog. Pre and post surveys on students' attitudes towards programming and peer-coaching were administered to pre-university and first year college participants, finding an overall increase in the Likert scale for all the programming-related constructs under study (confidence, interest, gender, usefulness and professional) after the introductory course. As regards the peer-based learning approach, younger students seemed to be more eager to be taught in a less formal way than their older counterparts. The course resulted in high degrees of satisfaction for both the student tutors and their tutees.}
}
@article{MCKELVEY2009476,
title = {Designing an electronic auction market for complex ‘smart parts’ logistics: Options based on LeBaron's computational stock market},
journal = {International Journal of Production Economics},
volume = {120},
number = {2},
pages = {476-494},
year = {2009},
note = {Special Issue on Introduction to Design and Analysis of Production Systems},
issn = {0925-5273},
doi = {https://doi.org/10.1016/j.ijpe.2009.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0925527309000899},
author = {Bill McKelvey and Christine Wycisk and Michael Hülsmann},
keywords = {Supply chain management, Electronic auction market, I&C technologies, Complexity theory, Neural networks},
abstract = {Modern technologies, such as RFID, offer never-before seen learning abilities to parts moving in supply chains. Logistics systems may be understood as complex adaptive logistics systems (CALS). They also may be conceived as electronic auction markets as ‘smart parts’ bid for the best routing and pricing from transportation firms. To ensure the world-wide functionality and efficiency of CALS transportation markets, we suggest the utility of an agent-based computational market design based on Blake LeBaron's stock-market model. Given that parts may be more or less smart, markets more or less complex, and self-organizing CALS systems probabilistically subject to the bullwhip effect, we suggest nine different computational CALS market-design options, offering more adaptivity to unexpected environmental contingencies.}
}
@article{GOMEZCARRILLO2023296,
title = {Integrating neuroscience in psychiatry: a cultural–ecosocial systemic approach},
journal = {The Lancet Psychiatry},
volume = {10},
number = {4},
pages = {296-304},
year = {2023},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(23)00006-8},
url = {https://www.sciencedirect.com/science/article/pii/S2215036623000068},
author = {Ana Gómez-Carrillo and Laurence J Kirmayer and Neil Krishan Aggarwal and Kamaldeep S Bhui and Kenneth Po-Lun Fung and Brandon A Kohrt and Mitchell G Weiss and Roberto Lewis-Fernández},
abstract = {Summary
Psychiatry has increasingly adopted explanations for psychopathology that are based on neurobiological reductionism. With the recognition of health disparities and the realisation that someone's postcode can be a better predictor of health outcomes than their genetic code, there are increasing efforts to ensure cultural and social–structural competence in psychiatric practice. Although neuroscientific and social–cultural approaches in psychiatry remain largely separate, they can be brought together in a multilevel explanatory framework to advance psychiatric theory, research, and practice. In this Personal View, we outline how a cultural–ecosocial systems approach to integrating neuroscience in psychiatry can promote social–contextual and systemic thinking for more clinically useful formulations and person-centred care.}
}
@article{RAJ2021474,
title = {Assessment of antiviral potencies of cannabinoids against SARS-CoV-2 using computational and in vitro approaches},
journal = {International Journal of Biological Macromolecules},
volume = {168},
pages = {474-485},
year = {2021},
issn = {0141-8130},
doi = {https://doi.org/10.1016/j.ijbiomac.2020.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S0141813020351783},
author = {Vinit Raj and Jae Gyu Park and Kiu-Hyung Cho and Pilju Choi and Taejung Kim and Jungyeob Ham and Jintae Lee},
keywords = {Cannabinols,  antiviral assay, SARS-CoV-2 and M enzyme},
abstract = {Effective treatment choices to the severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) are limited because of the absence of effective target-based therapeutics. The main object of the current research was to estimate the antiviral activity of cannabinoids (CBDs) against the human coronavirus SARS-CoV-2. In the presented research work, we performed in silico and in vitro experiments to aid the sighting of lead CBDs for treating the viral infections of SARS-CoV-2. Virtual screening was carried out for interactions between 32 CBDs and the SARS-CoV-2 Mpro enzyme. Afterward, in vitro antiviral activity was carried out of five CBDs molecules against SARS-CoV-2. Interestingly, among them, two CBDs molecules namely Δ9 -tetrahydrocannabinol (IC50 = 10.25 μM) and cannabidiol (IC50 = 7.91 μM) were observed to be more potent antiviral molecules against SARS-CoV-2 compared to the reference drugs lopinavir, chloroquine, and remdesivir (IC50 ranges of 8.16–13.15 μM). These molecules were found to have stable conformations with the active binding pocket of the SARS-CoV-2 Mpro by molecular dynamic simulation and density functional theory. Our findings suggest cannabidiol and Δ9 -tetrahydrocannabinol are possible drugs against human coronavirus that might be used in combination or with other drug molecules to treat COVID-19 patients.}
}
@article{GUERRAMACIAS2025e41099,
title = {Development of transversal skills in higher education programs in conjunction with online learning: relationship between learning strategies, project-based pedagogical practices, e-learning platforms, and academic performance},
journal = {Heliyon},
volume = {11},
number = {2},
pages = {e41099},
year = {2025},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e41099},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024171307},
author = {Yolanda Guerra-Macías and Sergio Tobón},
keywords = {Generic competencies, 21st-century skills, Virtual education, Higher education, Socioformation, Generic skills, Socioformative rubrics},
abstract = {This study investigates the development of transversal skills and their association with academic performance in university students enrolled in on-campus programs with online activities. A cross-sectional, descriptive, and quantitative research was conducted with 252 students from a public university in Mexico. Transversal skills, socioformative project-based practices, learning strategies, and the relevance of online activities were assessed using validated rubrics. The results indicated a low level of development in three transversal skills: research, entrepreneurship, and English, with the latter being the poorest rated. Critical and creative thinking exhibited the highest level of development. In the didactic component, socioformative project-based pedagogical practices and learning strategies showed acceptable levels. Students expressed satisfaction with complementary online activities, showing a preference for interactive videos and short videos under 4 min. Regression analysis and structural equations were used to examine the relationships between various factors. Results demonstrated that socioformative project-based pedagogical practices, learning strategies, and online education positively correlated with the development of transversal skills. Furthermore, a higher level of transversal skills was associated with better academic averages among students. Socioformative project-based pedagogical practices also correlated with academic performance through transversal skills. The study concludes that integrating online activities into on-campus programs, based on the socioformative pedagogical model, can enhance the development of transversal skills and improve academic performance. Further research into the implementation of this educational model and its long-term impact on university education and professional success is recommended.}
}
@article{YOUNG201719,
title = {Technology-enhanced mathematics instruction: A second-order meta-analysis of 30 years of research},
journal = {Educational Research Review},
volume = {22},
pages = {19-33},
year = {2017},
issn = {1747-938X},
doi = {https://doi.org/10.1016/j.edurev.2017.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S1747938X1730026X},
author = {Jamaal Young},
keywords = {Meta-analysis, Mathematics achievement, Technology, Calculators, Computer-assisted instruction},
abstract = {It is important to assess the cumulative effects of technology on student achievement captured in the last 30 years of technologyenhanced mathematics instruction. Synthesizing the thousands of articles and gray literature on this subject is necessary but would require a considerable commitment of academic resources. A second-order metaanalysis or meta-analysis of meta-analyses is an alternative that is reasonable and effective. Thus, a second-order meta-analysis of 19 prior meta-analyses with minimum overlap between primary studies was conducted. The results represent 663 primary studies (approximately 141,733 participants) and 1,263 effect sizes. The random effects' mean effect size of .38 was statistically significantly different from zero. The results provide a historical and contextualized summary of 30 years of meta-analytic research, which supports meta-analytic thinking and better interpretation of future effect sizes. Results indicate that technology function and study quality are major contributors to effect size variation. Specifically, computation enhancement technologies were most effective, while studies that examine combinations of enhancements were least effective. Implications for technology-enhanced mathematics instruction and meta-analytic research are provided.}
}
@article{SPEISER2011271,
title = {Models for products},
journal = {The Journal of Mathematical Behavior},
volume = {30},
number = {4},
pages = {271-290},
year = {2011},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2011.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732312311000307},
author = {Bob Speiser and Chuck Walter},
keywords = {Model, Representation, Presentation, Operator product, Controlled variable, Frame, Core knowledge, Analog magnitude, Parallel individuation, Shared intentionality},
abstract = {This paper explores how models can support productive thinking. For us a model is a thing, a tool to help make sense of something. We restrict attention to specific models for whole-number multiplication, hence the wording of the title. They support evolving thinking in large measure through the ways their users redesign them. They assume new forms, come to be seen and understood in different ways. We show how work that learners do with models can help them to transform, not simply their understanding of key concepts, but also how they come to view themselves as thinkers and learners, as collaborators in a social process that their work and thinking help to constitute. We draw on recent research on core knowledge, especially by Carey, Spelke, and Tomasello, to clarify how models, as we view them here, can underpin specific actions that support emerging understanding.}
}
@article{MURRAY202483,
title = {Brain mechanisms of rumination and negative self-referential processing in adolescent depression},
journal = {Journal of Affective Disorders},
volume = {366},
pages = {83-90},
year = {2024},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2024.08.114},
url = {https://www.sciencedirect.com/science/article/pii/S0165032724013466},
author = {Laura Murray and Nigel M. Jaffe and Anna O. Tierney and Kristina Pidvirny and Emma G. Balkind and Batool S. Abbasi and Miranda Brown and Christian A. Webb},
keywords = {Depression, Adolescence, Ecological momentary assessment, fMRI, Rumination, Self-referent encoding task},
abstract = {Background
Depression is linked to cognitive biases towards more negative and less positive self-relevant information. Rumination, perseverative negative thinking about the past and the self, may contribute to these biases.
Methods
159 adolescents (12–18 years), with a range of depression symptoms, completed the SRET during fMRI. Multiple regressions tested associations between conventional self-report and ecological momentary assessment (EMA) measured rumination, and neural and behavioral responses during a self-referent encoding task (SRET).
Results
Higher rumination (conventional self-report and EMA) was associated with more negative and fewer positive words endorsed and recalled. Higher self-reported (but not EMA) rumination was associated with higher accuracy in recognizing negative words and greater insula and dorsal anterior cingulate activity to negative versus positive words.
Limitations
The sample included mostly non-Hispanic White participants with household incomes above the national average, highlighting the need for replication in more diverse samples. Word endorsement discrepancies required fMRI analyses to model neural response to viewing negative versus positive words.
Conclusions
Adolescents with higher rumination endorsed and recalled more negative and fewer positive words and recognized more negative words during the SRET. Higher insula reactivity, a key region for modulating externally-oriented attention and internally-oriented self-referential processes, may contribute to links between rumination and negative memory biases. These findings provide insight into neurocognitive mechanisms underlying depression.}
}
@article{MARINIER200948,
title = {A computational unification of cognitive behavior and emotion},
journal = {Cognitive Systems Research},
volume = {10},
number = {1},
pages = {48-69},
year = {2009},
note = {Modeling the Cognitive Antecedents and Consequences of Emotion},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2008.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041708000302},
author = {Robert P. Marinier and John E. Laird and Richard L. Lewis},
abstract = {Existing models that integrate emotion and cognition generally do not fully specify why cognition needs emotion and conversely why emotion needs cognition. In this paper, we present a unified computational model that combines an abstract cognitive theory of behavior control (PEACTIDM) and a detailed theory of emotion (based on an appraisal theory), integrated in a theory of cognitive architecture (Soar). The theory of cognitive control specifies a set of required computational functions and their abstract inputs and outputs, while the appraisal theory specifies in more detail the nature of these inputs and outputs and an ontology for their representation. We argue that there is a surprising functional symbiosis between these two independently motivated theories that leads to a deeper theoretical integration than has been previously obtained in other computational treatments of cognition and emotion. We use an implemented model in Soar to test the feasibility of the resulting integrated theory, and explore its implications and predictive power in several task domains.}
}
@article{SCHMALZL20031021,
title = {Using standard image compression algorithms to store data from computational fluid dynamics},
journal = {Computers & Geosciences},
volume = {29},
number = {8},
pages = {1021-1031},
year = {2003},
issn = {0098-3004},
doi = {https://doi.org/10.1016/S0098-3004(03)00098-0},
url = {https://www.sciencedirect.com/science/article/pii/S0098300403000980},
author = {Jörg Schmalzl},
keywords = {Computational fluid dynamics, Data compression, Visualization, Post-processing},
abstract = {Three-dimensional numerical modeling of fluid flows is an important research tool to understand many fluid dynamical effects observed in nature. With the strong growth of available computational resources the use of such models has greatly increased over the last years. Because the available mass storage has not increased in the same order as the CPU speed many researchers nowadays face the problem of how to store and transfer the large data sets produced by the model calculations for post-processing. The use of lossy wavelet-based compression techniques on this data has been investigated in several publications. These techniques are often specialized to one problem and are not easy to implement. In the area of digital media, however, advances have been made for still image (JPEG, JPEG-2000) and motion image (MPEG) compression. In this paper we investigate the usefulness of these image compression algorithms for the storage of data from computational fluid dynamics on regular cartesian grids. We analyze both the compression ratios achieved and the error introduced by these lossy compression schemes. We found that, for our purposes, the JPEG compression scheme allows an easy-to-use, portable, robust, and computationally efficient lossy compression. For the easy use of these compression algorithms we present a simple wrapper library.}
}
@article{KARAGIANNIS2022103631,
title = {The OMiLAB Digital Innovation environment: Agile conceptual models to bridge business value with Digital and Physical Twins for Product-Service Systems development},
journal = {Computers in Industry},
volume = {138},
pages = {103631},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103631},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522000264},
author = {Dimitris Karagiannis and Robert Andrei Buchmann and Wilfrid Utz},
keywords = {Digital twin, Physical twin, Smart Product-service Systems, Agile modeling method engineering, OMiLAB, Domain-specific conceptual modeling},
abstract = {OMiLAB is a community of practice which offers a digital ecosystem bringing together open technologies to investigate and apply conceptual modeling methods for varying purposes and domains. One of the core value propositions is a dedicated Digital Innovation environment comprising several toolkits and workspaces, designed to support Product-Service Systems (PSS) prototyping – a key ingredient for PSS lifecycle management. At the core of this environment is a notion of Agile Digital Twin – a conceptual representation that can be tailored with knowledge engineering means to bridge the semantic and functional gap between a business perspective (focusing on value creation) and an engineering perspective (focusing on cyber-physical proofs-of-concept). To facilitate this bridging, the hereby proposed environment orchestrates, across three abstraction layers, methods such as Design Thinking, Agile Modeling Method Engineering and Model-driven Engineering to turn Ideation into smart Product-Service Systems experiments, in a laboratory setting. The proposed environment was built following Design Science principles. It addresses the problem of historically-disconnected skills required for Digital Innovation projects and it provides a testbed for feasibility experimentation. For design-oriented, artifact building research, a higher Technology Readiness Level can thus be achieved (compared to the level that idea development methods typically attain).}
}
@article{YAN20158006,
title = {Trustworthiness evaluation and retrieval-based revision method for case-based reasoning classifiers},
journal = {Expert Systems with Applications},
volume = {42},
number = {21},
pages = {8006-8013},
year = {2015},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2015.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S0957417415004297},
author = {Aijun Yan and Dianhui Wang},
keywords = {Case-based reasoning classifiers, Classification accuracy, Case evaluation, Case revision},
abstract = {To achieve better classification performance using case-based reasoning classifiers, we propose a retrieval-based revision method with trustworthiness evaluation for problem solving. An improved case evaluation method is employed to evaluate the trustworthiness of the suggested solution after the reuse step, which will divide the target cases and its suggested solutions into a trustworthy set and an untrustworthy set in accordance with a threshold value of trustworthiness. The attribute weights are adjusted by running a genetic algorithm and are used in the second round of retrieval of the untrustworthy set to obtain the classification results. Experimental results demonstrate that our proposed method performs favorably compared with other methods. Also, the proposed method has less computation complexity for the trustworthiness evaluation, and enhances understanding on thinking and inference for case-based reasoning classifiers.}
}
@article{BYTYQIDAMONI2024137516,
title = {Synthesis, characterization, and computational study of novel carvacrol-based 2-aminothiol and sulfonic acid derivatives as metabolic enzyme inhibitors},
journal = {Journal of Molecular Structure},
volume = {1303},
pages = {137516},
year = {2024},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2024.137516},
url = {https://www.sciencedirect.com/science/article/pii/S0022286024000395},
author = {Arlinda Bytyqi-Damoni and Eda Mehtap Uc and Rıfat Emin Bora and Hayriye Genc Bilgicli and Mehmet Abdullah Alagöz and Mustafa Zengin and İlhami Gülçin},
keywords = {Carvacrol, Carbonic anhydrase, α-glucosidase, Acetylcholinesterase, Butyrylcholinesterase},
abstract = {Eight new 2-aminothiols (69–96%) and three new sulfonic acids (51–76%) were synthesized and characterized by NMR and HRMS spectra. This study presents the inhibitory effects of a series of novel carvacrol-based 2-aminothiol and sulfonic acid derivatives (3a-f,4a-c) against human carbonic anhydrase I and II isozymes (hCA I and II) acetylcholinesterase (AChE), butyrylcholinesterase (BChE) and α-glycosidase. Ki values were calculated as 12.52±3.61–335.65±60.56 nM for hCA I, 12.20±3.59–389.69±119.41 nM for hCA II, 1.79±0.56–84.86±23.34 nM for AChE, 6.57±2.54–88.05±21.05 nM for BChE and 14.63±4.76–116.39±33.70 nM α-glucosidase enzymes. Also, the inhibition effects of novel carvacrol-based 2-aminothiol (3a-h) and sulfonic acid derivatives (4a-c) were compared to standard and clinically used inhibitors of acetazolamide, Tacrine and acarbose, respectively. Molecular modeling studies of novel compounds, docking scores, and free binding energies were calculated. The activity results of the compounds were found to be compatible with the docking scores. Molecular dynamics studies were conducted with the best activity against CA I and CA II compounds, 4b (IC50: 4.76 nM) and 4a (IC50: 4.36 nM), respectively. In Dynamic Simulation studies, it was observed that the compounds remained stable at the active sites of the proteins.}
}
@article{STRASS201534,
title = {Analyzing the computational complexity of abstract dialectical frameworks via approximation fixpoint theory},
journal = {Artificial Intelligence},
volume = {226},
pages = {34-74},
year = {2015},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2015.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0004370215000776},
author = {Hannes Strass and Johannes Peter Wallner},
keywords = {Abstract dialectical frameworks, Computational complexity, Approximation fixpoint theory},
abstract = {Abstract dialectical frameworks (ADFs) have recently been proposed as a versatile generalization of Dung's abstract argumentation frameworks (AFs). In this paper, we present a comprehensive analysis of the computational complexity of ADFs. Our results show that while ADFs are one level up in the polynomial hierarchy compared to AFs, there is a useful subclass of ADFs which is as complex as AFs while arguably offering more modeling capacities. As a technical vehicle, we employ the approximation fixpoint theory of Denecker, Marek and Truszczyński, thus showing that it is also a useful tool for complexity analysis of operator-based semantics.}
}
@article{PARK20151,
title = {A Neuro-educational Study of the Development of the Creativity-based Teaching Program and its Effect},
journal = {Procedia - Social and Behavioral Sciences},
volume = {186},
pages = {1-8},
year = {2015},
note = {The Proceedings of 5th World Conference on Learning, Teaching and Educational Leadership},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2015.04.200},
url = {https://www.sciencedirect.com/science/article/pii/S187704281502460X},
author = {Sun-Hyung Park and Kwang-Ki Kim and Kyung-Hwa Lee},
keywords = {Creativity-based teaching programs, Divergent thinking, The TTCT, FMRI},
abstract = {This study aims at exploring a possibility of developing a creativity-based teaching program needed for enhancing prospective teachers’ creative potentials based on the theories of Sawyer and Renzulli. Neuroimaging tools such as fMRI were used to identify effects of the program on pre-service teachers’ neural activations on divergent thinking measured primarily by the Torrance Tests of Creative Thinking (TTCT). Since the research is still in progress, we present a theoretical model for the teaching program, and preliminary test results of comparing changes of neural recruitments in students’ brain participated in fMRI with the TTCT.}
}
@article{GARCIASANCHO201216,
title = {From the genetic to the computer program: the historicity of ‘data’ and ‘computation’ in the investigations on the nematode worm C. elegans (1963–1998)},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {43},
number = {1},
pages = {16-28},
year = {2012},
note = {Data-Driven Research in the Biological and Biomedical Sciences On Nature and Normativity: Normativity, Teleology, and Mechanism in Biological Explanation},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2011.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1369848611000781},
author = {Miguel García-Sancho},
keywords = {, Genetics, Computer, Program, Software, Data, Genomics, Model organism},
abstract = {This paper argues that the history of the computer, of the practice of computation and of the notions of ‘data’ and ‘programme’ are essential for a critical account of the emergence and implications of data-driven research. In order to show this, I focus on the transition that the investigations on the worm C. elegans experienced in the Laboratory of Molecular Biology of Cambridge (UK). Throughout the 1980s, this research programme evolved from a study of the genetic basis of the worm’s development and behaviour to a DNA mapping and sequencing initiative. By examining the changing computing technologies which were used at the Laboratory, I demonstrate that by the time of this transition researchers shifted from modelling the worm’s genetic programme on a mainframe apparatus to writing minicomputer programs aimed at providing map and sequence data which was then circulated to other groups working on the genetics of C. elegans. The shift in the worm research should thus not be simply explained in the application of computers which transformed the project from hypothesis-driven to a data-intensive endeavour. The key factor was rather a historically specific technology—in-house and easy programmable minicomputers—which redefined the way of achieving the project’s long-standing goal, leading the genetic programme to co-evolve with the practices of data production and distribution.}
}
@article{ACAR2006993,
title = {Endowing cognitive mapping with computational properties for strategic analysis},
journal = {Futures},
volume = {38},
number = {8},
pages = {993-1009},
year = {2006},
note = {Organisational Foresight},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2005.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S0016328705002302},
author = {William Acar and Douglas Druckenmiller},
abstract = {A number of cognitive, causal mapping and simulation techniques exist for dealing with the growing importance of environmental uncertainty. After briefly commenting on some of the more salient extant approaches, this paper offers a new one for consideration by the scenario planning community. Comprehensive Situation Mapping (CSM) is a powerful analytical tool combined with a process for framing and debating strategic situations. The CSM approach combines the problem framing features of causal mapping with a dialectical inquiry process patterned after Churchman's. Like the better approaches to planning through cognitive mapping, it facilitates the “backward analysis” of the underlying strategic assumptions. Its novelty is that it also allows the “forward analysis” of a situation by computing the potential change scenarios. Initially developed for manual application, the principles of CSM were originally tested in appropriate case studies. The contribution of the present paper is to present its theory and point out that its future potential is even greater: in concluding we indicate that, by using recent distributed artificial intelligence (DAI) technology, a fully computerized and interactive prototype is now being set up for commercial applications.}
}
@article{EMILYESTHERRANI2025107032,
title = {Alzheimer disease classification using optimal clustering based pre-trained SqueezeNet model},
journal = {Biomedical Signal Processing and Control},
volume = {100},
pages = {107032},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.107032},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424010905},
author = {K. {Emily Esther Rani} and S. Baulkani},
keywords = {Alzheimer disease, Optimal center, Clustering, Adaptive reptile search algorithm, Pre-trained squeezenet},
abstract = {Alzheimer’s disease (AD) is an irreversible neurological illness identified by deficits in thinking, behavior, and memory. Early detection and prevention of AD is a crucial and difficult task. DL (Deep Learning) has gained significant attention recently as a potential tool for early AD detection. However, traditional diagnostic methods such as cognitive tests and manual analysis of brain imaging are time consuming and prone to error. Hence, there is a need for an automated model which shows better classification performance. To tackle these issues, this study presents a system to improve AD recognition performance. Initially, the pre-processing and skull stripping processes are performed. Then, for segmenting the grey, whiter matters and Cerebrospinal Fluid (CSF), the optimal clustering process is carried out. Here, the optimal center of clusters is selected by the metaheuristic optimization Adaptive Reptile Search Algorithm-Clustering Approach (ARSA-CA) is utilized. The proposed ARSA is the integration of the optimization RSA and simulated annealing (SA). Finally, for classifying the different classes of AD, the DL approach pre-trained SqueezeNet is utilized. The experimentation is carried out on the ADNI and OASIS datasets and achieved better accuracies of 98.3% and 98.2% respectively. Thus, it is proved that the proposed model is suitable for identifying AD.}
}
@article{MORTON2019,
title = {Computer Programming: Should Medical Students Be Learning It?},
journal = {JMIR Medical Education},
volume = {5},
number = {1},
year = {2019},
issn = {2369-3762},
doi = {https://doi.org/10.2196/11940},
url = {https://www.sciencedirect.com/science/article/pii/S2369376219000011},
author = {Caroline E Morton and Susan F Smith and Tommy Lwin and Michael George and Matt Williams},
keywords = {coding, medical education, undergraduate curriculum},
abstract = {Background
The ability to construct simple computer programs (coding) is being progressively recognized as a life skill. Coding is now being taught to primary-school children worldwide, but current medical students usually lack coding skills, and current measures of computer literacy for medical students focus on the use of software and internet safety. There is a need to train a cohort of doctors who can both practice medicine and engage in the development of useful, innovative technologies to increase efficiency and adapt to the modern medical world.
Objective
The aim of the study was to address the following questions: (1) is it possible to teach undergraduate medical students the basics of computer coding in a 2-day course? (2) how do students perceive the value of learning computer coding at medical school? and (3) do students see computer coding as an important skill for future doctors?
Methods
We developed a short coding course to teach self-selected cohorts of medical students basic coding. The course included a 2-day introduction on writing software, discussion of computational thinking, and how to discuss projects with mainstream computer scientists, and it was followed on by a 3-week period of self-study during which students completed a project. We explored in focus groups (FGs) whether students thought that coding has a place in the undergraduate medical curriculum.
Results
Our results demonstrate that medical students who were complete novices at coding could be taught enough to be able to create simple, usable clinical programs with 2 days of intensive teaching. In addition, 6 major themes emerged from the FGs: (1) making sense of coding, (2) developing the students’ skill set, (3) the value of coding in medicine, research, and business, (4) role of teaching coding in medical schools, (5) the concept of an enjoyable challenge, and (6) comments on the course design.
Conclusions
Medical students can acquire usable coding skills in a weekend course. They valued the teaching and identified that, as well as gaining coding skills, they had acquired an understanding of its potential both for their own projects and in health care delivery and research. They considered that coding skills teaching should be offered as an optional part of the medical curriculum.}
}
@article{CARLOZZI2022263,
title = {Daily Variation in Sleep Quality is Associated With Health-Related Quality of Life in People With Spinal Cord Injury},
journal = {Archives of Physical Medicine and Rehabilitation},
volume = {103},
number = {2},
pages = {263-273.e4},
year = {2022},
issn = {0003-9993},
doi = {https://doi.org/10.1016/j.apmr.2021.07.803},
url = {https://www.sciencedirect.com/science/article/pii/S0003999321013630},
author = {Noelle E. Carlozzi and Jenna Freedman and Jonathan P. Troost and Traci Carson and Ivan R. Molton and Dawn M. Ehde and Kayvan Najarian and Jennifer A. Miner and Nicholas R. Boileau and Anna L. Kratz},
keywords = {Ecological momentary assessment, Quality of life, Rehabilitation, Sleep, Spinal cord injuries},
abstract = {Objective
Although sleep difficulties are common after spinal cord injury (SCI), little is known about how day-to-day fluctuations in sleep quality affects health-related quality of life (HRQOL) among these individuals. We examined the effect of sleep quality on same-day HRQOL using ecological momentary assessment methods over a 7-day period.
Design
Repeated-measures study involving 7 days of home monitoring; participants completed HRQOL measures each night and ecological momentary assessment ratings 3 times throughout the day; multilevel models were used to analyze data.
Setting
Two academic medical centers.
Participants
A total of 170 individuals with SCI (N=170).
Interventions
Not applicable.
Main Outcome Measures
Daily sleep quality was rated on a scale of 0 (worst) to 10 (best) each morning. Participants completed end-of-day diaries each night that included several HRQOL measures (Sleep Disturbance, Sleep-related Impairment, Fatigue, Cognitive Abilities, Pain Intensity, Pain Interference, Ability to Participate in Social Roles and Activities, Depression, Anxiety) and ecological momentary assessment ratings of HRQOL (pain, fatigue, subjective thinking) 3 times throughout each day.
Results
Multilevel models indicated that fluctuations in sleep quality (as determined by end-of-day ratings) were significantly related to next-day ratings of HRQOL; sleep quality was related to other reports of sleep (Sleep Disturbance; Sleep-related Impairment; Fatigue) but not to other aspects of HRQOL. For ecological momentary assessment ratings, nights of poor sleep were related to worse pain, fatigue, and thinking. Generally, sleep quality showed consistent associations with fatigue and thinking across the day, but the association between sleep quality and these ecological momentary assessment ratings weakened over the course of the day.
Conclusions
Findings highlight the important association between sleep and HRQOL for people with SCI. Future work targeting sleep quality improvement may have positive downstream effects for improving HRQOL in people with SCI.}
}
@incollection{LANDAUER200243,
title = {On the computational basis of learning and cognition: Arguments from LSA},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {41},
pages = {43-84},
year = {2002},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(02)80004-4},
url = {https://www.sciencedirect.com/science/article/pii/S0079742102800044},
author = {Thomas K Landauer},
abstract = {Publisher Summary
This chapter discusses the computational basis of learning and cognition. To deal with a continuously changing environment, living things have three choices: (1) evolve unvarying processes that usually succeed, (2) evolve genetically fixed effector, perceptual, and computational functions that are contingent on the environment, and (3) learn adaptive functions during their lifetimes. The theme of this chapter is the relation between (2) and (3): the nature of evolutionarily determined computational processes that support learning. The principal goal of this chapter has been to suggest that high-dimensional vector space computations based on empirical associations among very large numbers of components could be a close model of a fundamental computational basis of most learning in both verbal and perceptual domains. More powerful representational effects can be brought about by linear inductive combinations of the elements of very large vocabularies than has often been realized. Success of one such model to demonstrate many natural properties of language commonly assumed to be essentially more complex, nonlinear, and/or unlearned, along with evidence and argument that similar computations may serve similar roles in object recognition, are taken to reaffirm the possibility that a single underlying associational mechanism lies behind many more special and complex appearing cognitive phenomena.}
}
@incollection{DEAN2014157,
title = {Chapter 7 - Decorrelation Learning in the Cerebellum: Computational Analysis and Experimental Questions},
editor = {Narender Ramnani},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {210},
pages = {157-192},
year = {2014},
booktitle = {Cerebellar Learning},
issn = {0079-6123},
doi = {https://doi.org/10.1016/B978-0-444-63356-9.00007-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444633569000078},
author = {Paul Dean and John Porrill},
keywords = {Cerebellum, eye blink conditioning, vestibulo-ocular reflex, spike-timing dependent plasticity, avoidance learning, long-term depression, long-term potentiation, supervised learning, reafference, least mean squares},
abstract = {Many cerebellar models use a form of synaptic plasticity that implements decorrelation learning. Parallel fibers carrying signals positively correlated with climbing-fiber input have their synapses weakened (long-term depression), whereas those carrying signals negatively correlated with climbing input have their synapses strengthened (long-term potentiation). Learning therefore ceases when all parallel-fiber signals have been decorrelated from climbing-fiber input. This is a computationally powerful rule for supervised learning and can be cast in a spike-timing dependent plasticity form for comparison with experimental evidence. Decorrelation learning is particularly well suited to sensory prediction, for example, in the reafference problem where external sensory signals are interfered with by reafferent signals from the organism’s own movements, and the required circuit appears similar to the one found to mediate classical eye blink conditioning. However, for certain stimuli, avoidance is a much better option than simple prediction, and decorrelation learning can also be used to acquire appropriate avoidance movements. One example of a stimulus to be avoided is retinal slip that degrades visual processing, and decorrelation learning appears to play a role in the vestibulo-ocular reflex that stabilizes gaze in the face of unpredicted head movements. Decorrelation learning is thus suitable for both sensory prediction and motor control. It may also be well suited for generic spatial and temporal coordination, because of its ability to remove the unwanted side effects of movement. Finally, because it can be used with any kind of time-varying signal, the cerebellum could play a role in cognitive processing.}
}
@article{GOMEZTALAL2024108109,
title = {Understanding the disparities in Mathematics performance: An interpretability-based examination},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108109},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108109},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624002677},
author = {Ismael Gómez-Talal and Luis Bote-Curiel and José Luis Rojo-Álvarez},
keywords = {Programme for International Student Assessment, Interpretable machine learning, Shapley additive explanations, Explainable black-box models},
abstract = {Problem:
Educational disparities in Mathematics performance are a persistent challenge. This study aims to unravel the complex factors contributing to these disparities among students internationally, with a focus on the interpretability of the contributing factors.
Methodology:
Utilizing data from the Programme for International Student Assessment (PISA), we conducted rigorous preprocessing and variable selection to prepare for applying binary classification interpretability models. These models were trained using the Stratified K-Fold technique to ensure balanced representation and assessed using six key metrics.
Solution:
By applying interpretability models such as Shapley Additive Explanations (SHAP) analysis, we identified critical factors impacting student performance, including reading accessibility, critical thinking skills, gender, and geographical location.
Results:
Our findings reveal significant disparities linked to resource availability, with students from lower socioeconomic backgrounds possessing fewer books and demonstrating lower performance in Mathematics. The geographical analysis highlighted regional educational disparities, with certain areas consistently underperforming in PISA assessments. Gender also emerged as a determinant, with females contributing differently to performance levels across the spectrum.
Conclusion:
The study provides insights into the multifaceted determinants of student Mathematics performance and suggests potential avenues for future research to explore global interpretability models and further investigate the socioeconomic, cultural, and educational factors at play.}
}
@article{HEYLIGHEN2014113,
title = {Designing in the absence of sight: Design cognition re-articulated},
journal = {Design Studies},
volume = {35},
number = {2},
pages = {113-132},
year = {2014},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2013.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X13000926},
author = {Ann Heylighen and Greg Nijs},
keywords = {design cognition, design research, epistemology},
abstract = {Starting from the study of an architect who designs in the absence of sight, we question to what extent prevailing notions of design may be complemented with alternative articulations. In doing so, we point to the cognitivist understanding of human cognition underlying design researchers' strong attention to ‘visual thinking’, and contrast this with more situated understandings of human cognition. The ontological and epistemological differences between both raise questions about how design research is produced, and consequently what design can also be. By accounting for how a blind architect re-articulates prevailing notions of design, we invite researchers to keep the discussion open and call for an ontological and epistemological re-articulation in design research.}
}
@incollection{KRETZER202153,
title = {Chapter 4 - Digital crafting: a new frontier for material design},
editor = {Owain Pedgley and Valentina Rognoli and Elvin Karana},
booktitle = {Materials Experience 2},
publisher = {Butterworth-Heinemann},
pages = {53-66},
year = {2021},
isbn = {978-0-12-819244-3},
doi = {https://doi.org/10.1016/B978-0-12-819244-3.00003-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012819244300003X},
author = {Manuel Kretzer},
keywords = {Digital, crafting, design, architecture, production, fabrication, parametric, generative, Industry 4.0},
abstract = {This chapter provides an overview of the potentials of employing computational design methods and digital fabrication tools for the creation of novel, material-based design. Just as in the early days of architecture, when the master builder was responsible for all areas of building, these new technologies allow a return to the exploration of experimental design methods and the direct exchange with different materials. Designing for and through digital production techniques thus shifts the focus from formal design representations toward the physically realized. As such, material and tectonic thinking are reintroduced as the very base of the design approach. Due to this a new type of design becomes possible with a formerly unknown degree of complexity—both on a formal and on a functional level. This chapter gives an overview of the history of design, speaks about the so-called “digital continuum,” highlights the benefits of customization and individual production, stresses the nuisance of new esthetic formalizations and the importance of education to mediate such understanding to students of design and architecture.}
}
@article{TRINDADE2025101104,
title = {Teaching mathematical concepts in management with generative artificial intelligence: The power of human oversight in AI-driven learning},
journal = {The International Journal of Management Education},
volume = {23},
number = {2},
pages = {101104},
year = {2025},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101104},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001757},
author = {Maria A.M. Trindade and Gihan S. Edirisinghe and Lan Luo},
keywords = {Generative artificial intelligence in education, Generative AI-Driven learning, Mathematics in management education, Operations management, Economic order quantity, Generative AI in management education},
abstract = {This study demonstrates a successful use of Generative Artificial Intelligence (AI) in teaching mathematical material to management students. We herein introduce the EOQ World Tour game, which substantially improves understanding of inventory-related concepts and long-term knowledge retention compared with traditional methods. Generative AI is revolutionizing management education, by offering innovative methods for teaching and learning. The integration of AI into quantitative business disciplines through novel learning mechanisms provides significant benefits, including enhanced data analysis, improved decision-making models, and sophisticated simulations for hands-on experience. This study introduces the EOQ World Tour game, specifically designed to teach the Economic Order Quantity concept in Operations Management. The game addresses challenges in integrating Generative AI into mathematics in management education by combining human oversight and instructor control through three innovative features: (1) a Generative AI-based simulation, (2) a macropowered Excel worksheet for validating the calculations of an AI chatbot, and (3) a Google Sheets dashboard for centralizing team-generated AI data for postgame analysis. Our study included 41 students divided into experimental and control groups. Pretest results indicated no significant differences in baseline knowledge. However, the post-test results showed that the experimental group achieved a better understanding of inventory-related concepts and practical applications, along with higher engagement, excitement, confidence, and long-term knowledge retention.}
}
@article{GISIGER2000250,
title = {Computational models of association cortex},
journal = {Current Opinion in Neurobiology},
volume = {10},
number = {2},
pages = {250-259},
year = {2000},
issn = {0959-4388},
doi = {https://doi.org/10.1016/S0959-4388(00)00075-1},
url = {https://www.sciencedirect.com/science/article/pii/S0959438800000751},
author = {Thomas Gisiger and Stanislas Dehaene and Jean-Pierre Changeux},
abstract = {Recent computational models, or mathematical realizations of neurobiological theories, are providing insights into the organization and workings of the association cortex. Such models concern the construction of cortical maps, the neural basis of cognitive functions such as visual perception, reward-motivated learning and some aspects of consciousness.}
}
@article{COSTA20221810,
title = {Multicriteria analysis by PROMETHEE-SAPEVO-M1 method: choice of Brazilian sugar and ethanol plants for biomethane production},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {10},
pages = {1810-1815},
year = {2022},
note = {10th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.09.661},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322019796},
author = {Wallace L.T. Costa and Igor P.A. Costa and Adilson V. Terra and Miguel Â.L. Moreira and Carlos, F.S. Gomes and Marcos Santos},
keywords = {Multicriteria, PROMETHEE, SAPEVO, Energy, Biomethane},
abstract = {Given the need for cleaner energy sources associated with the ESG (Environmental, social and corporate governance) policy, the work in question is a case study referring to the project to expand biomethane production in national territory, especially for industrial commercialization. By applying the Value Focused Thinking (VFT) methodology, the study initially seeks the approach based on the values of decision-makers, these being three professionals in the energy sector. After the central objective of supporting decision-making, the hybrid method PROMETHEE-SAPEVO-M1 was used, characterized by the possibility of evaluating quantitative data and qualitative variables. To this end, the modeling occurred through the software of the PROMETHEE-SAPEVO-M1 method to clarify the best plants, because of the range of possibilities in the national territory, for project implementation and subsequent production of biomethane for industrial use. As a result, we verified that São Paulo is the best alternative for applying the investment in biomethane production.}
}
@article{2004263,
title = {Computational Statistics and Data Analysis},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {73},
number = {2},
pages = {263},
year = {2004},
issn = {0169-7439},
doi = {https://doi.org/10.1016/j.chemolab.2004.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169743904001820}
}
@article{FELLOWS2013541,
title = {Towards fully multivariate algorithmics: Parameter ecology and the deconstruction of computational complexity},
journal = {European Journal of Combinatorics},
volume = {34},
number = {3},
pages = {541-566},
year = {2013},
note = {Combinatorial Algorithms and Complexity},
issn = {0195-6698},
doi = {https://doi.org/10.1016/j.ejc.2012.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0195669812001400},
author = {Michael R. Fellows and Bart M.P. Jansen and Frances Rosamond},
abstract = {The aim of this article is to motivate and describe the parameter ecology program, which studies how different parameters contribute to the difficulty of classical problems. We call for a new type of race in parameterized analysis, with the purpose of uncovering the boundaries of tractability by finding the smallest possible parameterizations which admit FPT-algorithms or polynomial kernels. An extensive overview of recent advances on this front is presented for the Vertex Cover problem. Moving even beyond the parameter ecology program we advocate the principle of model enrichment, which raises the challenge of generalizing positive results to problem definitions with greater modeling power. The computational intractability which inevitably emerges can be deconstructed by introducing additional parameters, leading towards a theory of fully multivariate algorithmics.}
}