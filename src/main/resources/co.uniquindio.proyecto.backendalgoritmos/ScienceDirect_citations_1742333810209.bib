@article{HONG2024422,
title = {AF-FTTSnet: An end-to-end two-stream convolutional neural network for online quality monitoring of robotic welding},
journal = {Journal of Manufacturing Systems},
volume = {74},
pages = {422-434},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524000724},
author = {Yuxiang Hong and Xingxing He and Jing Xu and Ruiling Yuan and Kai Lin and Baohua Chang and Dong Du},
keywords = {Welding quality monitoring, Visual sensing, Molten pool, Defect prediction, Two-stream network},
abstract = {Online welding quality monitoring (WQM) is crucial for intelligent welding, and deep learning approaches considering spatiotemporal features for WQM tasks show great potential. However, one of the important challenges for existing approaches is to balance the spatiotemporal representation learning capability and computational efficiency, which makes it challenging to adapt welding processes with complex and drastic molten pool dynamic behavior. This paper proposes a novel approach for WQM using molten pool visual sensing and deep learning considering spatiotemporal features, the proposed deep learning network called attention fusion based frame-temporality two-stream network (AF-FTTSnet). Firstly, a passive vision sensor is used to acquire continuous dynamic molten pool images. Meanwhile, temporal difference images are computed to provide novel features and temporal representations. Then, a two-stream feature extraction module is designed to concurrently extract rich spatiotemporal features from molten pool images and temporal difference images. Finally, an attention fusion module with the ability to automatically identify and weight the most relevant features is designed to achieve optimal fusion of the two-stream features. The shop welding experimental results indicate that the proposed AF-FTTSnet model can effectively and robustly recognize five typical welding states during helium arc welding, with an accuracy of 99.26%. This model has been demonstrated to exhibit significant performance improvements compared to mainstream temporal sequence models. Available: https://github.com/Just199806/TSCNN/tree/master.}
}
@article{LAI2023101343,
title = {Optimization of urban and rural ecological spatial planning based on deep learning under the concept of sustainable development},
journal = {Results in Engineering},
volume = {19},
pages = {101343},
year = {2023},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2023.101343},
url = {https://www.sciencedirect.com/science/article/pii/S259012302300470X},
author = {Yilin Lai},
keywords = {Sustainable development, Spatial planning, Remote sensing images, CNN, GPU},
abstract = {At present, the speed of urbanization in China is constantly accelerating. At the same time, due to the severe situation of tight resource constraints, severe environmental pollution, and ecosystem degradation, vigorously promoting the construction of ecological civilization has become a key planning direction. However, traditional urban and rural ecological spatial planning is influenced by factors such as region, terrain, and spatial scale, which cannot adapt to the current spatial planning requirements. To achieve sustainable urban and rural ecological spatial planning, we propose a method that uses the optimized remote sensing images and convolutional neural networks to achieve spatial planning. In the analysis of the application effect of the usage method, the experimental results show that increasing the amount of data such as image size can improve the execution performance of the computer when the computer is not fully utilizing its resources and its computational volume fails to saturate the computational capacity. The parallel configuration designed in this experiment can accelerate the performance of the computer better, and the acceleration effect becomes more obvious as the difficulty of the algorithm increases. The Faster RCNN algorithm proposed in this experiment has the highest retrieval accuracy in the Flickr30K dataset and MS-COCO dataset compared with other algorithms. In Flickr30k data set, compared with other models in the table, the model used in this paper has the highest retrieval accuracy. The retrieval accuracy of R@1, R@5, R@10 increased by 23.1%, 8.1% and 5.3%, respectively. In MS-COCO data set, the retrieval accuracy increased by 19.2%, 13.1% and 8.3% respectively. The above results confirm that the combination of remote sensing images and convolutional neural network technology can perform simple ecological planning of a city's urban and rural areas, which proves that the method proposed in this experiment has practicality.}
}
@article{MULLER1987271,
title = {Computational problems in supernova simulations},
journal = {Computer Physics Communications},
volume = {44},
number = {3},
pages = {271-277},
year = {1987},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(87)90082-8},
url = {https://www.sciencedirect.com/science/article/pii/0010465587900828},
author = {Ewald Müller},
abstract = {Theoretical models of type I and type II supernova explosions are reviewed from a computational physics point of view. After discussing briefly the underlying physics the numerical problems and challenges encountered in the simulation of type I and type II supernova are addressed.}
}
@article{1991202,
title = {Use of computational methods in drug design},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {11},
number = {2},
pages = {202-203},
year = {1991},
issn = {0169-7439},
doi = {https://doi.org/10.1016/0169-7439(91)80072-X},
url = {https://www.sciencedirect.com/science/article/pii/016974399180072X}
}
@article{LAWRENCE2023100786,
title = {Translational argument technology: Engineering a step change in the argument web},
journal = {Journal of Web Semantics},
volume = {77},
pages = {100786},
year = {2023},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2023.100786},
url = {https://www.sciencedirect.com/science/article/pii/S157082682300015X},
author = {John Lawrence and Jacky Visser and Chris Reed},
keywords = {Argumentation, Argument analytics, Argument mining, Argument technology, Argument web, Debate technology},
abstract = {Following the establishment in 2006 of a representational standard for the computational handling of structures of argumentation, the Argument Interchange Format, it became possible to develop a vision for the coherent integration of multifarious services, components and tools that create, consume, navigate, analyse, evaluate and manipulate arguments and debates. This vision was the Argument Web with theoretical foundations laid by Rahwan et al. (2007), and practical engineering work described by Bex et al. (2013). Over the intervening period, the key challenge has been to demonstrate the practical and societal value of the Argument Web by taking its tools and applications to larger audiences. This paper lays out three approaches by which the Argument Web has been scaled up in this way, each in partnership with the BBC, and each with different kinds of evaluation and impact. Transitioning these technologies to large user groups paves the way for broader-scale uptake of the Argument Web and heralds the translation from lab to real-world application for a substantial research community working in argument technology.}
}
@article{YANG20163,
title = {Modeling Urban Design with Energy Performance},
journal = {Energy Procedia},
volume = {88},
pages = {3-8},
year = {2016},
note = {CUE 2015 - Applied Energy Symposium and Summit 2015: Low carbon cities and urban energy systems},
issn = {1876-6102},
doi = {https://doi.org/10.1016/j.egypro.2016.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S1876610216300662},
author = {Perry Pei-Ju Yang and Jinyue Yan},
keywords = {Urban design computational model, Energy process model, Urban energy system, Urban design, Energy performance},
abstract = {Traditional urban design methods focus on the form-making process and lack performance dimensions such as energy efficiency. There are inherent differences between Urban Design as a model of decision-making for choosing form alternatives and Energy System Modeling as a model of evaluating and assessing system functions. To design a high energy performance city, the gap between the two models must be bridged. We propose a research design that combines the Urban Design Computational Model (UDCM) and the Optimization Model of Energy Process (OMEP) to demonstrate how an urban design computation can be integrated with an energy performance process and system. An evidence-based case study of community-level near zero energy districts will be needed for future work.}
}
@article{THOMPSON2024100094,
title = {Alzheimer’s disease and the mathematical mind},
journal = {Brain Multiphysics},
volume = {6},
pages = {100094},
year = {2024},
issn = {2666-5220},
doi = {https://doi.org/10.1016/j.brain.2024.100094},
url = {https://www.sciencedirect.com/science/article/pii/S2666522024000054},
author = {Travis B. Thompson and Bradley Z. Vigil and Robert S. Young},
keywords = {Alzheimer’s disease, Mathematical modeling, Scientific computing},
abstract = {Throughout the 19th and 20th centuries, aided by advances in medical imaging, discoveries in physiology and medicine have added nearly 25 years to the average life expectancy. This resounding success brings with it a need to understand a broad range of age-related health conditions, such as dementia. Today, mathematics, neuroimaging and scientific computing are being combined with fresh insights, from animal models, to study the brain and to better understand the etiology and progression of Alzheimer’s disease, the most common cause of age-related dementia in humans. In this manuscript, we offer a brief primer to the reader interested in engaging with the exciting field of mathematical modeling and scientific computing to advance the study of the brain and, in particular, human AD research. Statement of Significance Modeling Alzheimer’s disease is a highly interdisciplinary field and finding an effective starting point can be a considerable challenge. To address this challenge, this manuscript briefly highlights some central components of AD related protein pathology, useful classes of mathematical models for brain and AD research and effective computational resources for the practical prospective practitioner.}
}
@article{CHEN2024e26409,
title = {Physiological records-based situation awareness evaluation under aviation context: A comparative analysis},
journal = {Heliyon},
volume = {10},
number = {5},
pages = {e26409},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e26409},
url = {https://www.sciencedirect.com/science/article/pii/S240584402402440X},
author = {Jun Chen and Anqi Chen and Bingkun Jiang and Xinyu Zhang},
keywords = {Situation awareness, Electroencephalogram, Brain electrical activity mapping, Convolutional neural network, Multi-class classification, Aviation decision-making},
abstract = {Situational Awareness (SA) assessment is of paramount importance in various domains, with particular significance in the military for safe aviation decision-making. It involves encompassing perception, comprehension, and projection levels in human beings. Accurate evaluation of SA statuses across these three levels is crucial for mitigating human false-positive and false-negative rates in monitoring complex scenarios in the aviation context. This study proposes a comprehensive comparative analysis by involving two types of physiological records: electroencephalogram (EEG) signals and brain electrical activity mapping (BEAM) images. These two modalities are leveraged to automate precise SA evaluation using both conventional machine learning and advanced deep learning techniques. Benchmarking experiments reveal that the BEAM-based deep learning models attain state-of-the-art performance scores of 0.955 for both SA perception and comprehension levels, respectively. Conversely, the EEG signals-based manual feature extraction, selection, and classification approach achieved a superior accuracy of 0.929 for the projection level of SA. These findings collectively highlight the potential of deploying diverse physiological records as valuable computational tools for enhancing SA evaluation throughout aviation decision-making safety.}
}
@article{SAYALI2023614,
title = {The costs and benefits of psychedelics on cognition and mood},
journal = {Neuron},
volume = {111},
number = {5},
pages = {614-630},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322011527},
author = {Ceyda Sayalı and Frederick S. Barrett},
keywords = {psychedelics, cognitive control, meta-control, creativity, cognitive flexibility, cognitive stability, dopamine, serotonin, dose-dependency, baseline dependency},
abstract = {Summary
Anecdotal evidence has indicated that psychedelic substances may acutely enhance creative task performance, although empirical support for this claim is mixed at best. Clinical research has shown that psychedelics might have enduring effects on mood and well-being. However, there is no neurocognitive framework that ties acute changes in cognition to long-term effects in mood. In this review, we operationalize creativity within an emerging cognitive control framework and assess the current empirical evidence of the effects of psychedelics on creativity. Next, we leverage insights about the mechanisms and computations by which other psychoactive drugs act to enhance versus impair cognition, in particular to those that act on catecholamines, the neurophysiological consequences of which are relatively well understood. Finally, we use the same framework to link the suggested psychedelic-induced improvements in creativity with enduring psychedelic-induced improvements in mood.}
}
@article{VERDECCHIA2022100767,
title = {The future of sustainable digital infrastructures: A landscape of solutions, adoption factors, impediments, open problems, and scenarios},
journal = {Sustainable Computing: Informatics and Systems},
volume = {35},
pages = {100767},
year = {2022},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2022.100767},
url = {https://www.sciencedirect.com/science/article/pii/S2210537922000889},
author = {Roberto Verdecchia and Patricia Lago and Carol {de Vries}},
keywords = {Sustainability, Green IT, Energy efficiency, Digital infrastructures, Data centers, Cloud, Landscape, Qualitative research},
abstract = {Background:
Digital infrastructures, i.e., ICT systems, or system-of-systems, providing digital capabilities, such as storage and computational services, are experiencing an ever-growing demand for data consumption, which is only expected to increase in the future. This trend leads to a question we need to answer: How can we evolve digital infrastructures to keep up with the increasing data demand in a sustainable way?
Objective:
The goal of this study is to understand what is the future of sustainable digital infrastructures, in terms of: which solutions are, or will be, available to sustainably evolve digital infrastructures, and which are the related adoption factors, impediments, and open problems.
Method:
We carried out a 3-phase mixed-method qualitative empirical study, comprising semi-structured interviews, followed by focus groups, and a plenary session with parallel working groups. In total, we conducted 13 sessions involving 48 digital infrastructure practitioners and researchers.
Results:
From our investigation emerges a landscape for sustainable digital infrastructures, composed of 30 solutions, 5 adoption factors, 4 impediments, and 13 open problems. We further synthesized our results in 4 incremental scenarios, which outline the future evolution of sustainable digital infrastructures.
Conclusions:
From an initial shift from on-premise to the cloud, as time progresses, digital infrastructures are expected to become increasingly distributed, till it will be possible to dynamically allocate resources by following time, space, and energy. Numerous solutions will support this change, but digital infrastructures are envisaged to be able to evolve sustainably only by (i) gaining a wider awareness of digital sustainability, (ii) holding every party accountable for their sustainability throughout value chains, and (iii) establishing cross-domain collaborations.}
}
@article{HUSSAIN2025109490,
title = {A neural network integrated mathematical model to analyze the impact of nutritional status on cognitive development of child},
journal = {Computers in Biology and Medicine},
volume = {185},
pages = {109490},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.109490},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524015750},
author = {Zakir Hussain and Malaya Dutta Borah},
keywords = {Cognitive development, Cognition, Nutritional status, Neural network, Mathematical model},
abstract = {Cognitive development is a crucial developmental aspect of children. It is a concise field of study in psychology and neuroscience that focuses on various developmental aspects of the brain. Among all other factors, nutritional status is believed to play a very important role in cognitive development. The purpose of this work is to analyze the impacts of different nutritional status levels on the child’s cognitive development. This work designs a model that uses a neural network and differential equations. The neural network is applied on a dataset called “Child Birth Weight Dataset” available at IEEE Dataport ( http://dx.doi.org/10.21227/dvd4-3232) for finding the nutritional status of a child. The different levels of nutritional status, such as low-nutritional status, normal-nutritional status, and over-nutritional status are integrated with the formulated differential equations. The model is computationally simulated considering four different sets of parameter values that represent four different perspectives such as ‘only positive’, ‘only negative’, ‘mix and unequal weight’, and ‘mix and equal weight’ of the influencing factors. The experimental results show that normal-nutritional status is the best nutritional status for cognitive development. However, the best cognitive development happens when all other influencing factors like environmental effects, socioeconomic status, heredity, learning opportunities, and use of experiences are given equal importance. The results also depict that the low- and over-nutritional status cannot restrict cognitive development for a long time. After a certain period, the development gets triggered and it happens. It may be slow and not up to the mark of the development under normal-nutritional status, but it happens. Simply it can be said that nutritional status alone does not have control over the cognitive development of a child. Along with nutritional status, other influencing factors are important too.}
}
@article{WU2020107246,
title = {miRNA-324/-133a essential for recruiting new synapse innervations and associative memory cells in coactivated sensory cortices},
journal = {Neurobiology of Learning and Memory},
volume = {172},
pages = {107246},
year = {2020},
issn = {1074-7427},
doi = {https://doi.org/10.1016/j.nlm.2020.107246},
url = {https://www.sciencedirect.com/science/article/pii/S1074742720300903},
author = {Ruixiang Wu and Shan Cui and Jin-Hui Wang},
keywords = {Associative learning, Memory cell, Neural circuit, Barrel cortex, Piriform cortex},
abstract = {After the integrative storage of associated signals, a signal induces the recollection of its associated signal, or the other way around. This associative memory is essential to associative thinking, logical reasoning, imagination and computation. In terms of cellular mechanisms underlying associative memory, new mutual synapse innervations are formed among those coactivated neurons, so that they are recruited to be associative memory cells or associative memory neurons. These associative memory cells receive new synapse innervations alongside innate synapse inputs and encode signals carried by these inputs. We proposed to examine microRNAs as initiative factors for recruiting new synapse innervations and associative memory cells. In a mouse model of associative memory characterized as the reciprocal retrieval of associated whisker and odor signals, barrel and piriform cortical neurons gain their ability to encode whisker and odorant signals based on the newly formed synapse innervations between these coactivated cortices besides innate synapse inputs. miRNA-324 and miRNA-133a are required for recruiting these new synapse innervations and associative memory cells as well as sufficient for facilitating their recruitments, but not for innate synapse inputs. Therefore, the coactivation of sensory cortices through microRNA as initiative factor to recruit new mutual synapse innervations and associative memory cells for associative memory.}
}
@article{DUAN2024101258,
title = {Concept cognition for knowledge graphs: Mining multi-granularity decision rule},
journal = {Cognitive Systems Research},
volume = {87},
pages = {101258},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101258},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724000524},
author = {Jiangli Duan and Guoyin Wang and Xin Hu and Qun Liu and Qin Jiang and Huamin Zhu},
keywords = {Granular computing, Cognitive intelligence, Concept cognition, Knowledge graph, Decision rule},
abstract = {As part of cognitive intelligence, concept cognition for knowledge graphs aims to clearly grasp the typical characteristics of the things referred to by the concept, which can provide prior knowledge for machine understanding and thinking. Different from concept learning and formal concept analysis that learn new concepts from data and the general decision rule that comes from an independent decision table, this paper cognizes an existing concept by decision rules that come from multiple granularities. Specifically, 1) concept cognition for knowledge graphs is realized from the perspective of mining multi-granularity decision rule. 2) Decision tables corresponding to four granularities form a multi-granularity decision table group, and then the result from coarser granularity can guide and help obtaining the result from finer granularity. 3) We propose a framework for mining multi-granularity decision rules, which involves going from a multi-granularity decision table group to the frequent maximal attribute patterns to the decision rules to the credible decision rules. Finally, we verified effectiveness of dividing positive and negative data, monotonicity of attribute patterns in a multi-granularity decision table group, and downward monotonicity of credibility, and observed the impact of the parameter min_cov and min_conf on execution times.}
}
@article{KNIGHT20158,
title = {Making grammars: From computing with shapes to computing with things},
journal = {Design Studies},
volume = {41},
pages = {8-28},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000605},
author = {Terry Knight and George Stiny},
keywords = {computational model(s), design theory, perception, reflective practice, shape grammar},
abstract = {Recent interest in making and materiality spans from the humanities and social sciences to engineering, science, and design. Here, we consider making through the lens of a unique computational theory of design: shape grammars. We propose a computational theory of making based on the improvisational, perception and action approach of shape grammars and the shape algebras that support them. We modify algebras for the materials (basic elements) of shapes to define algebras for the materials of objects, or things. Then we adapt shape grammars for computing shapes to making grammars for computing things. We give examples of making grammars and their algebras. We conclude by reframing designing and making in light of our computational theory of making.}
}
@incollection{SARSANI2011231,
title = {Computers and Creativity},
editor = {Mark A. Runco and Steven R. Pritzker},
booktitle = {Encyclopedia of Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {231-240},
year = {2011},
isbn = {978-0-12-375038-9},
doi = {https://doi.org/10.1016/B978-0-12-375038-9.00041-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123750389000418},
author = {M.R. Sarsani},
keywords = {Approaches to creativity, Computer applications, Computer functions, Computers, Computers and creativity, Creativity definitions, Metaphor, Problem solving, Productivity tools},
abstract = {Computers have entered all walks of human life across the world. Computers are being used by people of all ages and in every profession, in their work as well as in their leisure. There is growing interest in the application of computer-based productivity tools to support simulation effects, higher level thinking, metacognitive processes, maintaining interest, promoting learning, developing curiosity, and fostering creativity. The Internet has brought abort a revolution in the world of information technology by providing searching facilities for exploring or seeking information from all over the world (e.g., e-learning, e-shopping, e-mail, Telnet and Usenet, audio and video conferences, etc.). Different viewpoints have been put forward to explain the concept, emphasizing different aspects of creativity. Generally, creativity has been discussed in terms of its end product, creative person, creative process, and creative press or environments. There are no substantial researches directly measuring the effect of the computer simulation technology to support either uncreative drill or creative production. Some researchers speculate that computer simulation technology may have a positive effect on creativity. However, due to a lack of empirical research, the true effect of simulation technology on creativity is still unknown and inconclusive.}
}
@article{DING2012264,
title = {Finding MicroRNA Targets in Plants: Current Status and Perspectives},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {10},
number = {5},
pages = {264-275},
year = {2012},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2012.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1672022912000733},
author = {Jiandong Ding and Shuigeng Zhou and Jihong Guan},
keywords = {MicroRNA, Target prediction, Degradome-seq, Integration},
abstract = {MicroRNAs (miRNAs), a class of ∼20–24nt long non-coding RNAs, have critical roles in diverse biological processes including development, proliferation, stress response, etc. With the development and availability of experimental technologies and computational approaches, the field of miRNA biology has advanced tremendously over the last decade. By sequence complementarity, miRNAs have been estimated to regulate certain mRNA transcripts. Although it was once thought to be simple and straightforward to find plant miRNA targets, this viewpoint is being challenged by genetic and biochemical studies. In this review, we summarize recent progress in plant miRNA target recognition mechanisms, principles of target prediction, and introduce current experimental and computational tools for plant miRNA target prediction. At the end, we also present our thinking on the outlook for future directions in the development of plant miRNA target finding methods.}
}
@article{YANG2022107728,
title = {Mixed data-driven sequential three-way decision via subjective–objective dynamic fusion},
journal = {Knowledge-Based Systems},
volume = {237},
pages = {107728},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107728},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121009692},
author = {Xin Yang and Yang Chen and Hamido Fujita and Dun Liu and Tianrui Li},
keywords = {Three-way decision, Sequential three-way decision, Mixed data, subjective–objective, Dynamic fusion},
abstract = {In the context of granular computing, sequential three-way decision is a useful tool to triadic thinking, triadic computing and triadic processing from coarser to finer under multilevel and multiview granularity space. In this paper, we mainly explore a novel framework of sequential three-way decision for the fusion of mixed data from the subjective and objective dynamic perspectives. The former focuses on the decision maker’s dynamic behavior without considering the time-evolving data, and the latter emphasizes on dealing with dynamic mixed data over time by multi-stage decision-making. We firstly utilize four T-norm operators and kernel-based similarity relations to integrate different types of dynamic data. Then the subjective and objective models of sequential three-way decision are investigated based on decision thresholds, attribute importance and cost reduction. Finally, the comparative experiments are reported to verify that our proposed models can achieve the lower decision cost and the acceptable accuracy.}
}
@article{ALI2024100170,
title = {A conceptual IoT framework based on Anova-F feature selection for chronic kidney disease detection using deep learning approach},
journal = {Intelligence-Based Medicine},
volume = {10},
pages = {100170},
year = {2024},
issn = {2666-5212},
doi = {https://doi.org/10.1016/j.ibmed.2024.100170},
url = {https://www.sciencedirect.com/science/article/pii/S2666521224000371},
author = {Md Morshed Ali and Md Saiful Islam and Mohammed Nasir Uddin and Md. Ashraf Uddin},
keywords = {IoT Framework, Machine learning, Deep learning, Feature selection techniques, ANOVA F-test, Healthcare technology, Medical diagnosis, Kidney disease prediction, Classification},
abstract = {Chronic kidney disease (CKD) is becoming an increasingly significant health issue, especially in low-income countries where access to affordable treatment is limited. Additionally, CKD is associated with various dietary factors, including liver failure, diabetes, anemia, nerve damage, inflammation, peroxidation, obesity, and other related conditions. Therefore, early prediction of CKD is important to progress the functionality of the kidney. In recent times, IoT has been widely used in a diversity of healthcare sectors through the incorporation of monitoring devices such as digital sensors and medical devices for patient monitoring from remote places. To overcome the problem, this research proposed a conceptual architecture for CKD detection. The sensor layer of the architecture includes IoT devices to collect data and the proposed classifier, MLP (Multi-Layer Perceptron), utilizes the Anova-F feature selection technique to effectively detect CKD (Chronic Kidney Disease). In addition to MLP, four other classifiers including ANN (Artificial Neural Network), Simple RNN (Recurrent Neural Network), GRU (Gated Recurrent Unit), and SVM (Support Vector Machine), are employed for comparative analysis of accuracy. Furthermore, three additional feature selection techniques, namely Chi-squared, SFFS (Sequential Floating Forward Selection), and SBFS (Sequential Backward Floating Selection), are utilized to evaluate their impact on the accuracy of CKD detection. Our proposed method outperforms all other approaches with a remarkable accuracy of 99 % while maintaining efficient computational time. This advancement is crucial in developing a highly accurate machine capable of predicting CKD in remote areas with ease.}
}
@article{HELBING2023102061,
title = {Democracy by Design: Perspectives for Digitally Assisted, Participatory Upgrades of Society},
journal = {Journal of Computational Science},
volume = {71},
pages = {102061},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102061},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001217},
author = {Dirk Helbing and Sachit Mahajan and Regula Hänggli Fricker and Andrea Musso and Carina I. Hausladen and Cesare Carissimo and Dino Carpentras and Elisabeth Stockinger and Javier {Argota Sanchez-Vaquerizo} and Joshua C. Yang and Mark C. Ballandies and Marcin Korecki and Rohit K. Dubey and Evangelos Pournaras},
keywords = {Computational diplomacy, Digital democracy, Participation, Collective intelligence, Value-based engineering},
abstract = {The technological revolution, particularly the availability of more data and more powerful computational tools, has led to the emergence of a new scientific field called “Computational Diplomacy”. Our work tries to define its scope and focuses on a popular subarea of it, namely “Digital Democracy”. In recent years, there has been a surge of interest in using digital technologies to promote more participatory forms of democracy. While there are numerous potential benefits to using digital tools to enhance democracy, significant challenges must be addressed. It is essential to ensure that digital technologies are used in an accessible, equitable, and fair manner rather than reinforcing existing power imbalances. This paper investigates how digital tools can be used to help design more democratic societies by investigating three key research areas: (1) the role of digital technologies for facilitating civic engagement in collective decision-making; (2) the use of digital tools to improve transparency and accountability in governance; and (3) the potential for digital technologies to enable the formation of more inclusive and representative democracies. We argue that more research on how digital technologies can be used to support democracy upgrade is needed. Along these lines, we lay out a research agenda for the future.}
}
@article{ELIAZ2010304,
title = {Paying for confidence: An experimental study of the demand for non-instrumental information},
journal = {Games and Economic Behavior},
volume = {70},
number = {2},
pages = {304-324},
year = {2010},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2010.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0899825610000229},
author = {Kfir Eliaz and Andrew Schotter},
abstract = {This paper presents experimental evidence that when individuals are about to make a given decision under risk, they are willing to pay for information on the likelihood that this decision is ex-post optimal, even if this information will not affect their decision. Our findings suggest that this demand for non-instrumental information is caused by what we refer to as a “confidence effect”: the desire to increase one's posterior belief by ruling out “bad news”, even when such news would have no effect on one's decision. We conduct various treatments to show that our subjects' behavior is not likely to be caused by an intrinsic preference for information, failure of backward induction or an attempt to minimize thinking costs.}
}
@incollection{ZIELINSKI2024116,
title = {Coupled-Cluster Theories for Excited States},
editor = {Manuel Yáñez and Russell J. Boyd},
booktitle = {Comprehensive Computational Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {116-140},
year = {2024},
isbn = {978-0-12-823256-9},
doi = {https://doi.org/10.1016/B978-0-12-821978-2.00035-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128219782000350},
author = {Patrik Zielinski and Andreas Köhn},
keywords = {Accurate computations, Analytic gradients, Basis-set convergence, Benchmark computations, Cluster expansion, Coupled-cluster theory, Equation of motion, Excited-state properties, Gradient theory, Linear response, Multireference, Open-shell systems, Single-reference, Size consistency, Transition moments},
abstract = {Coupled-cluster theory offers a hierarchy of increasingly accurate methods and provides thus an important basis for accurate quantum chemistry, also for the computation of electronic excited states. This chapter explains and compares the two main approaches, equation-of-motion and linear-response theory and sketches the computation of transition moments and expectation values, as well as analytic geometric gradients. The basic approaches to arrive at approximations are discussed, and recent benchmark works are used to demonstrate their relative accuracy. Some challenges in coupled-cluster theory, like going to large systems, open-shell and multireference theory and the slow basis-set convergence are also covered.}
}
@article{SCHEFFLER201575,
title = {NeurOS™ and NeuroBlocks™ a neural/cognitive operating system and building blocks},
journal = {Biologically Inspired Cognitive Architectures},
volume = {11},
pages = {75-105},
year = {2015},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2014.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X14000747},
author = {Lee Scheffler},
keywords = {Cognition, Perception, Pattern recognition, Memory, Learning, Behavior},
abstract = {NeurOS is an open platform for accelerating research, development and hosting execution of intelligent applications. A NeurOS application is a directed “neural graph” of modular components connected by signal paths, similar to biological brain connectivity and functional block diagrams of neural pathways. Built-in reusable modules (NeuroBlocks) provide a wide range of general- and special-purpose capabilities: inputs/senses, outputs/effectors, processing, memory, pattern learning and recognition, visualization/instrumentation, custom module development, integrating external intelligence capabilities, and sub-graph reuse. NeurOS sub-graph assemblies address neural/cognitive functions including perception, pattern learning and recognition, working memory, imagination, prediction, context priming, attention, abstraction, classification, associational thinking and behavior. NeurOS applications are inherently portable, scalable, networkable, extensible and embeddable. NeurOS development tools provide simple intuitive graphical drag and drop application assembly from components without programming, along with testing, debugging, monitoring and visualization. Prototype NeurOS applications have begun to explore a wide range of intelligent functions in diverse areas, including aspects of pattern recognition, vision, music, reading, puzzle solving, reasoning, behavior. Building working intelligent systems using NeurOS and NeuroBlocks lets researchers and developers focus on their core functions and rapidly iterate and instrument working models, fostering both analytical and biological insight as well as usable systems.}
}
@incollection{BUTTON199067,
title = {Chapter 4 - Going Up a Blind Alley: Conflating Conversation Analysis and Computational Modelling},
editor = {PAUL LUFF and NIGEL GILBERT and DAVID FROHLICH},
booktitle = {Computers and Conversation},
publisher = {Academic Press},
address = {London},
pages = {67-90},
year = {1990},
isbn = {978-0-08-050264-9},
doi = {https://doi.org/10.1016/B978-0-08-050264-9.50009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080502649500099},
author = {Graham Button},
abstract = {Publisher Summary
This chapter discusses the desirability of developing computational models of conversational phenomena, and the supportive role given to conversation analysis (CA) in the development of such models. The arguments presented in this chapter are not an attempt to restrict the range of creative resources that software designers might turn to for inspiration. In particular, it is implicitly endorsed in the attempts to develop descriptively adequate models of conversation for use in computer systems, and explicitly endorsed when it is argued that by providing a simulacrum of conversation one has naturally occurring conversation between computers and humans. The attraction of CA for people who want to develop rules of conversational organization that can be used to program computers is two-fold: (1) CA might seem to provide a ready-made package of conversational rules that they can use or adapt for their purposes; and (2) their models may be authorized by appealing to CA. However, CA is used to authorize computational models of conversation that misrepresent the details of how conversation works.}
}
@article{RULE2020900,
title = {The Child as Hacker},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {11},
pages = {900-915},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320301741},
author = {Joshua S. Rule and Joshua B. Tenenbaum and Steven T. Piantadosi},
keywords = {Learning and cognitive development, Language of thought, Hacking, Computational modeling, Program induction},
abstract = {The scope of human learning and development poses a radical challenge for cognitive science. We propose that developmental theories can address this challenge by adopting perspectives from computer science. Many of our best models treat learning as analogous to computer programming because symbolic programs provide the most compelling account of sophisticated mental representations. We specifically propose that children’s learning is analogous to a particular style of programming called hacking, making code better along many dimensions through an open-ended set of goals and activities. By contrast to existing theories, which depend primarily on local search and simple metrics, this view highlights the many features of good mental representations and the multiple complementary processes children use to create them.}
}
@article{CHERNYSHOV20151345,
title = {Information Support and Skill Evaluation of Human-Operators},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {3},
pages = {1345-1350},
year = {2015},
note = {15th IFAC Symposium onInformation Control Problems inManufacturing},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.06.273},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315005121},
author = {K.R. Chernyshov and E.Ph Jharko},
keywords = {Human-operator, Information support, Flexible simulation, Evaluation of skills, Random processes, Measures of dependence},
abstract = {The paper presents an approach to design an intelligent information support system to be used as a human-operator assistant to control large complex industrial plants. Tasks and structure of such an intelligent information support system (IISS), IISS design stages, methodology of IISS design, toolkits for IISS design are considered. A flexible simulation complex (FSC) as such an intelligent toolkit has been presented. The complex is used as a “kernel” of IISS for human-operators of a nuclear power plant. A new approach to abnormal situations with regard for the heuristic regularities of human-operator thinking process is proposed. The regularities are revealed on basis of recording the motions of the human- operator eyes over the information field of the control board and processing the experimental data obtained. For data processing, a probability theoretical approach is used based on involving the notion of consistency of measures of dependence of random variables.}
}
@article{MARITAN2022167351,
title = {Building Structural Models of a Whole Mycoplasma Cell},
journal = {Journal of Molecular Biology},
volume = {434},
number = {2},
pages = {167351},
year = {2022},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2021.167351},
url = {https://www.sciencedirect.com/science/article/pii/S002228362100588X},
author = {Martina Maritan and Ludovic Autin and Jonathan Karr and Markus W. Covert and Arthur J. Olson and David S. Goodsell},
keywords = {whole cell modeling, computational modeling, nucleoid structure, scientific visualization, mycoplasma genitalium},
abstract = {Building structural models of entire cells has been a long-standing cross-discipline challenge for the research community, as it requires an unprecedented level of integration between multiple sources of biological data and enhanced methods for computational modeling and visualization. Here, we present the first 3D structural models of an entire Mycoplasma genitalium (MG) cell, built using the CellPACK suite of computational modeling tools. Our model recapitulates the data described in recent whole-cell system biology simulations and provides a structural representation for all MG proteins, DNA and RNA molecules, obtained by combining experimental and homology-modeled structures and lattice-based models of the genome. We establish a framework for gathering, curating and evaluating these structures, exposing current weaknesses of modeling methods and the boundaries of MG structural knowledge, and visualization methods to explore functional characteristics of the genome and proteome. We compare two approaches for data gathering, a manually-curated workflow and an automated workflow that uses homologous structures, both of which are appropriate for the analysis of mesoscale properties such as crowding and volume occupancy. Analysis of model quality provides estimates of the regularization that will be required when these models are used as starting points for atomic molecular dynamics simulations.}
}
@article{SCHWABER1993126,
title = {Computational modeling of neuronal dynamics for systems analysis: application to neurons of the cardiorespiratory NTS in the rat},
journal = {Brain Research},
volume = {604},
number = {1},
pages = {126-141},
year = {1993},
issn = {0006-8993},
doi = {https://doi.org/10.1016/0006-8993(93)90359-U},
url = {https://www.sciencedirect.com/science/article/pii/000689939390359U},
author = {J.S. Schwaber and E.B. Graves and J.F.R. Paton},
keywords = {Nucleus tractus solitarii, Systems modeling, Cardiovascular reflex, Neuronal dynamics},
abstract = {The study constructs computational models of neurons in order to examine the contribution that their response dynamics may make to functional properties at the system level. As described in the accompanying study, neurons in the cardiorespiratory nucleus tractus solitarii (NTS) of the rat were recorded in vitro. When these cells were intracellularly injected with a constant current pulse, spike discharge patterns and subthreshold voltage trajectories were observed that were time- and voltage-dependent. The accompanying manuscript describes these dynamic responses in 4 classes of putative second-order cells that appear to receive direct primary afferent input, and a previous paper described two populations of rhythmically firing interneurons, one of which is intrinsically auto-active. In the present manuscript experimental neuronal voltage response data was collected across a current injection series for the S3 neuron type described in the accompanying study and for the auto-active neuron described previously. Using this data, computational model neurons have been constructed for these two neurons by using membrane ion channels to produce and match the observed neuronal voltage behavior. The channels were those implicated in the dynamic responses observed in the companion study, and include gNafast, gKdr, gKA, gKCa, gKAHP, gKM, gCaT and gCaL. The description of channel kinetics follows the Hodgkin-Huxley form. Different neuronal sources from the literature of channel kinetics were investigated and assembled into a ‘channel kinetics library’ from which both neuron models were tuned, primarily by adjusting the maximum channel densities, g¯, and time-dependence of kinetics. Methods are described for tuning the channel kinetics library to match various physiological responses. This approach created neuron models that were able to closely replicate the observed complex voltage and spiking responses of the two very different cardiorespiratory NTS neurons. The interaction of voltage- and calcium-dependent conductances were analyzed for their functional contributions by tuning their kinetics. Specific parameters are given that account for the behavior of each model. Sensitivity analyses by perturbing KCa and KA are are shown for both neurons, and I/F curves are presented for the auto-active neuron's simulated and recorded responses. The potential systems-level functional implications resulting from the different kinetics is demonstrated by driving the S3 model neuron in simulation with the pattern of input produced by model primary baroreceptor afferents. The limitations and significance of this approach are discussed. The present study of model neurons are being extended to the larger family of neurons found in the cardiorespiratory NTS (e.g. S1, S2 and S4), are being related to the baroreceptor vagal reflex by in vivo studies, and are being used to explore systems level computation, for example by creating networks reflecting baroreceptor reflex organization. The present kinetics library in principle could be used in this way for other neuronal systems.}
}
@article{BORDY201329,
title = {Radiotherapy out-of-field dosimetry: Experimental and computational results for photons in a water tank},
journal = {Radiation Measurements},
volume = {57},
pages = {29-34},
year = {2013},
note = {Proceedings of the Workshop: Dosimetry for Second Cancer Risk Estimation EURADOS Annual Meeting Vienna 2012},
issn = {1350-4487},
doi = {https://doi.org/10.1016/j.radmeas.2013.06.010},
url = {https://www.sciencedirect.com/science/article/pii/S1350448713002710},
author = {J.M. Bordy and I. Bessieres and E. d'Agostino and C. Domingo and F. d'Errico and A. {di Fulvio} and Ž. Knežević and S. Miljanić and P. Olko and A. Ostrowsky and B. Poumarede and S. Sorel and L. Stolarczyk and D. Vermesse},
keywords = {Radiotherapy, Photon dosimetry, Out of field doses, Scatter radiation, Leakage},
abstract = {The first objective of this work was to check and select a set of four kinds of passive photon, dosimeters (two thermo-luminescence dosimeter (TLD) types, one radiophotoluminescence (RPL) dosimeter and one optically stimulated luminescence (OSL) dosimeter) together with a common measurement protocol. Dosimeters were calibrated in a reference clinical linear acccelerator beam in a water tank at a reference facility at the Laboratoire National Henri Becquerel (CEA LIST/LNE LNHB, Saclay. Radiation qualities of 6, 12 and 20 MV were used with standard calibration conditions described in IAEA TRS 398 and non-standard conditions. Profile and depth dose ion chamber measurements were also made to provide reference values. Measurements were made in a water tank into which pipes could be inserted which held dosimeters in pre-determined and reproducible positions. The water tank was built to enable investigation of doses up to 60 cm from the beam axis. A first set of experiments was carried out with the beam passing through the tank. From this first experiment, penumbra and out-of-field dose profiles including water and collimator scatter and leakage were found over three orders of magnitude. Two further sets of experiments using the same experimental arrangement with the beam outside the tank, to avoid water scatter, were designed to measure collimator scatter and leakage by closing the jaws of the collimator. Depending on the energy, typical leakage and collimator scatter represents 10–40% and 30–50% of the total out-of-field doses respectively. It was concluded that all dosimeters can be used for out-of-field photon dosimetry. All show good uniformity, good reproducibility, and can be used down to low doses expected at distances remote from the subsequent radiotherapy target volume.}
}
@incollection{KOCH2009125,
title = {Consciousness: Theoretical and Computational Neuroscience},
editor = {Larry R. Squire},
booktitle = {Encyclopedia of Neuroscience},
publisher = {Academic Press},
address = {Oxford},
pages = {125-130},
year = {2009},
isbn = {978-0-08-045046-9},
doi = {https://doi.org/10.1016/B978-008045046-9.00407-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080450469004071},
author = {C. Koch and G. Tononi},
abstract = {Consciousness is a puzzling, state-dependent property of certain types of complex, adaptive, and highly interconnected systems. The best example is a healthy and attentive human brain. If the brain is anesthetized, consciousness ceases. Small lesions in the midbrain and thalamus of patients can lead to a complete loss of consciousness, while destruction of circumscribed parts of the cerebral cortex of patients can eliminate very specific aspects of consciousness, such as the ability to be aware of motion or to recognize objects (e.g., faces), without a concomitant loss of consciousness in general. Given the similarity in brain structure and behavior, biologists commonly assume that at least some animals, in particular nonhuman primates, share certain aspects of consciousness with humans. Brain scientists are exploiting a number of empirical approaches that shed light on the neural basis of consciousness. At present, it is not known to what extent artificial systems, such as computers, robots, or the World Wide Web as a whole, are or can become ‘conscious.’ What is needed is a theory of consciousness that explains in quantitative terms what types of systems, with what architecture, can possess conscious states.}
}
@article{DARICI2024123327,
title = {How will I break AI? Post-Luddism in the AI age: Fuzzy MCDM synergy},
journal = {Technological Forecasting and Social Change},
volume = {202},
pages = {123327},
year = {2024},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2024.123327},
url = {https://www.sciencedirect.com/science/article/pii/S0040162524001239},
author = {Sefer Darıcı and Muhammad Riaz and Gülay Demir and Zekiye Tamer Gencer and Dragan Pamucar},
keywords = {AI, Communication, Post-Luddism, Fuzzy set, DEMATEL, LMAW},
abstract = {This study proposes a fuzzy multi-criteria model to assess the risk of unemployment among professionals in the communication sector in Turkey, prompted by the rapid development and evolution of artificial intelligence (AI) technologies. The method integrates Fuzzy The Decision Making Trial and Evaluation Laboratory (F-DEMATEL) and Fuzzy Logarithm Methodology of Additive Weights (F-LMAW) procedures. Data were collected from 20 experts representing professions such as public relations, advertising, journalism, and design through a 12-question survey. In the analysis, the F-DEMATEL procedure was initially employed to determine attitudes towards AI technologies, followed by the application of the F-LMAW procedure to assess the magnitude of AI's impact on occupational groups. Findings reveal a nuanced stance: while professionals acknowledge the necessity of AI for their work, they are unwilling to accept unemployment due to more advanced AI. This newly identified structure, termed Post-Luddism, highlights concerns over technological unemployment, particularly pronounced in professions like journalism where job prospects are limited and creative thinking is paramount. In other communication fields, the intensive use of technology mitigates fears of AI harm. However, even in journalism, there exists a propensity to perceive AI as detrimental. These insights shed light on communication professionals' apprehensions and attitudes towards AI's effects. Policymakers and stakeholders can leverage this understanding to formulate strategic measures, considering the divergent perspectives among professional groups regarding AI, towards mitigating potential unemployment risks and fostering AI-adaptive strategies.}
}
@article{BROWN19921,
title = {Some conceptual issues in the modeling and computational analysis of the Canada-U.S. Free Trade Agreement},
journal = {The North American Journal of Economics and Finance},
volume = {3},
number = {1},
pages = {1-20},
year = {1992},
issn = {1062-9408},
doi = {https://doi.org/10.1016/1062-9408(92)90009-G},
url = {https://www.sciencedirect.com/science/article/pii/106294089290009G},
author = {Drusilla K. Brown and Robert M. Stern},
abstract = {We present an interpretive history of the development of the computational analysis of the Canada-U.S. FTA. Several important conceptual issues are identified, including: perfect competition and national product differentiation; imperfect competition and increasing returns to scale; tariff liberalization and monopolistic competition; adjustment and dynamic effects; macroeconomic effects; and other pertinent aspects of market structure and firm behavior.}
}
@article{LAO2022,
title = {Analyzing Suicide Risk From Linguistic Features in Social Media: Evaluation Study},
journal = {JMIR Formative Research},
volume = {6},
number = {8},
year = {2022},
issn = {2561-326X},
doi = {https://doi.org/10.2196/35563},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X22007910},
author = {Cecilia Lao and Jo Lane and Hanna Suominen},
keywords = {evaluation study, interdisciplinary research, linguistics, machine learning, mental health, natural language processing, social media, suicide risk},
abstract = {Background
Effective suicide risk assessments and interventions are vital for suicide prevention. Although assessing such risks is best done by health care professionals, people experiencing suicidal ideation may not seek help. Hence, machine learning (ML) and computational linguistics can provide analytical tools for understanding and analyzing risks. This, therefore, facilitates suicide intervention and prevention.
Objective
This study aims to explore, using statistical analyses and ML, whether computerized language analysis could be applied to assess and better understand a person’s suicide risk on social media.
Methods
We used the University of Maryland Suicidality Dataset comprising text posts written by users (N=866) of mental health–related forums on Reddit. Each user was classified with a suicide risk rating (no, low, moderate, or severe) by either medical experts or crowdsourced annotators, denoting their estimated likelihood of dying by suicide. In language analysis, the Linguistic Inquiry and Word Count lexicon assessed sentiment, thinking styles, and part of speech, whereas readability was explored using the TextStat library. The Mann-Whitney U test identified differences between at-risk (low, moderate, and severe risk) and no-risk users. Meanwhile, the Kruskal-Wallis test and Spearman correlation coefficient were used for granular analysis between risk levels and to identify redundancy, respectively. In the ML experiments, gradient boost, random forest, and support vector machine models were trained using 10-fold cross validation. The area under the receiver operator curve and F1-score were the primary measures. Finally, permutation importance uncovered the features that contributed the most to each model’s decision-making.
Results
Statistically significant differences (P<.05) were identified between the at-risk (671/866, 77.5%) and no-risk groups (195/866, 22.5%). This was true for both the crowd- and expert-annotated samples. Overall, at-risk users had higher median values for most variables (authenticity, first-person pronouns, and negation), with a notable exception of clout, which indicated that at-risk users were less likely to engage in social posturing. A high positive correlation (ρ>0.84) was present between the part of speech variables, which implied redundancy and demonstrated the utility of aggregate features. All ML models performed similarly in their area under the curve (0.66-0.68); however, the random forest and gradient boost models were noticeably better in their F1-score (0.65 and 0.62) than the support vector machine (0.52). The features that contributed the most to the ML models were authenticity, clout, and negative emotions.
Conclusions
In summary, our statistical analyses found linguistic features associated with suicide risk, such as social posturing (eg, authenticity and clout), first-person singular pronouns, and negation. This increased our understanding of the behavioral and thought patterns of social media users and provided insights into the mechanisms behind ML models. We also demonstrated the applicative potential of ML in assisting health care professionals to assess and manage individuals experiencing suicide risk.}
}
@article{BLAND2025,
title = {Quantal response equilibrium as a structural model for estimation: The missing manual},
journal = {Games and Economic Behavior},
year = {2025},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2025.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0899825625000211},
author = {James R. Bland and Theodore L. Turocy},
keywords = {Quantal response, Estimation, Computation, Experiments},
abstract = {One of the original objectives of the (logit) quantal response equilibrium (LQRE) model was to provide a method for structural estimation of behavior in games, when behavior deviated from Nash equilibrium predictions. To date, only Chapter 6 of the book on quantal response equilibrium by Goeree et al. (2016) focuses on how such estimation can be implemented. We build on that chapter to provide here a more detailed treatment of the methodological issues of implementing maximum likelihood estimation of QRE. We compare the equilibrium correspondence and empirical payoff approaches to estimation, and identify some considerations in interpreting the results of those approaches when applied to the same data on the same game. We also provide a more detailed “field guide” to using numerical continuation methods to accomplish estimation, including guidance on how to tailor implementations to games with different structures.}
}
@article{MUTHUSAMY2025112916,
title = {High-precision malware detection in android apps using quantum explainable hierarchical interaction network},
journal = {Knowledge-Based Systems},
volume = {310},
pages = {112916},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112916},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124015508},
author = {Ramnath Muthusamy and Yesubai Rubavathi Charles},
keywords = {Recommender system, Android applications, Real or fake app detection, Privacy, Feature interaction, Quantum superposition and entanglement},
abstract = {The exponential growth of Android applications has increased the prevalence of fraudulent and malicious apps, posing significant risks to user security and privacy. Existing detection methodologies often struggle with poor interpretability, scalability, and computational complexity, limiting their effectiveness. To address these challenges, this study introduces the Quantum Explainable Hierarchical Interaction Network (QEHIN), a novel framework designed to detect real and fake Android applications with superior accuracy and interpretability. QEHIN incorporates quantum computing principles such as superposition and entanglement to model high-order feature interactions effectively. Its innovative architecture includes a Quantum Embedding Layer for transforming input features into quantum states, a Quantum Hierarchical Interaction Network (QHIN) for capturing complex dependencies, a Quantum Deep Neural Network (QDNN) for enhanced feature processing, and a Quantum Cross-Hierarchical Unit (QCHU) to ensure seamless integration across hierarchical levels. This design achieves precise, transparent, and scalable detection of malicious applications, addressing the shortcomings of traditional methods. Evaluation on the Google Play Store Reviews, MobileRec, and Android-App-Recommendation datasets demonstrates the novelty and effectiveness of QEHIN. It achieves an accuracy of 98.86 %, precision of 98.78 %, recall of 98.82 %, and a kappa score of 98.54 %, significantly outperforming existing approaches.}
}
@article{PURWANTO2019118170,
title = {Using group model building to develop a causal loop mapping of the water-energy-food security nexus in Karawang Regency, Indonesia},
journal = {Journal of Cleaner Production},
volume = {240},
pages = {118170},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.118170},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619330409},
author = {Aries Purwanto and Janez Sušnik and F.X. Suryadi and Charlotte {de Fraiture}},
keywords = {Group model building, Causal loop diagram, Water-energy-food (WEF) security, Nexus modelling},
abstract = {This paper develops a qualitative causal model of a water, energy, and food (WEF) security nexus system to be used in analysing the interlinkages among those and other sectors that influence and are influenced by each other in a local context. Local stakeholder engagement through a group model building (GMB) approach was applied in Karawang Regency, Indonesia, to develop the model with the goals of improving problem understanding, raising consensus among participants, and building acceptance and commitment regarding the subsequent development of a quantitative nexus model. After recognizing the issues regarding water, energy and food sectors in the study area and eliciting opinions about nexus interactions, the next stage was to build a conceptual framework to describe the nexus system and to develop an integrated causal loop diagram (CLD) that describes critical system (inter-)linkages. The developed Karawang WEF security (K-WEFS) model is composed of six sub-models with water, energy and food sectors as endogenous factors. In addition, population, economic and ecosystem services were considered as exogenous drivers of the system. It is expected that all the major internal and external factors and drivers are covered, including possible feedback mechanisms, and key variables will be analysed further in the system. The future achievement of WEF security targets can be based on robust evaluation and planning processes underpinned by thorough understanding of whole system dynamics and the impacts of changes in the linked sectors, even in a qualitative way. In this way, a first step towards breaking silo thinking in regional planning may be attained.}
}
@article{DELI2021784,
title = {The thermodynamics of cognition: A mathematical treatment},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {784-793},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S200103702100012X},
author = {Eva Deli and James Peters and Zoltán Kisvárday},
keywords = {Consciousness, Free will, Mental energy, Intellect, Emotional regulation, Fermionic mind hypothesis, Carnot cycle, Landauer's principle},
abstract = {There is a general expectation that the laws of classical physics must apply to biology, particularly the neural system. The evoked cycle represents the brain's energy/information exchange with the physical environment through stimulus. Therefore, the thermodynamics of emotions might elucidate the neurological origin of intellectual evolution, and explain the psychological and health consequences of positive and negative emotional states based on their energy profiles. We utilized the Carnot cycle and Landauer's principle to analyze the energetic consequences of the brain's resting and evoked states during and after various cognitive states. Namely, positive emotional states can be represented by the reversed Carnot cycle, whereas negative emotional reactions trigger the Carnot cycle. The two conditions have contrasting energetic and entropic aftereffects with consequences for mental energy. The mathematics of the Carnot and reversed Carnot cycles, which can explain recent findings in human psychology, might be constructive in the scientific endeavor in turning psychology into hard science.}
}
@article{GHAVAM2021128776,
title = {The life cycle environmental impacts of a novel sustainable ammonia production process from food waste and brown water},
journal = {Journal of Cleaner Production},
volume = {320},
pages = {128776},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.128776},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621029747},
author = {Seyedehhoma Ghavam and Caroline M. Taylor and Peter Styring},
keywords = {Green ammonia, Waste utilization, Carbon capture and sequestration, Carbon capture and utilization, Greenhouse gas emissions, Life cycle assessment},
abstract = {To replace existing high impact ammonia production technologies, a new sustainability-driven waste-based technology producing green ammonia with and without urea was devised using life cycle thinking and sustainable design principles, targeting efficiency, carbon emissions, water, and power use competitiveness. We have used life cycle assessment to determine whether cradle-to-gate, multiple configurations of the core waste-based processes integrating several carbon capture/utilization options can compete environmentally with other available ammonia technologies. Our waste-to-ammonia processes reduce potential impacts from abiotic depletion, human toxicity, and greenhouse gas (GHG) emissions relative to fossil-based and renewable technologies. Among the assessed technologies, coupling dark fermentation with anaerobic digestion and capturing CO2 for sequestration or later use is most efficient for GHGs, water, and energy, consuming 27% less energy and reducing GHGs by 98% compared to conventional ammonia. Water use is 38% lower than water electrolysis and GHGs are 94% below municipal waste incineration routes per kg NH3. Additionally, displacing conventional, high impact urea by integrating urea production from process CO2 decreases life cycle environmental impacts significantly despite increased energy demand. On a fertilizer-N basis, the ammonia + urea configuration without dark fermentation performs best on all categories included. Methane and ammonia leakage cause nearly all life cycle impacts, indicating that failing to prevent leakage undermines the effectiveness of new technologies such as these. Our results show that a green ammonia/ammonia + urea process family as designed here can reduce waste and prevent the release of additional CO2 from ammonia production while avoiding fossil-based alternatives and decreasing emissions from biogenic waste sources.}
}
@article{HERNANDEZRAMIREZ2024414,
title = {The Future End of Design Work: A Critical Overview of Managerialism, Generative AI, and the Nature of Knowledge Work, and Why Craft Remains Relevant},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {414-440},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000960},
author = {Rodrigo Hernández-Ramírez and João Batalheiro Ferreira},
keywords = {creativity, design work, generative artificial intelligence (GenAI), knowledge work, managerialism},
abstract = {This article examines the transformation of design work under the influence of managerialism and the rise of Generative Artificial Intelligence (GenAI). Drawing on John Maynard Keynes’s projections of technological unemployment and the evolving nature of work, it argues that despite advancements in automation, work has not diminished but rather devalued. Design, understood as a type of knowledge work, faces an apparent existential crisis. GenAI grows adept at mimicking the output of creative processes. The article explores how the fear of the end of design work fueled by the rise of GenAI is rooted in a misunderstanding of design work. This misunderstanding is driven by managerialism—an ideology that prioritizes efficiency and quantifiable outcomes over the intrinsic value of work. Managerialism seeks to instrumentalize and automate design, turning it into a controllable procedure to generate quantifiable creative outputs. The article argues why design work cannot be turned into a procedure and automated using GenAI. Advocates of these systems claim they enhance productivity and open new opportunities. However, evidence so far shows that flawed GenAI models produce disappointing outcomes while operating at a significant environmental cost. The article concludes by arguing for a robust theory of design—one that acknowledges the unique ontological and epistemic boundaries of design work and underscores why design cannot be reduced to a procedural output.}
}
@article{TAMILVENDAN2024469,
title = {Parametric optimization in drilling of sisal–glass reinforced epoxy composites using Taguchi grey relational analysis method},
journal = {Transactions of the Canadian Society for Mechanical Engineering},
volume = {48},
number = {3},
pages = {469-476},
year = {2024},
issn = {0315-8977},
doi = {https://doi.org/10.1139/tcsme-2024-0018},
url = {https://www.sciencedirect.com/science/article/pii/S0315897724000570},
author = {D. Tamilvendan and A.R. Ravikumar and R. Thirumalai},
keywords = {Taguchi grey relational analysis, drlling, glass fiber, sisal fiber, composite},
abstract = {This research work intends to study the effect of hybridization of glass and sisal fiber, stacking sequence and tensile properties of the composite. The sisal-glass fiber hybrid composites laminates are prepared using reinforced plain woven sisal fabric (unidirectional) and plainwoven glass fabric. In this research study, 27 experiments are conducted as per L27 orthogonal array. Five process parameters are selected and three responses are considered in this work. The drilling of the composite specimen is considered and the drilling process parameters such as speed, feed rate, drill diameter, material thickness, and drill point angle are selected. The responses considered in this work are delamination factor, thrust force, and torque. Taguchi analysis is performed and the response table for means for the responses is determined, and the most influencing parameter in the drilling of the composite specimen is analyzed. The grey relational coefficients are computed and followed with the computation of the grey relational grade. The grey relational grades are calculated for determining the highest contributing parameter in the drilling of the sisal fiber and glass fiber reinforced hybrid composite specimen. The optimum drilling process parameters are ranked and the ranks presented represent the sequence of run resulting in optimum solutions.}
}
@article{HOIFODT2015,
title = {Predictors of Response to Web-Based Cognitive Behavioral Therapy With High-Intensity Face-to-Face Therapist Guidance for Depression: A Bayesian Analysis},
journal = {Journal of Medical Internet Research},
volume = {17},
number = {9},
year = {2015},
issn = {1438-8871},
doi = {https://doi.org/10.2196/jmir.4351},
url = {https://www.sciencedirect.com/science/article/pii/S1438887115002137},
author = {Ragnhild Sørensen Høifødt and Matthias Mittner and Kjersti Lillevoll and Susanne Kvam Katla and Nils Kolstrup and Martin Eisemann and Oddgeir Friborg and Knut Waterloo},
keywords = {treatment outcome, computer-assisted therapy, cognitive behavior therapy, depression, primary health care, Bayesian analysis},
abstract = {Background
Several studies have demonstrated the effect of guided Internet-based cognitive behavioral therapy (ICBT) for depression. However, ICBT is not suitable for all depressed patients and there is a considerable level of nonresponse. Research on predictors and moderators of outcome in ICBT is inconclusive.
Objective
This paper explored predictors of response to an intervention combining the Web-based program MoodGYM and face-to-face therapist guidance in a sample of primary care patients with mild to moderate depressive symptoms.
Methods
Participants (N=106) aged between 18 and 65 years were recruited from primary care and randomly allocated to a treatment condition or to a delayed treatment condition. The intervention included the Norwegian version of the MoodGYM program, face-to-face guidance from a psychologist, and reminder emails. In this paper, data from the treatment phase of the 2 groups was merged to increase the sample size (n=82). Outcome was improvement in depressive symptoms during treatment as assessed with the Beck Depression Inventory-II (BDI-II). Predictors included demographic variables, severity variables (eg, number of depressive episodes and pretreatment depression and anxiety severity), cognitive variables (eg, dysfunctional thinking), module completion, and treatment expectancy and motivation. Using Bayesian analysis, predictors of response were explored with a latent-class approach and by analyzing whether predictors affected the slope of response.
Results
A 2-class model distinguished well between responders (74%, 61/82) and nonresponders (26%, 21/82). Our results indicate that having had more depressive episodes, being married or cohabiting, and scoring higher on a measure of life satisfaction had high odds for positively affecting the probability of response. Higher levels of dysfunctional thinking had high odds for a negative effect on the probability of responding. Prediction of the slope of response yielded largely similar results. Bayes factors indicated substantial evidence that being married or cohabiting predicted a more positive treatment response. The effects of life satisfaction and number of depressive episodes were more uncertain. There was substantial evidence that several variables were unrelated to treatment response, including gender, age, and pretreatment symptoms of depression and anxiety.
Conclusions
Treatment response to ICBT with face-to-face guidance may be comparable across varying levels of depressive severity and irrespective of the presence and severity of comorbid anxiety. Being married or cohabiting, reporting higher life satisfaction, and having had more depressive episodes may predict a more favorable response, whereas higher levels of dysfunctional thinking may be a predictor of poorer response. More studies exploring predictors and moderators of Internet-based treatments are needed to inform for whom this treatment is most effective.
Trial Registration
Australian New Zealand Clinical Trials Registry number: ACTRN12610000257066; https://www.anzctr.org.au/trial_view.aspx?id=335255 (Archived by WebCite at http://www.webcitation.org/6GR48iZH4).}
}
@incollection{HARNAD2005817,
title = {Chapter 36 - A GROUNDED MIND IN A ROBOTIC BODY},
editor = {Henri Cohen and Claire Lefebvre},
booktitle = {Handbook of Categorization in Cognitive Science},
publisher = {Elsevier Science Ltd},
address = {Oxford},
pages = {817-820},
year = {2005},
isbn = {978-0-08-044612-7},
doi = {https://doi.org/10.1016/B978-008044612-7/50091-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780080446127500913},
author = {STEVAN HARNAD},
abstract = {Publisher Summary
This chapter presents the important themes of embodied cognition. In the chapter, Poirier and others first point out that minds (and brains) have bodies, and that this is not only unlikely to be incidental, but also most of the things that minds can do, they do with their bodies. Pure thinking, that is cognition, seems in and of itself to be a disembodied mental activity, conducted autonomously inside our heads without any signs of sensorimotor interaction with the world of objects, organisms, states, events, and properties that most of our thoughts are about. But surely whatever pure thinking does go on in our heads occurs in the service of our present and future doings in the world, and is grounded in our past doings. Both Proulx and Hélie, and Cangelosi are concerned with how to give a cognitive system the sensorimotor capacity, which is the capacity to detect, recognize and do the kinds of things that one is able to do with the kinds of things there are in the world. In other words, it is the capacity to categorize. The shapes that objects project on one's sensory surfaces can be processed by neural networks that do what is called unsupervised learning.}
}
@article{PUTICA2024105836,
title = {Reconceptualizing complex posttraumatic stress disorder: A predictive processing framework for mechanisms and intervention},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {164},
pages = {105836},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105836},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424003051},
author = {Andrea Putica and James Agathos},
keywords = {Complex Posttraumatic Stress Disorder (C-PTSD), Predictive processing, Trauma, Interoceptive inference, Active inference},
abstract = {In this article, we introduce a framework for interpreting Complex Posttraumatic Stress Disorder (C-PTSD) through predictive processing, a neuroscience concept explaining the brain’s interpretation and prediction of sensory information. While closely related to PTSD, C-PTSD encompasses additional symptom clusters marked by disturbances in self-organization (DSO), such as negative self-concept, affect dysregulation, and relational difficulties, typically resulting from prolonged traumatic stressors. Our model leverages advances in computational psychiatry and neuroscience, offering a mechanistic explanation for these symptoms by illustrating how prolonged trauma disrupts the brain's predictive processing. Specifically, altered predictive mechanisms contribute to C-PTSD's symptomatology, focusing on DSO: (1) Negative self-concept emerges from maladaptive priors that bias perception towards self-criticism, misaligning expected and actual interoceptive states; (2) Misalignment between predicted and actual interoceptive signals leads to affect dysregulation, with sensitivity to bodily cues; and (3) Relationship challenges arise from skewed social prediction errors, fostering mistrust and withdrawal. This precision-focused approach sheds light on the dynamics underpinning C-PTSD and highlights potential intervention targets aimed at recalibrating the predictive processing system.}
}
@article{DAI2024108354,
title = {Leveraging artificial intelligence (AI) in English as a foreign language (EFL) classes: Challenges and opportunities in the spotlight},
journal = {Computers in Human Behavior},
volume = {159},
pages = {108354},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108354},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400222X},
author = {Kun Dai and Quanguo Liu},
keywords = {Artificial intelligence (AI), AI-Powered instruments, Challenges and opportunities, English as a foreign language (EFL) classes, EFL students},
abstract = {The widespread use of Artificial Intelligence (AI) in language education contexts has motivated several scholars around the world to uncover the advantages and disadvantages of AI and AI-powered instruments in different language classrooms. Yet, as the review of earlier investigations revealed, few inquiries have been carried out to divulge the pros and cons of leveraging AI in EFL classes. To narrow this gap, using the phenomenological approach, this inquiry investigated the opportunities and challenges of implementing AI in EFL classes from the perspective of Chinese EFL students. To do so, through the criterion sampling technique, a total of 45 EFL students was recruited from different educational institutions in China. To collect the dataset, participants were asked to complete an open-ended questionnaire. For the sake of triangulation, among the 45 participants, 15 were randomly selected to engage in a follow-up interview session. With the aid of MAXQDA software (version 2023), participants’ perceptions of AI opportunities and challenges were carefully analyzed. Overall, the analysis findings uncovered that leveraging AI in EFL classes can bring numerous opportunities for EFL students, including individualized learning, timely and immediate feedback, rich educational resources, and an interactive learning atmosphere. However, as demonstrated by the analysis outcomes, implementing AI in EFL courses may also face students with a range of challenges and problems. The research outcomes would be of great help to teachers and educational leaders in mitigating the challenges of leveraging AI in language classrooms.}
}
@article{CAGNAC2023,
title = {Codes and methods improvements for safety assessment and LTO: varied approaches},
journal = {EPJ - Nuclear Sciences & Technologies},
volume = {9},
year = {2023},
issn = {2491-9292},
doi = {https://doi.org/10.1051/epjn/2023001},
url = {https://www.sciencedirect.com/science/article/pii/S2491929223000109},
author = {Albannie Cagnac and Denis Verrier and Vladislav Pištora},
abstract = {Nuclear safety has always been at the heart of the concerns of nuclear power plant operators and developers, as well as of various nuclear research organizations and regulatory authorities. Over the last decades, all these nuclear actors have developed and integrated a large number of calculation codes and other tools into their safety work. From the system approach to the local understanding of a phenomenon on a given component, from neutronics to operation optimization for long-term operation, these methods and codes have been constantly evolving since their appearance, in order to be able to integrate new plant designs and components, to improve the results of modeling physical phenomena or quantify and thus reduce the uncertainties on these results. Currently, several H2020 Euratom projects are working on the improvement of these codes and methods. This article will focus on three of these projects: CAMIVVER (Codes And Methods Improvements for VVER comprehensive safety assessment), APAL (Advanced PTS Analysis for LTO), and sCO2-4-NPP (innovative SCO2-based heat removal technology for an increased level of safety of Nuclear Power Plants) in order to illustrate our thinking on the improvement of calculation frameworks. First, we will present the work and the approach adopted with regard to the different calculation codes and methods used in each of these three projects. We will then conclude with an overall analysis of these three approaches, highlighting the difficulties and successes of these three projects, and identifying areas of work for the general improvement of the calculation codes.}
}
@incollection{PANDEY202563,
title = {Chapter 4 - Impact of quantum computing on healthcare data security},
editor = {Gayathri Nagasubramanian and S. Rakesh Kumar and Valentina {Emilia Balas}},
booktitle = {Quantum Computing for Healthcare Data},
publisher = {Academic Press},
pages = {63-90},
year = {2025},
series = {Advances in Biomedical Informatics},
isbn = {978-0-443-29297-2},
doi = {https://doi.org/10.1016/B978-0-443-29297-2.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443292972000022},
author = {Manoj Kumar Pandey and Jyoti Upadhyay and Naresh Kumar Kar and Velliangiri Sarveshwaran},
keywords = {Quantum computing, security, cryptography, healthcare, challenges, sustainable development goals},
abstract = {With the potential to completely transform computation, quantum computing (QC) is a young topic at the vanguard of scientific inquiry and technological advancement. QC promises to bring about dramatic improvements in data security and processing capabilities when it is integrated into healthcare systems. Conventional encryption techniques like RSA and ECC are based on discrete logarithms and integer factorization, two cryptographic issues that are currently unsolvable but can be solved by QC. This trend, however, also makes it more likely that current cryptographic systems will be subject to quantum attacks, which will force the creation and use of encryption methods that are resistant to quantum attacks. Additionally, by employing quantum-resistant hashing techniques, QC enables improved data integrity verification, guaranteeing the veracity and validity of medical data. The applied application of quantum-resistant cryptography techniques and the integration of quantum secure protocols into the current healthcare infrastructure still facing some difficulties therefore anyhow these encouraging advancements in this technique. This chapter focuses on the effect of the QC on the security of healthcare data with particular importance on how it revolutionized encryption, data integrity, privacy protection, and other related issues.}
}
@article{SALCEANU2014837,
title = {The Influence of Computer Games on Children's Development. Exploratory Study on the Attitudes of Parents},
journal = {Procedia - Social and Behavioral Sciences},
volume = {149},
pages = {837-841},
year = {2014},
note = {LUMEN 2014 - From Theory to Inquiry in Social Sciences, Iasi, Romania, 10-12 April 2014},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.08.323},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814050368},
author = {Claudia Sălceanu},
keywords = {Computer games, influence on children, positive and negative effects of computer games, parents’ attitudes;},
abstract = {The current study aims to investigate the attitudes of parents (N=1087) regarding the influence of computer games on their children's development in the following aspects: time they spend at the computer to play, types of favourite games, ways of child supervision, benefits and disadvantages of computer games. The results of the research show: 30.47% of children may access the computer anytime they want; the computer is mostly used for games (36.28%); 42.87% of parents supervise their children's activities at the computer only when they have spare time; 50% of parents allow their children to spend 1-2hours at computer games every day, while 28.54% allow 3-4hours (and more) of computer games every day. The biggest benefits of computer games, according to parents, are thinking development (9.60%), observation capacity (8.27%), and creativity (8.01%). The biggest disadvantages of computer games are the lack of physical movement (13.37%), sight disorders (13.15%) and agitation (8.58%). Parents recognize that games can have powerful effects on children, and should therefore set limits on the amount and content of games their children play. In this way, we can realize the potential benefits while minimizing the potential harms.}
}
@article{PERIGNAT201931,
title = {STEAM in practice and research: An integrative literature review},
journal = {Thinking Skills and Creativity},
volume = {31},
pages = {31-43},
year = {2019},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1871187118302190},
author = {Elaine Perignat and Jen Katz-Buonincontro},
keywords = {STEAM education, Creativity, Arts-integration, Transdisciplinary, Interdisciplinary},
abstract = {This integrative review examines 44 published articles (empirical, descriptive, and pedagogical frameworks) on the topic of STEAM (Science, Technology, Engineering, Arts, Mathematics) education from 2007 to 2018. Despite the emergence of STEAM as a popular pedagogical approach for enhancing students’ creativity, problem-solving skills, and interest in STEM fields, the definitions and purposes of STEAM education remain ubiquitous. Therefore, the review examined descriptions of the overall purpose of STEAM education, definitions of the STEAM acronym and the ‘A’ in STEAM, creativity as a learning outcome, elements of arts education, and arts education learning outcomes. The review found a myriad of definitions of the STEAM concept in general, a variety of interpretations for the “A” in STEAM, and an overall lack of reported learning outcomes in the areas of creativity, problem-solving, and arts education. The articles also differentiate in methods for merging STEAM disciplines, described in one of five ways: transdisciplinary, interdisciplinary, multi-disciplinary, cross-disciplinary, and arts-integration. Recommendations are provided to advance both research and practice in STEAM education.}
}
@article{CUSHEN2011458,
title = {Aha! Voila! Eureka! Bilingualism and insightful problem solving},
journal = {Learning and Individual Differences},
volume = {21},
number = {4},
pages = {458-462},
year = {2011},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2011.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1041608011000215},
author = {Patrick J. Cushen and Jennifer Wiley},
keywords = {Bilingualism, Creativity, Insight, Problem solving},
abstract = {What makes a person able to solve problems creatively? One interesting factor that may contribute is experience with multiple languages from an early age. Bilingual individuals who acquire two languages by the age of 6 have been shown to demonstrate superior performance on a number of thinking tasks that require flexibility. However, bilingual advantages have yet to be identified particularly on insight problems that are used as a model of creative problem solving following initial impasse. As such, the goal of the present study was to investigate the influence of language experience on problem solving performance on a matched set of insight and non-insight problems. Results demonstrate an interaction between type of problem (insight versus non-insight) and language status.}
}
@incollection{ZIEGLERRODRIGUEZ2025169,
title = {Chapter 6 - Life cycle assessment of constructed wetlands: measuring their contribution to sustainable development},
editor = {Asheesh Kumar Yadav and Jan Vymazal and Yaqian Zhao and Pratiksha Srivastava},
booktitle = {Emerging Developments in Constructed Wetlands},
publisher = {Elsevier},
pages = {169-193},
year = {2025},
isbn = {978-0-443-14078-5},
doi = {https://doi.org/10.1016/B978-0-443-14078-5.00006-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443140785000064},
author = {Kurt Ziegler-Rodriguez and Marianna Garfí},
keywords = {Sustainable development, life cycle assessment, constructed wetland, biological waste treatment, water management},
abstract = {Life cycle thinking has led to the development of a series of methodologies that evaluate the sustainability of any process, product, or activity, considering the three aspects of sustainable development: the environmental, economic, and social pillars. These methodologies called the (Environmental) Life Cycle Assessment, the Social Life Cycle Assessment and the Life Cycle Costing, have the peculiarity to consider the whole life cycle of a product or process, from the extraction of raw materials to their end of life. At the same time, sustainable development has led to the strengthening of disciplines and novel technologies such as circular bioeconomy, industrial ecology, and nature-based solutions. In this context, constructed wetlands have been gaining popularity since they are a low-cost alternative for urban and industrial wastewater treatment in small communities. The performed life cycle assessments of these technologies have shown that, regardless of the model, configuration, or type of waste treated, they have low environmental impacts compared with conventional solutions (e.g., activated sludge system) due to low energy requirements, no chemicals consumption, and avoidance of off-site management and transportation practices. In terms of costs, constructed wetlands can drastically reduce the costs associated with wastewater treatment and management. However, more efforts should be made in order to define the social benefits of this technology (e.g., local employment generation, landscape improvement) and the quality of the recovered resources (e.g., treated water, fertilizer).}
}
@article{KISAALITA201658,
title = {Perspectives on context, design teams and diffusion of technological innovations in low-resource settings: A practical approach based on sub-Saharan African projects},
journal = {Technology in Society},
volume = {46},
pages = {58-62},
year = {2016},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2016.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X16300495},
author = {William S. Kisaalita},
keywords = {Technological innovations, Sustainable development, Developing countries, Design teams, Poverty alleviation, Food and energy security},
abstract = {A human-centered design approach for creating science/engineering-driven solutions or innovations, referred to as “connect-the-dots,” is presented. Dots symbolize the best questions and the connections reveal the best order in which these questions should be answered. In this approach, the number of customer or user behavioral changes are critically analyzed, revealing the overall context in which the solution or innovation will operate; especially to undergraduate students creating solutions to problems from settings that are less familiar, from cultural, economic, and geopolitical viewpoints. Solutions or innovations that result in minimal user behavior changes are preferred. Additional benefits include better incorporation of systems theory thinking, ease with which team multidisciplinarity and diversity can be identified, and seamlessly integrating design and research.}
}
@article{YIN2022109800,
title = {Deep learning-accelerated optimization algorithm for controller parameters optimization of doubly-fed induction generators},
journal = {Applied Soft Computing},
volume = {131},
pages = {109800},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109800},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622008493},
author = {Linfei Yin and Xinghui Cao and Senlin Wang},
keywords = {Deep fully connected models, Gray wolf optimizer, Adaptive differential evolution, Global search, Parameter optimization},
abstract = {In this work, a cooperative Gray wolf Optimizer with adaptive differential Evolution (GOE) is proposed for the multimodal controller parameters optimization of doubly-fed induction generators (DFIGs) based on maximum power point tracking (MPPT) strategies. Moreover, the optimization process of the GOE is accelerated by a deep fully connected model (DFCM). The GOE contains a cooperative gray wolf optimizer (GWO) and adaptive differential evolution (ADE). The cooperative GWO contains alpha, beta, delta, and omega wolves to explore and exploit optimization problems and achieves optimization tasks wider and deeper than GWO. The ADE cooperates with the cooperative GWO to solve global optimization over continuous spaces. The simulation results on seven uni-model benchmark functions show that the GOE accelerated by DFCM obtains acceptable fitness values with 39.99% lesser computation time than the symmetry adapted stochastic search (SASS) algorithm and 80.72% lesser computation time than the Lévy flights-success-history based adaptive differential evolution with constraint handling technique (COLSHADE) algorithm, which are the winners of the CEC2020 Competition on Real-World Single Objective Constrained Optimization. Furthermore, the simulation results on DFIG with MPPT strategies in three real-world cases verify that the GOE accelerated by DFCM can effectively obtain global optimization solutions for non-smooth problems with 99.51% lesser average computation time than the SASS algorithm, 99.63% less than the COLSHADE algorithm, and 89.52% less than other methods. In addition, the accelerated GOE algorithm by DFCM has the feature of faster convergence.}
}
@article{BERNABEI2023100172,
title = {Students’ use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100172},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100172},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000516},
author = {Margherita Bernabei and Silvia Colabianchi and Andrea Falegnami and Francesco Costantino},
keywords = {LLM, ChatGPT, Higher education, Essay generation},
abstract = {The accessibility of advanced Artificial Intelligence-based tools, like ChatGPT, has made Large Language Models (LLMs) readily available to students. These LLMs can generate original written content to assist students in their academic assessments. With the rapid adoption of LLMs, exemplified by the popularity of OpenAI's ChatGPT, there is a growing need to explore their application in education. Few studies examine students' use of LLMs as learning tools. This paper focuses on the application of ChatGPT in engineering higher education through an in-depth case study. It investigates whether engineering students can generate high-quality university essays with LLMs assistance, whether existing LLMs identification systems can detect essays produced with LLMs, and how students perceive the usefulness and acceptance of LLMs in learning. The research adopts a deductive/inductive approach, combining conceptualization and empirical evidence analysis. The study involves mechanical and management engineering students, who compose essays using LLMs. The essay assessment showed good results, but some recommendations emerged for teachers and students. Thirteen LLMs detectors were tested without achieving satisfactory results, suggesting to avoid LLMs ban. In addition, students were administered a questionnaire based on constructs and items that follow the technology acceptance models available in the literature. The results contribute to qualitative evidence by highlighting possible future research and educational practices.}
}
@article{BERX2022107827,
title = {Identification and classification of risk factors for human-robot collaboration from a system-wide perspective},
journal = {Computers & Industrial Engineering},
volume = {163},
pages = {107827},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107827},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221007312},
author = {Nicole Berx and Wilm Decré and Ido Morag and Peter Chemweno and Liliane Pintelon},
keywords = {Human-robot collaboration, Human factors, Industry 4.0, Safety, Risk factors, Socio-technical},
abstract = {Industry 4.0 systems in general and advanced manufacturing systems such as collaborative robots, in particular, are characterized by a high level of complexity leading to new safety concerns. Safety, specifically for collaborative robots, has been mainly addressed from a technical perspective, to safeguard the physical safety of the operator. Concerns have been raised regarding less focus in Industry 4.0 literature on how other factors, such as psychosocial can produce safety-related risks for the operator in human-robot collaboration. This paper identifies and classifies the risk factors in a human-robot collaboration that have been described in research papers in the last decade. The resulting five classes constitute dimensions that will be used as preliminary building blocks for a safety evaluation framework to be developed in the next step. By evaluating the resulting classes with the underlying dimensions of contemporary socio-technical thinking, this paper demonstrates that these five classes offer a comprehensive, system-wide perspective including risk factors beyond technological considerations. Topics emerging from new risks related to the impact of working with collaborative robots, such as psychosocial, ethical, and cyber risk factors will need to be taken into account in the risk factors that are important to identify, assess and mitigate before working with collaborative robots. Operator involvement and participation, especially throughout the risk assessment and mitigation cycle are recommended as new areas of attention in human-robot collaboration. Going forward, one challenge will be the agility and adaptability of legislation to at least keep track of risk factors emerging from continuously changing technologies and to translate them into practically applicable tools for enterprises and design engineers implementing collaborative applications. Another key challenge will be the measurement of the new emerging and sometimes less technological risks.}
}
@incollection{HE2013241,
title = {5.16 - Flood Inundation Dynamics and Socioeconomic Vulnerability under Environmental Change},
editor = {Roger A. Pielke},
booktitle = {Climate Vulnerability},
publisher = {Academic Press},
address = {Oxford},
pages = {241-255},
year = {2013},
isbn = {978-0-12-384704-1},
doi = {https://doi.org/10.1016/B978-0-12-384703-4.00508-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780123847034005086},
author = {Y. He and F. Pappenberger and D. Manful and H. Cloke and P. Bates and F. Wetterhall and B. Parkes},
keywords = {Flood inundation dynamics, Two-faced flood, Model cascade, Uncertainties, Flood vulnerability, Impact studies, Flood risk, Living with floods, Harnessing floods},
abstract = {Floods are a major threat to human existence and historically have both caused the collapse of civilizations and forced the emergence of new cultures. The physical processes of flooding are complex. Increased population, climate variability, change in catchment and channel management, modified landuse and land cover, and natural change of floodplains and river channels all lead to changes in flood dynamics, and as a direct or indirect consequence, social welfare of humans. Section 5.16.1 explores the risks and benefits brought about by floods and reviews the responses of floods and floodplains to climate and landuse change. Section 5.08.2 reviews the existing modeling tools, and the top–down and bottom–up modeling frameworks that are used to assess impacts on future floods. Section 5.08.3 discusses changing flood risk and socioeconomic vulnerability based on current trends in emerging or developing countries and presents an alternative paradigm as a pathway to resilience. Section 5.08.4 concludes the chapter by stating a portfolio of integrated concepts, measures, and avant-garde thinking that would be required to sustainably manage future flood risk.}
}
@article{SIEGELMANN2013117,
title = {Turing on Super-Turing and adaptivity},
journal = {Progress in Biophysics and Molecular Biology},
volume = {113},
number = {1},
pages = {117-126},
year = {2013},
note = {Can Biology Create a Profoundly New Mathematics and Computation?},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2013.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0079610713000278},
author = {Hava T. Siegelmann},
keywords = {Adaptive computation, Biological computation, Super-Turing computation},
abstract = {Biological processes are often compared to computation and modeled on the Universal Turing Machine. While many systems or aspects of systems can be well described in this manner, Turing computation can only compute what it has been programmed for. It has no ability to learn or adapt to new situations. Yet, adaptation, choice and learning are all hallmarks of living organisms. This suggests that there must be a different form of computation capable of this sort of calculation. It also suggests that there are current computational models of biological systems that may be fundamentally incorrect. We argue that the Super-Turing model is both capable of modeling adaptive computation, and furthermore, a possible answer to the computational model searched for by Turing himself.}
}
@article{LI2024124918,
title = {A method of dense point cloud SLAM based on improved YOLOV8 and fused with ORB-SLAM3 to cope with dynamic environments},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124918},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124918},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424017858},
author = {Yanke Li and Huabo Shen and Yaping Fu and Kai Wang},
keywords = {SLAM, VSLAM, Neural Network, Deep learning},
abstract = {With the development of society and the advancement of technology, intelligent robots have been widely used in various fields. At the same time, Simultaneous Localization and Mapping (SLAM) technology is a key technology in the research field of intelligent robots. However, in dynamic environments, achieving accurate and robust visual SLAM remains a major challenge. In this paper, we propose a method based on improved YOLOv8 fused with ORB-SLAM3 to address dense point cloud SLAM in dynamic environments. Our proposed method successfully integrates real-time object detection and image segmentation technologies of YOLOv8 into the ORB-SLAM3 framework, achieving high-precision and robust visual SLAM in dynamic environments. In the YOLOv8 framework, we use a balanced convolution method, GSConv, instead of some traditional convolution layers (Conv), which balances accuracy with computational load. Based on the GSConv convolution method, we adopt a new feature fusion module, VoVGSCSP, to replace traditional C2f feature fusion modules, thereby improving the Neck structure of YOLOv8 and achieving a lightweight network model. We compare our proposed method with ORB-SLAM3 and some computer vision algorithms on the TUM dataset. Experimental data confirms that our method outperforms existing visual SLAM algorithms in dynamic environments. In fast-moving dynamic environments, the RMSE of absolute pose estimation of our method is 96.28% lower than that of ORB-SLAM3, and the RMSE of relative pose estimation is 51.57% lower than that of ORB-SLAM3. The experimental results demonstrate that our method significantly improves the accuracy of pose estimation in dynamic environments and greatly enhances the performance compared to ORB-SLAM3.}
}
@article{TANG2014245,
title = {On the causes of early life experience effects: Evaluating the role of mom},
journal = {Frontiers in Neuroendocrinology},
volume = {35},
number = {2},
pages = {245-251},
year = {2014},
note = {CRH/Stress in Honor of Wylie Vale},
issn = {0091-3022},
doi = {https://doi.org/10.1016/j.yfrne.2013.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S009130221300068X},
author = {Akaysha C. Tang and Bethany C. Reeb-Sutherland and Russell D. Romeo and Bruce S. McEwen},
keywords = {Maternal care, Stress, CORT, HPA, Self-regulation, Novelty, Maternal mediation, Maternal modulation, Early experience, Cognitive development},
abstract = {Early life experiences are thought to have long-lasting effects on cognitive, emotional, and social function during adulthood. Changes in neuroendocrine function, particularly the hypothalamic–pituitary–adrenal (HPA) axis, contribute to these systems-level behavioral effects. In searching for causal mechanisms underlying these early experience effects, pioneering research has demonstrated an important role for maternal care in offspring development, and this has led to two persistent ideas that permeate current research and thinking: first, environmental impact on the developing infant is mediated through maternal care behavior; second, the more care that a mother provides, the better off her offspring. While a good beginning, the reality is likely more complex. In this review, we critically examine these ideas and propose a computationally-motivated theoretical framework, and within this framework, we consider evidence supporting a hypothesis of maternal modulation. These findings may inform policy decisions in the context of child health and development.}
}
@article{BARTOLOZZI2011163,
title = {eMorph: Towards Neuromorphic Robotic Vision},
journal = {Procedia Computer Science},
volume = {7},
pages = {163-165},
year = {2011},
note = {Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911005874},
author = {Chiara Bartolozzi and Charles Clercq and Neeraj Mandloi and Francesco Rea and Giacomo Indiveri and Daniel Fasnacht and Giorgio Metta and Michael Hofstätter and Ryad Benosman},
keywords = {neuromorphic, humanoid robot, event-driven computation, vision},
abstract = {The eMorph project aims at introducing a new concept for vision in the field of humanoid robotics. The system that is currently being developed is inspired by the biology of mammalian visual systems, introducing concepts such as stimulus-driven signal acquisition and processing, together with space-variant sensor design coupled with active vision. This approach is leading to the realization of a system that goes beyond current thinking in robotic vision.}
}
@article{PUZANTIAN2021387,
title = {Redesigning a PhD measurement course for a new era in nursing science},
journal = {Journal of Professional Nursing},
volume = {37},
number = {2},
pages = {387-390},
year = {2021},
issn = {8755-7223},
doi = {https://doi.org/10.1016/j.profnurs.2020.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S8755722320300983},
author = {Houry Puzantian and Hala Darwish},
keywords = {Measurement, Quantitative, Nursing research, PhD},
abstract = {Measurement is at the core of the research process. At the PhD level, students need to develop an in-depth understanding of measures relevant to their area of work and refine their knowledge of measurement issues. Traditionally, measurement coursework in Nursing focused on the psychometric evaluation of instruments measuring cognition and behavior. However, in the age of Big Data, precision medicine, and translational science, PhD students need to develop knowledge and skills relevant to these fields and to collaborate with experts from the different disciplines. Therefore, Nursing faculty need to recognize the state-of-the-science of nursing research and tend to a variety of measurement issues across a spectrum of operationalized concepts. Herein we present an overview of learning outcomes, instructional content and methods of delivery for a contemporary PhD-level course on measurement for Nursing Science. We also present our experience in the design, implementation, and evaluation of a novel PhD measurement course.}
}
@article{WANG2021102528,
title = {Automatic diagnosis of ECG disease based on intelligent simulation modeling},
journal = {Biomedical Signal Processing and Control},
volume = {67},
pages = {102528},
year = {2021},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2021.102528},
url = {https://www.sciencedirect.com/science/article/pii/S1746809421001257},
author = {Xu Wang and Runchuan Li and Shuhong Wang and Shengya Shen and Wenzhi Zhang and Bing Zhou and Zongmin Wang},
keywords = {Intelligent simulation modeling, Rule, ECG diseases, Diagnosis},
abstract = {In order to better assist doctors in diagnosing cardiovascular diseases, a set of end-to-end automatic diagnosis algorithms for ECG diseases based on intelligent simulation modeling are proposed. Firstly, wavelet transform and threshold method are used to denoise the ECG signal and locate the waveform in this paper. Secondly, waveform features are extracted. Finally, the rule method is used to convert the doctors’ thinking of diagnosing the disease into a description of the ECG characteristics of the disease to diagnose the ECG disease, and the algorithm is verified on the public database CCDD and the private data all-in-one machine data. The results show that this method is not inferior to the deep learning method. Now 11 types of diseases and 10 types of rhythm can be diagnosed.}
}
@article{TEIXEIRADUARTE2022112513,
title = {Review on layout optimization strategies of offshore parks for wave energy converters},
journal = {Renewable and Sustainable Energy Reviews},
volume = {163},
pages = {112513},
year = {2022},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2022.112513},
url = {https://www.sciencedirect.com/science/article/pii/S1364032122004178},
author = {Felipe Teixeira-Duarte and Daniel Clemente and Gianmaria Giannini and Paulo Rosa-Santos and Francisco Taveira-Pinto},
keywords = {Computational intelligence techniques, Wave energy, Renewable energy, Layout optimization, Offshore parks, Energy parks, WEC arrays},
abstract = {Layout optimization of wave energy offshore parks is a challenging task, as it encompasses various design objectives and constraints attributed to the complex hydrodynamic interactions. The wave energy converter (WEC) park performance is affected by local environment and device characteristics. To solve this challenge, advanced numerical algorithms, including artificial intelligence, have been applied to a wide range of case studies. Nevertheless, this process remains incomplete, which keeps it as a pertinent research topic in the field of WEC development. The present paper provides an overview of the current state and research trends of offshore WEC park layout optimization. To analyze the state-of-the-art, the paper targets the last decades’ research on this topic, summarizing the studies, addressing the optimization objective and the employed methods and separating them according to the corresponding technique. The review showed that the results strongly depend on the methodologies applied. Furthermore, a preferential use of computational intelligence techniques has been observed in recent years.}
}
@article{KONOVALOV20213323,
title = {Dissecting functional contributions of the social brain to strategic behavior},
journal = {Neuron},
volume = {109},
number = {20},
pages = {3323-3337.e5},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321005699},
author = {Arkady Konovalov and Christopher Hill and Jean Daunizeau and Christian C. Ruff},
keywords = {fMRI, TPJ, dmPFC, social, decision making, strategic},
abstract = {Summary
Social interactions routinely lead to neural activity in a “social brain network” comprising, among other regions, the temporoparietal junction (TPJ) and the dorsomedial prefrontal cortex (dmPFC). But what is the function of these areas? Are they specialized for behavior in social contexts or do they implement computations required for dealing with any reactive process, even non-living entities? Here, we use fMRI and a game paradigm separating the need for these two aspects of cognition. We find that most social-brain areas respond to both social and non-social reactivity rather than just to human opponents. However, the TPJ shows a dissociation from the dmPFC: its activity and connectivity primarily reflect context-dependent outcome processing and reactivity detection, while dmPFC engagement is linked to implementation of a behavioral strategy. Our results characterize an overarching computational property of the social brain but also suggest specialized roles for subregions of this network.}
}
@article{BARFAR2019173,
title = {Cognitive and affective responses to political disinformation in Facebook},
journal = {Computers in Human Behavior},
volume = {101},
pages = {173-179},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219302699},
author = {Arash Barfar},
keywords = {Political disinformation, Polarization, Echo chamber, Text analysis, Social media, Facebook},
abstract = {The epidemic of political disinformation in social media has in part triggered the transition to the post-truth era in which emotional and ideological appeals are more influential in shaping public opinion than objective facts. In this study we examined the cognitive and affective responses that political disinformation prompted in Facebook, as the most popular social media platform. Through text analysis of user comments corpora on nearly 2,100 political posts from popular sources in Facebook, we found that compared to true news, political disinformation received significantly less analytic responses from Facebook followers. While the results indicated greater anxiety in responses to true news, responses to political disinformation were filled with greater anger and incivility. We also found similar (low) levels of cognitive thinking in responses to extreme conservative and extreme liberal disinformation. Contrary to prior research findings, our results indicated that responses to extreme liberal disinformation in Facebook were filled with greater anger and incivility. This suggests that the incivility and outrage in online political discourses should not be attributed to a specific political party without considering the concurrent political events.}
}
@article{HAMDI2019772,
title = {Fuzzy Approach for Locating Sensors in Industrial Internet of Things},
journal = {Procedia Computer Science},
volume = {160},
pages = {772-777},
year = {2019},
note = {The 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919317120},
author = {Sarah El Hamdi and Mustapha Oudani and Abdellah Abouabdellah and Anass Sebbar},
keywords = {I2oT, Architecture, Fuzzy Theory},
abstract = {Nowadays, in this era of a data driven thinking and reflection, data mining and data analysis are keys to any business survival in a competitive conjectural market. The internet of things is an emerging technology that manages to create a path for the new generation of industrial production system. This advanced technology is requirement to the proliferation of Smart factories, it represents the best tool to help this new concept of plants to organize themselves and optimize the available resources and their consumption. The purpose of this paper is two-pronged; a proposal for an architectural framework of the industrial internet of things, and a mathematical formulation based on fuzzy logic to determine the ideal location of sensors at the shop floor taking into consideration several restrictions.}
}
@article{STRATFORD2022115813,
title = {Exploring the potential neurotoxicity of vaping vitamin E or vitamin E acetate},
journal = {Toxicology and Applied Pharmacology},
volume = {434},
pages = {115813},
year = {2022},
issn = {0041-008X},
doi = {https://doi.org/10.1016/j.taap.2021.115813},
url = {https://www.sciencedirect.com/science/article/pii/S0041008X21004178},
author = {Kimberly Stratford and Prabha Kc and Susan Rudy and Anna-Sophie Weidner and Priscilla Callahan-Lyon and Luis G. Valerio},
keywords = {Pulmonary injury, Electronic Nicotine Delivery Systems (ENDS), Tobacco products, Electronic cigarettes, Vitamin E, Vitamin E acetate, E-Cigarette or Vaping Product Use-Associated Lung Injury (EVALI), Vaping, Neurotoxicity, Computational model},
abstract = {Serious adverse health effects have been reported with the use of vaping products, including neurologic disorders and e-cigarette or vaping product use-associated lung injury (EVALI). Vitamin E acetate, likely added as a diluent to cannabis-containing products, was linked to EVALI. Literature searches were performed on vitamin E and vitamin E acetate-associated neurotoxicity. Blood brain barrier (BBB) penetration potential of vitamin E and vitamin E acetate were evaluated using cheminformatic techniques. Review of the literature showed that the neurotoxic potential of inhalation exposures to these compounds in humans is unknown. Physico-chemical properties demonstrate these compounds are lipophilic, and molecular weights indicate vitamin E and vitamin E acetate have the potential for BBB permeability. Computational models also predict both compounds may cross the BBB via passive diffusion. Based on literature search, no experimental nonclinical studies and clinical information on the neurotoxic potential of vitamin E via inhalation. Neurotoxic effects from pyrolysis by-product, phenyl acetate, structurally analogous to vitamin E acetate, suggests vitamin E acetate has potential for central nervous system (CNS) impairment. Cheminformatic model predictions provide a theoretical basis for potential CNS permeability of these inhaled dietary ingredients suggesting prioritization to evaluate for potential hazard to the CNS.}
}
@article{ROOTESMURDY2024100987,
title = {Cortical similarities in psychiatric and mood disorders identified in federated VBM analysis via COINSTAC},
journal = {Patterns},
volume = {5},
number = {7},
pages = {100987},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100987},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924001028},
author = {Kelly Rootes-Murdy and Sandeep Panta and Ross Kelly and Javier Romero and Yann Quidé and Murray J. Cairns and Carmel Loughland and Vaughan J. Carr and Stanley V. Catts and Assen Jablensky and Melissa J. Green and Frans Henskens and Dylan Kiltschewskij and Patricia T. Michie and Bryan Mowry and Christos Pantelis and Paul E. Rasser and William R. Reay and Ulrich Schall and Rodney J. Scott and Oliver J. Watkeys and Gloria Roberts and Philip B. Mitchell and Janice M. Fullerton and Bronwyn J. Overs and Masataka Kikuchi and Ryota Hashimoto and Junya Matsumoto and Masaki Fukunaga and Perminder S. Sachdev and Henry Brodaty and Wei Wen and Jiyang Jiang and Negar Fani and Timothy D. Ely and Adriana Lorio and Jennifer S. Stevens and Kerry Ressler and Tanja Jovanovic and Sanne J.H. {van Rooij} and Lydia M. Federmann and Christiane Jockwitz and Alexander Teumer and Andreas J. Forstner and Svenja Caspers and Sven Cichon and Sergey M. Plis and Anand D. Sarwate and Vince D. Calhoun},
keywords = {transdiagnostic, federated analysis, COINSTAC, psychiatric disorders, regression, mood disorders, decentralized, gray matter, PTSD, mild cognitive impairment},
abstract = {Summary
Structural neuroimaging studies have identified a combination of shared and disorder-specific patterns of gray matter (GM) deficits across psychiatric disorders. Pooling large data allows for examination of a possible common neuroanatomical basis that may identify a certain vulnerability for mental illness. Large-scale collaborative research is already facilitated by data repositories, institutionally supported databases, and data archives. However, these data-sharing methodologies can suffer from significant barriers. Federated approaches augment these approaches by enabling access or more sophisticated, shareable and scaled-up analyses of large-scale data. We examined GM alterations using Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation, an open-source, decentralized analysis application. Through federated analysis of eight sites, we identified significant overlap in the GM patterns (n = 4,102) of individuals with schizophrenia, major depressive disorder, and autism spectrum disorder. These results show cortical and subcortical regions that may indicate a shared vulnerability to psychiatric disorders.}
}
@article{KERREN2025,
title = {Exploring the role of dimensionality transformation in episodic memory},
journal = {Trends in Cognitive Sciences},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2025.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S136466132500021X},
author = {Casper Kerrén and Daniel Reznik and Christian F. Doeller and Benjamin J. Griffiths},
keywords = {episodic memory, dimensionality reduction and dimensionality expansion, neural oscillations, corticohippocampal connectivity, neural representations},
abstract = {Episodic memory must accomplish two adversarial goals: encoding and storing a multitude of experiences without exceeding the finite neuronal structure of the brain, and recalling memories in vivid detail. Dimensionality reduction and expansion (‘dimensionality transformation’) enable the brain to meet these demands. Reduction compresses sensory input into simplified, storable codes, while expansion reconstructs vivid details. Although these processes are essential to memory, their neural mechanisms for episodic memory remain unclear. Drawing on recent insights from cognitive psychology, systems neuroscience, and neuroanatomy, we propose two accounts of how dimensionality transformation occurs in the brain: structurally (via corticohippocampal pathways) and functionally (through neural oscillations). By examining cross-species evidence, we highlight neural mechanisms that may support episodic memory and identify crucial questions for future research.}
}
@article{NOVIANTRI2023446,
title = {Unsteady State Temperature Distribution Inside House Based on Slope Roof},
journal = {Procedia Computer Science},
volume = {227},
pages = {446-453},
year = {2023},
note = {8th International Conference on Computer Science and Computational Intelligence (ICCSCI 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.545},
url = {https://www.sciencedirect.com/science/article/pii/S187705092301712X},
author = {Viska Noviantri and Agus Diemas Prayoga and Denny Pratama},
keywords = {unsteady state heat equation, ghost point, finite difference method, slope roof},
abstract = {The house is a building that serves as a place to gather with family and also to get comfort. The house is designed so the occupants can feel aesthetically and functionally comfortable. It will be interesting to discuss the temperature inside the house as one of the comfort factors. The study aims to analyze the temperature conditions inside the house, which are influenced by the slope of the roof. A two-dimensional unsteady state heat equation represents this temperature since the temperature distribution satisfies the heat transfer concept and changes over time. This governing equation will be approximated by the forward time center space scheme as one finite difference method and completed by the quadratic ghost point method since the house domain is an irregular shape. Van Neumann criteria are applied here to analyze the stability of the computational approach for this numerical scheme. Furthermore, these schemes are implemented in MATLAB application to quantitatively and visually display temperature dynamics. Some simulations completed these approximations to see temperature variations over time. The results show that the bigger slope causes the average temperature to be cooler. In other words, the temperature in the house will be more comfortable when the roof slope gets bigger.}
}
@incollection{LEVY1989243,
title = {A Computational Approach to Hippocampal Function},
editor = {Robert D. Hawkins and Gordon H. Bower},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {23},
pages = {243-305},
year = {1989},
booktitle = {Computational Models of Learning in Simple Neural Systems},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(08)60113-9},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108601139},
author = {William B Levy},
abstract = {Publisher Summary
This chapter describes the early, formative stages of a theory of hippocampal function. This theory has been stimulated by the psychological observations indicating a role for the hippocampus in short-term working memory and spatial behavior and develops mainly through the consideration of computational issues. These computational issues are related to the psychological viewpoint through physiological and anatomical observations. The hippocampus participates in the prediction of future representations based on past and present representations. All three classes of representations are derived from a multiplicity of sensory modalities, such as auditory, visual, and olfactory signals from neo- and piriform cortices. This fusion of sensory modalities requires recoding because of computational complexity problems. The CA1 region of the hippocampus is postulated to be a prediction-generating layer or tier. This region produces a prediction based on its input from hippocampal region CA3. The combined hippocampal dentate gyrus/CA3 (DG/CA3) system is postulated to be a preprocessor serving the CA1 prediction layer. The computational complexity problems arise from the combinatorial explosion of possible representations resulting when the hippocampus and supporting limbic structures mix representations from multiple sensory modalities.}
}
@article{AKANDA2025112329,
title = {Understanding comment practices in Scratch: A study of comments in a block-based visual programming language},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112329},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112329},
url = {https://www.sciencedirect.com/science/article/pii/S016412122400373X},
author = {Wahiduzzaman Akanda and James Clause},
keywords = {Comment, Text-based programming, Visual programming, Scratch, Taxonomy},
abstract = {Comments are vital for software documentation. They provide necessary insights and assist developers in understanding and maintaining the software. Due to their importance, comments have been extensively studied, and much has been learned about them. These existing studies have predominantly focused on text-based languages. Conversely, block-based visual programming languages, particularly Scratch, are becoming increasingly popular. Some studies regarding comments related to the Scratch online community focus on topics such as fostering online community and engagement, sentiment analysis, etc. However, they overlook the visual aspects and the qualitative analysis of comments within code in Scratch projects. This is a meaningful limitation, and this research project studies comments and their pattern in Scratch projects from both textual and visual perspectives. We examined comments collected from different Scratch projects. Each comment was manually annotated based on textual and visual attributes, producing a taxonomy model of comments for a visual programming language. The classification results were analyzed to understand better the practice of commenting in Scratch. Our result revealed that Scratch projects produced noisier(i.e., less understandable) comments than text-based programming languages like Java. In addition, the study also revealed several limitations and shortcomings that could be addressed to improve the commenting experience in Scratch.}
}
@article{SHI2023926,
title = {Decoding Human Biology and Disease Using Single-cell Omics Technologies},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {21},
number = {5},
pages = {926-949},
year = {2023},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2023.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1672022923001043},
author = {Qiang Shi and Xueyan Chen and Zemin Zhang},
keywords = {Single-cell omics, Computational method, Cellular heterogeneity, Disease, Cancer research},
abstract = {Over the past decade, advances in single-cell omics (SCO) technologies have enabled the investigation of cellular heterogeneity at an unprecedented resolution and scale, opening a new avenue for understanding human biology and disease. In this review, we summarize the developments of sequencing-based SCO technologies and computational methods, and focus on considerable insights acquired from SCO sequencing studies to understand normal and diseased properties, with a particular emphasis on cancer research. We also discuss the technological improvements of SCO and its possible contribution to fundamental research of the human, as well as its great potential in clinical diagnoses and personalized therapies of human disease.}
}
@article{WANG19951,
title = {Peripheral dynamics of the Cl + CH4 → HCl + CH3 reaction. A classical trajectory computation},
journal = {Chemical Physics},
volume = {197},
number = {1},
pages = {1-17},
year = {1995},
issn = {0301-0104},
doi = {https://doi.org/10.1016/0301-0104(95)00134-A},
url = {https://www.sciencedirect.com/science/article/pii/030101049500134A},
author = {Xuebin Wang and M. Ben-Nun and R.D. Levine},
abstract = {The Cl + CH4 → HCl + CH3 reaction is expected to provide a prototype of a peripheral mechanism. This proposal is examined via a classical trajectory computation using a number of model potentials in which the degrees of freedom which do not take part in the net reaction are, or are not, frozen. The models include a full six-atom potential. The essential features of the dynamics are not sensitive to the level of detail with which the CH3 is described, showing that the intramolecular dynamics of the radical do not significantly affect the dynamics of the reactive event. The reaction is found to proceed by two distinct mechanisms: for trajectories with a large impact parameter, a very short lived complex is formed and dissociates to a rotationally cold HCl product, scattered into the forward direction. At smaller impact parameters, the reaction proceeds via a direct mechanism with a rotationally hot HCl which is scattered backward. The computed angular distribution is in agreement with the experiment, which detects HCl in the j = 1, 3 states and suggests that higher rotational states of HCl, which were not probed in the experiment, will also be scattered backward. The role of the initial vibrational excitation of CH4 is discussed.}
}
@article{XIE2024e34960,
title = {Enhanced nonlinear active noise control: A novel approach using brain storm optimization algorithm},
journal = {Heliyon},
volume = {10},
number = {15},
pages = {e34960},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e34960},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024109917},
author = {Jiangchun Xie and Jianmin Ma},
keywords = {Active noise control, Brain storm optimization (BSO) algorithm, Filtered-x least mean squares (FxLMS) algorithm, Nonlinear noise reduction extended Kalman Filter (EKF), Noise reduction performance, Multi-frequency noise},
abstract = {Active Noise Control (ANC) systems play a crucial role in reducing unwanted noise in various settings. Traditional ANC methods, like the Filtered-x Least Mean Squares (FxLMS) algorithm, are effective in linear noise scenarios. However, they often struggle with more nonlinear and complex noise patterns. This paper introduces a novel approach using the brain storm optimization (BSO) algorithm in nonlinear ANC systems, which represents a significant departure from conventional techniques. The BSO algorithm, inspired by human brainstorming processes, excels in addressing the complexities of nonlinear noise by incorporating principles, such as delayed evaluation, free imagination, quantity and quality, and comprehensive improvement. By combining the BSO algorithm with an Extended Kalman Filter (EKF), a new ANC system is proposed that can adapt to a wide range of noise types with improved speed and accuracy. Experimental results showcase the superior performance of the BSO algorithm, achieving an impressive noise reduction of up to 48 dB (dB) in a 500Hz sinusoidal noise scenario, with a convergence time as fast as 0.01 s, outperforming the FxLMS algorithm by a significant margin. Moreover, in complex environments with multi-frequency and random noise, the BSO algorithm consistently demonstrates better noise reduction and quicker convergence, reducing noise levels by up to 27 dB within 0.001 s. The innovative use of the BSO algorithm in ANC systems not only enhances noise reduction capabilities, especially for nonlinear and complex noise signals, but also improves convergence times, paving the way for future advancements in ANC technologies.}
}
@article{RITCHIE2012649,
title = {Styles for philosophers of science},
journal = {Studies in History and Philosophy of Science Part A},
volume = {43},
number = {4},
pages = {649-656},
year = {2012},
note = {Part Special Issue: Styles of Thinking},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2012.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0039368112000490},
author = {Jack Ritchie},
keywords = {Ian Hacking, Styles of Thinking, Realism, Self-authentication},
abstract = {In this paper I discuss the bearing of Hacking’s ideas about Scientific Styles on traditional debates in the philosophy of science concerning rationality and realism. I argue that a kind of deflationary position with regard to realism debates is a natural consequence of Hacking’s claim that styles are self-authenticating. I then go on to argue, using an example of van Fraassen’s, that Hacking should allow a methodological role for realism debates and hence they are not idle, as he has claimed, although their resolution may not be important.}
}
@incollection{KRAWCZYK2018101,
title = {Chapter 5 - Reasoning Origins: Human Development During Childhood},
editor = {Daniel C. Krawczyk},
booktitle = {Reasoning},
publisher = {Academic Press},
pages = {101-129},
year = {2018},
isbn = {978-0-12-809285-9},
doi = {https://doi.org/10.1016/B978-0-12-809285-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092859000053},
author = {Daniel C. Krawczyk},
keywords = {Analogies, Causal reasoning, Decision making, Development, Developmental stages, Moral reasoning, Relational reasoning},
abstract = {The developmental process is remarkably dynamic. The process is both a biological one and an environmental one with both factors frequently contributing to the output of increasingly sophisticated and abstract reasoning behavior. Children begin with a process of cortical thickening as large numbers of synaptic connections are formed. From age three onward, the cortex undergoes a tuning process as some synaptic connections strengthen and others weaken. The net result of this process is a decrease in cortical volume from age 5 through 20. Children's thinking is guided by a variety of factors. The context of a problem becomes a significant factor in determining how children will reason and developmental reasoning studies require sensitivity toward making the experimental stimuli understandable and interesting to the child. Children exhibit some competencies in causal reasoning and learning from a very young age. Children show increasing reasoning abilities as they develop. Skills such as relational and analogical reasoning grow during the elementary school years and are supported by increases in cognitive control and decreases in impulsivity. The child becomes less concrete in how he or she views and interacts with the world. This increasing abstraction ability encompasses semantic knowledge, deduction, and moral thinking.}
}
@incollection{WILLIAMS2020341,
title = {Chapter 17 - Begin with the human: Designing for safety and trustworthiness in cyber-physical systems},
editor = {William F. Lawless and Ranjeev Mittu and Donald A. Sofge},
booktitle = {Human-Machine Shared Contexts},
publisher = {Academic Press},
pages = {341-357},
year = {2020},
isbn = {978-0-12-820543-3},
doi = {https://doi.org/10.1016/B978-0-12-820543-3.00017-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128205433000171},
author = {Elizabeth T. Williams and Ehsan Nabavi and Genevieve Bell and Caitlin M. Bentley and Katherine A. Daniell and Noel Derwort and Zac Hatfield-Dodds and Kobi Leins and Amy K. McLennan},
keywords = {Trust, Safety, Autonomy, Agency, Assurance, Metrics, Interfaces, Human-machine interaction, Cyber-physical systems},
abstract = {Control systems are designed and built to manage and regulate the behavior of other systems. The use of artificial intelligence (AI) in control systems has simultaneously created new opportunities and new challenges in how we create, manage, and govern cyber-physical systems. In this paper, we discuss the challenge of defining and developing a model for contemplating how these systems will potentially learn, evolve, and act without human intervention. We present an analytical framework for thinking about trust and safety in these systems—both key factors for shared context in human-machine teams—and demonstrate its application using an example from history.}
}
@article{ALBALAWI201712033,
title = {Distributed Economic MPC with Safety-Based Constraints for Nonlinear Systems**Financial support from the National Science Foundation and the Department of Energy is gratefully acknowledged.},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {12033-12040},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.2098},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317327581},
author = {Fahad Albalawi and Helen Durand and Panagiotis D. Christofides},
keywords = {Process safety, distributed model predictive control, computation time},
abstract = {Promoting process safety of chemical processes while operating them in an economically-optimal manner is a matter of great importance. In Albalawi et al. (2016), a safety-based economic model predictive control methodology (safety-EMPC) was developed to operate nonlinear processes in an economically-optimal manner while maintaining process safety and closed-loop stability. However, the safety-EMPC control strategy was developed with a centralized economic model predictive control (EMPC) structure; thus, computation time limitations within a sampling period may reduce the effectiveness of such a controller design for promoting process safety. Alternatively, we develop in this work sequential and iterative safety-based distributed EMPC schemes (safety-DEMPC) that may overcome the computation time limitations of the centralized safety-EMPC while maintaining similar closed-loop performance. Using a catalytic reactor example, the two proposed safety-DEMPC schemes were demonstrated to achieve similar closed-loop performance to the centralized safety-EMPC while reducing the on-line computation time requirements compared to the centralized safety-EMPC.}
}
@article{CRAGG1974315,
title = {Thinking about the future: A critique of the limits to growth: Edited by H. S. D. Cole, Christopher Freeman, Marie Jahoda & K. L. R. Pavitt. Chatto & Windus for Sussex University Press, London: 218 pp., £3.00, 1973},
journal = {Biological Conservation},
volume = {6},
number = {4},
pages = {315-316},
year = {1974},
issn = {0006-3207},
doi = {https://doi.org/10.1016/0006-3207(74)90014-7},
url = {https://www.sciencedirect.com/science/article/pii/0006320774900147},
author = {J.B. Cragg}
}
@incollection{TANQUE202113,
title = {Chapter 2 - Knowledge Representation and Reasoning in AI-Based Solutions and IoT Applications},
editor = {Gurjit Kaur and Pradeep Tomar and Marcus Tanque},
booktitle = {Artificial Intelligence to Solve Pervasive Internet of Things Issues},
publisher = {Academic Press},
pages = {13-49},
year = {2021},
isbn = {978-0-12-818576-6},
doi = {https://doi.org/10.1016/B978-0-12-818576-6.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128185766000022},
author = {Marcus Tanque},
keywords = {Artificial intelligence, machine learning, intelligent machine, artificial neural networks, cognitive science, deep learning, artificial general networks, knowledge representation, and reasoning, cognitive informatics, Internet of Things},
abstract = {Artificial intelligence (AI)-based solutions, knowledge representation and reasoning, and the Internet of Things applications have transformed how researchers and practitioners view the analytical and computational capabilities. The disruptive evolution of these technologies has encouraged researchers and practitioners to develop integrated AI-based analytical solutions needed for solving pervasive issues affecting computational applications. The capabilities include AI, knowledge Representation and Reasoning and Internet of Things. Such capabilities are designed to support AI-based solutions, knowledge representation and reasoning, and the Internet of Things (IoT) applications. These technology trends involve relevant computational areas, that is, intelligent devices, sensors, autonomous vehicles, robotics, virtual reality, augmented intelligence, and others. The study addresses and validates solutions on how researchers can solve issues that affect AI, knowledge representation and reasoning, and IoT applications.}
}
@article{AIROLDI2024101864,
title = {The nested relationality of perceived legitimacy: Mapping taste hierarchies with granular digital traces},
journal = {Poetics},
volume = {102},
pages = {101864},
year = {2024},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2024.101864},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X24000032},
author = {Massimo Airoldi},
keywords = {Taste, Cultural hierarchies, Music classification, Youtube, Digital traces},
abstract = {The article has a double purpose. On the one hand, it contributes to theories of cultural legitimacy and classification. Based on data about consumers’ music evaluations, it shows that taste hierarchies are configured as nested and relational classificatory systems. Nested, because rank systems of symbolic value are collectively recognized, reproduced, and negotiated by consumers not only at the level of genres, but also at lower, nested levels – e.g., sub-genre, artist, single artwork; relational, because the value attributed to music by consumers is ordinarily assessed and constructed through analogies and comparisons, and partly depends on the classifier's relative position in the social space. On the other hand, this paper makes a key methodological contribution: by analyzing large amounts of YouTube data through computational methods and in combination with survey data, it illustrates how the granularity of digital traces can advance sociological research on cultural categories, meaning structures and symbolic imaginaries.}
}
@article{YANG2025105265,
title = {Harmony in diversity: Digital literacy research in a multidisciplinary landscape},
journal = {Computers & Education},
volume = {230},
pages = {105265},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105265},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000338},
author = {Feng Yang and Ruiyang Yao and Yunyue Ren and Luxuan Guo},
keywords = {Information literacy, Interdisciplinary projects, Applications in subject areas, Bibliometrics},
abstract = {The advent of the digital era has significantly heightened interest in digital literacy across multidisciplinary backgrounds and has endowed these fields with interdisciplinary and integrative characteristics. In this study, we employed VOSviewer and Bibliometrix for bibliometric and descriptive analyses of digital literacy, and we analyzed 3005 records from the Social Science Citation Index and Science Citation Index. We constructed keyword co-occurrence time networks across five distinct research areas and supplemented them with keyword co-occurrence frequencies to examine similarities and differences between research themes from diverse disciplinary perspectives. The findings of this study indicate that although various fields recognize the significance of digital literacy, different fields prioritize different aspects. As the main field of research, Education & Educational Research focus primarily on the pedagogical practices of cultivating digital literacy, whereas Communication emphasizes the cultivation of digital literacy to address challenges in information dissemination. Information Science & Library Science typically view libraries as central to digital literacy. Moreover, Computer Science research emphasizes the leveraging of technology, whereas Psychology explores the connection between digital literacy and cognitive processes. Analyzing the differences between different disciplines and drawing new ideas from them is of great significance for Education & Educational Research regarding how to deepen digital literacy education content, construct digital literacy education contexts, integrate digital literacy education resources, narrow the digital divide, and promote educational equity in the future.}
}
@article{CONRAD1991316,
journal = {Bulletin of Mathematical Biology},
volume = {53},
number = {1},
pages = {316-318},
year = {1991},
issn = {0092-8240},
doi = {https://doi.org/10.1016/S0092-8240(05)80052-7},
url = {https://www.sciencedirect.com/science/article/pii/S0092824005800527},
author = {Michael Conrad}
}
@incollection{GARDNER2024153,
title = {Chapter 7 - Smart design for cultural heritage},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {153-174},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00005-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443184529000057},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Heritage futures, Interaction, Physical computing, Smart cultural heritage, Smart heritage, Smart city, Urban technology},
abstract = {This chapter explores the evolving relationship between cultural heritage and the smart city. The role of smart technologies in a cultural heritage context is often assumed to involve the integration of sensor-based technologies and computational systems to autonomously monitor and manage sites. This chapter expands the definition of smart heritage to include urban technology projects that use sensor-based technologies and physical computing to realize situated and embodied interaction experiences that encourage citizens and visitors to share and co-create cultural heritage experiences with each other. It discusses existing and speculative urban technology projects that combine spatial design and physical computing affordances to create cultural heritage experiences that can be simultaneously attuned to both the past and the future.}
}
@article{GIORGI2024119928,
title = {Embedding parametric resonance in a 2:1 wave energy converter to get a broader bandwidth},
journal = {Renewable Energy},
volume = {222},
pages = {119928},
year = {2024},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2023.119928},
url = {https://www.sciencedirect.com/science/article/pii/S0960148123018438},
author = {Giuseppe Giorgi},
keywords = {2:1 parametric resonance, Parametric instability, Wave energy converter, Nonlinear Froude–Krylov force},
abstract = {The effort to increase the converted power is a common challenge to players in the field of wave energy conversion, both academic and industrial. In the case devices are found to be prone to parametric resonance, it typically has a negative impact on power harvesting and may jeopardize the reliability of the device. This paper makes the case that parametric resonance is not a danger that should be avoided, but rather a chance to achieve a broader system response bandwidth and ultimately increase the amount of power available at the power take-off. Since a time-varying wetted surface causes the highly nonlinear phenomenon of parametric resonance, linear models are unable to fully capture this instability. As a result, nonlinear Froude–Krylov forces are herein implemented via a computationally effective method for prismatic floaters that is compatible with both exhaustive simulation methods and real-time computing, as the whole simulations runs up to 50 times faster than real-time. A novel pendulum-based device is intentionally defined to exhibit a 2:1 ratio between heave and pitch natural frequencies, causing parametric instability. Results demonstrate that linear models predict a single zone of meaningful potential power extraction around the pitch natural frequency, as expected; however, by using the designed attitude to develop parametric instability, a second additional region develops near the heave natural period. As a result, the free response bandwidth is in fact increased, making more energy available at the power take-off axis thanks to the nonlinear instability embedded in the wave energy converter.}
}
@article{REN2025109484,
title = {A multi-criteria decision-making method based on discrete Z-numbers and Aczel-Alsina aggregation operators and its application on early diagnosis of depression},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109484},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109484},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624016427},
author = {Dong Ren and Xiuqin Ma and Hongwu Qin and Siyue Lei and Xuli Niu},
keywords = {Multi-criteria decision-making, Fuzzy sets, Discrete Z-numbers, Aczel-alsina aggregation operator},
abstract = {In mental health diagnostics, the questionnaire is an effective and cost-effective method. However, the traditional questionnaire test methods for depression and anxiety have great ambiguity. The discrete Z-numbers (DZs) provide solutions for describing and resolving complex fuzzy issues in the intelligent multi-criteria decision-making (MCDM) process. However, large-scale datasets are not suited for the present MCDM techniques due to their extremely high computational cost. Additionally, these techniques are less stable and flexible. To address the above issues, a novel MCDM method is introduced, which is based on the DZs theory and the Aczel-Alsina (AA) aggregation operator (AO) for large-scale datasets. To begin with, centroid points are calculated for DZs, and a series of novel AOs are introduced. And then a score function with a parameter is introduced to balance the influence between the possibility restriction and the fuzzy restriction of DZs. Thirdly, a new MCDM method under DZs is presented based on the proposed AA AOs and score function. Finally, to support the early diagnosis of depression and anxiety, we apply our method to the real-life online Depression, Anxiety, and Stress Scale (DASS) which can be transformed into DZs by our proposed preprocessing method. According to experimental results, our method is applicable to large-scale datasets and has much lower complexity as well as higher flexibility and stability.}
}
@article{GROEGER1987295,
title = {Computation—The final metaphor? An interview with Philip Johnson-Laird},
journal = {New Ideas in Psychology},
volume = {5},
number = {2},
pages = {295-304},
year = {1987},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(87)90030-4},
url = {https://www.sciencedirect.com/science/article/pii/0732118X87900304},
author = {J.A. Groeger}
}
@article{ESCOUFLAIRE2024129,
title = {Automated text classification of opinion vs. news French press articles. A comparison of transformer and feature-based approaches},
journal = {Language & Communication},
volume = {99},
pages = {129-140},
year = {2024},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2024.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0271530924000624},
author = {Louis Escouflaire and Antonin Descampe and Cédrick Fairon},
keywords = {Subjectivity, Transformers, Feature-based model, Text classification, Discourse analysis, Explainability},
abstract = {This study explores Natural Language Processing (NLP) methods for distinguishing between press articles belonging to the journalistic genres of ‘objective’ news and ‘subjective’ opinion. Two classification models are compared: CamemBERT, a French transformer model fine-tuned for the task, and a machine learning model using 32 linguistic features. Trained on 8000 Belgian French articles, both models are evaluated on 1000 Canadian French articles. Results show CamemBERT’s superiority but highlight potential for hybrid approaches and emphasizes the need for robust and transparent methods in NLP. The research contributes to understanding NLP’s role in journalism by addressing challenges of point of view detection in press discourse.}
}
@article{BENARIE1992291,
title = {Air pollution modeling: P. Zannetti, Computational Mechanics Publications, Southampton, U.K. 1990, 444 pp. Price: £59.00},
journal = {Science of The Total Environment},
volume = {119},
pages = {291},
year = {1992},
issn = {0048-9697},
doi = {https://doi.org/10.1016/0048-9697(92)90273-U},
url = {https://www.sciencedirect.com/science/article/pii/004896979290273U},
author = {Michel Benarie}
}
@article{MUGHAL2020159,
title = {Goals of the national mathematics curriculum of Pakistan: educators’ perceptions and challenges toward achievement},
journal = {International Journal of Educational Management},
volume = {35},
number = {1},
pages = {159-172},
year = {2020},
issn = {0951-354X},
doi = {https://doi.org/10.1108/IJEM-04-2020-0203},
url = {https://www.sciencedirect.com/science/article/pii/S0951354X20000678},
author = {Shahid Hussain Mughal and Muhammad Mujtaba Asad and Donnie Adams},
keywords = {Mathematics, Curriculum design, Pedagogy, Content knowledge, National plan},
abstract = {Purpose
The national mathematics curriculum of Pakistan has emphasized on improving content knowledge, reasoning abilities and problem-solving skills of students about thinking, communicating and solving mathematics (national mathematics curriculum of Pakistan, 2006). Whereas, there is a need to understand the point of view of teachers about the challenges they face in achieving the goals of national mathematics curriculum. This will help leading teacher training institutions to revisit their math teacher continuous professional development (CPD) programs and facilitate school leadership in improving the quality of math education in rural schools of the province. However, the purpose of this research study is to figure out the challenges that teachers are facing while achieving the goals of the national curriculum by teaching mathematics at the primary level in educational institutes of Pakistan.
Design/methodology/approach
In this research study qualitative research approaches have been utilized, in which focus group discussions (FGDs) were used as data collection techniques. Furthermore, thematic analysis of the data led toward the development of four overarching themes such as teachers' knowledge about mathematics curriculum, challenges relating to mathematics content and pedagogy, difficulties in developing conceptual understanding and designing lesson plans to address students' diversity.
Findings
The overall findings of this research study suggested that the majority of teachers are facing difficulties in mathematics content teaching such as decimal fraction, unitary method, measurement principles, practical geometry and data handling. Moreover, teachers are also facing challenges and difficulties in developing hands-on and minds-on activities in the teaching of mathematical concepts to the students of primary level in educational institutes of Pakistan.
Practical implications
This research study will facilitate the teachers and stakeholders to address the problematic issues in the domain of content delivery of mathematics. Whereas, this study recommends educating teachers about national mathematics curriculum and to develop a CPD framework for mathematics teachers for the enhancement of their pedagogical content knowledge. The study also recommends orientating school heads about the different aspects of math curriculum so that they can mentor math teachers in achieving math curriculum goals.
Originality/value
This is the first research study of its nature, which targets and highlights the teacher's perceptions toward the achieving the goals of national mathematics curriculum of Pakistan and addressing the pedagogical challenges faced in mathematics teachers. There is a dearth of studies in mathematics education in Sindh province. The issue is of immense importance, the findings will help teachers to improve mathematics instructions at primary level.}
}
@article{NOST202223,
title = {Earth for AI: A Political Ecology of Data-Driven Climate Initiatives},
journal = {Geoforum},
volume = {130},
pages = {23-34},
year = {2022},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2022.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0016718522000240},
author = {Eric Nost and Emma Colven},
keywords = {Adaptation, Artificial intelligence, Climate change, Digital geographies, Environmental data justice, Knowledge production},
abstract = {Emerging narratives around artificial intelligence (AI) and machine learning place great faith in these technologies’ ability to ameliorate threats posed by climate change. They promise the capacity to analyze vast amounts of more precise and real-time data, improving how decision-makers predict, respond, and adapt. Yet scholars in political ecology have long observed that technocentric approaches typically reduce complex human-environment relationships in ways that fail to account for social relations and power dynamics. This paper charts the emerging political economy of “climate AI” – the philanthropies, NGOs, private consultancies, and tech giants investing in data-driven climate initiatives. Mapping out two case studies, we show that environmental and climate crises are grist for tech solutions and find that many climate AI actors are interested in it for surveillance, greenwashing, and commodifying algorithms. We pay special attention to how neocolonial and racialized power structures manifest in climate AI and outline three ways for political ecologists and digital geographers to research its socio-materiality: how computational resources are environmentally embedded, how disasters become “shocks” that the AI industry capitalizes on, and how climate AI shapes material investment flows and landscapes. Highlighting how data-driven approaches to climate crises reproduce injustices already faced by marginalized communities, our analysis contributes to research on environmental data justice.}
}
@incollection{LOEWER20012166,
title = {Cognitive Science: Philosophical Aspects},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2166-2171},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/01026-3},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767010263},
author = {B. Loewer},
abstract = {Three questions have dominated the philosophy of mind in the analytic tradition since Descartes. They are: what are thoughts and thinking? How can the mind represent the world? What is consciousness? Most contemporary analytic philosophers attempt to answer these questions within a broadly materialistic framework since they think that there is overwhelming reason to believe that human beings are biological organisms entirely composed of ordinary matter. Recently the central questions in the philosophy of mind have been given some new twists and partial answers by developments within cognitive science. This article reviews some of the main ideas in cognitive science and its impact on these issues in the philosophy of mind.}
}
@article{B2021107538,
title = {A survey on genomic data by privacy-preserving techniques perspective},
journal = {Computational Biology and Chemistry},
volume = {93},
pages = {107538},
year = {2021},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2021.107538},
url = {https://www.sciencedirect.com/science/article/pii/S1476927121001055},
author = {Abinaya B. and Santhi S.},
keywords = {Data sharing, Data access and storage, Data computation, Outsourcing, Privacy-preserving techniques},
abstract = {Nowadays, the purpose of human genomics is widely emerging in health-related problems and also to achieve time and cost-efficient healthcare. Due to advancement in genomics and its research, development in privacy concerns is needed regarding querying, accessing and, storage and computation of the genomic data. While the genomic data is widely accessible, the privacy issues may emerge due to the untrusted third party (adversaries/researchers), they may reveal the information or strategy plans regarding the genome data of an individual when it is requested for research purposes. To mitigate this problem many privacy-preserving techniques are used along with cryptographic methods are briefly discussed. Furthermore, efficiency and accuracy in a secure and private genomic data computation are needed to be researched in future.}
}
@article{MOTANIETO2023103965,
title = {The Mexican Carbon Capture and Storage Platform: Construction of a boundary object for bridging the gaps between contexts, actors, and disciplines},
journal = {International Journal of Greenhouse Gas Control},
volume = {129},
pages = {103965},
year = {2023},
issn = {1750-5836},
doi = {https://doi.org/10.1016/j.ijggc.2023.103965},
url = {https://www.sciencedirect.com/science/article/pii/S1750583623001354},
author = {J. Mota-Nieto and J.A. Fernández-Reyes and P.M. García-Meneses},
keywords = {CCS/CCUS, Communication platform, Mexico, Boundary objects, Stakeholders},
abstract = {Carbon Capture and Storage (CCS) is a technology identified as a potential solution to mitigate climate change by reducing carbon emissions from large-scale emitters. If CCS is expected to be adopted globally, transparent and reliable data and information must be readily attainable to all stakeholders to support the technology choice and decision-making process. The implementation of CCS requires effective communication and collaboration strategies. Still, materials and communication platforms to inform stakeholders about the potential and contribution of CCS are predominantly accessible in English since ongoing projects are mainly located in English-speaking countries. The Mexican Carbon Capture and Storage platform (MeCCS) was developed as a digital sharing and learning space for national stakeholders to obtain and expand their knowledge about CCS technology in Spanish. It was constructed as a boundary object (BO) to bridge different communities and disciplines, facilitating communication, understanding, and cooperation. The platform includes diverse elements that combine science and art to produce dissemination materials for different audiences to help build critical thinking and inform them about CCS technology. The platform confirmed its capacity to transfer and translate knowledge one year after its launch. It also served to connect different audiences in Mexico and globally and identify further areas of research and CCS-related efforts.}
}
@article{CORTESE2024108397,
title = {Applications of genome-scale metabolic models to the study of human diseases: A systematic review},
journal = {Computer Methods and Programs in Biomedicine},
volume = {256},
pages = {108397},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108397},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724003900},
author = {Nicola Cortese and Anna Procopio and Alessio Merola and Paolo Zaffino and Carlo Cosentino},
keywords = {Genome-scale metabolic networks, Constraint-based modeling, Systems biology, Simulation, Systematic literature review},
abstract = {Background and Objectives:
Genome-scale metabolic networks (GEMs) represent a valuable modeling and computational tool in the broad field of systems biology. Their ability to integrate constraints and high-throughput biological data enables the study of intricate metabolic aspects and processes of different cell types and conditions. The past decade has witnessed an increasing number and variety of applications of GEMs for the study of human diseases, along with a huge effort aimed at the reconstruction, integration and analysis of a high number of organisms. This paper presents a systematic review of the scientific literature, to pursue several important questions about the application of constraint-based modeling in the investigation of human diseases. Hopefully, this paper will provide a useful reference for researchers interested in the application of modeling and computational tools for the investigation of metabolic-related human diseases.
Methods:
This systematic review was conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Elsevier Scopus®, National Library of Medicine PubMed® and Clarivate Web of Science™ databases were enquired, resulting in 566 scientific articles. After applying exclusion and eligibility criteria, a total of 169 papers were selected and individually examined.
Results:
The reviewed papers offer a thorough and up-to-date picture of the latest modeling and computational approaches, based on genome-scale metabolic models, that can be leveraged for the investigation of a large variety of human diseases. The numerous studies have been categorized according to the clinical research area involved in the examined disease. Furthermore, the paper discusses the most typical approaches employed to derive clinically-relevant information using the computational models.
Conclusions:
The number of scientific papers, utilizing GEM-based approaches for the investigation of human diseases, suggests an increasing interest in these types of approaches; hopefully, the present review will represent a useful reference for scientists interested in applying computational modeling approaches to investigate the aetiopathology of human diseases; we also hope that this work will foster the development of novel applications and methods for the discovery of clinically-relevant insights on metabolic-related diseases.}
}
@article{ZOU2025106959,
title = {LCFFNet: A Lightweight Cross-scale Feature Fusion Network for human pose estimation},
journal = {Neural Networks},
volume = {183},
pages = {106959},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106959},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024008888},
author = {Xuelian Zou and Xiaojun Bi},
keywords = {Human pose estimation, 2d dynamic multi-scale convolution, Contextual semantic information, Adaptive feature fusion},
abstract = {Human pose estimation is one of the most critical and challenging problems in computer vision. It is applied in many computer vision fields and has important research significance. However, it is still a difficult challenge to strike a balance between the number of parameters and computing load of the model and the accuracy of human pose estimation. In this study, we suggest a Lightweight Cross-scale Feature Fusion Network (LCFFNet) to strike a balance between accuracy and computational load and parameter volume. The Lightweight HRNet-Like (LHRNet) network, Cross-Resolution-Aware Semantics Module (CRASM), and Adapt Feature Fusion Module (AFFM) make up LCFFNet. To be more precise, first, we suggest a lightweight LHRNet network that includes Dynamic Multi-scale Convolution Basic (DMSC-Basic block) block, Basic block, and DMSC-Basic block submodules in the network’s three high-resolution subnetwork stages. The proposed dynamic multi-scale convolution in DMSC-Basic block can reduces the amount of model parameters and complexity of the LHRNet network, and has the ability to extract variable pose features. In order to maintain the model’s ability to express features, the Basic block is introduced. As a result, the LHRNet network not only makes the model more lightweight but also enhances its feature expression capabilities. Second, we propose a CRASM module to enhance contextual semantic information while reducing the semantic gap between different scales by fusing features from different scales. Finally, the augmented semantic feature map’s spatial resolution is finally restored from bottom to top using our suggested AFFM, and adaptive feature fusion is used to increase the positioning accuracy of important sites. Our method successfully predicts keypoints with 74.2 % AP, 89.9 % PCKh@0.5 and 66.9 % AP on the MSCOCO 2017, MPII and Crowdpose datasets, respectively. Our model reduces the number of parameters by 89.0 % and the computational complexity by 87.5 % compared with HRNet. The proposed network performs as well as current large-model human pose estimation networks while outperforming state-of the-art lightweight networks.}
}
@article{FERNANDEZ20181,
title = {Natural deep eutectic solvents-mediated extractions: The way forward for sustainable analytical developments},
journal = {Analytica Chimica Acta},
volume = {1038},
pages = {1-10},
year = {2018},
issn = {0003-2670},
doi = {https://doi.org/10.1016/j.aca.2018.07.059},
url = {https://www.sciencedirect.com/science/article/pii/S0003267018309231},
author = {María de los Ángeles Fernández and Joana Boiteux and Magdalena Espino and Federico J.V. Gomez and María Fernanda Silva},
keywords = {Natural deep eutectic solvents, Extraction, Green analytical chemistry, Sample prep, Microextractions},
abstract = {The concept of sustainable development has impacted in analytical chemistry changing the way of thinking processes and methods. It is important for analytical chemists to consider how sample preparation can integrate the basic concepts of Green Chemistry. In this sense, the replacement of traditional organic solvents is of utmost importance. Natural Deep Eutectic Solvents (NADES) have come to light as a green alternative. In the last few years, a growing number of contributions have applied these natural solvents proving their efficiency in terms of extraction ability, analyte stabilization capacity and detection compatibility. However, the arising question that has to be answered is: the use of NADES is enough to green an extraction process? This review presents an overview of knowledge regarding sustainability of NADES-based extraction procedures, focused on reported literature within the timeframe spanning from 2011 up to date. The contributions were analyzed from a green perspective in terms of energy, time, sample and solvent consumption. Moreover, we include a critical analysis to clarify whether the use of NADES as extraction media is enough for greening an analytical methodology; strategies to make them even greener are also presented. Finally, recent trends and future perspectives on how NADES-based extraction approaches in combination with computational methodologies can contribute are discussed.}
}
@article{BYLYA20172358,
title = {Modelling challenges for incremental bulk processes despite advances in simulation technology: example issues and approaches},
journal = {Procedia Engineering},
volume = {207},
pages = {2358-2363},
year = {2017},
note = {International Conference on the Technology of Plasticity, ICTP 2017, 17-22 September 2017, Cambridge, United Kingdom},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.10.1008},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817358010},
author = {O.I. Bylya and M. Ward and B. Krishnamurty and S. Tamang and R.A. Vasin},
keywords = {Flow forming, rotary forging, process modelling, simplification approaches. Introduction},
abstract = {Incremental bulk deformation processes have traditionally been difficult to simulate. This paper will argue that, despite advances in computation and software, they remain difficult to model. The main reason for this is the shortage of ideas on what is the real objective of FE modelling for such processes. Even a very detailed model and data obtained in simulation does not give answers to the main question - how to optimise the process parameters? High computational time and volume of information only aggravate the situation. All modern mathematical techniques of dimensionality reduction (such as POD/PGD) lose their power when the priorities and acceptable compromises of modelling are not clear. This paper tries to use a large volume of available experimental and modelling experience to illustrate this problem and look for possible break-through directions.}
}
@incollection{CUMMINS20171,
title = {Chapter 1 - The Agile Enterprise},
editor = {Fred A. Cummins},
booktitle = {Building the Agile Enterprise (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {1-34},
year = {2017},
series = {The MK/OMG Press},
isbn = {978-0-12-805160-3},
doi = {https://doi.org/10.1016/B978-0-12-805160-3.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128051603000016},
author = {Fred A. Cummins},
keywords = {Agile enterprise, Business impact of technology, Capability-based architecture, Business collaboration management, Value delivery management, Value delivery modeling language},
abstract = {This chapter begins with an introduction to the agile enterprise concept and provides a somewhat historical perspective on the evolution of information technology and its impact on business operations and management. It then introduces three new ways of thinking that are key to today's agile enterprise and are referenced in the subtitle of this book: (1) capability-based architecture, (2) business collaboration management (BCM), and (3) value delivery management (VDM). Finally, the impact of VDM is discussed related to the management of major business changes, along with some critical success factors for the journey to agility.}
}
@article{GOTTS2019100728,
title = {Agent-based modelling of socio-ecological systems: Models, projects and ontologies},
journal = {Ecological Complexity},
volume = {40},
pages = {100728},
year = {2019},
note = {Agent-based modelling to study resilience in socio-ecological systems},
issn = {1476-945X},
doi = {https://doi.org/10.1016/j.ecocom.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S1476945X18301272},
author = {Nicholas M. Gotts and George A.K. {van Voorn} and J. Gareth Polhill and Eline de Jong and Bruce Edmonds and Gert Jan Hofstede and Ruth Meyer},
keywords = {Socio-ecological system, Agent-based model, Complexity, Ontology},
abstract = {Socio-Ecological Systems (SESs) are the systems in which our everyday lives are embedded, so understanding them is important. The complex properties of such systems make modelling an indispensable tool for their description and analysis. Human actors play a pivotal role in SESs, but their interactions with each other and their environment are often underrepresented in SES modelling. We argue that more attention should be given to social aspects in models of SESs, but this entails additional kinds of complexity. Modelling choices need to be as transparent as possible, and to be based on analysis of the purposes and limitations of modelling. We recommend thinking in terms of modelling projects rather than single models. Such a project may involve multiple models adopting different modelling methods. We argue that agent-based models (ABMs) are an essential tool in an SES modelling project, but their expressivity, which is their major advantage, also produces problems with model transparency and validation. We propose the use of formal ontologies to make the structure and meaning of models as explicit as possible, facilitating model design, implementation, assessment, comparison and extension.}
}
@article{EVANS2008100,
title = {When can we say ‘if’?},
journal = {Cognition},
volume = {108},
number = {1},
pages = {100-116},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2008.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010027708000310},
author = {Jonathan St.B.T. Evans and Helen Neilens and Simon J. Handley and David E. Over},
keywords = {Conditionals, Reasoning, Decision making, Language comprehension},
abstract = {In this study, we focus on the conditions which permit people to assert a conditional statement of the form ‘if p then q’ with conversational relevance. In a broadly decision-theoretic approach, also drawing on hypothetical thinking theory [Evans, J. St. B. T. (2007). Hypothetical thinking: Dual processes in reasoning and judgement. Hove, UK: Psychology Press.], we predicted that conditional tips and promises would appear more useful and persuasive and be more likely to encourage an action p when (a) the conditional link from p to q was stronger, (b) the cost of the action p was lower and (c) the benefit of the consequence q was higher. Similarly, we predicted that conditional warnings and threats would be seen as more useful and persuasive and more likely to discourage an action p when (a) the conditional link from p to q was stronger, (b) the benefit of the action p was lower and (c) the cost of the consequence q was higher. All predictions were strongly confirmed, suggesting that such conditionals may best be asserted when they are of high relevance to the goals of the listener.}
}