@article{KHOONG2024124091,
title = {Evaluating the growth of Singapore's solar electricity capacity towards Green Plan 2030 targets and beyond using system dynamics modelling approach},
journal = {Applied Energy},
volume = {376},
pages = {124091},
year = {2024},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2024.124091},
url = {https://www.sciencedirect.com/science/article/pii/S0306261924014740},
author = {Wei Kit Khoong and Sreenivasulu Bellam},
keywords = {Solar electricity capacity, Singapore's energy mix, Systems thinking, System dynamics modelling, Carbon savings, Singapore Green Plan 2030},
abstract = {Having no native energy resources of fossil fuels, with poor wind resource and scarcity of land, the Solar Photovoltaic (PV) roadmap identified solar electricity as the most feasible source of renewable energy for Singapore's energy mix and supply. Moving towards net-zero emissions and to combat climate change, the Singapore government is aiming to achieve 2-Gigawatt-peak (GWp) of solar electricity target by 2030. Accordingly, the share of solar energy in the national grid is targeted to be between ∼2–6% in 2030 and ∼ 3.5–8% in 2040, and carbon emission savings to be ∼0.5–1.4 and ∼ 0.8–2.1 million tonnes per annum in 2030 and 2040 respectively. Although these ambitious targets align with the government's plans for mitigating emissions, Singapore faces great challenge in terms of land availability to install ground-mounted solar PV panels. In this paper, a system dynamics model is developed to study- to what extent can Singapore achieve the targeted solar electricity goals by 2030 or even beyond based on Green Plan 2030, what policies can be identified to achieve these targets, and how much carbon savings can be achieved through Solar electricity deployment. Accordingly, this paper presents systems thinking and system dynamics (ST&SD) methodology to model the growth of Singapore's solar capacity, carbon emission savings and share of electricity demand met by solar electricity while focusing on key complex factors such as area utilisation, subsidies, PV panel efficiency etc. Results of our model simulations and projections, based on the key data and assumptions, and policy scenarios show that Singapore's solar capacity can be accelerated by the implementation of the proposed policies to reach 2GWp goal towards 2030 or even slightly ahead of this timeline. However, should the government revise its solar capacity targets higher for the years past 2030 i.e. to achieve 8% share of total electricity generation, perhaps by 2040, policies such as an increased area utilisation, subsidies and higher panel efficiency need to be introduced. Our model simulations incorporating and evaluating these policy scenarios yielded the results aligning with the projections mentioned above. The results and insights presented in this paper offer useful recommendations to the researchers and policy makers in the field of solar electricity system in Singapore, and to study further for better policy making.}
}
@article{SANKARANARAYANAN20151,
title = {Genome-based, mechanism-driven computational modeling of risks of ionizing radiation: The next frontier in genetic risk estimation?},
journal = {Mutation Research/Reviews in Mutation Research},
volume = {764},
pages = {1-15},
year = {2015},
issn = {1383-5742},
doi = {https://doi.org/10.1016/j.mrrev.2014.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S138357421400091X},
author = {K. Sankaranarayanan and H. Nikjoo},
keywords = {Radiation risk, DNA damage, DNA repair, Biophysical models},
abstract = {Research activity in the field of estimation of genetic risks of ionizing radiation to human populations started in the late 1940s and now appears to be passing through a plateau phase. This paper provides a background to the concepts, findings and methods of risk estimation that guided the field through the period of its growth to the beginning of the 21st century. It draws attention to several key facts: (a) thus far, genetic risk estimates have been made indirectly using mutation data collected in mouse radiation studies; (b) important uncertainties and unsolved problems remain, one notable example being that we still do not know the sensitivity of human female germ cells to radiation-induced mutations; and (c) the concept that dominated the field thus far, namely, that radiation exposures to germ cells can result in single gene diseases in the descendants of those exposed has been replaced by the concept that radiation exposure can cause DNA deletions, often involving more than one gene. Genetic risk estimation now encompasses work devoted to studies on DNA deletions induced in human germ cells, their expected frequencies, and phenotypes and associated clinical consequences in the progeny. We argue that the time is ripe to embark on a human genome-based, mechanism-driven, computational modeling of genetic risks of ionizing radiation, and we present a provisional framework for catalyzing research in the field in the 21st century.}
}
@incollection{DASILVASOARES202349,
title = {Chapter Three - Exploring the potential of eye tracking on personalized learning and real-time feedback in modern education},
editor = {Mariuche Gomides and Isabela Starling-Alves and Flávia H. Santos},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {282},
pages = {49-70},
year = {2023},
booktitle = {Brain and Maths in Ibero-America},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S0079612323000936},
author = {Raimundo {da Silva Soares} and Amanda Yumi Ambriola Oku and Cândida da Silva Ferreira Barreto and João Ricardo Sato},
keywords = {Mathematics education, Eye tracking, Teaching practice, Student gaze},
abstract = {Eye tracking is one of the techniques used to investigate cognitive mechanisms involved in the school context, such as joint attention and visual perception. Eye tracker has portability, straightforward application, cost-effectiveness, and infant-friendly neuroimaging measures of cognitive processes such as attention, engagement, and learning. Furthermore, the ongoing software enhancements coupled with the implementation of artificial intelligence algorithms have improved the precision of collecting eye movement data and simplified the calibration process. These characteristics make it plausible to consider eye-tracking technology a promising tool to assist the teaching-learning process in school routines. However, eye tracking needs to be explored more as an educational instrument for real-time classroom activities and teachers' feedback. This perspective article briefly presents the fundamentals of the eye-tracking technique and four illustrative examples of employing this method in everyday school life. The first application shows how eye tracker information may contribute to teacher assessment of students' computational thinking in coding classes. In the second and third illustrations, we discuss the additional information provided by the eye-tracker to the teacher assessing the student's strategies to solve fraction problems and chart interpretation. The last illustration demonstrates the potential of eye tracking to provide Real-time feedback on learning difficulties/disabilities. Thus, we highlight the potential of the eye tracker as a complementary tool to promote personalized education and discuss future perspectives. In conclusion, we suggest that an eye-tracking system could be helpful by providing real-time student gaze leading to immediate teacher interventions and metacognition strategies.}
}
@article{ANDRADE2017111,
title = {Exact posterior computation in non-conjugate Gaussian location-scale parameters models},
journal = {Communications in Nonlinear Science and Numerical Simulation},
volume = {53},
pages = {111-129},
year = {2017},
issn = {1007-5704},
doi = {https://doi.org/10.1016/j.cnsns.2017.04.036},
url = {https://www.sciencedirect.com/science/article/pii/S100757041730151X},
author = {J.A.A. Andrade and P.N. Rathie},
keywords = {Bayesian computation, Exact posterior distribution, Non-conjugate models, Special functions, H-function},
abstract = {In Bayesian analysis the class of conjugate models allows to obtain exact posterior distributions, however this class quite restrictive in the sense that it involves only a few distributions. In fact, most of the practical applications involves non-conjugate models, thus approximate methods, such as the MCMC algorithms, are required. Although these methods can deal with quite complex structures, some practical problems can make their applications quite time demanding, for example, when we use heavy-tailed distributions, convergence may be difficult, also the Metropolis-Hastings algorithm can become very slow, in addition to the extra work inevitably required on choosing efficient candidate generator distributions. In this work, we draw attention to the special functions as a tools for Bayesian computation, we propose an alternative method for obtaining the posterior distribution in Gaussian non-conjugate models in an exact form. We use complex integration methods based on the H-function in order to obtain the posterior distribution and some of its posterior quantities in an explicit computable form. Two examples are provided in order to illustrate the theory.}
}
@article{RUBENSTEIN2022101030,
title = {Exploring creativity's complex relationship with learning in early elementary students},
journal = {Thinking Skills and Creativity},
volume = {44},
pages = {101030},
year = {2022},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101030},
url = {https://www.sciencedirect.com/science/article/pii/S1871187122000335},
author = {Lisa DaVia Rubenstein and Jenna Thomas and W. Holmes Finch and Lisa M. Ridgley},
keywords = {Creativity, Learning, Early elementary, Academic achievement, Kindergarten},
abstract = {The purpose of this study was to examine the relationship between learning and creativity in early elementary students using both static and growth achievement scores in reading and mathematics. Participants were kindergarten and first grade students from the Midwestern United States. Initial correlations demonstrated significant positive relationships between students’ performance on the Torrance Test of Creative Thinking –Figural (TTCT-F) and static academic achievement scores in both reading and mathematics, but that same relationship did not exist with academic growth scores. Specifically, when academic growth was examined further using Generalized Additive Models (GAMs), a complex picture emerged, such that grade level (i.e., kindergarten v. first grade) and subscale type (e.g., Fluency v. Originality) influenced the significance and nature of the relationship (i.e., linear v. nonlinear). In general, as students increased in creativity performance, they demonstrated less academic growth. Future work should explore the underlying mechanisms explaining these relationships to better help students leverage their creative abilities for positive academic gains in the classroom setting.}
}
@article{YOUSIF201880,
title = {Fuzzy logic computational model for performance evaluation of Sudanese Universities and academic staff},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {30},
number = {1},
pages = {80-119},
year = {2018},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2016.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1319157816300556},
author = {Mohamed Khalid Yousif and Adnan Shaout},
keywords = {Evaluation criteria, Performance evaluation, Sudanese universities, Survey design, Fuzzy computational model, Consistency checking},
abstract = {The excellence of a Sudanese universities and academic staff member can be effectively classified by systematic and objective design criteria, which participates in developing the learning outcomes in Sudan. In the first phase of this study, we reviewed the literatures, determined and defined the suitable quantitative and qualitative criteria and then designed & exploited pairwise comparison and evaluation forms through a survey to get experts opinions/preference on the evaluation criteria that are used to measure the universities and academic staff performance. This paper presents a fuzzy logic computational model based on this survey to measure and classify the performance of Sudanese universities and academic staff, which includes computation of criteria weights and overall evaluation of Sudanese universities and academic staff using AHP and TOPSIS techniques.}
}
@article{ARJMANDI202350,
title = {Embedding computer programming into a chemical engineering course: The impact on experiential learning},
journal = {Education for Chemical Engineers},
volume = {43},
pages = {50-57},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000064},
author = {Mohammadreza Arjmandi and Meng Wai Woo and Cody Mankelow and Thomas Loho and Kaveh Shahbaz and Amar Auckaili and Ashvin Thambyah},
keywords = {Engineering education, Qualitative study, Programming with MATLAB, Problem-based learning, Student experience},
abstract = {The need for autonomous engineering graduates who demonstrate hands-on skills has increased in the industry. Computer programming helps engineering students solve real-world problems systematically and accurately by applying governing physical and mathematical models into a format that a computer can read and execute. This study describes the pedagogical approach of incorporating programming workshops and assessments into a second-year chemical engineering course. The impact of this intervention on experiential learning amongst the students was then evaluated by analysing the feedback provided by voluntary participants during several focus group sessions. The feedback gave further insight into teaching pedagogy with respect to Kolb's experiential learning cycle. It was found the programming background of an individual clearly affects the phase of the learning cycle they predominantly experience during the workshops. Furthermore, programming background affected an individual's critical thinking while approaching an engineering problem. Constructive feedback provided by the student participants offered an invaluable opportunity for the teaching team to reflect on what went well and the areas for improvement in future iterations. The findings of this study can advance knowledge around design and implementation of a programming module within an engineering course.}
}
@article{KONDINSKI20226397,
title = {Composition-driven archetype dynamics in polyoxovanadates††Electronic supplementary information (ESI) available. CCDC 2128841 and 2130016. For ESI and crystallographic data in CIF or other electronic format see https://doi.org/10.1039/d2sc01004f},
journal = {Chemical Science},
volume = {13},
number = {21},
pages = {6397-6412},
year = {2022},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d2sc01004f},
url = {https://www.sciencedirect.com/science/article/pii/S2041652023011690},
author = {Aleksandar Kondinski and Maren Rasmussen and Sebastian Mangelsen and Nicole Pienack and Viktor Simjanoski and Christian Näther and Daniel L. Stares and Christoph A. Schalley and Wolfgang Bensch},
abstract = {ABSTRACT
Molecular metal oxides often adopt common structural frameworks (i.e. archetypes), many of them boasting impressive structural robustness and stability. However, the ability to adapt and to undergo transformations between different structural archetypes is a desirable material design feature offering applicability in different environments. Using systems thinking approach that integrates synthetic, analytical and computational techniques, we explore the transformations governing the chemistry of polyoxovanadates (POVs) constructed of arsenate and vanadate building units. The water-soluble salt of the low nuclearity polyanion [V6As8O26]4− can be effectively used for the synthesis of the larger spherical (i.e. kegginoidal) mixed-valent [V12As8O40]4− precipitate, while the novel [V10As12O40]8− POVs having tubular cyclic structures are another, well soluble product. Surprisingly, in contrast to the common observation that high-nuclearity polyoxometalate (POM) clusters are fragmented to form smaller moieties in solution, the low nuclearity [V6As8O26]4− anion is in situ transformed into the higher nuclearity cluster anions. The obtained products support a conceptually new model that is outlined in this article and that describes a continuous evolution between spherical and cyclic POV assemblies. This new model represents a milestone on the way to rational and designable POV self-assemblies.}
}
@article{PUPKOV2021489,
title = {Dynamic and Information Properties of Intelligent Control Systems},
journal = {Procedia Computer Science},
volume = {186},
pages = {489-494},
year = {2021},
note = {14th International Symposium "Intelligent Systems},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.04.169},
url = {https://www.sciencedirect.com/science/article/pii/S187705092101005X},
author = {K.A. Pupkov and Y.K. Brovarskaya},
keywords = {traffic flow model, optimal control, evolutionary computations, uncertainties},
abstract = {The paper considers the dynamic and informational properties of intelligent systems. The relationship is established between control quality and stability in such systems. The method was developed and a study was conducted of the dependence of the control quality and the time spent by the human operator on the evaluation of the test image. The influence of the clean delay time on the stability margin and the quality of the setting process is studied. The study shows that in intelligent systems that work in connection with a human-operator (a group of people) or independently, the time spent (a latent period) to implement thinking forms affects on the one hand the control quality, on the other the system stability. The desired value clean delay time is set. The research results are presented. The new parameter of information properties of intelligent systems has been introduced – the control quality.}
}
@article{VALLEETOURANGEAU2020100812,
title = {Mapping systemic resources in problem solving},
journal = {New Ideas in Psychology},
volume = {59},
pages = {100812},
year = {2020},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2020.100812},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X17300272},
author = {Frédéric Vallée-Tourangeau and Gaëlle Vallée-Tourangeau},
abstract = {In the wild, thinking demonstrably uses interactive processes that draw on a wide range of external resources, spanning multiple time scales. As Malafouris (2015, p. 361) puts it, “cognition is not a within property; it is an in-between process”. Interactive processes configure extended systems within which each human agent is embedded. Yet much research on higher cognition, such as problem solving, reflects an implicit but deep commitment to methodological individualism that casts the agent as the ontological locus of cognition, and largely dictates the nature of the research enterprise. Thus, tasks to measure capacities and gauge reasoning performance are designed in a manner that reduces or eliminates the possibility of interacting with the problem presentation; if thinking takes place in the head, there is no need or reason to engineer procedures wherein agents can interact with the task's physical constituents. Conversely, a methodological interactivism forces one to acknowledge the participative yet not all-encompassing role of capacities such as working memory and thinking dispositions; it also encourages the granular mapping of the cognitive ecosystem from which new ideas emerge. To adopt an interactivist perspective is thus to focus on the cognitive resources of the extended system inviting a careful description of how these resources are dynamically configured over time and space to promote the development of new ideas in problem solving. In turn, a systemic perspective encourages the development of interventions that promote cognitive performance through the optimisation of systemic rather than individualist cognitive resources.}
}
@article{DUKHANOV20141433,
title = {Double-degree Master's Program in Computational Science: Experiences of ITMO University and University of Amsterdam},
journal = {Procedia Computer Science},
volume = {29},
pages = {1433-1445},
year = {2014},
note = {2014 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.130},
url = {https://www.sciencedirect.com/science/article/pii/S187705091400307X},
author = {Alexey V. Dukhanov and Valeria V. Krzhizhanovskaya and Anna Bilyatdinova and Alexander V. Boukhanovsky and Peter M.A. Sloot},
keywords = {teaching computational science, M aster's program, double degree, curriculum, enrollment, student research, funding opportunities},
abstract = {We present a new double-degree graduate (Master's) programme developed together by the ITMO University, Russia and University of Amsterdam, The Netherlands. First, we look into the global aspects of integration of d ifferent educational systems and list some funding opportunities fro m European foundations. Then we describe our double-degree program curricu lu m, suggest the time line of enrollment and studies, and give some e xa mples of student research topics. Finally, we d iscuss the peculiarities of joint progra ms with Russia, re flect on the first lessons learnt, and share our thoughts and experiences that could be of interest to the international community e xpanding the educational ma rkets to the vast countries like Russia, Ch ina or India. The paper is written for education professionals and contains useful information for potential students.}
}
@article{CHEN20121,
title = {Varieties of agents in agent-based computational economics: A historical and an interdisciplinary perspective},
journal = {Journal of Economic Dynamics and Control},
volume = {36},
number = {1},
pages = {1-25},
year = {2012},
issn = {0165-1889},
doi = {https://doi.org/10.1016/j.jedc.2011.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0165188911001692},
author = {Shu-Heng Chen},
keywords = {Cellular automata, Autonomous agents, Tournaments, Genetic algorithms, Genetic programming, Cognitive capacity},
abstract = {In this paper, we trace four origins of agent-based computational economics (ACE), namely, the markets origin, the cellular-automata origin, the tournaments origin, and the experiments origin. Along with this trace, we examine how these origins have motivated different concepts and designs of agents in ACE, which starts from the early work on simple programmed agents, randomly behaving agents, zero-intelligence agents, human-written programmed agents, autonomous agents, and empirically calibrated agents, and extends to the newly developing cognitive agents, psychological agents, and culturally sensitive agents. The review also shows that the intellectual ideas underlying these varieties of agents cross several disciplines, which may be considered as a part of a general attempt to study humans (and their behavior) with an integrated interdisciplinary foundation.}
}
@article{SILAGHI20121303,
title = {A time-constrained SLA negotiation strategy in competitive computational grids},
journal = {Future Generation Computer Systems},
volume = {28},
number = {8},
pages = {1303-1315},
year = {2012},
note = {Including Special sections SS: Trusting Software Behavior and SS: Economics of Computing Services},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2011.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X11002251},
author = {Gheorghe Cosmin Silaghi and Liviu Dan Şerban and Cristian Marius Litan},
keywords = {SLA negotiation, Intelligent strategies, Bayesian learning, Time constraints},
abstract = {Automated and intelligent negotiation solutions for reaching service level agreements (SLA) represent a hot research topic in computational grids. Previous work regarding SLA negotiation in grids focuses on devising bargaining models where service providers and consumers can meet and exchange SLA offers and counteroffers. Recent developments in agent research introduce strategies based on opponent learning for contract negotiation. In this paper we design a generic framework for strategical negotiation of service level values under time constraints and exemplify the usage of our framework by extending the Bayesian learning agent to cope with the limited duration of a negotiation session. We prove that opponent learning strategies are worth for consideration in open competitive computational grids, leading towards an optimal allocation of resources and fair satisfaction of participants.}
}
@article{GAAR202167,
title = {Towards a computational proof of Vizing's conjecture using semidefinite programming and sums-of-squares},
journal = {Journal of Symbolic Computation},
volume = {107},
pages = {67-105},
year = {2021},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2021.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0747717121000092},
author = {Elisabeth Gaar and Daniel Krenn and Susan Margulies and Angelika Wiegele},
keywords = {Vizing's conjecture, Algebraic model, Gröbner basis, Sum-of-squares problems, Semidefinite programming},
abstract = {Vizing's conjecture (open since 1968) relates the product of the domination numbers of two graphs to the domination number of their Cartesian product graph. In this paper, we formulate Vizing's conjecture as a Positivstellensatz existence question. In particular, we select classes of graphs according to their number of vertices and their domination number and encode the conjecture as an ideal/polynomial pair such that the polynomial is non-negative on the variety associated with the ideal if and only if the conjecture is true for this graph class. Using semidefinite programming we obtain numeric sum-of-squares certificates, which we then manage to transform into symbolic certificates confirming non-negativity of our polynomials. Specifically, we obtain exact low-degree sparse sum-of-squares certificates for particular classes of graphs. The obtained certificates allow generalizations for larger graph classes. Besides computational verification of these more general certificates, we also present theoretical proofs as well as conjectures and questions for further investigations.}
}
@article{SUN2001241,
title = {Computation, reduction, and teleology of consciousness},
journal = {Cognitive Systems Research},
volume = {1},
number = {4},
pages = {241-249},
year = {2001},
issn = {1389-0417},
doi = {https://doi.org/10.1016/S1389-0417(00)00013-9},
url = {https://www.sciencedirect.com/science/article/pii/S1389041700000139},
author = {Ron Sun},
keywords = {Consciousness, Cognition, Qualia, Implicit learning, Computation, Reduction, Teleology},
abstract = {This paper aims to explore mechanistic and teleological explanations of consciousness. In terms of mechanistic explanations, it critiques various existing views, especially those embodied by existing computational cognitive models. In this regard, the paper argues in favor of the explanation based on the distinction between localist (symbolic) representation and distributed representation (as formulated in the connectionist literature), which reduces the phenomenological difference to a mechanistic difference. Furthermore, to establish a teleological explanation of consciousness, the paper discusses the issue of the functional role of consciousness on the basis of the aforementioned mechanistic explanation. A proposal based on synergistic interaction between the conscious and the unconscious is advanced that encompasses various existing views concerning the functional role of consciousness. This two-step deepening explanation has some empirical support, in the form of a cognitive model and various cognitive data that it captures.}
}
@article{LOHSE2012236,
title = {Thinking about muscles: The neuromuscular effects of attentional focus on accuracy and fatigue},
journal = {Acta Psychologica},
volume = {140},
number = {3},
pages = {236-245},
year = {2012},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2012.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0001691812000807},
author = {Keith R. Lohse and David E. Sherwood},
keywords = {Attention, Force production, Motor control, Fatigue},
abstract = {Although the effects of attention on movement execution are well documented behaviorally, much less research has been done on the neurophysiological changes that underlie attentional focus effects. This study presents two experiments exploring effects of attention during an isometric plantar-flexion task using surface electromyography (sEMG). Participants' attention was directed either externally (towards the force plate they were pushing against) or internally (towards their own leg, specifically the agonist muscle). Experiment 1 tested the effects of attention on accuracy and efficiency of force produced at three target forces (30, 60, and 100% of the maximum voluntary contraction; MVC). An internal focus of attention reduced the accuracy of force being produced and increased cocontraction of the antagonist muscle. Error on a given trial was positively correlated with the magnitude of cocontraction on that trial. Experiment 2 tested the effects of attention on muscular fatigue at 30, 60 and 100%MVC. An internal focus of attention led to less efficient intermuscular coordination, especially early in the contraction. These results suggest that an internal focus of attention disrupts efficient motor control in force production resulting in increased cocontraction, which potentially explains other neuromechanical findings (e.g. reduced functional variability with an internal focus).}
}
@article{WELLS1998269,
title = {Turing's analysis of computation and theories of cognitive architecture},
journal = {Cognitive Science},
volume = {22},
number = {3},
pages = {269-294},
year = {1998},
issn = {0364-0213},
doi = {https://doi.org/10.1016/S0364-0213(99)80041-X},
url = {https://www.sciencedirect.com/science/article/pii/S036402139980041X},
author = {A.J. Wells},
abstract = {Turing's analysis of computation is a fundamental part of the background of cognitive science. In this paper it is argued that a re-interpretation of Turing's work is required to underpin theorizing about cognitive architecture. It is claimed that the symbol systems view of the mind, which is the conventional way of understanding how Turing's work impacts on cognitive science, is deeply flawed. There is an alternative interpretation that is more faithful to Turing's original insights, avoids the criticisms made of the symbol systems approach and is compatible with the growing interest in agent-environment interaction. It is argued that this interpretation should form the basis for theories of cognitive architecture.}
}
@article{GOLDSMITH198815,
title = {Idiots savants — Thinking about remembering: A response to White},
journal = {New Ideas in Psychology},
volume = {6},
number = {1},
pages = {15-23},
year = {1988},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(88)90020-7},
url = {https://www.sciencedirect.com/science/article/pii/0732118X88900207},
author = {Lynn T. Goldsmith and David Henry Feldman}
}
@article{OXMAN1999105,
title = {Educating the designerly thinker},
journal = {Design Studies},
volume = {20},
number = {2},
pages = {105-122},
year = {1999},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(98)00029-5},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X98000295},
author = {Rivka Oxman},
keywords = {design education, design cognition, design knowledge, conceptual design, computational models},
abstract = {This paper presents a hypothesis about design education that is framed within and derived from cognitive theories of learning. The relevance of design thinking and cognitive approaches to the development of pedagogical approaches in design education is presented and discussed. A conceptual model for design education that emphasizes the acquisition of explicit knowledge of design is proposed. The acquisition of knowledge is achieved through the explication of cognitive structures and strategies of design thinking. The explication process is constructed by exploiting a representational formalism, and a computational medium which supports both the learning process as well as the potential re-use of this knowledge. Finally, an argument is presented that the measure of learning, generally equated with the evaluation of the product of designing, can instead be based upon evaluating learning increments of acquired knowledge.}
}
@article{ZETTERLUND2023104508,
title = {Computational modelling to advise and inform optimization for aeration and nutrient-dosing in wastewater treatment: Case study from pulp and paper mill in south-central Sweden},
journal = {Journal of Water Process Engineering},
volume = {56},
pages = {104508},
year = {2023},
issn = {2214-7144},
doi = {https://doi.org/10.1016/j.jwpe.2023.104508},
url = {https://www.sciencedirect.com/science/article/pii/S2214714423010280},
author = {Selma Zetterlund and Olivia Schwartz and Maria Sandberg and G. Venkatesh},
keywords = {Aeration, Biological wastewater treatment, Energy use optimisation, Nutrients, Pulp and paper mills},
abstract = {Sweden's pulp and paper sector accounts for a significant proportion of national energy usage, besides generating wastewater that causes eutrophication of nearby sinks. In this paper, the possibility of optimizing biological wastewater treatment at the Stora Enso Skoghall mill south of the city of Karlstad in central Sweden, with respect to electricity usage and the addition of nutrients, has been investigated. A computational model of the treatment process was developed, based on process data obtained from the said mill, and nine different scenarios were compared subsequently, with energy use, environmental impacts and operational expenses, as criteria. The most energy-efficient and cost-effective alternative was a combination of measures such as lowering the oxygen level in the MBBR (Moving Bed Bio-Reactor) from 3 mg/l to 2 mg/l and using the Hyperclassic aerator in the aerated lagoon. This arrangement yielded a 48.5 % reduction in operational expenses, and a 60 % decrease in the energy use, vis-à-vis the reference case, without affecting the efficiency of the treatment process. This also uncovered an opportunity to mitigate the annual global warming and eutrophication impacts, by approximately 100 tons CO2-eq. and 140 kg PO43−-eq. respectively. All attempts to optimise the use of resources and decrease the anthropogenic environmental footprint ought to be made to come closer to the targets set by the United Nations' sustainable development goals (SDGs). The authors' conclusion predicated on the results of the modelling and analysis done in this study is that the potential of seemingly small process modifications, such as lowering the oxygen level in the MBBR, and applying a more optimal dosage of nutrient salts, must not be overlooked by wastewater treatment plants in general (and those in pulp and paper mills in particular).}
}
@article{GOLIGHER20241067,
title = {Bayesian statistics for clinical research},
journal = {The Lancet},
volume = {404},
number = {10457},
pages = {1067-1076},
year = {2024},
issn = {0140-6736},
doi = {https://doi.org/10.1016/S0140-6736(24)01295-9},
url = {https://www.sciencedirect.com/science/article/pii/S0140673624012959},
author = {Ewan C Goligher and Anna Heath and Michael O Harhay},
abstract = {Summary
Frequentist and Bayesian statistics represent two differing paradigms for the analysis of data. Frequentism became the dominant mode of statistical thinking in medical practice during the 20th century. The advent of modern computing has made Bayesian analysis increasingly accessible, enabling growing use of Bayesian methods in a range of disciplines, including medical research. Rather than conceiving of probability as the expected frequency of an event (purported to be measurable and objective), Bayesian thinking conceives of probability as a measure of strength of belief (an explicitly subjective concept). Bayesian analysis combines previous information (represented by a mathematical probability distribution, the prior) with information from the study (the likelihood function) to generate an updated probability distribution (the posterior) representing the information available for clinical decision making. Owing to its fundamentally different conception of probability, Bayesian statistics offers an intuitive, flexible, and informative approach that facilitates the design, analysis, and interpretation of clinical trials. In this Review, we provide a brief account of the philosophical and methodological differences between Bayesian and frequentist approaches and survey the use of Bayesian methods for the design and analysis of clinical research.}
}
@article{VAZQUEZ2017550,
title = {Price computation in electricity auctions with complex rules: An analysis of investment signals},
journal = {Energy Policy},
volume = {105},
pages = {550-561},
year = {2017},
issn = {0301-4215},
doi = {https://doi.org/10.1016/j.enpol.2017.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0301421517300770},
author = {Carlos Vazquez and Michelle Hallack and Miguel Vazquez},
keywords = {Electricity auctions, Investment signals, Side payments, Integer decisions, Marginal cost},
abstract = {This paper discusses the problem of defining marginal costs when integer variables are present, in the context of short-term power auctions. Most of the proposals for price computation existing in the literature are concerned with short-term competitive equilibrium (generators should not be willing to change the dispatch assigned to them by the auctioneer), which implies operational-cost recovery for all of the generators accepted in the auction. However, this is in general not enough to choose between the different pricing schemes. We propose to include an additional criterion in order to discriminate among different pricing schemes: prices have to be also signals for generation expansion. Using this condition, we arrive to a single solution to the problem of defining prices, where they are computed as the shadow prices of the balance equations in a linear version of the unit commitment problem. Importantly, not every linearization of the unit commitment is valid; we develop the conditions for this linear model to provide adequate investment signals. Compared to other proposals in the literature, our results provide a strong motivation for the pricing scheme and a simple method for price computation.}
}
@article{KHANUM2022131890,
title = {Synthesis, single crystal, characterization and computational study of 2-amino-N-cyclopropyl-5-ethyl-thiophene-3-carboxamide},
journal = {Journal of Molecular Structure},
volume = {1250},
pages = {131890},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2021.131890},
url = {https://www.sciencedirect.com/science/article/pii/S0022286021020123},
author = {Ghazala Khanum and Aysha Fatima and Nazia Siddiqui and D.D. Agarwal and R.J. Butcher and Sanjay Kumar Srivastava and Saleem Javed},
keywords = {DFT studies, Fukui function, MEP, ELF, Hirshfeld, Molecular docking},
abstract = {2-amino-N-cyclopropyl-5-ethylthiophene-3-carboxamide (ACPETC) (C10H14N2OS) has been synthesized, characterized via single-crystal X-ray diffraction at 296 K and studied theoretically via DFT approach. The compound crystallizes in tetragonal crystal system, space group I-4 with Z = 8 and the following unit cell dimensions: a = 16.0892(4) Å, b = 16.0892(4) Å, c = 8.4059(2) Å. ACPETC was experimentally characterized by 1H, 13C NMR, FT-IR, UV–Vis and ESI-MS analysis. The molecular structure, vibrational spectra, MEP, ELF, NLO, NBO, NHO, and FMO analysis of ACPETC (C10H14N2OS) in the ground state were estimated using HF, MP2, DFT/B3LYP using the 6–311++G(d,p) basis set. Computed NMR chemical shifts (1H and 13C), as well as discrete regions in IR active vibrations, are in good concurrence with their experimental counterparts. FT-IR spectra of ACPETC were obtained in the ranges of 4000−450 cm−1. The UV–vis spectrum as well as the effects of solvents has been studied. The estimated HOMO and LUMO energies reveal that charge transfer happens within the molecule and MEP surface to be a chemically reactive region suitable for drug action. The O1-atom appears to be more vulnerable to electrophilic assault. The NBO analysis was also performed. It indicates that the greatest second order perturbation energy E(2) = 50.11 kcal/mol associated with electron delocalization from the donor (N15) → π* (C10-O14) acceptor interaction. On the atomic charges of the title chemical, the Fukui function and Mulliken analysis have been calculated. 3-D and 2-D interactions in crystals were studies and Hirshfeld surface analysis was used. To discover the optimum ligand-protein interactions, molecular docking was used using eight protein receptors.}
}
@article{MCLEAN2023104019,
title = {From Anti-doping-I to Anti-doping-II: Toward a paradigm shift for doping prevention in sport},
journal = {International Journal of Drug Policy},
volume = {115},
pages = {104019},
year = {2023},
issn = {0955-3959},
doi = {https://doi.org/10.1016/j.drugpo.2023.104019},
url = {https://www.sciencedirect.com/science/article/pii/S0955395923000683},
author = {Scott McLean and Mitchell Naughton and Hugo Kerhervé and Paul M. Salmon},
keywords = {Sport, Doping, World anti-doping agency, Systems thinking, Systems analysis},
abstract = {Doping remains an intractable issue in sport and occurs in a complex and dynamic environment comprising interactions between individual, situational, and environmental factors. Anti-doping efforts have previously predominantly focused on athlete behaviours and sophisticated detection methods, however, doping issues remain. As such, there is merit in exploring an alternative approach. The aim of this study was to apply a systems thinking approach to model the current anti-doping system for four football codes in Australia, using the Systems Theoretic Accident Model and Processes (STAMP). The STAMP control structure was developed and validated by eighteen subject matter experts across a five-phase validation process. Within the developed model, education was identified as a prominent approach anti-doping authorities use to combat doping. Further, the model suggests that a majority of existing controls are reactive, and hence that there is potential to employ leading indicators to proactively prevent doping and that new incident reporting systems could be developed to capture such information. It is our contention that anti-doping research and practice should consider a shift away from the current reactive and reductionist approach of detection and enforcement to a proactive and systemic approach focused on leading indicators. This will provide anti-doping agencies a new lens to look at doping in sport.}
}
@article{TIBURU201836,
title = {Investigating the Conformation of S100β Protein Under Physiological Parameters Using Computational Modeling: A Clue for Rational Drug Design},
journal = {The Open Biomedical Engineering Journal},
volume = {12},
pages = {36-50},
year = {2018},
issn = {1874-1207},
doi = {https://doi.org/10.2174/1874120701812010036},
url = {https://www.sciencedirect.com/science/article/pii/S1874120718000036},
author = {Elvis K. Tiburu and Ibrahim Issah and Mabel Darko and Robert E. Armah-Sekum and Stephen O. A. Gyampo and Nadia K. Amoateng and Samuel K. Kwofie and Gordon Awandare},
keywords = {S100β Protein, Molecular Dynamics, Cofactors, Energy Minimization, Physiological Parameters, Alzheimer's},
abstract = {Background
Physiochemical factors such as temperature, pH and cofactors are well known parameters that confer conformational changes in a protein structure. With S100β protein being a metal binding brain-specific receptor for both extracellular and intracellular functions, a change in conformation due to the above-mentioned factors, can compromise their cellular functions and therefore result in several pathological conditions such as Alzheimer’s disease, Ischemic stroke, as well as Myocardial Infarction.
Objective
The studies conducted sought to elucidate the effect of these physiological factors on the conformational dynamics of S100β protein using computational modeling approaches.
Method
Temperature-dependent and protein-cofactor complexes molecular dynamics simulations were conducted by varying the temperature from 100 to 400K using GROMACS 5.0.3. Additionally, the conformational dynamics of the protein was studied by varying the pH at 5.0, 7.4 and 9.0 using Ambertools17. This was done by preparing the protein molecule, solvating and minimizing its energy level as well as heating it to the required temperature, equilibrating and simulating under desired conditions (NVT and NPT ensembles).
Results
The results show that the protein misfolds as a function of increasing temperature with alpha helical content at 100K and 400K being 57.8% and 43.3%, respectively. However, the binding sites of the protein were not appreciably affected by temperature variations. The protein displayed high conformational instability in acidic medium (pH ~5.0). The binding sites of Ca2+, Mg2+ and Zn2+ were identified and each exhibited different groupings of the secondary structural elements (binding motifs). The secondary structure analysis revealed different conformational changes with the characteristic appearance of two beta hairpins in the presence of Zn2+and Mg2+.
Conclusion
High temperatures, different cofactors and acidic pH confer conformational changes to the S100β structure and these results may indicate the design of novel drugs against the protein.}
}
@article{SAHADEVAN2025103141,
title = {Knowledge augmented generalizer specializer: A framework for early stage design exploration},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103141},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103141},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625000345},
author = {Vijayalaxmi Sahadevan and Rohin Joshi and Kane Borg and Vishal Singh and Abhishek Raj Singh and Bilal Muhammed and Soban Babu Beemaraj and Amol Joshi},
abstract = {In non-routine engineering design projects, the design outcome is determined by how the problem is formulated and represented in the early conceptual stage. The problem representation comprises schemas, ontologies, variables, and parameters relevant to the given problem class. Despite the critical role of early conceptual decisions in shaping the eventual design outcome, most of the computational support and automation are focused on the latter stages of parametric modelling, problem-solving, and optimization. There is inadequate support for aiding and automating problem formulation, variable and parameter identification and representation, and early-stage conceptual decisions. Therefore, this paper presents an innovative, transparent, and explainable method employing semantic reasoning to automate the step-by-step conceptual design generation process, including problem formulation, identification and representation of the variables and parameters and their dependencies. The method is realized through a novel framework called Knowledge Augmented Generalizer Specializer (KAGS). KAGS employs the Function-Behavior-Structure (FBS) ontology and the Graph-of-Thought (GoT) mechanism to enable automated reasoning with a Large Language Model (LLM). The workflow comprises various stages: problem breakdown, design prototype creation, assessment, and prototype merging. The framework is implemented and tested on a Subsea Layout (SSL) planning problem, a special class of infrastructure planning projects in deep-sea oil and gas production systems. The experimentations with KAGS demonstrate its capacity to support problem formulation, hierarchical decomposition, and solution generation. The research also provides new insights into the FBS framework and meta-level reasoning in early design stages.}
}
@article{EGRINAGY2008135,
title = {Algebraic properties of automata associated to Petri nets and applications to computation in biological systems},
journal = {Biosystems},
volume = {94},
number = {1},
pages = {135-144},
year = {2008},
note = {Seventh International Workshop on Information Processing in Cells and Tissues},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2008.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0303264708001366},
author = {Attila Egri-Nagy and Chrystopher L. Nehaniv},
keywords = {Algebraic automata theory, Petri nets, Krohn-Rhodes theorem, Algebraic biology},
abstract = {Biochemical and genetic regulatory networks are often modeled by Petri nets. We study the algebraic structure of the computations carried out by Petri nets from the viewpoint of algebraic automata theory. Petri nets comprise a formalized graphical modeling language, often used to describe computation occurring within biochemical and genetic regulatory networks, but the semantics may be interpreted in different ways in the realm of automata. Therefore, there are several different ways to turn a Petri net into a state-transition automaton. Here, we systematically investigate different conversion methods and describe cases where they may yield radically different algebraic structures. We focus on the existence of group components of the corresponding transformation semigroups, as these reflect symmetries of the computation occurring within the biological system under study. Results are illustrated by applications to the Petri net modelling of intermediary metabolism. Petri nets with inhibition are shown to be computationally rich, regardless of the particular interpretation method. Along these lines we provide a mathematical argument suggesting a reason for the apparent all-pervasiveness of inhibitory connections in living systems.}
}
@article{KALPOKIENE2023102197,
title = {Creative encounters of a posthuman kind – anthropocentric law, artificial intelligence, and art},
journal = {Technology in Society},
volume = {72},
pages = {102197},
year = {2023},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2023.102197},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X23000027},
author = {Julija Kalpokiene and Ignas Kalpokas},
keywords = {Anthropocentrism, Artificial intelligence, Creativity, Copyright},
abstract = {Artificial Intelligence (AI) is becoming an increasingly transformative force in human life. Crucially, its impact is already extending beyond automation of routine tasks and encroaching on creativity – a domain once seen as exclusively human. Hence, this article first surveys the discriminatory and exploitative underpinnings of the anthropocentric thinking that lies beyond attempts at sidelining the creative capacities of AI. Next, four different approaches to creativity and art are analyzed, ultimately conceptualizing art-ness as externally ascribed. Ultimately, the article moves to one way of such ascription – copyrightability – demonstrating the anthropocentric thinking behind attempts to both deny and award copyright protection to AI-generated content. Moreover, it transpires that human authors are under threat whichever of such strategies ends up dominant.}
}
@article{KENNEDY198538,
title = {Thinking of opening your own business? Be prepared!},
journal = {Business Horizons},
volume = {28},
number = {5},
pages = {38-42},
year = {1985},
issn = {0007-6813},
doi = {https://doi.org/10.1016/0007-6813(85)90066-7},
url = {https://www.sciencedirect.com/science/article/pii/0007681385900667},
author = {Carson R. Kennedy},
abstract = {The good news is that new businesses are booming. The bad news is that many are going bust. Careful preparation prior to opening your own business is the best way to forestall failure.}
}
@incollection{MOLE2022367,
title = {Executive/Cognitive Control},
editor = {Sergio {Della Sala}},
booktitle = {Encyclopedia of Behavioral Neuroscience, 2nd edition (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {367-376},
year = {2022},
isbn = {978-0-12-821636-1},
doi = {https://doi.org/10.1016/B978-0-12-819641-0.00111-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128196410001110},
author = {Joseph Mole and Lisa Cipolotti},
keywords = {Frontal lobes, Active thought, Executive functioning, Fluid intelligence, Language, Focal lesions, Neuropsychology, Supervisory system, Reasoning, Lateralization of function},
abstract = {The capacity for active thought is arguably one of humanity's defining features. The frontal lobes are critically involved in active thinking. In this article we will consider what can be learned from the effects of frontal lobe lesions about: (1) the relationship between active thought and intelligence, (2) whether active thought can occur without language, and (3) the processes involved in active thinking. The evidence reviewed reveals that different forms of active thought and their essential pre-requisites can be fractionated and appear to be underpinned by different frontal areas. Hence, active thinking may be achieved by distinct, interacting cognitive processes.}
}
@article{BATISTA2003189,
title = {A Computational Basis to Object?},
journal = {Neuron},
volume = {37},
number = {2},
pages = {189-190},
year = {2003},
issn = {0896-6273},
doi = {https://doi.org/10.1016/S0896-6273(03)00029-1},
url = {https://www.sciencedirect.com/science/article/pii/S0896627303000291},
author = {Aaron P. Batista},
abstract = {To use an object, we must be able to perceive the spatial relationship between the object's parts. The accepted view of how the brain coherently encodes an object is that some neurons in the frontal cortex employ an object-centered coordinate frame. A new computational model challenges this view, using the rich conceptual framework of neural basis functions.}
}
@article{YAO2018107,
title = {Three-way decision and granular computing},
journal = {International Journal of Approximate Reasoning},
volume = {103},
pages = {107-123},
year = {2018},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18302809},
author = {Yiyu Yao},
keywords = {Three-way decision, Three-way computing, Granular computing in threes, Thinking in threes, Magical number three},
abstract = {Based on results from cognitive science, this paper examines the two fields of three-way decision and granular computing, as well as their interplay. The ideas from one field shed new light on the other field. The integration of the two gives rise to three-way granular computing, that is, thinking, problem solving, and information processing in threes. We discuss a wide sense of three-way decision and propose a trisecting–acting–outcome (TAO) model. We explain fundamental notions of granular computing based on the philosophy of three-way decision as thinking in threes. We discuss a model of three-way granular computing by making use of two particular types of granular structures represented, respectively, by three granules and three levels. We use examples across different disciplines to demonstrate the values of the two types. Our investigation suggests that, in many situations, the power of granular computing is indeed the power of three-way decision, i.e., thinking in threes.}
}
@article{AGUIRRE2024101196,
title = {Mathematizing the world: A routine to advance mathematizing in the elementary classroom},
journal = {The Journal of Mathematical Behavior},
volume = {76},
pages = {101196},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101196},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000737},
author = {Julia M. Aguirre and Erin E. Turner and Elzena McVicar and Amy Roth McDuffie and Mary Q. Foote and Erin Carll},
keywords = {Mathematizing, Elementary, Mathematical thinking, Problem posing, Culturally responsive},
abstract = {The Mathematizing-the-World routine (MWR) is an efficient culturally responsive instructional routine for mathematizing that explicitly supports problem posing using an image or object. Given the under-representation of problem-posing studies in elementary school settings, our qualitative study analyzed student responses from 56 MWR enactments in grade 3–5 classrooms in two regions of the United States. Our findings include detailed examples of the MWR in action, including how three open-ended prompts engaged younger students in mathematizing and posing problems related to authentic, real-world situations. We summarize findings across the 56 MWR classroom enactments focusing on the understandings about the context and the mathematical ideas evidenced in student responses. Our findings demonstrate the potential of the MWR as a catalyst for eliciting and communicating diverse student ideas while engaged in the problem-posing process. We discuss research and practice implications for this routine to support mathematizing, and specifically problem posing in the elementary classroom.}
}
@article{SUTHAR2023122,
title = {The integrative approach of learning chemical engineering thermodynamics by using simulation-based exercises},
journal = {Education for Chemical Engineers},
volume = {45},
pages = {122-129},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S174977282300043X},
author = {Krunal J. Suthar and Milind H. Joshipura},
keywords = {Process simulation, Thermodynamics, Teaching-learning, Fluid package},
abstract = {The active learning integrative approach of simulation-based exercises along with the core course would help undergraduate students with more engaged learning. The present study describes the simulation approach using an open-source process simulator with the help of three simulation-based exercises. The first one exemplifies the importance of the selection of an appropriate fluid package. The second exercise presented in the study shows the effect of using optimized and default values of binary interaction parameters on VLE prediction of alcohol-ester systems. The small interactive simulation-based problems with expected outcomes were presented in the third exercise which makes the learning more engaging and interesting. The current study highlights an integrative approach to inculcating critical thinking and self-learning abilities using small simulation-based exercises while learning chemical engineering thermodynamics. Finally, a survey with closed- and open-ended questions was used to gather the opinions of students on the presented exercises. A short communication is needed that sheds light on the integrative approach of learning process simulation complementing the thermodynamic theory learning.}
}
@article{JOHNSON20241037,
title = {Minds and markets as complex systems: an emerging approach to cognitive economics},
journal = {Trends in Cognitive Sciences},
volume = {28},
number = {11},
pages = {1037-1050},
year = {2024},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2024.07.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661324001748},
author = {Samuel G.B. Johnson and Patrick R. Schotanus and J.A. Scott Kelso},
keywords = {decision-making, behavioral economics, narratives, agent-based models, extended mind, Coordination Dynamics},
abstract = {Cognitive economics is an emerging interdisciplinary field that uses the tools of cognitive science to study economic and social decision-making. Although most strains of cognitive economics share commitments to bridging levels of analysis (cognitive, behavioral, and systems) and embracing interdisciplinary approaches, we review a newer strand of cognitive economic thinking with a further commitment: conceptualizing minds and markets each as complex adaptive systems. We describe three ongoing research programs that strive toward these goals: (i) studying narratives as a cognitive and social representation used to guide decision-making; (ii) building cognitively informed agent-based models; and (iii) understanding markets as an extended mind – the Market Mind Hypothesis – analyzed using the concepts, methods, and tools of Coordination Dynamics.}
}
@article{HOGENDOORN2022128,
title = {Perception in real-time: predicting the present, reconstructing the past},
journal = {Trends in Cognitive Sciences},
volume = {26},
number = {2},
pages = {128-141},
year = {2022},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321002886},
author = {Hinze Hogendoorn},
keywords = {perception, time, prediction, real-time, neural delays},
abstract = {We feel that we perceive events in the environment as they unfold in real-time. However, this intuitive view of perception is impossible to implement in the nervous system due to biological constraints such as neural transmission delays. I propose a new way of thinking about real-time perception: at any given moment, instead of representing a single timepoint, perceptual mechanisms represent an entire timeline. On this timeline, predictive mechanisms predict ahead to compensate for delays in incoming sensory input, and reconstruction mechanisms retroactively revise perception when those predictions do not come true. This proposal integrates and extends previous work to address a crucial gap in our understanding of a fundamental aspect of our everyday life: the experience of perceiving the present.}
}
@article{WANG2013226,
title = {A Computational Knowledge Elicitation and Sharing System for mental health case management of the social service industry},
journal = {Computers in Industry},
volume = {64},
number = {3},
pages = {226-234},
year = {2013},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2012.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S0166361512001777},
author = {W.M. Wang and C.F. Cheung},
keywords = {Narratives, Knowledge management, Concept mapping, Knowledge-based system, Natural language processing},
abstract = {Narrative data provide rich information and knowledge to the workers. However, existing systems mainly served as a workflow system, a reporting system, or a database system for storing this kind of information. The massive amount of unstructured narrative data makes it extremely difficult to be shared and reused. Actual knowledge sharing and reuse among the workers is still limited. This paper presents a Computational Knowledge Elicitation and Sharing System which attempts to elicit knowledge from individuals as well as a team and converts it into a structured format and shared among the team. The proposed system accomplishes several current technologies in knowledge-based system, artificial intelligence and natural language processing, which converts the narrative knowledge of knowledge workers into a concept mapping representation. With a sufficient number of narratives, patterns are revealed and an aggregate concept map for all participating members is produced. It converts the unstructured text into a more structured format which helps to summarize and share the knowledge that can be taken in handling different case management issues. Such integration is considered to be novel. A prototype system has been implemented based on the method successfully in the mental healthcare of a social service organization for handling their case management issues. An experiment has been carried out for measuring the accuracy for converting the unstructured data into the structured format. The theoretical results are found to agree well with the experimental results.}
}
@article{RUSSO2020745,
title = {Neural Trajectories in the Supplementary Motor Area and Motor Cortex Exhibit Distinct Geometries, Compatible with Different Classes of Computation},
journal = {Neuron},
volume = {107},
number = {4},
pages = {745-758.e6},
year = {2020},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2020.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S0896627320303664},
author = {Abigail A. Russo and Ramin Khajeh and Sean R. Bittner and Sean M. Perkins and John P. Cunningham and L.F. Abbott and Mark M. Churchland},
keywords = {supplementary motor area, motor control, motor cortex, population coding, recurrent neural network, neural dynamics, neural computation, population geometry},
abstract = {Summary
The supplementary motor area (SMA) is believed to contribute to higher order aspects of motor control. We considered a key higher order role: tracking progress throughout an action. We propose that doing so requires population activity to display low "trajectory divergence": situations with different future motor outputs should be distinct, even when present motor output is identical. We examined neural activity in SMA and primary motor cortex (M1) as monkeys cycled various distances through a virtual environment. SMA exhibited multiple response features that were absent in M1. At the single-neuron level, these included ramping firing rates and cycle-specific responses. At the population level, they included a helical population-trajectory geometry with shifts in the occupied subspace as movement unfolded. These diverse features all served to reduce trajectory divergence, which was much lower in SMA versus M1. Analogous population-trajectory geometry, also with low divergence, naturally arose in networks trained to internally guide multi-cycle movement.}
}
@article{SNAIDER201259,
title = {Time production and representation in a conceptual and computational cognitive model},
journal = {Cognitive Systems Research},
volume = {13},
number = {1},
pages = {59-71},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389041710000781},
author = {Javier Snaider and Ryan McCall and Stan Franklin},
keywords = {Time, Time perception, Cognitive architecture, Event, Duration},
abstract = {Time perception and inferences there from are of critical importance to many autonomous agents. But time is not perceived directly by any sensory organ. We argue that time is constructed by cognitive processes. Here we present a model for time perception that concentrates on succession and duration, and that generates these concepts and others, such as continuity, immediate present duration, and lengths of time. These concepts are grounded through the perceptual process itself. We also address event representation, event hierarchy and expectations, as issues intimately related with time. The LIDA cognitive model is used to illustrate these ideas.}
}
@incollection{RUNCO2023115,
title = {Chapter 4 - Biological Perspectives on Creativity},
editor = {Mark A. Runco},
booktitle = {Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {115-154},
year = {2023},
isbn = {978-0-08-102617-5},
doi = {https://doi.org/10.1016/B978-0-08-102617-5.00005-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780081026175000059},
author = {Mark A. Runco},
keywords = {Adoption studies, Altered states of consciousness, Cerebellum, Corpus callosum, Dopamine, Dreams, Drugs, Exercise, Genealogies, Genetics, Prefrontal cortex, Split brain, Stress},
abstract = {This chapter discusses biological perspectives on creativity. Some of the research on creativity as of late involves the brain and biological correlates of originality, novelty, and insight. Handedness has long been used as an indication of hemispheric dominance or hemisphericity, with right-handed people being compared with left-handed people. There are several reports of left-handed persons outnumbering the right-handed ones in creative and eminent samples. Hemisphericity and other important brain structures and processes contributing to creative thinking and behavior have more recently been studied with electroencephalogram (EEG), positron emission topography (PET), cerebral blood flow, and magnetic resonance imaging (MRI) techniques. Numerous EEG studies suggest that there are particular brain wave patterns and brain structures that are associated with creative problem-solving or at least with specific phases within the problem-solving process. EEGs suggest a complex kind of activity while individuals work on tasks indicative of creative potential. Much of the complexity disappears when those same individuals work on convergent thinking tasks. Research suggests that the prefrontal cortex plays an important role in creative thinking and behaviour.}
}
@incollection{VERDICCHIO2025,
title = {Language of Artificial Intelligence Discourses},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00392-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041003926},
author = {Mario Verdicchio},
keywords = {Artificial intelligence, Figures of speech, Machine learning, Philosophy of mind},
abstract = {Language has played a fundamental role in Artificial Intelligence discourses from the very beginning of the establishment of the field. An early assumption was that every aspect of intelligence could be described in a manner compatible with machine operation. This assumption is critical for comparing humans and machines, given that, on the one hand, our understanding of how human brains work is insufficient to define intelligence clearly, and on the other hand, a focus on computational artifacts may lead to a limited conceptualization that overlooks significant aspects of what it means to be conscious and conscientious humans. A mindful analysis of the metaphors used to describe AI systems is key to navigating the intricate entanglements between society and technology that contribute to this endeavor.}
}
@article{CLEMENTZ2023143,
title = {Clinical characterization and differentiation of B-SNIP psychosis Biotypes: Algorithmic Diagnostics for Efficient Prescription of Treatments (ADEPT)-1},
journal = {Schizophrenia Research},
volume = {260},
pages = {143-151},
year = {2023},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2023.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0920996423002645},
author = {Brett A. Clementz and Ishanu Chattopadhyay and Rebekah L. Trotti and David A. Parker and Elliot S. Gershon and S. Kristian Hill and Elena I. Ivleva and Sarah K. Keedy and Matcheri S. Keshavan and Jennifer E. McDowell and Godfrey D. Pearlson and Carol A. Tamminga and Robert D. Gibbons},
abstract = {Clinically defined psychosis diagnoses are neurobiologically heterogeneous. The B-SNIP consortium identified and validated more neurobiologically homogeneous psychosis Biotypes using an extensive battery of neurocognitive and psychophysiological laboratory measures. However, typically the first step in any diagnostic evaluation is the clinical interview. In this project, we evaluated if psychosis Biotypes have clinical characteristics that can support their differentiation in addition to obtaining laboratory testing. Clinical interview data from 1907 individuals with a psychosis Biotype were used to create a diagnostic algorithm. The features were 58 ratings from standard clinical scales. Extremely randomized tree algorithms were used to evaluate sensitivity, specificity, and overall classification success. Biotype classification accuracy peaked at 91 % with the use of 57 items on average. A reduced feature set of 28 items, though, also showed 81 % classification accuracy. Using this reduced item set, we found that only 10–11 items achieved a one-vs-all (Biotype-1 or not, Biotype-2 or not, Biotype-3 or not) area under the sensitivity-specificity curve of .78 to .81. The top clinical characteristics for differentiating psychosis Biotypes, in order of importance, were (i) difficulty in abstract thinking, (ii) multiple indicators of social functioning, (iii) conceptual disorganization, (iv) severity of hallucinations, (v) stereotyped thinking, (vi) suspiciousness, (vii) unusual thought content, (viii) lack of spontaneous speech, and (ix) severity of delusions. These features were remarkably different from those that differentiated DSM psychosis diagnoses. This low-burden adaptive algorithm achieved reasonable classification accuracy and will support Biotype-specific etiological and treatment investigations even in under-resourced clinical and research environments.}
}
@article{MANNI2016260,
title = {Numerical study of airfoil stall cells using a very wide computational domain},
journal = {Computers & Fluids},
volume = {140},
pages = {260-269},
year = {2016},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2016.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S0045793016302894},
author = {Luca Manni and Takafumi Nishino and Pierre-Luc Delafin},
keywords = {Flow separation, 2D/3D transition, High aspect ratio wing, Unsteady RANS, Delayed DES},
abstract = {The formation of stall cells over a NACA 0012 airfoil at a Reynolds number of one million has been investigated numerically, using unsteady Reynolds-averaged Navier–Stokes (URANS) and delayed detached-eddy simulation (DDES) approaches. The simulations are performed with a very wide computational domain (10 chord length) to minimize the influence of spanwise periodic boundary conditions. For the URANS simulations, four different spanwise mesh resolutions are tested to determine the minimum resolution required to capture the formation of stall cells. Both URANS and DDES results show a sudden decrease in lift and increase in drag between 16° and 17° angle of attack, accompanied by a significant change of separated flow patterns. Stall cell structures are observed clearly in the URANS solutions between 17° and 19° with a spanwise spacing of about 1.4 to 1.8 chord length, which agrees well with a theoretical prediction based on the slope of the lift curve in this angle-of-attack range. The DDES results show much more complex flow patterns over the airfoil at these high angles of attack, although the spectral analysis of wall shear stress suggests the existence of flow structures having a similar spanwise length scale to the stall cells.}
}
@incollection{TOPLAK20221,
title = {1 - Defining cognitive sophistication in the development of judgment and decision-making},
editor = {Maggie E. Toplak},
booktitle = {Cognitive Sophistication and the Development of Judgment and Decision-Making},
publisher = {Academic Press},
pages = {1-22},
year = {2022},
isbn = {978-0-12-816636-9},
doi = {https://doi.org/10.1016/B978-0-12-816636-9.00010-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128166369000104},
author = {Maggie E. Toplak},
keywords = {Judgment and decision-making, Children and youth, Development, Cognitive sophistication, Critical thinking, Rationality, Stimulus equivalence, Miserly processing},
abstract = {Judgment and decision-making paradigms have been relatively well-studied in developmental samples. The measurement of these competencies in developmental samples has been of scientific interest. They have been recognized as having important implications for defining rational thinking in children and youth but also for teaching and training (such as, critical thinking in education). The origin of the theories and paradigms come from the adult literature, which has also undergone considerable progress in theoretical advancements and empirical studies over the last several years. The integration of our understanding from the work conducted in adults with consideration of developmental factors provides a way to advance our understanding of judgment and decision-making in children and youth. To accomplish this, establishing stimulus equivalence will be important given that these paradigms were first designed for adult samples. In addition, taking into account the rapid growth and change in cognitive capacities, that happen in development, are central for understanding performance on these paradigms. Using a working taxonomy of rational thinking based on adult samples, data from a longitudinal developmental study were used to empirically examine performance patterns on these paradigms.}
}
@article{SAIDI20091467,
title = {PLR-based heuristic for backup path computation in MPLS networks},
journal = {Computer Networks},
volume = {53},
number = {9},
pages = {1467-1479},
year = {2009},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2009.01.009},
url = {https://www.sciencedirect.com/science/article/pii/S1389128609000292},
author = {Mohand Yazid Saidi and Bernard Cousin and Jean-Louis {Le Roux}},
keywords = {Recovery, Local protection, Backup LSP, Failure risk, SRLG, MPLS, Bandwidth sharing, Path computation, Network},
abstract = {To ensure service continuity in networks, local protection pre-configuring the backup paths is preferred to global protection. Under the practical hypothesis of single physical failures in the network, the backup paths which protect against different logical failure risks (node, link and shared risk link group (SRLG)) cannot be active at the same time. Thus, sharing bandwidth between such backup paths is crucial to increase the bandwidth availability. In this article, we focus on the optimal on-line distributed computation of the bandwidth-guaranteed backup paths in MPLS networks. As the requests for connection establishment and release arrive dynamically without knowledge of future arrivals, we choose to use the on-line mode to avoid LSP reconfigurations. We also selected a distributed computation to offer scalability and decrease the LSP setup time. Finally, the optimization of bandwidth utilization can be achieved thanks to the flexibility of the path choice offered by MPLS and to the bandwidth sharing. For a good bandwidth sharing, the backup path computation entities (BPCEs) require the knowledge and maintenance of a great quantity of bandwidth information (e.g. non aggregated link information or per path information) which is undesirable in distributed environments. To get around this problem, we propose here a PLR (point of local repair)-based heuristic (PLRH) which aggregates and noticeably decreases the size of the bandwidth information advertised in the network while offering a high bandwidth sharing. PLRH permits an efficient computation of backup paths. It is scalable, easy to be deployed and balances equitably computations on the network nodes. Simulations show that with the transmission of a small quantity of aggregated information per link, the ratio of rejected backup paths is low and close to the optimum.}
}
@article{BALAHUR20141,
title = {Computational approaches to subjectivity and sentiment analysis: Present and envisaged methods and applications},
journal = {Computer Speech & Language},
volume = {28},
number = {1},
pages = {1-6},
year = {2014},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2013.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0885230813000697},
author = {Alexandra Balahur and Rada Mihalcea and Andrés Montoyo},
keywords = {Subjectivity analysis, Sentiment analysis, Multilingual resources, Social Media mining, Chat analysis},
abstract = {Recent years have witnessed a surge of interest in computational methods for affect, ranging from opinion mining, to subjectivity detection, to sentiment and emotion analysis. This article presents a brief overview of the latest trends in the field and describes the manner in which the articles contained in the special issue contribute to the advancement of the area. Finally, we comment on the current challenges and envisaged developments of the subjectivity and sentiment analysis fields, as well as their application to other Natural Language Processing tasks and related domains.}
}
@article{KUO2010307,
title = {Conceptual study of micro-tab device in airframe noise reduction: (I) 2D computation},
journal = {Aerospace Science and Technology},
volume = {14},
number = {5},
pages = {307-315},
year = {2010},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2010.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S1270963810000210},
author = {Brian C. Kuo and Nesrin Sarigul-Klijn},
keywords = {Computational aeroacoustics, High-lift device, Micro-tab, Airframe noise},
abstract = {A two-dimensional numerical study was performed to investigate the acoustic effects of micro-tab device on airframe noise reduction. As the noise generated by leading-edge slat and trailing-edge flap rise with their increased deflection angles, it is possible to mitigate such high-lift noise by using reduced settings without sacrificing the aerodynamic performance during approach. In this paper, micro-tab device attached to the pressure side of the flap surface is envisioned as a mean to achieve this goal. Hybrid method involving Computational Fluid Dynamics and acoustic analogy was used to predict the far-field noise spectrum. Results illustrate that the micro-tab device with reduced deflection angles of the high-lift settings provides lower noise signature at far-field positions, comparing to the baseline configuration, while the aerodynamic performance is maintained. In addition, two parametric studies which investigated the effects of micro-tab location and micro-tab height on acoustic spectra were also included.}
}
@article{LOURENCO2020258,
title = {Synaptic inhibition in the neocortex: Orchestration and computation through canonical circuits and variations on the theme},
journal = {Cortex},
volume = {132},
pages = {258-280},
year = {2020},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2020.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S001094522030318X},
author = {Joana Lourenço and Fani Koukouli and Alberto Bacci},
keywords = {Neocortex, Inhibition, Interneurons, Cortical circuits, Synaptic transmission},
abstract = {The neocortex plays a crucial role in all basic and abstract cognitive functions. Conscious mental processes are achieved through a correct flow of information within and across neocortical networks, whose particular activity state results from a tight balance between excitation and inhibition. The proper equilibrium between these indissoluble forces is operated with multiscale organization: along the dendro–somatic axis of single neurons and at the network level. Fast synaptic inhibition is assured by a multitude of inhibitory interneurons. During cortical activities, these cells operate a finely tuned division of labor that is epitomized by their detailed connectivity scheme. Recent results combining the use of mouse genetics, cutting-edge optical and neurophysiological approaches have highlighted the role of fast synaptic inhibition in driving cognition-related activity through a canonical cortical circuit, involving several major interneuron subtypes and principal neurons. Here we detail the organization of this cortical blueprint and we highlight the crucial role played by different neuron types in fundamental cortical computations. In addition, we argue that this canonical circuit is prone to many variations on the theme, depending on the resolution of the classification of neuronal types, and the cortical area investigated. Finally, we discuss how specific alterations of distinct inhibitory circuits can underlie several devastating brain diseases.}
}
@article{DAW2006199,
title = {The computational neurobiology of learning and reward},
journal = {Current Opinion in Neurobiology},
volume = {16},
number = {2},
pages = {199-204},
year = {2006},
note = {Cognitive neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2006.03.006},
url = {https://www.sciencedirect.com/science/article/pii/S0959438806000316},
author = {Nathaniel D Daw and Kenji Doya},
abstract = {Following the suggestion that midbrain dopaminergic neurons encode a signal, known as a ‘reward prediction error’, used by artificial intelligence algorithms for learning to choose advantageous actions, the study of the neural substrates for reward-based learning has been strongly influenced by computational theories. In recent work, such theories have been increasingly integrated into experimental design and analysis. Such hybrid approaches have offered detailed new insights into the function of a number of brain areas, especially the cortex and basal ganglia. In part this is because these approaches enable the study of neural correlates of subjective factors (such as a participant's beliefs about the reward to be received for performing some action) that the computational theories purport to quantify.}
}
@article{LONG201855,
title = {Data-driven decision making for supply chain networks with agent-based computational experiment},
journal = {Knowledge-Based Systems},
volume = {141},
pages = {55-66},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2017.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0950705117305294},
author = {Qingqi Long},
keywords = {Data-driven decision making, Supply chain network, Business analytics, Data-granularity model, Four-dimensional-flow model, Agent-based computational experiment},
abstract = {The complicated micro structures, macro emergences and dynamic evolutions in a supply chain network pose challenges to decision making for solving operational problems for the network's performance improvement. Most of these problems are complicated since various factors and their complicated relationships are involved. Success of this decision making relies on efficient business analytics based on the comprehensive and multi-dimensional data related to the static attributes and dynamic operations of the network. To confront the challenges, this paper proposes to explore a methodology of data-driven decision making for supply chain networks. In this methodology, a data-granularity model of a supply chain network is developed to standardize the data form for decision making. A four-dimensional-flow model of a supply chain network is proposed to satisfy the data requirements for decision making that are defined in the data-granularity model. Agent-based computational experiment is employed to support the generation of a comprehensive operational dataset of a supply chain network and to verify the solutions generated in decision making. Integrating these models, a data-driven decision-making framework for supply chain networks is proposed. In the framework, a new decision-making mode of “problem definition - business analytics - solution verification - parameter adjustment” is proposed. Oriented towards domain knowledge in supply chain networks, two approaches of business analytics—mapping analysis and correlation analysis—are presented. Finally, a case of a five-echelon manufacturing supply chain network is studied with the methodology. The findings indicate that the proposed methodology, models and framework are effective in supporting the data-centric decision making for solving complicated operational problems in supply chain networks and provide the networks’ managers or member enterprises with an effective tool to generate unbiased and efficient decisions for the networks’ performance improvement.}
}
@article{FAUL2024255,
title = {Update on “Emotion and autobiographical memory”: 14 years of advances in understanding functions, constructions, and consequences},
journal = {Physics of Life Reviews},
volume = {51},
pages = {255-272},
year = {2024},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2024.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S1571064524001301},
author = {Leonard Faul and Jaclyn H. Ford and Elizabeth A. Kensinger},
abstract = {Holland and Kensinger (2010) reviewed the literature on “Emotion and autobiographical memory.” They focused on two broad ways that emotions influence memory: (1) emotion during an event influences how the event is remembered, and (2) emotion and emotional goals during memory retrieval influence how past events are remembered. We begin by providing a brief update on the key points from that review. Holland and Kensinger (2010) also had noted a number of important avenues for future work. Here, we describe what has been learned about the functions of autobiographical memory and their reconstructive nature. Relatedly, we review more recent research on memory reconstruction in the context of visual perspective shifts, counterfactual thinking, nostalgia, and morality. This research has emphasized the reciprocal nature of the interactions between emotion and autobiographical memory: Not only do emotions influence memory, memories influence emotions. Next, we discuss advances that have been made in understanding the reciprocal relations between stress, mood, and autobiographical memory. Finally, we discuss the research that is situating emotional autobiographical memories within a social framework, providing a bedrock for collective memories. Despite the many advances of the past 14 years, many open questions remain; throughout the review we note domains in which we hope to see advances over the next decades.}
}
@incollection{HOUQUN2016155,
title = {Chapter 8 - Research on parallel computation of high arch dam structure seismic motion response},
editor = {Chen Houqun and Wu Shengxin and Dang Faning},
booktitle = {Seismic Safety of High Arch Dams},
publisher = {Academic Press},
address = {Oxford},
pages = {155-205},
year = {2016},
isbn = {978-0-12-803628-0},
doi = {https://doi.org/10.1016/B978-0-12-803628-0.00008-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128036280000082},
author = {Chen Houqun and Wu Shengxin and Dang Faning},
keywords = {seismic response analysis, high arch dam, high-performance parallel computation, component technique, technique of automatically generating programs, FEPG and PFEPG computation programs},
abstract = {The storage capacity and the computation time of dynamic analysis for seismic responses of high concrete arch dam systems are enormous. As a matter of course, the use of high-performance parallel computation for seismic analysis of high-concrete dams must be enforced. The significance and current situation of parallel computation for hydraulic structures using finite element method are briefly described. However, the more difficult task is to develop a parallel program. The EFPG is a finite element program generator using finite element language developed by Chinese Professor Liang Guoping in 1990. The program generated by FEPG can be automatically transformed to corresponding parallel program through the program PFEPG. The parallel computational program by means of FEPG and PFEPG applied in this stage to dynamic analysis for seismic responses of high concrete arch dam system is outlined. The strategy of FEPG is based on component technique and the technique of automatically generating programs. According to the characteristics of domain decomposition method, a finite element program can generally be decomposed to six modules as preprocess partition, start, bft, solv, E, and U programs, in which the subroutines of E and U component are generated by the system based on the scripts VDE or PDE of the partial differential equation describing the physical fields and the corresponding computational algorithms (NFE), other else components are fixed and provided by the FEPG Library. The structures and modules as well as the working operation of FEPG and PFEPG are briefly introduced. The parallel program developed for seismic response analysis of high arch dam by using the FEPG and PFEPG, including the corresponding treatments of dynamic explicit computation process, dynamic contact problem, artificial transmitting, and spring-viscous boundaries, are examined in slight details. The procedure of seismic analysis of arch dam includes three loading cases accomplished successively as follows:1.In case 1, the dam elements were treated as dead elements with zero degree of freedom for nodes, and only the dead load of the foundation rock is considered in the analysis. At the end of calculation, the initial normal compressive force along the contact planes was modified by adding the calculated contact force. All other states of the foundation were recovered to that before loading.2.In case 2, the dead load of dam and other static actions including water pressure, silt pressure, and temperature applied to the dam as well as the seepage pressure in the foundation are considered.3.In case 3, a three-component seismic input is applied to the base of the artificial transmitting boundaries in form of displacement ground motion, or to the spring-viscous boundaries with free field input including boundary stresses, velocities and displacements. In this loading case, the rate effect for dynamic strength and modulus of elasticity are considered.}
}
@incollection{WILLETT2018231,
title = {Chapter 8 - Application of Mathematical Models and Computation in Plant Metabolomics},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry},
publisher = {Elsevier},
pages = {231-254},
year = {2018},
isbn = {978-0-12-812364-5},
doi = {https://doi.org/10.1016/B978-0-12-812364-5.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128123645000080},
author = {Denis S. Willett and Caitlin C. Rering and Dominique A. Ardura and John J. Beck},
keywords = {Big data, Machine learning, Data science, Agriculture},
abstract = {The investigation and reporting of plant chemical constituents has greatly evolved over the course of natural products and phytochemical research. Starting from the extraction and identification of plant-based bioactive components, such as historical salicin or more recent paclitaxel, phytochemistry-based research now includes plant metabolomics that help delineate chemotaxonomy, phylogenetic biomarkers and the functional genetics of a plant’s response to biotic or abiotic stressors. Here, we examine the invaluable contributions of mathematical models and computation for analysing plant metabolomics data and discuss the analytics mindset, highlight best practices, provide example workflows, as well as introduce future opportunities. Important in this chapter is the application of statistical methods for the improved visualization and interpretation of plant metabolomics data and their relevance for future project planning.}
}
@article{FEKETE2011807,
title = {Towards a computational theory of experience},
journal = {Consciousness and Cognition},
volume = {20},
number = {3},
pages = {807-827},
year = {2011},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2011.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S1053810011000365},
author = {Tomer Fekete and Shimon Edelman},
keywords = {Representation, Experience, Qualia, Computation, State space, Trajectory, Dynamics, Brain activation, Concept, Clustering},
abstract = {A standing challenge for the science of mind is to account for the datum that every mind faces in the most immediate – that is, unmediated – fashion: its phenomenal experience. The complementary tasks of explaining what it means for a system to give rise to experience and what constitutes the content of experience (qualia) in computational terms are particularly challenging, given the multiple realizability of computation. In this paper, we identify a set of conditions that a computational theory must satisfy for it to constitute not just a sufficient but a necessary, and therefore naturalistic and intrinsic, explanation of qualia. We show that a common assumption behind many neurocomputational theories of the mind, according to which mind states can be formalized solely in terms of instantaneous vectors of activities of representational units such as neurons, does not meet the requisite conditions, in part because it relies on inactive units to shape presently experienced qualia and implies a homogeneous representation space, which is devoid of intrinsic structure. We then sketch a naturalistic computational theory of qualia, which posits that experience is realized by dynamical activity-space trajectories (rather than points) and that its richness is measured by the representational capacity of the trajectory space in which it unfolds.}
}
@article{RONEZRA2021100896,
title = {Engaging a third-grade student with autism spectrum disorder in an error finding activity},
journal = {The Journal of Mathematical Behavior},
volume = {63},
pages = {100896},
year = {2021},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2021.100896},
url = {https://www.sciencedirect.com/science/article/pii/S0732312321000572},
author = {Maya Ron-Ezra and Esther S. Levenson},
keywords = {Autism spectrum disorder, Two-digit addition, Error analysis, Mathematical explanations},
abstract = {This paper describes a case study of one mainstreamed third grade student with autism spectrum disorder (ASD) and his ability to explain his solutions for two-digit addition problems, and find and explain the mistake when presented with incorrectly solved addition problems. The study is presented as a counterexample to deficit views of ASD, views that focus on lack of communication skills, not being able to see someone else’s point of view, and poor executive functions. Each encounter with the student is analyzed in two ways, first analyzing his mathematical knowledge, and then analyzing obstacles the student faces that are associated with ASD. Some obstacles are overcome by the student on his own and others are overcome with the help of the researcher, who responds to the student’s thinking, and supports his endeavor to engage with a challenging activity.}
}
@article{KISS2020106823,
title = {Process systems engineering developments in Europe from an industrial and academic perspective},
journal = {Computers & Chemical Engineering},
volume = {138},
pages = {106823},
year = {2020},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2020.106823},
url = {https://www.sciencedirect.com/science/article/pii/S0098135420303069},
author = {Anton A. Kiss and Johan Grievink},
keywords = {Process systems engineering, Industry, Education, Research, Interface, Perspectives},
abstract = {Process Systems Engineering (PSE) is a discipline that deals with decision-making, at all levels and scales, by understanding any complex process system using a holistic view and a systems thinking framework. A closely related discipline (considered usually a part of PSE) is the Computer Aided Process Engineering (CAPE) which is a complementary field that focuses on developing methods and providing solution through systematic computer aided techniques for problems related to the design, control and operation of chemical systems. Nowadays, the ‘PSE’ term suffers from a branding issue to the point that PSE no longer gets the recognition that it deserves. In chemical engineering education the integrative systems frame for process design, control and operations is virtually absent. Its application potential in process industry lags relative to academic research progress and results. This work aims to provide an informative industrial and academic perspective on PSE (focused on the European region), arguing that the ‘systems thinking’ and ‘systems problem solving’ have to be given priority over just applications of computational problem solving methods. A multi-level view of the PSE field is provided within the academic and industrial context, and enhancements for PSE are suggested at their industrial and academic interfaces to create win-win situations.}
}
@incollection{SILVA20203,
title = {Chapter 1 - Introduction and overview of using computational fluid dynamics tools},
editor = {Valter Bruno Reis E. Silva and João Cardoso},
booktitle = {Computational Fluid Dynamics Applied to Waste-to-Energy Processes},
publisher = {Butterworth-Heinemann},
pages = {3-28},
year = {2020},
isbn = {978-0-12-817540-8},
doi = {https://doi.org/10.1016/B978-0-12-817540-8.00001-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128175408000017},
author = {Valter Bruno Reis E. Silva and João Cardoso},
keywords = {Computer fluid dynamics, Waste-to-energy, Simulation workflow, Fluid dynamics history},
abstract = {Over the last decades, with the increasing computational power and numerical solvers efficiency, computational fluid dynamics (CFD) is broadly used to design, optimize, and predict the physical-chemical phenomena regarding energy-related processes. A set of elaborate mathematical models is governed by partial differential equations representing conservation laws for mass, momentum, and energy, alongside with theoretical and empirical correlation. Therefore, CFD simulation is a crucial asset to understand the influence of parameters of interest in these processes and related operation and optimization of the technology involved. This chapter discusses how CFD can be used advantageously over waste-to-energy processes, also outlining advantages, disadvantages, and main setbacks with such an approach.}
}
@article{TARIM2011563,
title = {An efficient computational method for a stochastic dynamic lot-sizing problem under service-level constraints},
journal = {European Journal of Operational Research},
volume = {215},
number = {3},
pages = {563-571},
year = {2011},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2011.06.034},
url = {https://www.sciencedirect.com/science/article/pii/S0377221711005637},
author = {S. Armagan Tarim and Mustafa K. Dogˇru and Ulaş Özen and Roberto Rossi},
keywords = {Inventory, Relaxation, Stochastic non-stationary demand, Mixed integer programming, Service level, Static–dynamic uncertainty},
abstract = {We provide an efficient computational approach to solve the mixed integer programming (MIP) model developed by Tarim and Kingsman [8] for solving a stochastic lot-sizing problem with service level constraints under the static–dynamic uncertainty strategy. The effectiveness of the proposed method hinges on three novelties: (i) the proposed relaxation is computationally efficient and provides an optimal solution most of the time, (ii) if the relaxation produces an infeasible solution, then this solution yields a tight lower bound for the optimal cost, and (iii) it can be modified easily to obtain a feasible solution, which yields an upper bound. In case of infeasibility, the relaxation approach is implemented at each node of the search tree in a branch-and-bound procedure to efficiently search for an optimal solution. Extensive numerical tests show that our method dominates the MIP solution approach and can handle real-life size problems in trivial time.}
}
@article{ALPUENTE20153,
title = {Exploring conditional rewriting logic computations},
journal = {Journal of Symbolic Computation},
volume = {69},
pages = {3-39},
year = {2015},
note = {Symbolic Computation in Software Science},
issn = {0747-7171},
doi = {https://doi.org/10.1016/j.jsc.2014.09.028},
url = {https://www.sciencedirect.com/science/article/pii/S0747717114000960},
author = {M. Alpuente and D. Ballis and F. Frechina and J. Sapiña},
keywords = {Rewriting logic, Trace exploration, Maude, Conditional rewrite theories},
abstract = {Trace exploration is concerned with techniques that allow computation traces to be dynamically searched for specific contents. Depending on whether the exploration is carried backward or forward, trace exploration techniques allow provenance tracking or impact tracking to be done. The aim of provenance tracking is to show how (parts of) a program output depends on (parts of) its input and to help estimate which input data need to be modified to accomplish a change in the outcome. The aim of impact tracking is to identify the scope and potential consequences of changing the program input. Rewriting Logic (RWL) is a logic of change that supplements (an extension of) the equational logic by adding rewrite rules that are used to describe (nondeterministic) transitions between states. In this paper, we present a rich and highly dynamic, parameterized technique for the forward inspection of RWL computations that allows the nondeterministic execution of a given conditional rewrite theory to be followed up in different ways. With this technique, an analyst can browse, slice, filter, or search the traces as they come to life during the program execution. The navigation of the trace is driven by a user-defined, inspection criterion that specifies the required exploration mode. By selecting different inspection criteria, one can automatically derive a family of practical algorithms such as program steppers and more sophisticated dynamic trace slicers that compute summaries of the computation tree, thereby facilitating the dynamic detection of control and data dependencies across the tree. Our methodology, which is implemented in the Anima graphical tool, allows users to evaluate the effects of a given statement or instruction in isolation, track input change impact, and gain insight into program behavior (or misbehavior).}
}
@article{BASU2021135660,
title = {Integrative STEM education for undergraduate neuroscience: Design and implementation},
journal = {Neuroscience Letters},
volume = {746},
pages = {135660},
year = {2021},
issn = {0304-3940},
doi = {https://doi.org/10.1016/j.neulet.2021.135660},
url = {https://www.sciencedirect.com/science/article/pii/S0304394021000380},
author = {Alo C. Basu and Alexis S. Hill and André K. Isaacs and Michelle A. Mondoux and Ryan E.B. Mruczek and Tomohiko Narita},
keywords = {Integrative thinking, Spiral curriculum, Active learning, Inclusive pedagogy, Inclusive excellence, Anti-deficit},
abstract = {As an integrative discipline, neuroscience can serve as a vehicle for the development of integrative thinking skills and broad-based scientific proficiency in undergraduate students. Undergraduate neuroscience curricula incorporate fundamental concepts from multiple disciplines. Deepening the explicit exploration of these connections in a neuroscience core curriculum has the potential to support more meaningful and successful undergraduate STEM learning for neuroscience students. Curriculum and faculty development activities related to an integrative core curriculum can provide opportunities for faculty across disciplines and departments to advance common goals of inclusive excellence in STEM. These efforts facilitate analysis of the institutional STEM curriculum from the student perspective, and assist in creating an internal locus of accountability for diversity, equity, and inclusion within the institution. Faculty at the College of the Holy Cross have undertaken the collaborative design and implementation of an integrative core curriculum for neuroscience that embraces principles of inclusive pedagogy, emphasizes the connections between neuroscience and other disciplines, and guides students to develop broad proficiency in fundamental STEM concepts and skills.}
}
@article{CSILLERY2010410,
title = {Approximate Bayesian Computation (ABC) in practice},
journal = {Trends in Ecology & Evolution},
volume = {25},
number = {7},
pages = {410-418},
year = {2010},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2010.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0169534710000662},
author = {Katalin Csilléry and Michael G.B. Blum and Oscar E. Gaggiotti and Olivier François},
abstract = {Understanding the forces that influence natural variation within and among populations has been a major objective of evolutionary biologists for decades. Motivated by the growth in computational power and data complexity, modern approaches to this question make intensive use of simulation methods. Approximate Bayesian Computation (ABC) is one of these methods. Here we review the foundations of ABC, its recent algorithmic developments, and its applications in evolutionary biology and ecology. We argue that the use of ABC should incorporate all aspects of Bayesian data analysis: formulation, fitting, and improvement of a model. ABC can be a powerful tool to make inferences with complex models if these principles are carefully applied.}
}
@article{GROTH20211712,
title = {A systems-based framework to computationally describe putative transcription factors and signaling pathways regulating glycan biosynthesis},
journal = {Beilstein Journal of Organic Chemistry},
volume = {17},
pages = {1712-1724},
year = {2021},
issn = {1860-5397},
doi = {https://doi.org/10.3762/bjoc.17.119},
url = {https://www.sciencedirect.com/science/article/pii/S186053972102209X},
author = {Theodore Groth and Rudiyanto Gunawan and Sriram Neelamegham},
keywords = {ChIP-Seq, glycoinformatics, glycosylation, TCGA transcription factor},
abstract = {Glycosylation is a common posttranslational modification, and glycan biosynthesis is regulated by a set of glycogenes. The role of transcription factors (TFs) in regulating the glycogenes and related glycosylation pathways is largely unknown. In this work, we performed data mining of TF–glycogene relationships from the Cistrome Cancer database (DB), which integrates chromatin immunoprecipitation sequencing (ChIP-Seq) and RNA-Seq data to constitute regulatory relationships. In total, we observed 22,654 potentially significant TF–glycogene relationships, which include interactions involving 526 unique TFs and 341 glycogenes that span 29 the Cancer Genome Atlas (TCGA) cancer types. Here, TF–glycogene interactions appeared in clusters or so-called communities, suggesting that changes in single TF expression during both health and disease may affect multiple carbohydrate structures. Upon applying the Fisher’s exact test along with glycogene pathway classification, we identified TFs that may specifically regulate the biosynthesis of individual glycan types. Integration with Reactome DB knowledge provided an avenue to relate cell-signaling pathways to TFs and cellular glycosylation state. Whereas analysis results are presented for all 29 cancer types, specific focus is placed on human luminal and basal breast cancer disease progression. Overall, the article presents a computational approach to describe TF–glycogene relationships, the starting point for experimental system-wide validation.}
}
@article{SCHERER2020106349,
title = {A meta-analysis of teaching and learning computer programming: Effective instructional approaches and conditions},
journal = {Computers in Human Behavior},
volume = {109},
pages = {106349},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2020.106349},
url = {https://www.sciencedirect.com/science/article/pii/S0747563220301023},
author = {Ronny Scherer and Fazilat Siddiq and Bárbara {Sánchez Viveros}},
keywords = {Computational thinking, Computer programming, Intervention studies, Multilevel meta-analysis, Scratch programming},
abstract = {This meta-analysis maps the evidence on the effectiveness of instructional approaches and conditions for learning computer programming under three study conditions: (a) Studies focusing on the effectiveness of programming interventions per se, (b) studies focusing on the effectiveness of visualization and physicality, and (c) studies focusing on the effectiveness of dominant instructional approaches. Utilizing the data from 139 interventions and 375 effect sizes, we found (a) a strong effect of learning computer programming per se (Hedges’ g‾ = 0.81, 95% CI [0.42, 1.21]), (b) moderate to large effect sizes of visualization (g‾ = 0.44, 95% CI [0.29, 0.58]) and physicality interventions (g‾ = 0.72, 95% CI [0.23, 1.21]), and (c) moderate to large effect sizes for studies focusing on dominant instructional approaches (g‾s = 0.49–1.02). Moderator analyses indicated that the effect sizes differed only marginally between the instructional approaches and conditions—however, collaboration in metacognition instruction, problem solving instruction outside of regular lessons, short-term interventions focusing on physicality, and interventions focusing on visualization through Scratch were especially effective. Our meta-analysis synthesizes the existing research evidence on the effectiveness of computer programming instruction and, ultimately, provides references with which the effects of future studies could be compared.}
}
@incollection{GARDNER20243,
title = {Chapter 1 - Scaling the smart city},
editor = {Nicole Gardner},
booktitle = {Scaling the Smart City},
publisher = {Elsevier},
pages = {3-25},
year = {2024},
series = {Smart Cities},
isbn = {978-0-443-18452-9},
doi = {https://doi.org/10.1016/B978-0-443-18452-9.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044318452900001X},
author = {Nicole Gardner},
keywords = {Cyber-physical system, Design, Interaction, IoT, Scalar, Scale, Scaling, Smart city, Techno-urban imaginary, Urban design, Urban technology},
abstract = {This chapter explores the smart city through the conceptual lens of scale, as a scale-making project and as a project that is subject to scaling processes. It explores how scalar notions figure in smart city discourses, and how the drive to scale shapes the prevailing approach to digital technology and urban space integration. It argues that deprioritizing the smart city's scalability logic can bring into view different ways of designing the integration of digital technologies and urban space that can better connect with the contextual and material specificities of local contexts and less attended to dimensions of urban livability. Rescaling the smart city to the local urban precinct scale and paying close attention to life-technology relations is further reasoned as a way to productively re-orient and extend thinking on the ethical significance of the smart city.}
}
@article{JI20074338,
title = {A fuzzy logic-based computational recognition-primed decision model},
journal = {Information Sciences},
volume = {177},
number = {20},
pages = {4338-4353},
year = {2007},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2007.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S0020025507001193},
author = {Yanqing Ji and R. Michael Massanari and Joel Ager and John Yen and Richard E. Miller and Hao Ying},
keywords = {Medical decision-making, Naturalistic decision-making, Recognition-primed decision model, Computational recognition-primed decision model, Experience-based reasoning, Adverse drug reactions, Fuzzy logic, Similarity measure},
abstract = {The recognition-primed decision (RPD) model is a primary naturalistic decision-making approach which seeks to explicitly recognize how human decision makers handle complex tasks and environment based on their experience. Motivated by the need for quantitative computer modeling and simulation of human decision processes in various application domains, including medicine, we have developed a general-purpose computational fuzzy RPD model that utilizes fuzzy sets, fuzzy rules, and fuzzy reasoning to represent, interpret, and compute imprecise and subjective information in every aspect of the model. Experiences acquired by solicitation with experts are stored in experience knowledge bases. New local and global similarity measures have been developed to identify the experience that is most applicable to the current situation in a specific decision-making context. Furthermore, an action evaluation strategy has been developed to select the workable course of action. The proposed fuzzy RPD model has been preliminarily validated by using it to calculate the extent of causality between a drug (Cisapride, withdrawn by the FDA from the market in 2000) and some of its adverse effects for 100 hypothetical patients. The simulated patients were created based on the profiles of over 1000 actual patients treated with the drug at our medical center before its withdrawal. The model validity was demonstrated by comparing the decisions made by the proposed model and those by two independent internists. The levels of agreement were established by the weighted Kappa statistic and the results suggested good to excellent agreement.}
}
@article{SHAHZAD2022102190,
title = {Thermal cooling process by nanofluid flowing near stagnating point of expanding surface under induced magnetism force: A computational case study},
journal = {Case Studies in Thermal Engineering},
volume = {36},
pages = {102190},
year = {2022},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2022.102190},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X22004361},
author = {Faisal Shahzad and Wasim Jamshed and Amjad Ali Pasha and Rabia Safdar and Md. Mottahir Alam and Misbah Arshad and Syed M. Hussain and Muhammad Bilal Hafeez and Marek Krawczuk},
keywords = {, , , , },
abstract = {This paper is dedicated to the exam of entropy age and research of the effect of mixing nanosolid additives over an extending sheet. In this review, Newtonian nanofluid version turned into researched at the actuated appealing field, heat radiation and variable heat conductivity results. With becoming modifications, the proven PDEs are moved into popular differential situations and paintings mathematically making use of a specific mathematical plan called the Keller box method (KBM). The ranges of different dimensionless parameters used in our study are volume fraction of nanoparticles 0.01≤φ≤0.04, magnetic parameter 0.5≤Λ≤2, thermal radiation 0.1≤Nr≤0.3, heat source/sink parameter 0.5≤Q0≤2, Prandtl number 5.7≤Pr≤6.2, variable thermal conductivity 0.1≤ε≤0.3, reciprocal magnetic Prandtl number 0.6≤λ∗≤1, Brinkman number 5≤Br≤15, Reynolds number 5≤Re≤15, which shows up during mathematical arrangement are shown as tables and charts.Positive modifications in heat radiation and heat conductivity affects increment the hotness pass coefficient of solar primarily based totally plane wings. Titanium alloy primarily based totally water (H2O) are taken into consideration for our research. We will likewise alternate the grouping of nanoparticles to pay attention on their impact on numerous dynamic barriers of the framework. We can see that because the Reynolds range and Brinkman range increment, the entropy increments. The thermodynamic exhibition of Titanium alloy-water (Ti6Al4V–H2O) nanofluid has been portrayed higher that of base nanofluid with comparable situations. Recorded hypothetical reproductions may be greater beneficial to similarly increase daylight primarily based totally nuclear strength frameworks.}
}
@article{LI20203666,
title = {The computational approaches of lncRNA identification based on coding potential: Status quo and challenges},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3666-3677},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304979},
author = {Jing Li and Xuan Zhang and Changning Liu},
keywords = {LncRNA identification, , Algorithm, Feature, Coding potential, sORF},
abstract = {Long noncoding RNAs (lncRNAs) make up a large proportion of transcriptome in eukaryotes, and have been revealed with many regulatory functions in various biological processes. When studying lncRNAs, the first step is to accurately and specifically distinguish them from the colossal transcriptome data with complicated composition, which contains mRNAs, lncRNAs, small RNAs and their primary transcripts. In the face of such a huge and progressively expanding transcriptome data, the in-silico approaches provide a practicable scheme for effectively and rapidly filtering out lncRNA targets, using machine learning and probability statistics. In this review, we mainly discussed the characteristics of algorithms and features on currently developed approaches. We also outlined the traits of some state-of-the-art tools for ease of operation. Finally, we pointed out the underlying challenges in lncRNA identification with the advent of new experimental data.}
}
@article{BAWDEN1984205,
title = {Systems thinking and practices in the education of agriculturalists},
journal = {Agricultural Systems},
volume = {13},
number = {4},
pages = {205-225},
year = {1984},
issn = {0308-521X},
doi = {https://doi.org/10.1016/0308-521X(84)90074-X},
url = {https://www.sciencedirect.com/science/article/pii/0308521X8490074X},
author = {Richard J. Bawden and Robert D. Macadam and Roger J. Packham and Ian Valentine},
abstract = {A systems approach has been taken to a review of agricultural education programmes and as the essential theme of resultant curricula at Hawkesbury Agricultural College in Australia. The systems thinking and practices which have guided, and been shaped by, the innovations are outlined, and the rationale and framework of the major programme are described. The subsequent emphasis has been placed on effective learning for agricultural managers and their technologist advisors. It is argued that problem solving and learning are essentially the same psychological processes and that taking a systems approach to investigating problem situations provides a more useful paradigm for learning about agriculture than reductionist, discipline-based approaches. Experiential learning and autonomy in learning are seen as consistent with this and are basic features of the programmes. A conceptual framework for problem solving that incorporates soft and hard systems and scientific reductionist methodologies has been developed. A contingency approach to situation improving is emerging as a less restrictive and more realistic alternative to a normative approach to problem solving.}
}
@article{GANUTHULA2016216,
title = {Rationality and the reflective mind: A case for typical performance measure of cognitive ability},
journal = {Learning and Individual Differences},
volume = {49},
pages = {216-223},
year = {2016},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2016.06.019},
url = {https://www.sciencedirect.com/science/article/pii/S1041608016301029},
author = {Venkat Ram Reddy Ganuthula and Lata Dyaram},
keywords = {Typical performance measure of cognitive ability, Thinking dispositions, Rationality, Tripartite model of mind},
abstract = {Intelligence and cognitive abilities often denoted good thinking. However, critics of intelligence tests have long pointed out that the failures of rational judgments and decision-making imperfectly correlate with intelligence. Reviewing the work of Keith Stanovich and his colleagues, paper highlights the role of individual differences in judgment and decision-making. Paper presents a case for typical performance measure of cognitive ability besides thinking dispositions to explain variations in rational thought. Specifically, we examine and model the relationship between need for cognition (a measure of thinking dispositions), absorptive capacity (typical performance measure of intelligence) and normative decision-making tasks.}
}
@article{CARROLL1999111,
title = {Invented Computational Procedures of Students in a Standards-Based Curriculum},
journal = {The Journal of Mathematical Behavior},
volume = {18},
number = {2},
pages = {111-121},
year = {1999},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(99)00024-3},
url = {https://www.sciencedirect.com/science/article/pii/S0732312399000243},
author = {William M. Carroll},
abstract = {Fourth graders who had been in a standards-based elementary curriculum since kindergarten were individually interviewed and administered a whole-class test that probed their knowledge of facts and multidigit computation. Standard algorithms are not taught as part of the curriculum, which instead emphasizes student-invented procedures and discussions of solution methods. Of interest were the types of student-invented procedures that were used as well as their computational accuracy. Students used several procedures that involved sophisticated mental calculation strategies, such as decomposing numbers or adding from left to right. Many students also used the standard written algorithms. Both invented and standard algorithms used by the students were highly accurate, although invented procedures often indicated better mental flexibility and awareness of place value. On the written test, students' computational abilities were above national normative levels.}
}
@article{BOTTEGONI201223,
title = {The role of fragment-based and computational methods in polypharmacology},
journal = {Drug Discovery Today},
volume = {17},
number = {1},
pages = {23-34},
year = {2012},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2011.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S1359644611002534},
author = {Giovanni Bottegoni and Angelo D. Favia and Maurizio Recanatini and Andrea Cavalli},
abstract = {Polypharmacology-based strategies are gaining increased attention as a novel approach to obtaining potentially innovative medicines for multifactorial diseases. However, some within the pharmaceutical community have resisted these strategies because they can be resource-hungry in the early stages of the drug discovery process. Here, we report on fragment-based and computational methods that might accelerate and optimize the discovery of multitarget drugs. In particular, we illustrate that fragment-based approaches can be particularly suited for polypharmacology, owing to the inherent promiscuous nature of fragments. In parallel, we explain how computer-assisted protocols can provide invaluable insights into how to unveil compounds theoretically able to bind to more than one protein. Furthermore, several pragmatic aspects related to the use of these approaches are covered, thus offering the reader practical insights on multitarget-oriented drug discovery projects.}
}
@incollection{SLEPIAN2024516,
title = {4.01 - Synergistic Approaches of Cross-Fertilization and Feedback Together Driving and Advancing Health for All},
editor = {Kenneth S. Ramos},
booktitle = {Comprehensive Precision Medicine (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {516-523},
year = {2024},
isbn = {978-0-12-824256-8},
doi = {https://doi.org/10.1016/B978-0-12-824010-6.00081-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128240106000812},
author = {Marvin J. Slepian},
keywords = {Digital Health, Multiscale, Nested pots, Personalized medicine, Pharmacogenomics, Point-of-care, Precision medicine, System synergies, Systems biology, Wearable technologies},
abstract = {We are at a point in time with rapid advances occurring in digital technologies, developing a range of new quantifiable markers termed “digital biomarkers,” which are increasingly utilized for diagnostics, as well as defining new operative mechanisms of health and disease. In parallel, significant advances have occurred in precision medicine, utilizing breakthroughs in “omics biology,” coupled with our understanding of their impact across systems in “systems biology.” Contemporaneously, a new approach to thinking of how health and disease evolve and impact an individual has emerged—that of considering mechanisms and impact across scales, i.e. on a “multi-scale” level, extending from the patient down to the molecule, and similarly from the patient up to society. In this chapter details of each of these approaches, their evolution and key current concepts are outlined. Moreover, the main theme and postulate developed in this chapter outlines the interconnectedness and the way in which each approach informs each other. In essence a cyclic, reinforcing, feedback loop exists, connecting digital technologies with precision and personalization approaches, across systems and scales, leading to enhanced diagnostics, the potential for new therapeutics and increasing insight into mechanisms. This cyclic flow of information will lead to new, more exacting technologies, with the ultimate outcome of enhanced efficacy, safety and improved health outcomes for patients and society.}
}
@article{ZHOU2025103462,
title = {Co-design of analogical and embodied representations with children for child-centered AI learning experiences},
journal = {International Journal of Human-Computer Studies},
volume = {199},
pages = {103462},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103462},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925000199},
author = {Xiaofei Zhou and Yunfan Gong and Yushan Zhou and Yufei Jiang and Zhen Bai},
keywords = {Embodied learning, Analogical learning, AI recommendation systems, The filter bubble, Augmented reality, Children},
abstract = {AI recommendations shape our daily decisions and our young generation is no exception. The convenience of navigating personalized content comes with the notorious “filter bubble” effect, which can reduce exposure to diverse options and opinions. Children are particularly vulnerable to this due to their limited AI literacy and critical thinking skills. In this study, we explore how to engage children as co-designers to create child-centered experiences for learning AI concepts related to the filter bubble. Leveraging embodied and analogical learning theories, we co-designed an Augmented Reality (AR) application, BeeTrap, with children from underrepresented backgrounds in STEM. BeeTrap not only raises awareness of filter bubbles but also empowers children to understand recommendation system mechanisms. Our contributions include (1) insights into child-centered AI learning using embodied metaphors and analogies as educational representations of AI concepts; and (2) implications for enhancing children’s understanding of AI concepts through co-design processes.}
}
@article{BAR202135,
title = {Wanted: Architecture for changing minds: A comment on “The growth of cognition: Free energy minimization and the embryogenesis of cortical computation”},
journal = {Physics of Life Reviews},
volume = {36},
pages = {35-36},
year = {2021},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2020.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S1571064520300683},
author = {Moshe Bar}
}
@article{CRAWFORD202180,
title = {Efficient mechanisms for level-k bilateral trading},
journal = {Games and Economic Behavior},
volume = {127},
pages = {80-101},
year = {2021},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2021.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0899825621000282},
author = {Vincent P. Crawford},
keywords = {Mechanism design, Bilateral trading, Level- thinking, Behavioral game theory},
abstract = {This paper revisits Myerson and Satterthwaite's (1983) classic analysis of mechanism design for bilateral trading, replacing equilibrium with a level-k model of strategic thinking and focusing on direct mechanisms. The revelation principle fails for level-k models, so restricting attention to direct mechanisms and imposing incentive-compatibility are not without loss of generality. If, however, only direct, level-k-incentive-compatible mechanisms are feasible and traders' levels are observable, Myerson and Satterthwaite's characterization of mechanisms that maximize traders' total surplus subject to incentive constraints generalizes qualitatively to level-k models. If only direct, level-k-incentive-compatible mechanisms are feasible but traders' levels are not observable, generically a particular posted-price mechanism maximizes traders' total expected surplus subject to incentive constraints. If direct, non-level-k-incentive-compatible mechanisms are feasible and traders best respond to them, total expected surplus-maximizing mechanisms may take completely different forms.}
}
@article{BOND200481,
title = {A computational model for the primate neocortex based on its functional architecture},
journal = {Journal of Theoretical Biology},
volume = {227},
number = {1},
pages = {81-102},
year = {2004},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2003.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0022519303003825},
author = {Alan H Bond},
keywords = {Brain architecture, Perception-action hierarchy, Computational model, Logic programming, Primate social behavior},
abstract = {Experimental evidence has shown that the primate neocortex consists in the main of a set of cortical regions which form a perception hierarchy, an action hierarchy and connections between them. By using a computer science analysis, we develop a computational architecture for the brain in which each cortical region is represented by a computational module with processing and storage abilities. Modules are interconnected according to the connectivity of the corresponding cortical regions. We develop computational principles for designing such a hierarchical and parallel computing system. We demonstrate this approach by proposing a causal functioning model of the brain. We report on results obtained with an implementation of this model. We conclude with a brief discussion of some consequences and predictions of our work.}
}
@article{PU2023102577,
title = {Generative adversarial one-shot diagnosis of transmission faults for industrial robots},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {83},
pages = {102577},
year = {2023},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2023.102577},
url = {https://www.sciencedirect.com/science/article/pii/S0736584523000534},
author = {Ziqiang Pu and Diego Cabrera and Yun Bai and Chuan Li},
keywords = {One-shot diagnosis, Bi-directional generative adversarial network, Random forest, Industrial robot, Transmission system},
abstract = {Transmission systems of industrial robots are prone to get failures due to harsh operating environments. Fault diagnosis is of great significance for realizing safe operations for industrial robots. However, it is difficult to obtain faulty data in real applications. To migrate this issue, a generative adversarial one-shot diagnosis (GAOSD) approach is proposed to diagnose robot transmission faults with only one sample per faulty pattern. Signals representing kinematical characteristics were acquired by an attitude sensor. A bidirectional generative adversarial network (Bi-GAN) was then trained using healthy signals. Inspired by way of human thinking, the trained encoder in Bi-GAN was taken out to perform information abstraction for all signals. Finally, the abstracted signals were sent to a random forest for the one-shot diagnosis. The performance of the present technique was evaluated on an industrial robot experimental setup. Experimental results show that the proposed GAOSD has promising performance on the fault diagnosis of robot transmission systems.}
}
@article{WEBB2010903,
title = {Troubleshooting assessment: an authentic problem solving activity for it education},
journal = {Procedia - Social and Behavioral Sciences},
volume = {9},
pages = {903-907},
year = {2010},
note = {World Conference on Learning, Teaching and Administration Papers},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2010.12.256},
url = {https://www.sciencedirect.com/science/article/pii/S187704281002361X},
author = {David C. Webb},
keywords = {authentic assessment, computational thinking, computer programming, game design, problem solving, STEM education, technologybased assessment},
abstract = {To evaluate the effectiveness of an instructional unit for game design and computer programming, we designed an authentic assessment with five troubleshooting scenarios. This assessment was completed by 24 middle grades students (age 12 – 14 years) after 10hours of instruction using a visual programming environment. Students successfully completed most of the tasks in 45minutes. Results from the Troubleshooting Assessment demonstrated that students developed sufficient fluency with programming to be able to apply their knowledge to new problems. These results suggest that troubleshooting scenarios can be used to assess student fluency in computer programming and computer-based problem solving.}
}
@article{LITTLE20031285,
title = {The computational science major at SUNY Brockport},
journal = {Future Generation Computer Systems},
volume = {19},
number = {8},
pages = {1285-1292},
year = {2003},
note = {Selected papers from the Workshop on Education in Computational Sciences held at the International Conference on Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/S0167-739X(03)00086-4},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X03000864},
author = {Leigh J. Little},
keywords = {Computational science, Education, Undergraduate, Graduate},
abstract = {The field of computational science is a recent addition to academic study. While the content of such an education is generally agreed upon, effective methods for imparting this knowledge are still being investigated. This paper describes the current state of the computational science degree programs at SUNY Brockport and the successes that have been obtained. Issues relating to the implementation of such programs in the context of a small, liberal arts college are also discussed.}
}
@article{OLTETEANU201615,
title = {Object replacement and object composition in a creative cognitive system. Towards a computational solver of the Alternative Uses Test},
journal = {Cognitive Systems Research},
volume = {39},
pages = {15-32},
year = {2016},
note = {From human to artificial cognition (and back): new perspectives of cognitively inspired AI systems},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2015.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S1389041716000073},
author = {Ana-Maria Olteţeanu and Zoe Falomir},
keywords = {Cognitive systems, Computational creativity, Creative object replacement, Creative object composition, Alternative uses test},
abstract = {In creative problem solving, humans perform object replacement and object composition to improvise tools in order to carry out tasks in everyday situations. In this paper, an approach to perform Object Replacement and Object Composition (OROC) inside a Creative Cognitive framework (CreaCogs) is proposed. Multi-feature correspondence is used to define similarity between objects in an everyday object domain. This enables the cognitive system OROC to perform creative replacement of objects and creative object composition. The generative properties of OROC are analysed and proof-of-concept experiments with OROC are reported. An evaluation of the results is carried out by human judges and compared to human performance in the Alternative Uses Test.}
}
@article{DEOLIVEIRA2023133,
title = {Transdisciplinary competency-based development in the process engineering subjects: A case study in Brazil},
journal = {Education for Chemical Engineers},
volume = {44},
pages = {133-154},
year = {2023},
issn = {1749-7728},
doi = {https://doi.org/10.1016/j.ece.2023.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S1749772823000246},
author = {Roger Assis {de Oliveira} and Giovanna Milena Borges Hipólito and Ricardo de Freitas Fernandes Pontes and Paulo Henrique Nascimento Ferreira and Ricardo Sanz Moreira and José Plácido and Carlos Alexandre Moreira da Silva and Laura Plazas Tovar},
keywords = {Chemical engineering education, Competency, Learning outcome, Lifelong learning, Process systems engineering, Sustainability},
abstract = {Recently, the Brazilian Ministry of Education issued New Curriculum Guidelines for engineering programs. This paper encompasses a pedagogical intervention reflecting our efforts to incorporate these new guidelines into our engineering program. Specifically, this work has led to the competency-based rework of the following subjects offered in the Chemical Engineering Undergraduate Program at the Federal University of São Paulo (Unifesp): I) Modeling and Systems Analysis; II) Synthesis and Optimization of Chemical Processes; III) Chemical Process Simulation; IV) Process Analysis and Control; V) Chemical Process Design; and VI) Chemical Installations Design. Thirteen transdisciplinary competencies are integrated throughout the six subjects. Students highlighted design thinking, lifelong knowledge/learning, openness to act autonomously, teamwork, communication, and cooperation as essential qualities. Moreover, the greater focus on the process systems engineering approach involving the analysis, synthesis, design, and control of sustainable processes helps chemical engineers to face new challenges using renewable resources.}
}
@article{JAGER2014117,
title = {Thinking outside the channel: Timing pulse flows to benefit salmon via indirect pathways},
journal = {Ecological Modelling},
volume = {273},
pages = {117-127},
year = {2014},
issn = {0304-3800},
doi = {https://doi.org/10.1016/j.ecolmodel.2013.11.007},
url = {https://www.sciencedirect.com/science/article/pii/S0304380013005437},
author = {Henriette I. Jager},
keywords = {Reservoir releases, Environmental flows, Natural flow paradigm, Optimization, Quantile model, Pulse flows},
abstract = {Using models to represent relationships between flow and fishes has important practical applications for managing reservoir releases. Attempts to model such relationships often neglect indirect mechanisms by which flow influences fish. For example, growth of salmon juveniles is measurably faster when flows inundate floodplain and promote higher production of invertebrate prey, but out-of-channel flows have not yet been incorporated into models. The QUANTUS model developed here represents indirect linkages between flow and freshwater survival, mediated by temperature and prey availability, for fall Chinook salmon (Oncorhynchus tshawytscha). Quantiles of spawning time and place were used to define cohorts of salmon in a regulated Central Valley, California river. Survival of these quantile-cohorts was simulated through incubation, juvenile growth, and eventual downstream migration. A genetic algorithm was used to optimize the seasonal timing of pulse flows. Simulated survival was highest for flow regimes that provided a modest, temperature-moderating pulse flow in early summer and, for wetter years, a second, larger pulse of over-bank flow in late winter. For many rivers of the Pacific coast that support fall Chinook salmon, the thermal window of opportunity for spawning and rearing is narrow. Optimized flows made the most of this window by providing access to accelerated juvenile growth and early survival in floodplain habitat, a result that should be verified with field experiments. Timing of optimized pulse flows differed in some respects from the region's natural hydrograph, dominated by spring runoff. This suggests that understanding the mechanisms by which flow influences fishes can be important when shaping flows in the changed context of a regulated river.}
}
@article{DELORME2019133,
title = {When the meditating mind wanders},
journal = {Current Opinion in Psychology},
volume = {28},
pages = {133-137},
year = {2019},
note = {Mindfulness},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2018.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X1830157X},
author = {Arnaud Delorme and Tracy Brandmeyer},
abstract = {The capacity for thought and the ability to assemble and manipulate concepts are cognitive features unique to humans. Spontaneous thoughts often occur when we are engaged in attention-demanding tasks, with an increased frequency predicting negative affect. Meditation does not require thinking; however, thinking occurs naturally during meditation. We develop the hypothesis that chronic thinking associated with strong emotional arousal during meditation practice might be detrimental to meditation practice and well-being. One goal of meditation is to identify the arousal of emotions and thoughts, and remain equanimous with them. Over time, meditation may help dampen the attention-grabbing power of these thoughts both during practice and in daily life, which may consequently help deepen meditation practice. However, when meditators fail to remain equanimous, the effects of these thoughts may be deleterious. We discuss how this hypothesis may help guide future research on meditation.}
}
@article{BRIMKOV2005233,
title = {Exact Image Reconstruction from a Single Projection through Real Computation},
journal = {Electronic Notes in Discrete Mathematics},
volume = {20},
pages = {233-246},
year = {2005},
note = {Proceedings of the Workshop on Discrete Tomography and its Applications},
issn = {1571-0653},
doi = {https://doi.org/10.1016/j.endm.2005.05.066},
url = {https://www.sciencedirect.com/science/article/pii/S1571065305050705},
author = {Valentin E. Brimkov and Reneta P. Barneva},
keywords = {Discrete tomography, Computed tomography, Algebraic computation model, Algebraic complexity, Linear Diophantine equation},
abstract = {In Discrete Tomography one aims to reconstruct a function (image) with a known discrete range from its projection along certain directions. By modern electron-microscopy techniques, one can count the number of atoms laying on a line representing, e.g., an X-ray. The so obtained data is used in the integer programming formulation. However, in real applications the size of the problem, that is well-known to be NP-hard, is so large that no method seems to be applicable to it. Other natural restrictions can make the problem even harder. In an attempt to avoid such kind of difficulties, we present an alternative approach to the problem. With this, we also aim to shed more light on the theoretical limitations for efficient computation in Discrete Tomography. Our approach is based on image reconstruction from a single projection, under the hypothesis that all computations take place in an algebraic computation model. In terms of computational efficiency, the proposed algorithm is significantly superior to the known algorithms for the problem. We also discuss on the possibilities for practical implementation of our method.}
}
@article{GOLDBERG2011171,
title = {Computational physiology of the neural networks of the primate globus pallidus: function and dysfunction},
journal = {Neuroscience},
volume = {198},
pages = {171-192},
year = {2011},
note = {Function and Dysfunction of the Basal Ganglia},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2011.08.068},
url = {https://www.sciencedirect.com/science/article/pii/S0306452211010268},
author = {J.A. Goldberg and H. Bergman},
keywords = {basal ganglia, primate, neurons, correlations, oscillations, Parkinson's disease},
abstract = {The dorsal pallidal complex is made up of the external and internal segments of the globus pallidus (GPe and GPi respectively). It is part of the main axis of the basal ganglia (BG) that connects the thalamo-cortical networks to the BG input stages (striatum and subthalamic nucleus) and continues directly, and indirectly through the GPe, to the BG output stages (GPi and substantia nigra reticulata). Here we review the unique anatomical and physiological features of the pallidal complex and argue that they support the main computational goal of the BG main axis (actor); namely, a behavioral policy that maximizes future cumulative gains and minimizes costs. The three mono-layer competitive networks of the BG main axis flexibly extract relevant features from the current state of the thalamo-cortical activity to control current (ongoing) and future actions. We hypothesize that the striatal and the subthalamic projections neurons act as mono-stable integrators (class I excitability) and the in-vivo pallidal neurons act as bi-stable resonators (class II excitability). GPe neurons exhibit pausing behavior because their membrane potential lingers in the vicinity of an unstable equilibrium point and bi-stability, and these pauses enable a less-greedy exploratory behavioral policy. Finally, degeneration of midbrain dopaminergic neurons and striatal dopamine depletion (as in Parkinson's disease) lead to augmentation of striatal excitability and competitive dynamics. As a consequence the pallidal network, whose elements tend to synchronize as a result of their bi-stable resonance behavior, shifts from a Poissonian-like non-correlated to synchronous oscillatory discharge mode. This article is part of a Special Issue entitled: Function and Dysfunction of the Basal Ganglia.}
}
@article{EKINS201165,
title = {Computational databases, pathway and cheminformatics tools for tuberculosis drug discovery},
journal = {Trends in Microbiology},
volume = {19},
number = {2},
pages = {65-74},
year = {2011},
issn = {0966-842X},
doi = {https://doi.org/10.1016/j.tim.2010.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0966842X10001939},
author = {Sean Ekins and Joel S. Freundlich and Inhee Choi and Malabika Sarker and Carolyn Talcott},
abstract = {We are witnessing the growing menace of both increasing cases of drug-sensitive and drug-resistant Mycobacterium tuberculosis strains and the challenge to produce the first new tuberculosis (TB) drug in well over 40 years. The TB community, having invested in extensive high-throughput screening efforts, is faced with the question of how to optimally leverage these data to move from a hit to a lead to a clinical candidate and potentially, a new drug. Complementing this approach, yet conducted on a much smaller scale, cheminformatic techniques have been leveraged and are examined in this review. We suggest that these computational approaches should be optimally integrated within a workflow with experimental approaches to accelerate TB drug discovery.}
}
@article{FITRIANI2023e14769,
title = {The differential item functioning (DIF) testing for the WOCC (Ways of Coping Checklist) instrument based on gender},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e14769},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e14769},
url = {https://www.sciencedirect.com/science/article/pii/S240584402301976X},
author = {Arbania Fitriani and Dominikus David {Biondi Situmorang}},
keywords = {Differential item functioning, DIF, IRT, Stress, Coping stress, Psychometry},
abstract = {This study examined the Item Response Theory (IRT) method with statistical analysis to determine Differential Item Functioning (DIF) between men and women on the Ways of Coping Checklist (WOCC) Instruments revised by Vitaliano, Russo, Carr, Mauiro, and Becker (1985). Furthermore, it utilized primary data from 722 respondents with educational backgrounds ranging from senior high school, diplomas, and doctorates. The software packages QUEST, BILOG-MG, LISREL, and ITEMAN were used for analysis to address the concerns. Meanwhile, several items on the WOCC instrument indicated the presence of the DIF based on the calculation results using the IRT method with the QUEST and BILOG-MG software. According to the overall calculation for 1 PL and 2 PL using both tools, 8 items containing the DIF are distributed over the dimensions of problem solving, seeking social support, blaming self, and wishful thinking.}
}
@article{HAMED2018112,
title = {Quantitative modeling of gene networks of biological systems using fuzzy Petri nets and fuzzy sets},
journal = {Journal of King Saud University - Science},
volume = {30},
number = {1},
pages = {112-119},
year = {2018},
issn = {1018-3647},
doi = {https://doi.org/10.1016/j.jksus.2017.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S1018364716307819},
author = {Raed I. Hamed},
keywords = {FPNs, Fuzzy sets, Uncertain data, GRNs, Quantitative modeling},
abstract = {Quantitative demonstrating of organic frameworks has turned into an essential computational methodology in the configuration of novel and investigation of existing natural frameworks. Be that as it may, active information that portrays the framework's elements should be known keeping in mind the end goal to get pertinent results with the routine displaying strategies. This information is frequently robust or even difficult to get. Here, we exhibit a model of quantitative fuzzy rational demonstrating approach that can adapt to obscure motor information and hence deliver applicable results despite the fact that dynamic information is fragmented or just dubiously characterized. Besides, the methodology can be utilized as a part of the blend with the current cutting edge quantitative demonstrating strategies just in specific parts of the framework, i.e., where the data are absent. The contextual analysis of the methodology suggested in this paper is performed on the model of nine-quality genes. We propose a kind of FPN model in light of fuzzy sets to manage the quantitative modeling of biological systems. The tests of our model appear that the model is practical and entirely powerful for information impersonation and thinking of fuzzy expert frameworks.}
}
@article{BLOOM2001453,
title = {Novel thinking},
journal = {Trends in Cognitive Sciences},
volume = {5},
number = {10},
pages = {453-454},
year = {2001},
issn = {1364-6613},
doi = {https://doi.org/10.1016/S1364-6613(00)01758-7},
url = {https://www.sciencedirect.com/science/article/pii/S1364661300017587},
author = {Paul Bloom}
}
@article{IWENDI20225016,
title = {Combined power generation and electricity storage device using deep learning and internet of things technologies},
journal = {Energy Reports},
volume = {8},
pages = {5016-5025},
year = {2022},
issn = {2352-4847},
doi = {https://doi.org/10.1016/j.egyr.2022.02.304},
url = {https://www.sciencedirect.com/science/article/pii/S2352484722005510},
author = {Celestine Iwendi and Gai-Ge Wang},
keywords = {Energy storage, Machine learning, Internet of things, Fuzzy logic, Electricity storage device, Power generation},
abstract = {In microgrids, residential customers play a significant part in the operation. An alternative to client administration should be to utilize smart houses to deal with demand and implement demand responsiveness measures. A power generation and electricity storage device (PGESD) for next-generation technologies is proposed in this article. The current research provides an intelligent home load control system that promotes reaction to demand thinking about this circumstance. The technology is adapted to scenarios where users can charge fluctuating electric power and transmit microgeneration devices. The suggested system utilizes deep learning technology and a fuzzy logic model for better computation and lesser complexity. The choice process involves monitoring environmental information, power production, and battery storage. This article proposes a next-generation power generation and electricity storage device (PGESD). To create Smart Buildings and Microgrids, the proposed system employs technologies and techniques that have become increasingly important. With a precision and accuracy ratio of 89% and 92%, respectively, the proposed PGESD method yields precise numerical results.}
}
@incollection{HOUSE2018335,
title = {Chapter 14 - Comments on Computational Methods},
editor = {J.E. House},
booktitle = {Fundamentals of Quantum Mechanics (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
pages = {335-347},
year = {2018},
isbn = {978-0-12-809242-2},
doi = {https://doi.org/10.1016/B978-0-12-809242-2.00014-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092422000140},
author = {J.E. House},
keywords = {Basis set, Slater-type orbitals, Gaussian orbitals, Extended Hückel, Wolfsberg-Helmoltz approximation, Ballhausen-Gray approximation, Cusachs' approximation, Self-consistent field, Density functional theory},
abstract = {There are numerous types of molecular orbital calculations that are routinely performed. One of the early versions is the extended Hückel method that begins with the approach used in the Hückel method, but with the overlap and exchange integrals (approximated by the Wolfsberg-Helmholtz, Ballhausen-Gray, or Cusachs' method) included. A more robust type of calculation is that in which an electron is presumed to move in a field generated by the nucleus and other electrons. A trial wave function with some adjustable parameter(s) is taken, and the energy calculated. The wave function improves and the calculations continue until there is no additional improvement (i.e., a “self-consistent field” has been obtained). There are numerous variations of this approach that differ in the trial wave function chosen, extent of electron-electron interaction included, etc. Density functional theory is a newer approach that uses less computational capacity. These types of molecular orbital calculations are surveyed briefly in this chapter.}
}
@article{KAY20231697,
title = {Tasks and their role in visual neuroscience},
journal = {Neuron},
volume = {111},
number = {11},
pages = {1697-1713},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2023.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S0896627323002180},
author = {Kendrick Kay and Kathryn Bonnen and Rachel N. Denison and Mike J. Arcaro and David L. Barack},
keywords = {task, brain, behavior, visual cortex, information processing, modeling},
abstract = {Summary
Vision is widely used as a model system to gain insights into how sensory inputs are processed and interpreted by the brain. Historically, careful quantification and control of visual stimuli have served as the backbone of visual neuroscience. There has been less emphasis, however, on how an observer’s task influences the processing of sensory inputs. Motivated by diverse observations of task-dependent activity in the visual system, we propose a framework for thinking about tasks, their role in sensory processing, and how we might formally incorporate tasks into our models of vision.}
}
@article{BROCAS2021105366,
title = {Value computation and modulation: A neuroeconomic theory of self-control as constrained optimization},
journal = {Journal of Economic Theory},
volume = {198},
pages = {105366},
year = {2021},
issn = {0022-0531},
doi = {https://doi.org/10.1016/j.jet.2021.105366},
url = {https://www.sciencedirect.com/science/article/pii/S0022053121001836},
author = {Isabelle Brocas and Juan D. Carrillo},
keywords = {Neuroeconomic theory, Multiple brain systems, Self-control, Cue-triggered behavior, Self-regulation},
abstract = {We develop a theory based on the evidence reported in Hare et al. (2009) to explain consumption of goods that feature a low-order attribute (e.g., taste) and a high-order attribute (e.g., health). One brain system with access to the low-order attribute computes the goal value of consumption while another brain system can modulate this value, at a cost, by transmitting information regarding the high-order attribute. We determine the optimal modulation and consumption strategy as a function of the cost of information transmission and the environment. We show that in healthy environments, modulation is used to signal surprisingly unhealthy goods so as to trigger abstinence when consumption would ordinarily occur. Conversely, in unhealthy environments, modulation is used to signal surprisingly healthy choices so as to trigger consumption when abstinence would ordinarily occur. From an outside perspective, individuals may appear to under-regulate their choices (self-indulgence) but also to over-regulate them (self-restraint). Both modulation and decisions are affected by factors orthogonal to the decision problem. In particular, taxing executive functions results in less modulation and more inefficient behavior. Finally, the model can shed light on issues related to eating disorders, present-biased preferences, habit formation and compulsive behavior.}
}
@article{PEZZANO2024100078,
title = {Are we done with (Wordy) manifestos? Towards an introverted digital humanism},
journal = {Journal of Responsible Technology},
volume = {17},
pages = {100078},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000040},
author = {Giacomo Pezzano},
keywords = {Mediatic turn, Philosophy of technology, Learning, Book, Video game},
abstract = {Beginning with a reconstruction of the anthropological paradigms underlying The Vienna Manifesto and The Onlife Manifesto (§ 1.1), this paper distinguishes between two possible approaches to digital humanism: an extroverted one, principally engaged in finding a way to humanize digital technologies, and an introverted one, pointing instead attention to how digital technologies can re-humanize us, particularly our “mindframe” (§ 1.2). On this basis, I stress that if we take seriously the consequences of the “mediatic turn”, according to which human reason is finally recognized as mediatically contingent (§ 2.1), then we should accept that just as the book created the poietic context for the development of traditional humanism and its “bookish” idea of private and public reason, so too digital psycho-technologies today provide the conditions for the rise of a new humanism (§ 2.2). I then discuss the possible humanizing potential of digital simulated worlds: I compare the symbolic-reconstructive mindset to the sensorimotor mindset (§ 3.1), and I highlight their respective mediological association with the book and the video game, advocating for the peculiar thinking and reasoning affordances now offered by the new digital psycho-technologies (§ 3.2).}
}
@article{CHIN20201054,
title = {Rethinking Cancer Immunotherapy by Embracing and Engineering Complexity},
journal = {Trends in Biotechnology},
volume = {38},
number = {10},
pages = {1054-1065},
year = {2020},
note = {Special Issue: Therapeutic Biomanufacturing},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2020.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167779920301244},
author = {Matthew H.W. Chin and Eileen Gentleman and Marc-Olivier Coppens and Richard M. Day},
keywords = {bioengineering, complex systems, holism, immunotherapy, process intensification},
abstract = {The meteoric rise of cancer immunotherapy in the past decade has led to promising treatments for a number of hard-to-treat malignancies. In particular, adoptive T cell therapy has recently reached a major milestone with two products approved by the US FDA. However, the inherent complexity of cell-based immunotherapies means that their manufacturing time, cost, and controllability limit their effectiveness and geographic reach. One way to address these issues may lie in complementing the dominant, reductionistic mentality in modern medicine with complex systems thinking. In this opinion article, we identify key concepts from complexity theory to address manufacturing challenges in cell-based immunotherapies and raise the possibility of a unifying framework upon which future bioprocessing strategies may be designed.}
}
@article{NESI2024,
title = {Enactivism: A contemporary perspective of a reconceptualization of osteopathy},
journal = {Advances in Integrative Medicine},
year = {2024},
issn = {2212-9588},
doi = {https://doi.org/10.1016/j.aimed.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212958824001186},
author = {Jacson Nesi and Michele Benites and Filipe Boeira Schedler},
keywords = {Enactivism, Osteopathy, Medical rationalities, Reconceptualization},
abstract = {Enactivism is a philosophical and scientific approach that emphasizes the role of the body and its interactions with the environment in shaping cognitive processes and subjective experiences. Meanwhile, osteopathy is a person-centered health care discipline, highlighting the structure-function interrelationship of the body and its selfregulation mechanisms. Both approaches value the body and the environment in health. Several authors have been discussing the urgent need for a reconceptualization of osteopathy and also suggesting integrate biological, psychological and social aspects. Thinking osteopathy as a Therapeutic Rationality, implies recognize its fundamental dimensions: Human Morphology, Vital Dynamics, Medical Doctrine, Diagnostic System and Therapeutic System, all integrated by a philosophical Cosmology, as the original term Medical rationality states, but also embrace a broader perspective allowing an individual and unique process of each person, reflecting the transformation of contemporary medicine to a person approach. Enactivism principles can serve as a basis for a reconceptualization of osteopathy, integrating environmental, psychological, social, and spiritual factors. Osteopathic concepts can probably be updated through the convergence between enactivism and osteopathy, promoting more meaningful and evidence-based clinical practice. Advancing in this direction requires a collaborative dialogue between researchers, health professionals and interested people, seeking an integrated understanding of the relationship between body, mind, environment and health.}
}
@article{JANES200673,
title = {A biological approach to computational models of proteomic networks},
journal = {Current Opinion in Chemical Biology},
volume = {10},
number = {1},
pages = {73-80},
year = {2006},
note = {Proteomics and genomics},
issn = {1367-5931},
doi = {https://doi.org/10.1016/j.cbpa.2005.12.016},
url = {https://www.sciencedirect.com/science/article/pii/S1367593105001687},
author = {Kevin A Janes and Douglas A Lauffenburger},
abstract = {Computational modeling is useful as a means to assemble and test what we know about proteins and networks. Models can help address key questions about the measurement, definition and function of proteomic networks. Here, we place these biological questions at the forefront in reviewing the computational strategies that are available to analyze proteomic networks. Recent examples illustrate how models can extract more information from proteomic data, test possible interactions between network proteins and link networks to cellular behavior. No single model can achieve all these goals, however, which is why it is critical to prioritize biological questions before specifying a particular modeling approach.}
}
@article{YANG2023106838,
title = {Neuromorphic electronics for robotic perception, navigation and control: A survey},
journal = {Engineering Applications of Artificial Intelligence},
volume = {126},
pages = {106838},
year = {2023},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2023.106838},
url = {https://www.sciencedirect.com/science/article/pii/S0952197623010229},
author = {Yi Yang and Chiara Bartolozzi and Haiyan H. Zhang and Robert A. Nawrocki},
keywords = {Neuromorphic electronics, Organic and flexible electronic materials, Neuromorphic robot, Perception, Navigation, Control, SLAM, Path planning},
abstract = {Neuromorphic electronics have great potential in the emulation of the sensory, cognitive, self-learning, and actuating functions of robots. While typically implemented in rigid silicon, emerging technologies in organic and flexible electronic materials have also led to tremendous advances in the development of neuromorphic perception systems. However, a comprehensive review of the contribution/role of organic neuromorphic electronics for robotic applications is still missing. This review presents advancements in silicon-based and organic neuromorphic electronics for intelligent robot development, focusing on perception, navigation, and learning-based control. Organic synaptic devices, along with dynamic vision sensors, enable diverse forms of sensory-enabled computational perception, offering tunability, stability, low power consumption, and conformal substrates. Integration of simultaneous localization and mapping techniques and path planning algorithms empowers robots to efficiently navigate, build accurate maps, and make informed decisions. Different learning algorithms and their hardware implementations in neuromorphic robotic control are explored, enabling robots to learn and adapt to dynamic environments. The review highlights the potential of neuromorphic electronics for sensing, thinking, and acting in advanced robotic systems. Organic, inorganic, and hybrid materials are discussed for implementing perception, navigation, and control in robots. Future research directions in the field are outlined. Leveraging various neuromorphic electronics unlocks the full potential of intelligent robotic systems for diverse applications.}
}
@article{CHEN2005121,
title = {Computational intelligence in economics and finance: Carrying on the legacy of Herbert Simon},
journal = {Information Sciences},
volume = {170},
number = {1},
pages = {121-131},
year = {2005},
note = {Computational Intelligence in Economics and Finance},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2003.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0020025503004444},
author = {Shu-Heng Chen},
keywords = {Computational intelligence, Artificial intelligence, Agent-based computational economics, Autonomous agents, Stock price-volume relation, Micro-macro relation},
abstract = {This is an editorial guide for the special issue on computational intelligence (CI) in economics and finance. A historical introduction to the background is given. This research paradigm is traced back to Herbert Simon, who, as a founder of artificial intelligence, pioneered the applications of AI to economics. The move from the classical AI to CI indicates a continuation of the legacy of Herbert Simon. Computational intelligence has proved to be a constructive foundation for economics. In responding to what Herbert Simon referred as procedural rationality, our study of bounded rationality has been enriched by bringing autonomous agents into the economic analysis.}
}
@article{GOODSELL2020472,
title = {Art and Science of the Cellular Mesoscale},
journal = {Trends in Biochemical Sciences},
volume = {45},
number = {6},
pages = {472-483},
year = {2020},
issn = {0968-0004},
doi = {https://doi.org/10.1016/j.tibs.2020.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S0968000420300566},
author = {David S. Goodsell and Arthur J. Olson and Stefano Forli},
keywords = {mesoscale modeling, integrative structural biology, drug discovery, drug design, cell structure, cell function, molecular structure, molecular function},
abstract = {Experimental information from microscopy, structural biology, and bioinformatics may be integrated to build structural models of entire cells with molecular detail. This integrative modeling is challenging in several ways: the intrinsic complexity of biology results in models with many closely packed and heterogeneous components; the wealth of available experimental data is scattered among multiple resources and must be gathered, reconciled, and curated; and computational infrastructure is only now gaining the capability of modeling and visualizing systems of this complexity. We present recent efforts to address these challenges, both with artistic approaches to depicting the cellular mesoscale, and development and application of methods to build quantitative models.}
}