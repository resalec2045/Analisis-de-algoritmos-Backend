@article{CHEN2015247,
title = {Reinforcement learning in depression: A review of computational research},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {55},
pages = {247-267},
year = {2015},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2015.05.005},
url = {https://www.sciencedirect.com/science/article/pii/S0149763415001311},
author = {Chong Chen and Taiki Takahashi and Shin Nakagawa and Takeshi Inoue and Ichiro Kusumi},
keywords = {Anhedonia, Computational psychiatry, Depression, Dopamine, Incentive salience, Learning rate, ‘Liking’, Model-free, Model-based, Motivation, Prediction error, Reinforcement learning, Reward sensitivity, Stress, ‘Wanting’},
abstract = {Despite being considered primarily a mood disorder, major depressive disorder (MDD) is characterized by cognitive and decision making deficits. Recent research has employed computational models of reinforcement learning (RL) to address these deficits. The computational approach has the advantage in making explicit predictions about learning and behavior, specifying the process parameters of RL, differentiating between model-free and model-based RL, and the computational model-based functional magnetic resonance imaging and electroencephalography. With these merits there has been an emerging field of computational psychiatry and here we review specific studies that focused on MDD. Considerable evidence suggests that MDD is associated with impaired brain signals of reward prediction error and expected value (‘wanting’), decreased reward sensitivity (‘liking’) and/or learning (be it model-free or model-based), etc., although the causality remains unclear. These parameters may serve as valuable intermediate phenotypes of MDD, linking general clinical symptoms to underlying molecular dysfunctions. We believe future computational research at clinical, systems, and cellular/molecular/genetic levels will propel us toward a better understanding of the disease.}
}
@article{BORREGO2024101948,
title = {DPGraphJ: A Java package for the implementation of dynamic programming algorithms},
journal = {SoftwareX},
volume = {28},
pages = {101948},
year = {2024},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2024.101948},
url = {https://www.sciencedirect.com/science/article/pii/S2352711024003182},
author = {Diana Borrego and Irene Barba and Carmelo {Del Valle} and Miguel Toro},
keywords = {Dynamic programming, AND/OR graphs, Design & implementation, Software quality, Computational thinking},
abstract = {This paper introduces the DPGraphJ package, a collection of reusable Java functions to solve optimisation problems using a dynamic programming algorithm. The latter is based on a recursive schema that follows a top-down approach and uses the memoisation technique. This algorithm is a reusable software component that is generic and efficient. Moreover, it has been developed by paying special attention to good practices in the design of software. For using DPGraphJ, the problem to be solved needs to be modelled as an AND/OR graph. In the DPGraphJ package, we provide 5 academic case studies with detailed comments. We strongly believe that our proposal can be helpful for several kinds of users, such as students, researchers, and practitioners.}
}
@article{CHECIU2024127324,
title = {Reconstructing creative thoughts: Hopfield neural networks},
journal = {Neurocomputing},
volume = {575},
pages = {127324},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127324},
url = {https://www.sciencedirect.com/science/article/pii/S092523122400095X},
author = {Denisa Checiu and Mathias Bode and Radwa Khalil},
keywords = {Creative Thinking, Hopfield Neural Network, Patterns, Memory, Associative Chains, Semantic Association},
abstract = {From a brain processing perspective, the perception of creative thinking is rooted in the underlying cognitive process, which facilitates exploring and cultivating novel avenues and problem-solving strategies. However, it is challenging to emulate the intricate complexity of how the human brain presents a novel way to uncover unique solutions. One potential approach to mitigating this complexity is incorporating creative cognition into the evolving artificial intelligence systems and associated neural models. Hopfield neural network (HNN) are commonly acknowledged as a simplified neural model, renowned for their biological plausibility to store and retrieve information, specifically patterns of neurons. Our findings suggest utilizing modern HNN to emulate creative thinking by making meaningful associations between seemingly disparate concepts. This semantic link is represented as a radio knob that can be set to determine whether the network solves problems creatively or shuts down; the threshold is a parameter. We used the term "first knob of creativity" to describe a certain pattern and utilized the "second knob of creativity" to aid in the examination of alternatives within the network. By manipulating the knobs, it is possible to selectively suppress specific patterns, facilitating the creative functioning of the HNN and identifying other patterns with which input can be linked.}
}
@article{CHANG2023100529,
title = {Management accounting system: Insights from the decision making theories},
journal = {Social Sciences & Humanities Open},
volume = {8},
number = {1},
pages = {100529},
year = {2023},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2023.100529},
url = {https://www.sciencedirect.com/science/article/pii/S2590291123001341},
author = {Kirk Chang and Alhashmi Aboubaker Lasyoud and Diaeldin Osman},
keywords = {Decision making, MAS, Management account system, Pre-factor, Thinking styles},
abstract = {Management accounting system (MAS) improves business growth through quality decision making process, but scholars have mixed views about MAS and constantly debate its efficacy. Drawing on the decision-making theories, the current research deviates from the debates and adopts a ‘think-outside-the-box’ approach, aiming to advance the knowledge of MAS's efficacy. Research data are gathered from the MAS literatures and cognate studies. Following the research findings, we identify a new pre-factor (thinking style) and incorporate it into the MAS. Specifically, decision makers' cognitive process is found to affect the design and implementation of MAS, as rational thinking style, administrative thinking style, and political thinking style may affect the MAS's efficacy differently. Research findings have brought valuable insights to the MAS literatures, by highlighting the strength and weakness of different thinking styles in designing management accounting system. Moreover, decision makers, such as organizational leaders and business managers, are encouraged to monitor their thinking styles: that is, with better understanding of thinking styles, decision makers can better utilize MAS and rectify the style-driven deficits in time.}
}
@article{RUIZ20221641,
title = {Computational simulation as a decision-making support tool for prefabricated pillars production},
journal = {Canadian Journal of Civil Engineering},
volume = {49},
number = {10},
pages = {1641-1654},
year = {2022},
issn = {0315-1468},
doi = {https://doi.org/10.1139/cjce-2021-0565},
url = {https://www.sciencedirect.com/science/article/pii/S0315146822000451},
author = {Phelipe Viana Ruiz and Carlos Eduardo Marmorato Gomes and Patricia Stella Pucharelli Fontanini},
keywords = {industrialized building system, simulation, decision support systems, production control, prefabricated concrete elements, système de construction industrialisé, simulation, systèmes d’aide à la décision, contrôle de la production, éléments préfabriqués en béton},
abstract = {Competitive industrialization pressures the construction sector to move activities away from the construction site, contemplating the prefabricated elements use. Companies willing to remain in the competitive market must seek new positions and developments in their production and management chains. To support the managers' decision-making about the prefabricated concrete elements production line, this article presents a computer simulation model for prefabricated pillars production line productivity scenarios creation. The data used for this model development were collected through a case study in the production line of prefabricated pillars. A simulation software modelled the production line with a dashboard that enables multiple-scenario generation. The adopted approach works with stochastic data, allowing nonprogrammer users to: manipulate and control scenarios and layout settings, analyze results through a dashboard and provide management and decision-makers with a comprehensive view of possible solutions.
L’industrialisation concurrentielle pousse le secteur de la construction à s’éloigner du chantier, en envisageant l’utilisation des éléments préfabriqués. Les entreprises désireuses de demeurer sur le marché concurrentiel doivent rechercher de nouvelles positions et de nouveaux développements dans leurs chaînes de production et de gestion. Pour aider les gestionnaires à prendre des décisions au sujet de la ligne de production d’éléments préfabriqués en béton, cet article présente un modèle de simulation informatique pour la création de scénarios de productivité de ligne de production de piliers préfabriqués. Les données utilisées pour l’élaboration de ce modèle ont été recueillies au moyen d’une étude de cas sur la chaîne de production de piliers préfabriqués. Un logiciel de simulation a modélisé la ligne de production avec un tableau de bord permettant l’élaboration de scénarios multiples. L’approche adoptée fonctionne avec des données stochastiques, permettant aux utilisateurs non-programmeurs : de manipuler et contrôler les scénarios et les paramètres de mise en page, d’analyser les résultats au moyen d’un tableau de bord et de fournir à la direction et aux décideurs une vue d’ensemble des solutions possibles. [Traduit par la Rédaction]}
}
@incollection{ASPRION202257,
title = {Chapter 3 - Thinking multicriteria—A jackknife when it comes to optimization},
editor = {Michael Bortz and Norbert Asprion},
booktitle = {Simulation and Optimization in Process Engineering},
publisher = {Elsevier},
pages = {57-75},
year = {2022},
isbn = {978-0-323-85043-8},
doi = {https://doi.org/10.1016/B978-0-323-85043-8.00012-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032385043800012X},
author = {Norbert Asprion and Michael Bortz},
keywords = {Multicriteria optimization, Decision support, Robust optimization, Pareto set, Adaptive scalarization, Optimal control, Sensitivity analysis},
abstract = {Multicriteria optimization (MCO) can offer insight into trade-offs between different alternatives in process design and flowsheet alternatives. This chapter highlights the practical benefit obtained by integrating MCO into an industrial flowsheet simulator. Parametric model uncertainties, model adjustment, and design of experiments are considered as well from an MCO point of view.}
}
@article{KALRO1998267,
title = {3D computation of unsteady flow past a sphere with a parallel finite element method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {151},
number = {1},
pages = {267-276},
year = {1998},
note = {Containing papers presented at the Symposium on Advances in Computational Mechanics},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(97)00120-5},
url = {https://www.sciencedirect.com/science/article/pii/S0045782597001205},
author = {V. Kalro and T. Tezduyar},
abstract = {We present parallel computation of 3D, unsteady, incompressible flow past a sphere. The Navier-Stokes equations of incompressible flows are solved using a stabilized finite element formulation. Equal-order interpolation functions are used for velocity and pressure. The second-order accurate time-marching within the solution process is carried out in an implicit fashion. The coupled, nonlinear equations generated at each time step are solved using an element-vector-based iteration technique. The computed value of the primary frequency associated with vortex shedding is in close agreement with experimental measurements. The computation was performed on the Thinking Machines CM-5.}
}
@article{BEATTIE2003909,
title = {Post-genomic technologies – thinking beyond the hype},
journal = {Drug Discovery Today},
volume = {8},
number = {20},
pages = {909-910},
year = {2003},
issn = {1359-6446},
doi = {https://doi.org/10.1016/S1359-6446(03)02862-9},
url = {https://www.sciencedirect.com/science/article/pii/S1359644603028629},
author = {John Beattie and Peter Ghazal},
keywords = {Post-genomic, Proteomics, Biochip, DNA chip, Bioinformatics, Microarrays}
}
@article{WANG2025112869,
title = {Development and validation of the long and short forms of the rest intolerance scale for college students},
journal = {Personality and Individual Differences},
volume = {233},
pages = {112869},
year = {2025},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2024.112869},
url = {https://www.sciencedirect.com/science/article/pii/S0191886924003295},
author = {Fei Wang and Haoran Song and Xiaoxuan Meng and Ting Wang and Qian Zhang and Ziying Yu and Siyuan Fan and Yibo Wu},
keywords = {Rest intolerance, Negative feelings, Obsessive thinking, Social comparison, Cognitive bias},
abstract = {With the development of Chinese society, “rest intolerance” has become a topic of great concern and discussion. The purpose of this study was to investigate the dimensions and psychological connotations of rest intolerance and to develop both short and long versions of the rest intolerance scale suitable for Chinese university students. We used three steps to development the scales. In Study 1, we first used interviews and the grounded theory to propose the psychological connotation of rest intolerance and its characteristic dimensions, i.e., negative feelings, obsessive thinking, social comparison, and cognitive bias. On this basis, the rest intolerance scale was compiled, and a four-dimensional scale containing 24 items was obtained through item analysis, exploratory factor analysis, and exploratory graph analysis. Study 2 validated the 4 characteristic dimensions of rest intolerance in a new sample through confirmatory factor analysis, content validity test, and criterion-related validity test, the results show that the 24-item rest intolerance scale (RIS-24) has good reliability and validity. Study 3 developed a short version of the 8-item Rest Intolerance Scale (RIS-8) using genetic algorithms. Overall, the present study provides two instruments for the measurement of rest intolerance that will facilitate the progress of future research.}
}
@incollection{HASS202094,
title = {Measurement: Computerized Creativity Testing and Scoring},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {94-99},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23810-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245238108},
author = {Richard W. Hass},
keywords = {Creativity, Measurement, Assessment, Semantic memory, Computer algorithms, Divergent thinking, Remote association, Brainstorming, Domain-specificity, Creative problem solving},
abstract = {This entry discusses the use of computers in creativity measurement and assessment. Special emphasis is placed on the use of algorithms for scoring the responses generated during divergent thinking tasks. These algorithms are rooted in various theories of semantics, the details of which are also reviewed. In addition, advances in the use of computers for electronic brainstorming and for domain-specific creativity measurement beyond verbal divergent thinking are also reviewed. The objective is to provide readers with information on the various methods that are available, and a brief discussion of computational semantics.}
}
@article{VOYER2022101734,
title = {Symbols of class: A computational analysis of class distinction-making through etiquette, 1922-2017},
journal = {Poetics},
volume = {94},
pages = {101734},
year = {2022},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2022.101734},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X22001164},
author = {Andrea Voyer and Zachary D. Kline and Madison Danton},
keywords = {Social class, Status symbols, Word embeddings, Cultural sociology, Computational sociology},
abstract = {Social scientists of class and inequality have documented the rise of omnivorousness, informality, ordinariness, and emphasis on meritocracy. This apparent decline in class closure contrasts sharply with rising inequality and declining economic mobility. How are these competing developments reflected in everyday class distinction-making? In this article, we answer this question by applying Goffman's work on the symbols of class status to the analysis of unique data: a corpus of etiquette books published between 1922 and 2017. We use word embeddings to quantify the salience of six class concepts (affluence, cultivation, education, employment, morality, and status) in the corpus. We find that education and employment are increasingly salient while status, affluence, cultivation, and morality decline in their salience to class distinction-making. These results signal a decline of class operating as a status group through cultural closure, the rise of education and employment as the carriers of class in everyday life, and the corresponding legitimation of class position and class inequality based on supposedly meritocratic grounds. This research opens up new avenues for studies of class and the application of computational methods to investigations of social change.}
}
@article{NAGURNEY19981467,
title = {A massively parallel implementation of a discrete-time algorithm for the computation of dynamic elastic demand traffic problems modeled as projected dynamical systems},
journal = {Journal of Economic Dynamics and Control},
volume = {22},
number = {8},
pages = {1467-1485},
year = {1998},
issn = {0165-1889},
doi = {https://doi.org/10.1016/S0165-1889(98)00022-0},
url = {https://www.sciencedirect.com/science/article/pii/S0165188998000220},
author = {Anna Nagurney and Ding Zhang},
abstract = {In this paper we consider the solution of a dynamic traffic network model with elastic demands formulated as a projected dynamical system. We propose a discrete-time algorithm, the Euler method, which resolves the problem at each iteration into subproblems in path flow variables, all of which can be solved simultaneously and in closed form. Convergence results are also presented. We then discuss the implementation of the algorithm in CM Fortran on the massively parallel architecture, the Thinking Machine’s CM-5. Finally, we present numerical results for the parallel implementation on the CM-5 and for a serial implementation of the algorithm in Fortran on the IBM SP2 for several traffic network examples.}
}
@article{NOORIGOODARZI2022105372,
title = {Subtractive genomic approach toward introduction of novel immunogenic targets against Clostridioides difficile: Thinking out of the box},
journal = {Microbial Pathogenesis},
volume = {162},
pages = {105372},
year = {2022},
issn = {0882-4010},
doi = {https://doi.org/10.1016/j.micpath.2021.105372},
url = {https://www.sciencedirect.com/science/article/pii/S088240102100646X},
author = {Narjes {Noori Goodarzi} and Sepideh Fereshteh and Omid Azizi and Hamzeh Rahimi and Negin Bolourchi and Farzad Badmasti},
keywords = {, Reverse vaccinology, Immunogenic target},
abstract = {Clostridioides difficile is one of the major causatives of nosocomial infections worldwide. Antibiotic-associated diarrhea, pseudomembranous colitis, and toxic megacolon are the most common forms of C. difficile infection (CDI). Considering the high antibiotic resistance of C. difficile isolates and the low efficacy of immunization with toxin-related vaccines, we suggested that surface-exposed and secreted proteins could be considered as potential immunogenic targets against CDI. Various immuninformatics databases were used to predict antigenicity, allergenicity, B-cell epitopes, MHC-II binding sites, conserved domains, prevalence and conservation of proteins among the most common sequence types, molecular docking, and immunosimulation of immunogenic targets. Finally, 16 proteins belonging to three functional groups were identified, including proteins involved in the cell wall and peptidoglycan layer (nine proteins), flagellar assembly (five proteins), spore germination (one protein), and a protein with unknown function. Molecular docking results showed that among all the mentioned proteins, WP_009892971.1 (Acd) and WP_009890599.1 (a C40 family peptidase) had the strongest interactions with human Toll-like receptor 2 (TLR-2) and TLR-4. This study proposes a combination of C. difficile toxoid (Tcd) and surface-exposed proteins such as Acd as a promising vaccine formulation for protection against circulating clinical strains of C. difficile.}
}
@article{DERREUMAUX2023105304,
title = {Computational underpinnings of partisan information processing biases and associations with depth of cognitive reasoning},
journal = {Cognition},
volume = {230},
pages = {105304},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2022.105304},
url = {https://www.sciencedirect.com/science/article/pii/S001002772200292X},
author = {Yrian Derreumaux and Kimia Shamsian and Brent L. Hughes},
keywords = {Partisan bias, Motivated cognition, Sequential sampling, Drift diffusion modeling, Cognitive reflection},
abstract = {Despite unprecedented access to information, partisans increasingly disagree about basic facts that are backed by data, posing a serious threat to a democracy that relies on finding common ground based on objective truths. We examine the underpinnings of this phenomenon using drift diffusion modeling (DDM). Partisans (N = 148) completed a sequential sampling task where they evaluated the honesty of Democrat or Republican politicians during a debate based on fact-check scores. We found that partisans required less and weaker evidence to correctly categorize the ingroup as more honest, and were more accurate on trials when the ingroup candidate was more honest, compared to the outgroup. DDM revealed that such tendencies arise from both a prior preference for categorizing the ingroup as more honest (i.e., biased starting point) and more precise accumulation of information favoring the ingroup candidate compared to the outgroup (i.e., biased drift rate). Moreover, individual differences in cognitive reasoning moderated task performance for the most devoted partisans and maintained divergent associations with the DDM parameters. This suggests that partisans may reach biased conclusions via different pathways depending on their depth of cognitive reasoning. These findings provide key insights into the mechanisms driving partisan divides in polarized environments, and can inform interventions that reduce impasse and conflict.}
}
@article{2024267,
title = {Commentator Discussion: Autonomous Fontan pump: Computational feasibility study},
journal = {JTCVS Open},
volume = {21},
pages = {267},
year = {2024},
issn = {2666-2736},
doi = {https://doi.org/10.1016/j.xjon.2024.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S2666273624001906}
}
@article{BAUSO20161,
title = {Strategic thinking under social influence: Scalability, stability and robustness of allocations},
journal = {European Journal of Control},
volume = {32},
pages = {1-15},
year = {2016},
issn = {0947-3580},
doi = {https://doi.org/10.1016/j.ejcon.2016.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0947358016300115},
author = {Dario Bauso and Tamer Başar},
keywords = {Mean-field games, Coalitional game theory, Differential games, Optimal control},
abstract = {This paper studies the strategic behavior of a large number of game designers and studies the scalability, stability and robustness of their allocations in a large number of homogeneous coalitional games with transferable utilities (TU). For each TU game, the characteristic function is a continuous-time stochastic process. In each game, a game designer allocates revenues based on the extra reward that a coalition has received up to the current time and the extra reward that the same coalition has received in the other games. The approach is based on the theory of mean-field games with heterogeneous groups in a multi-population regime.}
}
@article{TREUR2013449,
title = {Conceptual and Computational Analysis of the Role of Emotions and Social Influence in Learning},
journal = {Procedia - Social and Behavioral Sciences},
volume = {93},
pages = {449-467},
year = {2013},
note = {3rd World Conference on Learning, Teaching and Educational Leadership},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.09.220},
url = {https://www.sciencedirect.com/science/article/pii/S1877042813033235},
author = {Jan Treur and Arlette {van Wissen}},
keywords = {emotion, learning, social influence, reflection.},
abstract = {In this paper, it is analyzed how emotions and social environment affect people's active and reflective learning processes. First, a conceptual analysis is made using recent insights from Cognitive, Affective and Social Neuroscience on the roles of emotions and social interactions on learning. Next, a computational analysis is made using a computational model of learning processes following these insights. In this analysis, neural mechanisms for the impact of both a person's own emotions and the emotions of others are taken into account. In particular, it is considered how these impacts influence different learning types, such as active or reflective learners. The analysis shows how the impacts of emotions and social interaction strengthen the learning process. It is discussed how from these insights indicators can be obtained that can be used to design technology-enhanced learning environments able to exploit these impacts.}
}
@article{JOHNSONLAIRD1994189,
title = {Mental models and probabilistic thinking},
journal = {Cognition},
volume = {50},
number = {1},
pages = {189-209},
year = {1994},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(94)90028-0},
url = {https://www.sciencedirect.com/science/article/pii/0010027794900280},
author = {Philip N. Johnson-Laird},
abstract = {This paper outlines the theory of reasoning based on mental models, and then shows how this theory might be extended to deal with probabilistic thinking. The same explanatory framework accommodates deduction and induction: there are both deductive and inductive inferences that yield probabilistic conclusions. The framework yields a theoretical conception of strength of inference, that is, a theory of what the strength of an inference is objectively: it equals the proportion of possible states of affairs consistent with the premises in which the conclusion is true, that is, the probability that the conclusion is true given that the premises are true. Since there are infinitely many possible states of affairs consistent with any set of premises, the paper then characterizes how individuals estimate the strength of an argument. They construct mental models, which each correspond to an infinite set of possibilities (or, in some cases, a finite set of infinite sets of possibilities). The construction of models is guided by knowledge and beliefs, including lay conceptions of such matters as the “law of large numbers”. The paper illustrates how this theory can account for phenomena of probabilistic reasoning.}
}
@article{MURILLO2020119,
title = {Confronting the Challenges of Computational and Social Perspectives of the Data Continuum},
journal = {Data and Information Management},
volume = {4},
number = {2},
pages = {119-126},
year = {2020},
issn = {2543-9251},
doi = {https://doi.org/10.2478/dim-2020-0008},
url = {https://www.sciencedirect.com/science/article/pii/S2543925122000559},
author = {Angela P. Murillo and Renata G. Curty and Wei Jeng and Daqing He},
keywords = {data acumen, data stewardship, agricultural data, biomedical data, archaeological data},
abstract = {As the availability of data is increasing everyday, the need to reflect on how to make these data meaningful and impactful becomes vital. Current data paradigms have provided data life cycles that often focus on data acumen and data stewardship approaches. In an effort to examine the convergence, tensions, and harmonies of these two approaches, a group of researchers participated in an interactive panel session at the Association of Information Science and Technology Annual meeting in 2019. The panel presenters described their various research activities in which they confront the challenges of the computational and social perspectives of the data continuum. This paper provides a summary of this interactive panel.}
}
@article{SHIN2025101771,
title = {Exploring creative problem-solving in computer-supported collaborative learning: Focusing on group cohesiveness and socially shared metacognitive regulation},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101771},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101771},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000203},
author = {Yoonhee Shin and Haengkyung Lee and Wooyoung Kim},
keywords = {Creative problem-solving, Knowledge construction, Computer-supported collaborative learning, Group cohesiveness, Socially shared metacognitive regulation},
abstract = {This study investigated the creative problem-solving (CPS) process in computer-supported collaborative learning (CSCL), examining its relationship with CPS skills and interaction patterns, with a particular focus on group cohesiveness and socially shared metacognitive regulation (SSMR). The research sought to determine how group cohesiveness within Design Thinking (DT) phases influences CPS skills and to identify the characteristics of SSMR in high- versus low-creativity groups. Participants included 108 first-year undergraduate students majoring in humanities and social sciences at a South Korean university. The study found a significant relationship between group cohesiveness and CPS skill levels across various CPS phases. Specifically, substantial differences in SSMR patterns, particularly concerning exploration and evaluation, were observed among low- and high-creativity groups. These findings suggest that the interplay of divergent and convergent thinking during CPS is crucial for devising novel and practical solutions. Employing a mixed-methods approach and collaboration analysis, the study closely examined the CPS process using CSCL tools, offering valuable insights for informing future CPS instructional strategies.}
}
@article{GRIFFITHS201521,
title = {Manifesto for a new (computational) cognitive revolution},
journal = {Cognition},
volume = {135},
pages = {21-23},
year = {2015},
note = {The Changing Face of Cognition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2014.11.026},
url = {https://www.sciencedirect.com/science/article/pii/S0010027714002467},
author = {Thomas L. Griffiths},
keywords = {Computational modeling, Big data, Crowdsourcing},
abstract = {The cognitive revolution offered an alternative to merely analyzing human behavior, using the notion of computation to rigorously express hypotheses about the mind. Computation also gives us new tools for testing these hypotheses – large behavioral databases generated by human interactions with computers and with one another. This kind of data is typically analyzed by computer scientists, who focus on predicting people’s behavior based on their history. A new cognitive revolution is needed, demonstrating the value of minds as intervening variables in these analyses and using the results to evaluate models of human cognition.}
}
@article{GIRARD202297,
title = {Computational analysis of spoken language in acute psychosis and mania},
journal = {Schizophrenia Research},
volume = {245},
pages = {97-115},
year = {2022},
note = {Computational Approaches to Understanding Psychosis},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2021.06.040},
url = {https://www.sciencedirect.com/science/article/pii/S0920996421002528},
author = {Jeffrey M. Girard and Alexandria K. Vail and Einat Liebenthal and Katrina Brown and Can Misel Kilciksiz and Luciana Pennant and Elizabeth Liebson and Dost Öngür and Louis-Philippe Morency and Justin T. Baker},
keywords = {Language, Schizophrenia, Bipolar disorder, Positive symptoms, Negative symptoms},
abstract = {Objectives
This study aimed to (1) determine the feasibility of collecting behavioral data from participants hospitalized with acute psychosis and (2) begin to evaluate the clinical information that can be computationally derived from such data.
Methods
Behavioral data was collected across 99 sessions from 38 participants recruited from an inpatient psychiatric unit. Each session started with a semi-structured interview modeled on a typical “clinical rounds” encounter and included administration of the Positive and Negative Syndrome Scale (PANSS).
Analysis
We quantified aspects of participants' verbal behavior during the interview using lexical, coherence, and disfluency features. We then used two complementary approaches to explore our second objective. The first approach used predictive models to estimate participants' PANSS scores from their language features. Our second approach used inferential models to quantify the relationships between individual language features and symptom measures.
Results
Our predictive models showed promise but lacked sufficient data to achieve clinically useful accuracy. Our inferential models identified statistically significant relationships between numerous language features and symptom domains.
Conclusion
Our interview recording procedures were well-tolerated and produced adequate data for transcription and analysis. The results of our inferential modeling suggest that automatic measurements of expressive language contain signals highly relevant to the assessment of psychosis. These findings establish the potential of measuring language during a clinical interview in a naturalistic setting and generate specific hypotheses that can be tested in future studies. This, in turn, will lead to more accurate modeling and better understanding of the relationships between expressive language and psychosis.}
}
@article{CUI20226,
title = {Green biomanufacturing promoted by automatic retrobiosynthesis planning and computational enzyme design},
journal = {Chinese Journal of Chemical Engineering},
volume = {41},
pages = {6-21},
year = {2022},
issn = {1004-9541},
doi = {https://doi.org/10.1016/j.cjche.2021.08.017},
url = {https://www.sciencedirect.com/science/article/pii/S1004954121004286},
author = {Ziheng Cui and Shiding Zhang and Shengyu Zhang and Biqiang Chen and Yushan Zhu and Tianwei Tan},
keywords = {Biomanufacturing, Retrobiosynthesis, Computational enzyme design, Biobased chemicals},
abstract = {Biomanufacturing, which uses renewable resources as raw materials and uses biological processes to produce energy and chemicals, has long been regarded as a production model that replaces the unsustainable fossil economy. The construction of non-natural and efficient biosynthesis routes of chemicals is an important goal of green biomanufacturing. Traditional methods that rely on experience are difficult to support the realization of this goal. However, with the rapid development of information technology, the intelligence of biomanufacturing has brought hope to achieve this goal. Retrobiosynthesis and computational enzyme design, as two of the main technologies in intelligent biomanufacturing, have developed rapidly in recent years and have made great achievements and some representative works have demonstrated the great value that the integration of the two fields may bring. To achieve the final integration of the two fields, it is necessary to examine the information, methods and tools from a bird's-eye view, and to find a feasible idea and solution for establishing a connection point. For this purpose, this article briefly reviewed the main ideas, methods and tools of the two fields, and put forward views on how to achieve the integration of the two fields.}
}
@article{POON2006177,
title = {Lay personality knowledge and dispositionist thinking: A knowledge-activation framework},
journal = {Journal of Experimental Social Psychology},
volume = {42},
number = {2},
pages = {177-191},
year = {2006},
issn = {0022-1031},
doi = {https://doi.org/10.1016/j.jesp.2005.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S002210310500051X},
author = {Connie S.K. Poon and Derek J. Koehler},
keywords = {Lay theories, Dispositional inferences, Knowledge activation},
abstract = {We explicate a knowledge-activation framework depicting the link between lay personality knowledge and dispositional judgments, building on work by Dweck et al., 1995a, Dweck et al., 1995b. According to this framework, most people possess knowledge consistent with an entity theory (personality is fixed) and incremental theory (personality is malleable), which operates according to knowledge-activation principles. Consistent with this claim, we find that people render more confident dispositional judgments when their entity knowledge is made relatively more accessible through priming manipulations that activate aspects of their existing knowledge. Findings also illustrate the usefulness of incorporating both specific and general knowledge in our analysis. The present framework enhances and complements the individual-differences approach to the study of person theories prevalent in the literature.}
}
@article{YILDIRIM201973,
title = {An integrative computational architecture for object-driven cortex},
journal = {Current Opinion in Neurobiology},
volume = {55},
pages = {73-81},
year = {2019},
note = {Machine Learning, Big Data, and Neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2019.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0959438818301995},
author = {Ilker Yildirim and Jiajun Wu and Nancy Kanwisher and Joshua Tenenbaum},
abstract = {Computational architecture for object-driven cortex Objects in motion activate multiple cortical regions in every lobe of the human brain. Do these regions represent a collection of independent systems, or is there an overarching functional architecture spanning all of object-driven cortex? Inspired by recent work in artificial intelligence (AI), machine learning, and cognitive science, we consider the hypothesis that these regions can be understood as a coherent network implementing an integrative computational system that unifies the functions needed to perceive, predict, reason about, and plan with physical objects—as in the paradigmatic case of using or making tools. Our proposal draws on a modeling framework that combines multiple AI methods, including causal generative models, hybrid symbolic-continuous planning algorithms, and neural recognition networks, with object-centric, physics-based representations. We review evidence relating specific components of our proposal to the specific regions that comprise object-driven cortex, and lay out future research directions with the goal of building a complete functional and mechanistic account of this system.}
}
@article{SHEARER1996465,
title = {Computational optimization of finite difference methods on the CM5},
journal = {Parallel Computing},
volume = {22},
number = {3},
pages = {465-481},
year = {1996},
issn = {0167-8191},
doi = {https://doi.org/10.1016/0167-8191(95)00009-7},
url = {https://www.sciencedirect.com/science/article/pii/0167819195000097},
author = {M.M. Shearer},
keywords = {Finite-difference method, Partial differential equation, CM5, Distributed memory multiprocessor, Optimization, Data partitioning, Performance},
abstract = {Techniques used to optimize a finite-difference program on a Thinking Machines' CM5 parallel processing system are presented. These techniques are discussed within several categories: vector unit optimization, separation of communications and computations, and optimal data partitioning. A simplified model is employed to illustrate these concepts. The results of applying these techniques to a more complicated finite-difference calculation are also reported.}
}
@article{ROOTBERNSTEIN2025100097,
title = {An art-science perspective on artificial intelligence creativity: From problem finding to materiality and embodied cognition},
journal = {Journal of Creativity},
volume = {35},
number = {2},
pages = {100097},
year = {2025},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2025.100097},
url = {https://www.sciencedirect.com/science/article/pii/S2713374525000044},
author = {Robert Root-Bernstein},
keywords = {Artificial intelligence, Expert systems, Creativity, Creative process, Problem recognition, Innovation, Art, Science, The illiac suite, Aspire mirror},
abstract = {Current large language models, image generators and discovery engines fuel fears that artificial intelligence systems will replace human-driven creativity. However, analysing AI systems from the perspective of creative process reveals significant limitations. Human creativity begins with finding or recognizing novel problems or challenges, which no AI system has managed. The problems AI systems address are predetermined by human users, who also provide the data and constraints bounding effective answers. Thus, human beings still carry out the vast majority of creative process-related functions for AI. Moreover, most human creativity is embodied and involves the manipulation of tools and materials. Furthermore, all human creativity is based on “tagging” information and experiences through perceptions, sensations and emotions with meanings or actions. No AI has these attributes. All human innovations also involve “untagging” preconceived meanings and actions so as to “retag” them in novel and effective ways that change how we feel, understand and act. No AI can untag or retag data, let alone act. Finally, human creative thinking is based on observing, imaging, abstracting, analogizing, playacting, modelling, body thinking, etc., of which AI systems are capable only of pattern forming and pattern recognition. Thus, the challenges for developing true AI creativity are extensive.}
}
@article{SHENHAV2022,
title = {Using Community Ecology Theory and Computational Microbiome Methods To Study Human Milk as a Biological System},
journal = {mSystems},
volume = {7},
number = {1},
year = {2022},
issn = {2379-5077},
doi = {https://doi.org/10.1128/msystems.01132-21},
url = {https://www.sciencedirect.com/science/article/pii/S2379507722000873},
author = {Liat Shenhav and Meghan B. Azad and Jack A. Gilbert},
keywords = {computational methods, human microbiome, human milk, chronobiology, community ecology theory, system biology, lactation, breastfeeding},
abstract = {Human milk is a complex and dynamic biological system that has evolved to optimally nourish and protect human infants. Yet, according to a recent priority-setting review, “our current understanding of human milk composition and its individual components and their functions fails to fully recognize the importance of the chronobiology and systems biology of human milk in the context of milk synthesis, optimal timing and duration of feeding, and period of lactation.” We attribute this critical knowledge gap to three major reasons as follows. (i) Studies have typically examined each subsystem of the mother-milk-infant “triad” in isolation and often focus on a single element or component (e.g., maternal lactation physiology or milk microbiome or milk oligosaccharides or infant microbiome or infant gut physiology).
ABSTRACT
Human milk is a complex and dynamic biological system that has evolved to optimally nourish and protect human infants. Yet, according to a recent priority-setting review, “our current understanding of human milk composition and its individual components and their functions fails to fully recognize the importance of the chronobiology and systems biology of human milk in the context of milk synthesis, optimal timing and duration of feeding, and period of lactation” (P. Christian et al., Am J Clin Nutr 113:1063–1072, 2021, https://doi.org/10.1093/ajcn/nqab075). We attribute this critical knowledge gap to three major reasons as follows. (i) Studies have typically examined each subsystem of the mother-milk-infant “triad” in isolation and often focus on a single element or component (e.g., maternal lactation physiology or milk microbiome or milk oligosaccharides or infant microbiome or infant gut physiology). This undermines our ability to develop comprehensive representations of the interactions between these elements and study their response to external perturbations. (ii) Multiomics studies are often cross-sectional, presenting a snapshot of milk composition, largely ignoring the temporal variability during lactation. The lack of temporal resolution precludes the characterization and inference of robust interactions between the dynamic subsystems of the triad. (iii) We lack computational methods to represent and decipher the complex ecosystem of the mother-milk-infant triad and its environment. In this review, we advocate for longitudinal multiomics data collection and demonstrate how incorporating knowledge gleaned from microbial community ecology and computational methods developed for microbiome research can serve as an anchor to advance the study of human milk and its many components as a “system within a system.”}
}
@article{CAKIROGLU2021100888,
title = {Understanding students’ abstractions in block-based programming environments: A performance based evaluation},
journal = {Thinking Skills and Creativity},
volume = {41},
pages = {100888},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100888},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121001036},
author = {Ünal Çakıroğlu and İsak Çevik and Engin Köşeli and Merve Aydın},
keywords = {Abstraction, Block-based programming, Computational thinking, Computer science education},
abstract = {Providing computational problems for enhancing students’ abstraction skills and monitoring how students make abstractions is difficult in block-based programming environments (BBPEs). Thus, concrete examples and principles are needed to guide computer science teachers about understanding and enhancing students’ abstractions. This study aims to examine the effect of using block-based coding environments on enhancing secondary school students’ abstraction skills. Referring to the programming knowledge, a rubric was created to analyze the data from screen recordings, observation and interviews were used together to reveal the students’ abstraction performances. The results suggested that students performed high in elimination, focusing and generalization; however, students’ performances were relatively low in customization. Students’ explanations were mostly related the nature of the problems, affordances of BBPE and the programming constructs used in coding. We hope the study will provide insights for the efforts on instructional designs for successful abstraction experiences for young students.}
}
@article{IGLESIAS2011744,
title = {Re-thinking water policy priorities in the Mediterranean region in view of climate change},
journal = {Environmental Science & Policy},
volume = {14},
number = {7},
pages = {744-757},
year = {2011},
note = {Adapting to Climate Change: Reducing Water-related Risks in Europe},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2011.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1462901111000207},
author = {Ana Iglesias and Luis Garrote and Agustin Diz and Jeremy Schlickenrieder and Francisco Martin-Carrasco},
keywords = {Mediterranean, Climate change, Water policy, Adaptation and assessment},
abstract = {Water is scarce in Mediterranean countries: cities are crowded with increasing demand; food is produced with large amounts of water; ecosystems demand more water that is often available; drought affects all. As climate change impacts become more noticeable and costlier, some current water management strategies will not be useful. According to the findings of CIRCE, the areas with limited water resources will increase in the coming decades with major consequences for the way we produce food and we protect ecosystems. Based on these projections this paper discusses water policy priorities for climate change adaptation in the Mediterranean. We first summarise the main challenges to water resources in Mediterranean countries and outline the risks and opportunities for water under climate change based on previous studies. Recognising the difficulty to go from precipitation to water policy, we then present a framework to evaluate water availability in response to natural and management conditions, with an example of application in the Ebro basin that exemplifies other Mediterranean areas. Then we evaluate adaptive capacity to understand the ability of Mediterranean countries to face, respond and recover from climate change impacts on water resources. Social and economic factors are key drivers of inequality in the adaptive capacity across the region. Based on the assessment of impacts and adaptive capacity we suggest thresholds for water policy to respond to climate change and link water scarcity indicators to relevant potential adaptation strategies. Our results suggest the need to further prioritise socially and economically sensitive policies.}
}
@article{LI2024127497,
title = {Fully automated diagnosis of thyroid nodule ultrasound using brain-inspired inference},
journal = {Neurocomputing},
volume = {582},
pages = {127497},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127497},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224002686},
author = {Guanghui Li and Qinghua Huang and Chunying Liu and Guanying Wang and Lingli Guo and Ruonan Liu and Longzhong Liu},
keywords = {Brain-inspired inference, TI-RADS, Deep learning, Knowledge tensor, Thyroid ultrasound},
abstract = {The interpretability of artificial intelligence (AI) based medical diagnostic systems is crucial to make the diagnosis adequately convincible. Deep learning has been extensively investigated and utilized in the area of medical assistance diagnosis in recent decades due to its outstanding performance and objective prediction. However, a huge semantic chasm dividing clinicians and unexplainable deep models emerges. Here we design a brain-inspired inference framework from medical images to explainable features, then to the final diagnostic conclusions. The fast thinking module is responsible for recognizing medical features in ultrasound (US) images, and the slow-thinking module builds a model for inferring from medical features to diagnostic results by constructing a knowledge graph of medical features with tensor decomposition. The whole model infers through intuition and thinking like a human being, and gives the recognized medical image features while inferring the diagnosis, which greatly improves the interpretability of the model. We conducted studies on thyroid cancer diagnoses using US images. The American College of Radiology (ACR) Thyroid Imaging Reporting and Data System (TI-RADS) characteristics are employed as medical features describing thyroid nodules. Our brain-inspired medical inference framework outperforms commonly used deep learning algorithms, with an AUC score of 0.963 (95% confidential interval (CI)=0.923–1.000) for thyroid US image diagnosis. Results indicate that our framework improves diagnostic objectivity and interpretability while providing performance that is better than deep models. Our proposed brain-inspired medical inference framework could improve the efficiency of diagnosis and our technique is performant, objective and interpretable.}
}
@article{MELHAM2013129,
title = {Modelling, abstraction, and computation in systems biology: A view from computer science},
journal = {Progress in Biophysics and Molecular Biology},
volume = {111},
number = {2},
pages = {129-136},
year = {2013},
note = {Conceptual Foundations of Systems Biology},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2012.08.015},
url = {https://www.sciencedirect.com/science/article/pii/S0079610712000892},
author = {Tom Melham},
keywords = {Algorithmic biological modelling, Abstraction, Multi-scale modelling, Biological computation},
abstract = {Systems biology is centrally engaged with computational modelling across multiple scales and at many levels of abstraction. Formal modelling, precise and formalised abstraction relationships, and computation also lie at the heart of computer science—and over the past decade a growing number of computer scientists have been bringing their discipline's core intellectual and computational tools to bear on biology in fascinating new ways. This paper explores some of the apparent points of contact between the two fields, in the context of a multi-disciplinary discussion on conceptual foundations of systems biology.}
}
@article{HOLROYD2021316,
title = {The Best Laid Plans: Computational Principles of Anterior Cingulate Cortex},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {4},
pages = {316-329},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000103},
author = {Clay B. Holroyd and Tom Verguts},
keywords = {anterior cingulate cortex, computational models, artificial intelligence, hierarchical model-based hierarchical reinforcement learning, distributed representations, cognitive control},
abstract = {Despite continual debate for the past 30 years about the function of anterior cingulate cortex (ACC), its key contribution to neurocognition remains unknown. However, recent computational modeling work has provided insight into this question. Here we review computational models that illustrate three core principles of ACC function, related to hierarchy, world models, and cost. We also discuss four constraints on the neural implementation of these principles, related to modularity, binding, encoding, and learning and regulation. These observations suggest a role for ACC in hierarchical model-based hierarchical reinforcement learning (HMB-HRL), which instantiates a mechanism motivating the execution of high-level plans.}
}
@article{ELLIS2022581,
title = {Comparison of apnoeic oxygen techniques in term pregnant subjects: a computational modelling study},
journal = {British Journal of Anaesthesia},
volume = {129},
number = {4},
pages = {581-587},
year = {2022},
issn = {0007-0912},
doi = {https://doi.org/10.1016/j.bja.2022.06.021},
url = {https://www.sciencedirect.com/science/article/pii/S0007091222003221},
author = {Reena Ellis and Marianna Laviola and Daniel Stolady and Rebecca L. Valentine and Arani Pillai and Jonathan G. Hardman},
keywords = {apnoea, computer simulation, high-flow nasal oxygenation, low-flow nasal oxygenation, obesity in pregnancy, obstetrics},
abstract = {Background
Hypoxaemia during general anaesthesia can cause harm. Apnoeic oxygenation extends safe apnoea time, reducing risk during airway management. We hypothesised that low-flow nasal oxygenation (LFNO) would extend safe apnoea time similarly to high-flow nasal oxygenation (HFNO), whilst allowing face-mask preoxygenation and rescue.
Methods
A high-fidelity, computational, physiological model was used to examine the progression of hypoxaemia during apnoea in virtual models of pregnant women in and out of labour, with BMI of 24–50 kg m−2. Subjects were preoxygenated with oxygen 100% to reach end-tidal oxygen fraction (FE'O2) of 60%, 70%, 80%, or 90%. When apnoea started, HFNO or LFNO was commenced. To simulate varying degrees of effectiveness of LFNO, periglottic oxygen fraction (FgO2) of 21%, 60%, or 100% was configured. HFNO provided FgO2 100% and oscillating positive pharyngeal pressure.
Results
Application of LFNO (FgO2 100%) after optimal preoxygenation (FE'O2 90%) resulted in similar or longer safe apnoea times than HFNO FE'O2 80% in all subjects in labour. For BMI of 24, the time to reach SaO2 90% with LFNO was 25.4 min (FE'O2 90%/FgO2 100%) vs 25.4 min with HFNO (FE'O2 80%). For BMI of 50, the time was 9.9 min with LFNO (FE'O2 90%/FgO2 100%) vs 4.3 min with HFNO (FE'O2 80%). A similar finding was seen in subjects with BMI ≥40 kg m−2 not in labour.
Conclusions
There is likely to be clinical benefit to using LFNO, given that LFNO and HFNO extend safe apnoea time similarly, particularly when BMI ≥40 kg m−2. Additional benefits to LFNO include the facilitation of rescue face-mask ventilation and ability to monitor FE'O2 during preoxygenation.}
}
@article{MCANDREW2020300,
title = {Re-Thinking the Role of Statistics in Informing Heart Team Decisions: A Consensus Distribution Approach},
journal = {Structural Heart},
volume = {4},
number = {4},
pages = {300-301},
year = {2020},
issn = {2474-8706},
doi = {https://doi.org/10.1080/24748706.2020.1782550},
url = {https://www.sciencedirect.com/science/article/pii/S2474870622004997},
author = {Thomas McAndrew and Bjorn Redfors}
}
@article{SHAFIR1994403,
title = {Uncertainty and the difficulty of thinking through disjunctions},
journal = {Cognition},
volume = {50},
number = {1},
pages = {403-430},
year = {1994},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(94)90038-8},
url = {https://www.sciencedirect.com/science/article/pii/0010027794900388},
author = {Eldar Shafir},
abstract = {This paper considers the relationship between decision under uncertainty and thinking through disjunctions. Decision situations that lead to violations of Savage's sure-thing principle are examined, and a variety of simple reasoning problems that often generate confusion and error are reviewed. The common difficulty is attributed to people's reluctance to think through disjunctions. Instead of hypothetically traveling through the branches of a decision tree, it is suggested, people suspend judgement and remain at the node. This interpretation is applied to instances of decision making, information search, deductive and inductive reasoning, probabilistic judgement, games, puzzles and paradoxes. Some implications of the reluctance to think through disjunctions, as well as potential corrective procedures, are discussed.}
}
@article{VAEVER2005137,
title = {Thinking within the spectrum: schizophrenic thought disorder in six Danish pedigrees},
journal = {Schizophrenia Research},
volume = {72},
number = {2},
pages = {137-149},
year = {2005},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2004.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S092099640400132X},
author = {Mette S. Væver and Deborah M. Licht and Lise Møller and Dorthe Perlt and Åge Jørgensen and Peter Handest and Josef Parnas},
keywords = {Formal thought disorder, TDI, Schizophrenia spectrum, Pedigree},
abstract = {Formal thought disorder (FTD), a major symptom of schizophrenia, is known to aggregate in families. Our aim was to examine the specificity of FTD in the schizophrenia spectrum disorders and the hypothesized linear aggregation of FTD within pedigrees. Six individuals with a diagnosis of schizophrenia were identified in the Copenhagen High-Risk study and each pedigree was centered on one of the six original schizophrenic probands' nuclear families. The 329 pedigree members in the study were considered at risk for schizophrenia spectrum disorders because most were genetically related to the originating schizophrenic probands. The participants were administered the Copenhagen Interview of Functional Illness to determine diagnoses and the Thought Disorder Index (TDI) was used to assess FTD. Individuals with a schizophrenia diagnosis had higher global levels of FTD, exhibited more severe types of FTD, and had a qualitatively different type of FTD than did participants with other diagnoses or no mental illness. Individuals with Cluster A diagnoses exhibited more FTD and FTD similar in quality to participants with schizophrenia. These results support the construct of a spectrum of schizophrenia conditions. There was a generally high level of FTD in the pedigrees, in part due to assortative mating in this sample. However, there was no apparent pattern of linear aggregation of FTD within the families.}
}
@article{CAETANO2020287,
title = {Computational design in architecture: Defining parametric, generative, and algorithmic design},
journal = {Frontiers of Architectural Research},
volume = {9},
number = {2},
pages = {287-300},
year = {2020},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2019.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S2095263520300029},
author = {Inês Caetano and Luís Santos and António Leitão},
keywords = {Algorithmic design, Computer-aided design, Computational design, Generative design, Parametric design},
abstract = {Computation-based approaches in design have emerged in the last decades and rapidly became popular among architects and other designers. Design professionals and researchers adopted different terminologies to address these approaches. However, some terms are used ambiguously and inconsistently, and different terms are commonly used to express the same concept. This paper discusses computational design (CD) and proposes an improved and sound taxonomy for a set of key CD terms, namely, parametric, generative, and algorithmic design, based on an extensive literature review from which different definitions by various authors were collected, analyzed, and compared.}
}
@article{KUCUK2020100167,
title = {Students’ attitudes towards robotics and STEM: Differences based on gender and robotics experience},
journal = {International Journal of Child-Computer Interaction},
volume = {23-24},
pages = {100167},
year = {2020},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2020.100167},
url = {https://www.sciencedirect.com/science/article/pii/S2212868920300039},
author = {Sevda Kucuk and Burak Sisman},
keywords = {Secondary education, Gender studies, Educational robotics, STEM},
abstract = {In this study, Turkish secondary school students’ attitudes towards robotics and STEM were examined in terms of gender and robotics experience. Sample consisted of 240 secondary school students (98 females and 142 males; grades 5–7). Two scales were used to collect data: STEM Attitude Scale and Robotics Attitude Scale. The data were analyzed using a One-way MANOVA and through correlational methods. Results show that the students’ attitudes towards robotics and STEM were positive. Gender had no effect on STEM attitudes. However, in terms of robotics attitudes, female students had significantly less desire and less confidence to learn robotics than male students. There was no gender effect on computational thinking and teamwork. Implications were discussed in terms of theoretical insights, practices for educational robotics in STEM, and directions for further research.}
}
@article{BERNAL2015163,
title = {On the role of computational support for designers in action},
journal = {Design Studies},
volume = {41},
pages = {163-182},
year = {2015},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000551},
author = {Marcelo Bernal and John R. Haymaker and Charles Eastman},
keywords = {design knowledge, computer aided design, design automation, computer supported design, design technology},
abstract = {Designers' actions are high-level mechanisms based on heuristics and assumptions learned from professional experience. Significant research has been devoted to understanding these actions as well as finding ways to aid, automate, or augment them with computational support. However, representing and manipulating such tacit knowledge in computational environments remains an open area of research. In this paper, we map designers' actions and relationships to compare them with computational approaches for the generation, evaluation, and selection of design alternatives, and attempt to integrate all of the above. The analysis provides a more thorough understanding of the role of computational approaches in supporting designer actions and identifies challenges and areas of future research.}
}
@article{AIZAWA2010227,
title = {Computation in cognitive science: it is not all about Turing-equivalent computation},
journal = {Studies in History and Philosophy of Science Part A},
volume = {41},
number = {3},
pages = {227-236},
year = {2010},
note = {Computation and cognitive science},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2010.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0039368110000452},
author = {Kenneth Aizawa},
keywords = {Circular causality, Computation, Cortical maps, Neural networks, Symbol manipulation, Turing-equivalent computation},
abstract = {It is sometimes suggested that the history of computation in cognitive science is one in which the formal apparatus of Turing-equivalent computation, or effective computability, was exported from mathematical logic to ever wider areas of cognitive science and its environs. This paper, however, indicates some respects in which this suggestion is inaccurate. Computability theory has not been focused exclusively on Turing-equivalent computation. Many essential features of Turing-equivalent computation are not captured in definitions of computation as (digital) symbol manipulation. Turing-equivalent computation did not play the role in McCulloch and Pitts’s early cybernetic work that is sometimes attributed to it. Finally, various segments of the neuroscientific community invoke a notion of computation that differs from the Turing-equivalent notion.}
}
@article{JOSHI2018740,
title = {Are you thinking what I'm thinking? Synchronization of resting fMRI time-series across subjects},
journal = {NeuroImage},
volume = {172},
pages = {740-752},
year = {2018},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2018.01.058},
url = {https://www.sciencedirect.com/science/article/pii/S1053811918300582},
author = {Anand A. Joshi and Minqi Chong and Jian Li and Soyoung Choi and Richard M. Leahy},
abstract = {We describe BrainSync, an orthogonal transform that allows direct comparison of resting fMRI (rfMRI) time-series across subjects. For this purpose, we exploit the geometry of the rfMRI signal space to propose a novel orthogonal transformation that synchronizes rfMRI time-series across sessions and subjects. When synchronized, rfMRI signals become approximately equal at homologous locations across subjects. The method is based on the observation that rfMRI data exhibit similar connectivity patterns across subjects, as reflected in the pairwise correlations between different brain regions. We show that if the data for two subjects have similar correlation patterns then their time courses can be approximately synchronized by an orthogonal transformation. This transform is unique, invertible, efficient to compute, and preserves the connectivity structure of the original data for all subjects. Analogously to image registration, where we spatially align structural brain images, this temporal synchronization of brain signals across a population, or within-subject across sessions, facilitates cross-sectional and longitudinal studies of rfMRI data. The utility of the BrainSync transform is illustrated through demonstrative simulations and applications including quantification of rfMRI variability across subjects and sessions, cortical functional parcellation across a population, timing recovery in task fMRI data, comparison of task and resting state data, and an application to complex naturalistic stimuli for annotation prediction.}
}
@article{ALONSOSANCHEZ202397,
title = {Language network self-inhibition and semantic similarity in first-episode schizophrenia: A computational-linguistic and effective connectivity approach},
journal = {Schizophrenia Research},
volume = {259},
pages = {97-103},
year = {2023},
note = {Language and Speech Analysis in Schizophrenia and Related Psychoses},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2022.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920996422001608},
author = {María Francisca Alonso-Sánchez and Roberto Limongi and Joseph Gati and Lena Palaniyappan},
keywords = {Psychosis, Lexical access, fMRI, Spectral dynamic causal modelling, Broca's area, Disorganization, Formal thought disorder},
abstract = {Introduction
A central feature of schizophrenia is the disorganization and impoverishment of language. Recently, we observed higher semantic similarity in first-episode-schizophrenia (FES) patients. In this study, we investigate if this aberrant similarity relates to the ‘causal’ connectivity between two key nodes of the word production system: inferior frontal gyrus (IFG) and the semantic-hub at the ventral anterior temporal lobe (vATL).
Methods
Resting-state fMRI scans were collected from 60 participants (30 untreated FES and 30 healthy controls). The semantic distance was measured with the CoVec semantic tool based on GloVe. A spectral dynamic causal model with Parametrical Empirical Bayes was constructed modelling the intrinsic self-inhibitory and extrinsic-excitatory connections within the brain regions. We estimated the parameters of a fully connected model with the semantic distance as a covariate.
Results
FES patients chose words with higher semantic similarity when describing the pictures compared to the HC group. Among patients, an increased semantic similarity was related with an increase in intrinsic connections within both the vATL and IFG, suggesting that reduced ‘synaptic gain’ in these regions likely contribute to aberrant sampling of the semantic space during discourse in schizophrenia.
Conclusions
Lexical impoverishment relates to increased self-inhibition in both the IFG and vATL. The associated reduction in synaptic gain may relate to reduced precision of locally generated neural activity, forcing the choice of words that are already ‘activated’ in a lexical network. One approach to improve word sampling may be via promoting synaptic gain via supra-physiological stimulation within the Broca's-vATL network; this proposal needs verification.}
}
@article{BOOKER2004331,
title = {Solving black box computation problems using expert knowledge theory and methods},
journal = {Reliability Engineering & System Safety},
volume = {85},
number = {1},
pages = {331-340},
year = {2004},
note = {Alternative Representations of Epistemic Uncertainty},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2004.03.021},
url = {https://www.sciencedirect.com/science/article/pii/S0951832004000705},
author = {Jane M Booker and Laura A McNamara},
keywords = {Expert judgment, Elicitation, Probability theory, Epistemic uncertainty},
abstract = {The challenge problems for the Epistemic Uncertainty Workshop at Sandia National Laboratories provide common ground for comparing different mathematical theories of uncertainty, referred to as General Information Theories (GITs). These problems also present the opportunity to discuss the use of expert knowledge as an important constituent of uncertainty quantification. More specifically, how do the principles and methods of eliciting and analyzing expert knowledge apply to these problems and similar ones encountered in complex technical problem solving and decision making? We will address this question, demonstrating how the elicitation issues and the knowledge that experts provide can be used to assess the uncertainty in outputs that emerge from a black box model or computational code represented by the challenge problems. In our experience, the rich collection of GITs provides an opportunity to capture the experts' knowledge and associated uncertainties consistent with their thinking, problem solving, and problem representation. The elicitation process is rightly treated as part of an overall analytical approach, and the information elicited is not simply a source of data. In this paper, we detail how the elicitation process itself impacts the analyst's ability to represent, aggregate, and propagate uncertainty, as well as how to interpret uncertainties in outputs. While this approach does not advocate a specific GIT, answers under uncertainty do result from the elicitation.}
}
@incollection{SCHLESINGER2020337,
title = {Computational Models of Development},
editor = {Janette B. Benson},
booktitle = {Encyclopedia of Infant and Early Childhood Development (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {337-346},
year = {2020},
isbn = {978-0-12-816511-9},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23615-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245236158},
author = {Matthew Schlesinger},
keywords = {Computational model, Connectionist model, Artificial neural network, Learning algorithm, Symbolic versus sub-symbolic representations, Adaptive versus static, Learning mechanism, Rule-based model, Dynamic field theory model, Bayesian model, Developmental pattern},
abstract = {Conventional research methods for investigating development are powerful and diverse, but they also have their limits. Many of these limitations can be overcome or addressed through computer modeling. To help make this argument, the current chapter provides a broad, accessible overview to the study of computational models of learning and development. First, we explore the technical vocabulary of computational modeling research by reviewing a set of basic concepts, including the different kinds of representations that are employed by computational models, as well as the array of learning algorithms that are typically used. Next, we review four major types of models: connectionist models, dynamic field theory models, rule-based models, and Bayesian models. In the final section, we put these concepts and approaches into practice by surveying findings from models that simulate the development of object knowledge, language learning, and motor-skill acquisition.}
}
@article{WOLFENGAGEN2016306,
title = {Computational Model of the Tangled Web},
journal = {Procedia Computer Science},
volume = {88},
pages = {306-311},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.440},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916316969},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey Kosikov},
keywords = {event-driven computations, scripts, vulnerability, information security, computational model, tangled web},
abstract = {In this paper we attempt to build computational models of entanglement among the event-driven computations. The proposed model operates on the notion of dynamics of the events. This allows selection of entanglement zone that characterizes the area of risks where possible vulnerability and, as a consequence, security violations of web application arise. All constructions for objects are treated as virtual objects. The stated range of issues focuses on computational technologies used scripts, though other explanatory systems are admissible as well but within other appropriate contexts.}
}
@incollection{COUCLELIS2020357,
title = {Computational Human Geography},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {357-363},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10619-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955106195},
author = {Helen Couclelis},
keywords = {Agent-based models, Ambient computing, Cellular automata, Computer modeling, Data revolution, GIS, Geocomputation, Simulation, Urban informatics, Visualization},
abstract = {Computational human geography refers to the use of computational methods and techniques to solve problems in human geography research and applications. The approach goes back to the beginnings of the quantitative revolution in geography and is philosophically related though methodologically distinct from it. Geographic information systems (GIS) and science are a big part of computational human geography, but the latter notion is considerably broader, encompassing spatial process modeling and simulation, the modeling of spatial decision and behavior, visualization techniques, spatial analysis, and an increasing number of new research areas and methods enabled by the most recent technological developments. The latter are discussed under the rubrics of The Data Revolution, Urban (Spatial) Informatics, and Ambient Computing. Two major thrusts have persisted throughout the years: the use of numerical techniques to solve large, complex quantitative problems; the development of models of complex spatial processes expressed directly in computational terms. Both have evolved with the times and continue to be central to computational human geography. Critiques originate from both within the field and from the humanities and social theory perspectives. These address epistemological and methodological problems as well as issues of ontology and representation.}
}
@article{ROLLWAGE2019820,
title = {What Underlies Political Polarization? A Manifesto for Computational Political Psychology},
journal = {Trends in Cognitive Sciences},
volume = {23},
number = {10},
pages = {820-822},
year = {2019},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2019.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S1364661319301810},
author = {Max Rollwage and Leor Zmigrod and Lee de-Wit and Raymond J. Dolan and Stephen M. Fleming},
keywords = {political psychology, computational modeling, cognitive styles, behavioral tasks, radicalism, polarization},
abstract = {Polarization is one of the biggest societal challenges of our time, yet its drivers are poorly understood. Here we propose a novel approach – computational political psychology – which uses behavioral tasks in combination with formal computational models to identify candidate cognitive processes underpinning susceptibility to polarized beliefs about political and societal issues.}
}
@incollection{MALEY2016271,
title = {Chapter 20 - Closed Loops in Neuroscience and Computation: What It Means and Why It Matters},
editor = {Ahmed {El Hady}},
booktitle = {Closed Loop Neuroscience},
publisher = {Academic Press},
address = {San Diego},
pages = {271-277},
year = {2016},
isbn = {978-0-12-802452-2},
doi = {https://doi.org/10.1016/B978-0-12-802452-2.00020-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128024522000202},
author = {C.J. Maley and G. Piccinini},
keywords = {Closed-loop neuroscience, Feedback, Neural computation, Digital computation, Finite-state automata, Turing machine, Persistent Turing machine},
abstract = {We compare the computational power of different classes of computational systems and relate it to whether they contain closed loops. Adding closed loops to the architecture of computational systems increases their computational power. Different computational models are apt for capturing the computational power of different classes of neural systems. We argue that while ordinary Turing machines (TMs) are a poor model for a kind of feedback that the closed-loop approach to neuroscience highlights, suitably modified TMs are a better fit.}
}
@incollection{JUNG2023198,
title = {Design-based education in STEM: for learners of the 21st century},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {198-206},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.13077-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305130775},
author = {Yong Ju Jung and Gi Woong Choi and Soo Hyeon Kim},
keywords = {Design-based education, Design thinking, Digital media creation, Engineering design, Makerspaces, STEM+C education, STEM education, 21st century learning},
abstract = {This article aims to conceptualize design-based education (DBE) in STEM educational settings and provide examples of current DBE practices followed by discussing the gaps of current DBE. We define DBE as educational theory and practice that integrate and transform design processes and design thinking into learning experiences. DBE is well-aligned with the 21st century STEM education because it can enhance learner-centered pedagogy, learners' critical thinking, collaboration, interest-driven learning, and integrative STEM learning. More attention to concrete strategies for the integrative STEM education in DBE and systems of preparing educators for DBE is needed for better learning experiences.}
}
@article{DRUKARCH2018172,
title = {Thinking about the nerve impulse: A critical analysis of the electricity-centered conception of nerve excitability},
journal = {Progress in Neurobiology},
volume = {169},
pages = {172-185},
year = {2018},
issn = {0301-0082},
doi = {https://doi.org/10.1016/j.pneurobio.2018.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0301008218300509},
author = {Benjamin Drukarch and Hanna A. Holland and Martin Velichkov and Jeroen J.G. Geurts and Pieter Voorn and Gerrit Glas and Henk W. {de Regt}},
keywords = {Nerve impulse, Action potential, Electromechanical pulse, Signal propagation, Hodgkin-Huxley model, Neuroscientific models},
abstract = {Nerve impulse generation and propagation are often thought of as solely electrical events. The prevalence of this view is the result of long and intense study of nerve impulses in electrophysiology culminating in the introduction of the Hodgkin-Huxley model of the action potential in the 1950s. To this day, this model forms the physiological foundation for a broad area of neuroscientific research. However, the Hodgkin-Huxley model cannot account for non-electrical phenomena that accompany nerve impulse propagation, for which there is nevertheless ample evidence. This raises the question whether the Hodgkin-Huxley model is a complete model of the nerve impulse. Several alternative models have been proposed that do take into account non-electrical aspects of the nerve impulse and emphasize their importance in gaining a more complete understanding of the nature of the nerve impulse. In our opinion, these models deserve more attention in neuroscientific research, since, together with the Hodgkin-Huxley model, they will help in addressing and solving a number of questions in basic and applied neuroscience which thus far have remained outside our grasp. Here we provide a historico-scientific overview of the developments that have led to the current conception of the action potential as an electrical phenomenon, discuss some major objections against this conception, and suggest a number of scientific factors which have likely contributed to the enduring success of the Hodgkin-Huxley model and should be taken into consideration whilst contemplating the formulation of a more extensive and complete conception of the nerve impulse.}
}
@article{CHUNG200896,
title = {Revealing dimensions of thinking in open-ended self-descriptions: An automated meaning extraction method for natural language},
journal = {Journal of Research in Personality},
volume = {42},
number = {1},
pages = {96-132},
year = {2008},
issn = {0092-6566},
doi = {https://doi.org/10.1016/j.jrp.2007.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0092656607000451},
author = {Cindy K. Chung and James W. Pennebaker},
keywords = {LIWC, Meaning extraction method, Natural language, Self-descriptions},
abstract = {A new method for extracting common themes from written text is introduced and applied to 1165 open-ended self-descriptive narratives. Drawing on a lexical approach to personality, the most commonly-used adjectives within narratives written by college students were identified using computerized text analytic tools. A factor analysis on the use of these adjectives in the self-descriptions produced a 7-factor solution consisting of psychologically meaningful dimensions. Some dimensions were unipolar (e.g., Negativity factor, wherein most loaded items were negatively valenced adjectives); others were dimensional in that semantically opposite words clustered together (e.g., Sociability factor, wherein terms such as shy, outgoing, reserved, and loud all loaded in the same direction). The factors exhibited modest reliability across different types of writing samples and were correlated with self-reports and behaviors consistent with the dimensions. Similar analyses with additional content words (adjectives, adverbs, nouns, and verbs) yielded additional psychological dimensions associated with physical appearance, school, relationships, etc. in which people contextualize their self-concepts. The results suggest that the meaning extraction method is a promising strategy that determines the dimensions along which people think about themselves.}
}
@article{AUGELLO201674,
title = {Artwork creation by a cognitive architecture integrating computational creativity and dual process approaches},
journal = {Biologically Inspired Cognitive Architectures},
volume = {15},
pages = {74-86},
year = {2016},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2015.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X1500050X},
author = {Agnese Augello and Ignazio Infantino and Antonio Lieto and Giovanni Pilato and Riccardo Rizzo and Filippo Vella},
keywords = {Computational creativity, Cognitive architecture, Dual process theory, PSI model},
abstract = {The paper proposes a novel cognitive architecture (CA) for computational creativity based on the Psi model and on the mechanisms inspired by dual process theories of reasoning and rationality. In recent years, many cognitive models have focused on dual process theories to better describe and implement complex cognitive skills in artificial agents, but creativity has been approached only at a descriptive level. In previous works we have described various modules of the cognitive architecture that allows a robot to execute creative paintings. By means of dual process theories we refine some relevant mechanisms to obtain artworks, and in particular we explain details about resolution level of the CA dealing with different strategies of access to the Long Term Memory (LTM) and managing the interaction between S1 and S2 processes of the dual process theory. The creative process involves both divergent and convergent processes in either implicit or explicit manner. This leads to four activities (exploratory, reflective, tacit, and analytic) that, triggered by urges and motivations, generate creative acts. These creative acts exploit both the LTM and the WM in order to make novel substitutions to a perceived image by properly mixing parts of pictures coming from different domains. The paper highlights the role of the interaction between S1 and S2 processes, modulated by the resolution level which focuses the attention of the creative agent by broadening or narrowing the exploration of novel solutions, or even drawing the solution from a set of already made associations. An example of artificial painter is described in some experimentations by using a robotic platform.}
}
@article{BACELARALMEIDA2022100736,
title = {A formal treatment of the role of verified compilers in secure computation},
journal = {Journal of Logical and Algebraic Methods in Programming},
volume = {125},
pages = {100736},
year = {2022},
issn = {2352-2208},
doi = {https://doi.org/10.1016/j.jlamp.2021.100736},
url = {https://www.sciencedirect.com/science/article/pii/S2352220821000997},
author = {José Carlos {Bacelar Almeida} and Manuel Barbosa and Gilles Barthe and Hugo Pacheco and Vitor Pereira and Bernardo Portela},
keywords = {Secure multiparty computation, Secure compilation, Certified compilation, Formal verification, EasyCrypt, Computer-aided cryptography},
abstract = {Secure multiparty computation (SMC) allows for complex computations over encrypted data. Privacy concerns for cloud applications makes this a highly desired technology and recent performance improvements show that it is practical. To make SMC accessible to non-experts and empower its use in varied applications, many domain-specific compilers are being proposed. We review the role of these compilers and provide a formal treatment of the core steps that they perform to bridge the abstraction gap between high-level ideal specifications and efficient SMC protocols. Our abstract framework bridges this secure compilation problem across two dimensions: 1) language-based source- to target-level semantic and efficiency gaps, and 2) cryptographic ideal- to real-world security gaps. We link the former to the setting of certified compilation, paving the way to leverage long-run efforts such as CompCert in future SMC compilers. Security is framed in the standard cryptographic sense. Our results are supported by a machine-checked formalisation carried out in EasyCrypt.}
}
@article{LANDAU2024101463,
title = {Young children’s copying of block constructions: Significant constraints in a highly complex task},
journal = {Cognitive Development},
volume = {71},
pages = {101463},
year = {2024},
issn = {0885-2014},
doi = {https://doi.org/10.1016/j.cogdev.2024.101463},
url = {https://www.sciencedirect.com/science/article/pii/S0885201424000480},
author = {Barbara Landau and E. Emory Davis and Cathryn S. Cortesa and Zihan Wang and Jonathan D. Jones and Amy L. Shelton},
keywords = {Skilled action, Spatial skills, Spatial cognition, Development, Block construction, Intuitive physics},
abstract = {Block construction is ubiquitous in early development, yet is surprisingly complex, involving step-by-step sequenced actions to create specific structures. Here, we use novel analytic methods to characterize these action sequences in detail, including which individual parts of the structure (‘states’) are built and how these structures are combined, creating a fully specified build path towards the final structure. We find that, like adults tested in a previous study, 4- to 8-year-olds build by creating a small subset of possible individual states and full build paths, and that they prioritize building layer-by-layer. The individual states and build paths that children produce are strikingly similar to those of adults, resulting in structures that are more stable than other possible (but not attested) states and paths. Our approach serves as a lens into the cognitive processes underlying block building and suggests that children’s building is guided by significant cognitive constraints consistent with “computational thinking”.}
}
@article{CHRISTOU2001321,
title = {Mapping and development of intuitive proportional thinking},
journal = {The Journal of Mathematical Behavior},
volume = {20},
number = {3},
pages = {321-336},
year = {2001},
issn = {0732-3123},
doi = {https://doi.org/10.1016/S0732-3123(02)00077-9},
url = {https://www.sciencedirect.com/science/article/pii/S0732312302000779},
author = {Constantinos Christou and George Philippou},
keywords = {Multiplicative problems, Conceptual field, Cardinalities},
abstract = {The purpose of this study was two-fold. First, to find out students’ informal understanding of proportional problems, and discuss their solution strategies. Second, to investigate how the intuitions developed by students influence their strategies to solve proportional problems. To this end, we interviewed 16 students in Grades 4 and 5, while they were solving proportional problems. It was found that students intuitively used the unit-rate strategy indicating an attempt to transfer the knowledge resulted by their experience with solving simple multiplicative problems. Fourth and fifth graders tended to shift from the unit-rate strategy to other strategies if there was no easy way to calculate the unit-value directly from the context of the problems. Since fifth graders were more comfortable than fourth graders in calculating the unit-value, they felt less the need to invent other solution strategies.}
}
@article{DUNNE2013387,
title = {Insights from the application of computational neuroimaging to social neuroscience},
journal = {Current Opinion in Neurobiology},
volume = {23},
number = {3},
pages = {387-392},
year = {2013},
note = {Social and emotional neuroscience},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2013.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S095943881300055X},
author = {Simon Dunne and John P O’Doherty},
abstract = {A recent approach in social neuroscience has been the application of formal computational models for a particular social-cognitive process to neuroimaging data. Here we review preliminary findings from this nascent subfield, focusing on observational learning and strategic interactions. We present evidence consistent with the existence of three distinct learning systems that may contribute to social cognition: an observational-reward-learning system involved in updating expectations of future reward based on observing rewards obtained by others, an action-observational learning system involved in learning about the action tendencies of others, and a third system engaged when it is necessary to learn about the hidden mental-states or traits of another. These three systems appear to map onto distinct neuroanatomical substrates, and depend on unique computational signals.}
}
@article{VUQUOC20231069,
title = {Deep Learning Applied to Computational Mechanics: A Comprehensive Review, State of the Art, and the Classics},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {137},
number = {2},
pages = {1069-1343},
year = {2023},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2023.028130},
url = {https://www.sciencedirect.com/science/article/pii/S1526149223002412},
author = {Loc Vu-Quoc and Alexander Humer},
keywords = {, breakthroughs, network architectures, backpropagation, stochastic optimization methods from classic to modern, recurrent neural networks, long short-term memory, gated recurrent unit, attention, transformer, kernel machines, Gaussian processes, libraries, Physics-Informed Neural Networks, state-of-the-art, history, limitations, challenges, , Finite-element matrix integration, improved Gauss quadrature, Multiscale geomechanics, fluid-filled porous media, Fluid mechanics, turbulence, proper orthogonal decomposition, , autoencoder, hyper-reduction using gappy data, control of large deformable beam},
abstract = {Three recent breakthroughs due to AI in arts and science serve as motivation: An award winning digital image, protein folding, fast matrix multiplication. Many recent developments in artificial neural networks, particularly deep learning (DL), applied and relevant to computational mechanics (solid, fluids, finite-element technology) are reviewed in detail. Both hybrid and pure machine learning (ML) methods are discussed. Hybrid methods combine traditional PDE discretizations with ML methods either (1) to help model complex nonlinear constitutive relations, (2) to nonlinearly reduce the model order for efficient simulation (turbulence), or (3) to accelerate the simulation by predicting certain components in the traditional integration methods. Here, methods (1) and (2) relied on Long-Short-Term Memory (LSTM) architecture, with method (3) relying on convolutional neural networks. Pure ML methods to solve (nonlinear) PDEs are represented by Physics-Informed Neural network (PINN) methods, which could be combined with attention mechanism to address discontinuous solutions. Both LSTM and attention architectures, together with modern and generalized classic optimizers to include stochasticity for DL networks, are extensively reviewed. Kernel machines, including Gaussian processes, are provided to sufficient depth for more advanced works such as shallow networks with infinite width. Not only addressing experts, readers are assumed familiar with computational mechanics, but not with DL, whose concepts and applications are built up from the basics, aiming at bringing first-time learners quickly to the forefront of research. History and limitations of AI are recounted and discussed, with particular attention at pointing out misstatements or misconceptions of the classics, even in well-known references. Positioning and pointing control of a large-deformable beam is given as an example.}
}
@article{STUPURIENE2024104939,
title = {Teachers’ perceptions of the barriers and drivers for the integration of Informatics in primary education},
journal = {Computers & Education},
volume = {208},
pages = {104939},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2023.104939},
url = {https://www.sciencedirect.com/science/article/pii/S0360131523002166},
author = {Gabrielė Stupurienė and Margarida Lucas and Pedro Bem-Haja},
keywords = {Primary education, Teacher professional development, Thematic analysis, Network analysis, Informatics education},
abstract = {A growing trend of integrating and teaching Informatics and Computational Thinking (CT) skills at primary education levels poses different challenges for teachers. Research demonstrates that it is challenging to introduce Informatics in schools without well-prepared teachers. In this paper, we examine Lithuanian teachers' perceptions of the barriers and drivers to integrate the renewed Informatics curricula in primary education and the relation between them. Fifteen semi-structured interviews were conducted with primary school teachers, and a mixed-methods approach was employed to analyze them. The results show that explicit guidelines for renewed curricula and motivation to learn Informatics are both identified as the main barriers and drivers for integrating Informatics. The study further highlights the critical role of resources, appropriate tools, and guidelines in facilitating the successful implementation of Informatics. The study provides knowledge that could, for instance, benefit teacher training programmes and help better understand how teachers can be better supported to meet current and future challenges.}
}
@article{ARBELAEZOSSA2023102458,
title = {A smarter perspective: Learning with and from AI-cases},
journal = {Artificial Intelligence in Medicine},
volume = {135},
pages = {102458},
year = {2023},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2022.102458},
url = {https://www.sciencedirect.com/science/article/pii/S093336572200210X},
author = {Laura {Arbelaez Ossa} and Michael Rost and Giorgia Lorenzini and David M. Shaw and Bernice Simone Elger},
keywords = {Medical education, Artificial intelligence, Case-based learning, Critical thinking, Ethics},
abstract = {Artificial intelligence (AI) has only partially (or not at all) been integrated into medical education, leading to growing concerns regarding how to train healthcare practitioners to handle the changes brought about by the introduction of AI. Programming lessons and other technical information into healthcare curricula has been proposed as a solution to support healthcare personnel in using AI or other future technology. However, integrating these core elements of computer science knowledge might not meet the observed need that students will benefit from gaining practical experience with AI in the direct application area. Therefore, this paper proposes a dynamic approach to case-based learning that utilizes the scenarios where AI is currently used in clinical practice as examples. This approach will support students' understanding of technical aspects. Case-based learning with AI as an example provides additional benefits: (1) it allows doctors to compare their thought processes to the AI suggestions and critically reflect on the assumptions and biases of AI and clinical practice; (2) it incentivizes doctors to discuss and address ethical issues inherent to technology and those already existing in current clinical practice; (3) it serves as a foundation for fostering interdisciplinary collaboration via discussion of different views between technologists, multidisciplinary experts, and healthcare professionals. The proposed knowledge shift from AI as a technical focus to AI as an example for case-based learning aims to encourage a different perspective on educational needs. Technical education does not need to compete with other essential clinical skills as it could serve as a basis for supporting them, which leads to better medical education and practice, ultimately benefiting patients.}
}
@article{SPREVAK2010260,
title = {Computation, individuation, and the received view on representation},
journal = {Studies in History and Philosophy of Science Part A},
volume = {41},
number = {3},
pages = {260-270},
year = {2010},
note = {Computation and cognitive science},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2010.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0039368110000403},
author = {Mark Sprevak},
keywords = {Computation, Representation, Computational identity, Explanation, Narrow content, Physical computation},
abstract = {The ‘received view’ about computation is that all computations must involve representational content. Egan and Piccinini argue against the received view. In this paper, I focus on Egan’s arguments, claiming that they fall short of establishing that computations do not involve representational content. I provide positive arguments explaining why computation has to involve representational content, and how that representational content may be of any type (distal, broad, etc.). I also argue (contra Egan and Fodor) that there is no need for computational psychology to be individualistic. Finally, I draw out a number of consequences for computational individuation, proposing necessary conditions on computational identity and necessary and sufficient conditions on computational I/O equivalence of physical systems.}
}
@incollection{SHARMA2020123,
title = {Chapter 6 - Application of hybrid computational intelligence in health care},
editor = {Siddhartha Bhattacharyya and Václav Snášel and Deepak Gupta and Ashish Khanna},
booktitle = {Hybrid Computational Intelligence},
publisher = {Academic Press},
pages = {123-148},
year = {2020},
series = {Hybrid Computational Intelligence for Pattern Analysis and Understanding},
isbn = {978-0-12-818699-2},
doi = {https://doi.org/10.1016/B978-0-12-818699-2.00007-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012818699200007X},
author = {Moolchand Sharma and Suyash Agrawal and Suman Deswal},
keywords = {Computational intelligence, hybrid computational intelligence, healthcare systems, neural networks, genetic algorithms},
abstract = {The use of hybrid computational intelligence is currently broadening in the field of healthcare applications and research. Computational intelligence has played a vital role in health care for a significant period of time, but with the increased popularity and extensive use of these hybrid computational intelligent systems, a shift has been seen also in the field of health care. Hybrid computational intelligence can be implied in the field of decision making, remote monitoring, healthcare logistics, and modern information systems. Hybrid computational intelligence synergizes different computational intelligence techniques, such as the neural network, the fuzzy logic, the genetic algorithms, the evolutionary computation and the support vector machines, and have their application in the field of pattern recognition, system modeling, etc. In this chapter, we focus on the need for healthcare information technology, improvement of healthcare delivery systems, healthcare safety issues, and also various areas where it can be used.}
}
@article{WOLFRAM2020101132,
title = {What We’ve built Is a computational language (and that’s very important!)},
journal = {Journal of Computational Science},
volume = {46},
pages = {101132},
year = {2020},
note = {20 years of computational science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101132},
url = {https://www.sciencedirect.com/science/article/pii/S1877750320304336},
author = {Stephen Wolfram}
}
@article{DINOV2008284,
title = {Pedagogical utilization and assessment of the statistic online computational resource in introductory probability and statistics courses},
journal = {Computers & Education},
volume = {50},
number = {1},
pages = {284-300},
year = {2008},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2006.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0360131506001059},
author = {Ivo D. Dinov and Juana Sanchez and Nicolas Christou},
keywords = {Education research, Teaching with technology, Java applets, Online course materials, Probability and statistics},
abstract = {Technology-based instruction represents a new recent pedagogical paradigm that is rooted in the realization that new generations are much more comfortable with, and excited about, new technologies. The rapid technological advancement over the past decade has fueled an enormous demand for the integration of modern networking, informational and computational tools with classical pedagogical instruments. Consequently, teaching with technology typically involves utilizing a variety of IT and multimedia resources for online learning, course management, electronic course materials, and novel tools of communication, engagement, experimental, critical thinking, and assessment. The NSF-funded Statistics Online Computational Resource (SOCR) provides a number of interactive tools for enhancing instruction in various undergraduate and graduate courses in probability and statistics. These resources include online instructional materials, statistical calculators, interactive graphical user interfaces, computational and simulation applets, tools for data analysis and visualization. The tools provided as part of SOCR include conceptual simulations and statistical computing interfaces, which are designed to bridge between the introductory and the more advanced computational and applied probability and statistics courses. In this manuscript, we describe our designs for utilizing SOCR technology in instruction in a recent study. In addition, present the results of the effectiveness of using SOCR tools at two different course intensity levels on three outcome measures: exam scores, student satisfaction and choice of technology to complete assignments. Learning styles assessment was completed at baseline. We have used three very different designs for three different undergraduate classes. Each course included a treatment group, using the SOCR resources, and a control group, using classical instruction techniques. Our findings include marginal effects of the SOCR treatment per individual classes; however, pooling the results across all courses and sections, SOCR effects on the treatment groups were exceptionally robust and significant. Coupling these findings with a clear decrease in the variance of the quantitative examination measures in the treatment groups indicates that employing technology, like SOCR, in a sound pedagogical and scientific manner enhances overall the students’ understanding and suggests better long-term knowledge retention.}
}
@article{PATON199363,
title = {Some computational models at the cellular level},
journal = {Biosystems},
volume = {29},
number = {2},
pages = {63-75},
year = {1993},
issn = {0303-2647},
doi = {https://doi.org/10.1016/0303-2647(93)90084-P},
url = {https://www.sciencedirect.com/science/article/pii/030326479390084P},
author = {Ray C. Paton},
keywords = {Computational models of the cell, Levels of organisation, Systemic metaphors},
abstract = {A number of viewpoints on how a cell can be modelled are discussed in this paper in light of the ability it has to process information. The paper begins with a very brief summary of four general types of computation: sequential, parallel, distributed, and emergent. These form the general framework from which a number of comparisons are made. Several metaphors are introduced to enable reflections to be made about cellular computational properties. The most important metaphor, namely the cell as a machine, is discussed, and then a number of other ideas are introduced that complement much current thinking in this area. The idea of networks or circuits in the cell is then developed, as this provides a means of describing the mechanisms within a machine. Following on from this, three further metaphors are applied in order to overcome certain limitations in current machine thinking, cell-as-society, cell-as-text, and cell-as-field.}
}
@incollection{SNYDER2011467,
title = {The Complex Dyanmics of the Climate System: Constraints on our Knowledge, Policy Implications and the Necessity of Systems Thinking},
editor = {Cliff Hooker},
booktitle = {Philosophy of Complex Systems},
publisher = {North-Holland},
address = {Amsterdam},
pages = {467-505},
year = {2011},
volume = {10},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-52076-0.50017-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780444520760500171},
author = {Carolyn W. Snyder and Michael D. Mastrandrea and Stephen H. Schneider},
abstract = {Publisher Summary
This chapter describes the contribution of complexity science to understanding of the climate system and the unique challenges its complex properties pose to climate predictions and policy analysis. First, it presents a brief exploration of the Earth's climate system through the lens of complexity science. Then, it introduces the data sources and modeling strategies that climate science uses to understand past behavior, to fingerprint causes of current climate changes, and to project future climate. The complex dynamics of the climate system constrain ability to gain knowledge about the climate system and add uncertainty to predictions of the impacts of human-induced climate change. It also investigates six case studies that illustrate the importance and development of key complexity themes in climate science: glacial-interglacial cycles, thermohaline ocean circulation, ice sheets, vegetation cover changes, extinction, and overshoot scenarios. In addition, it investigates the implications of the complexity of the Earth system for climate policy analysis. Assessments of the impacts of climate change are often disciplinary-based and not sufficiently integrative across important disciplinary subcomponents, producing misleading results that have potentially dangerous environmental consequences. The current framework of cost-benefit optimization is particularly flawed. Further, it describes how one should restructure climate policy analysis as an integrated assessment process, combining data and relationships from the physical, biological and social sciences, that includes robust assessments of potential risks within a vulnerability framework.}
}
@article{ZELENY1992563,
title = {An essay into a philosophy of MCDM: A way of thinking or another algorithm?},
journal = {Computers & Operations Research},
volume = {19},
number = {7},
pages = {563-566},
year = {1992},
note = {Implementing Multiobjective Optimization Methods: Behavioral and Computational Issues},
issn = {0305-0548},
doi = {https://doi.org/10.1016/0305-0548(92)90027-3},
url = {https://www.sciencedirect.com/science/article/pii/0305054892900273},
author = {Milan Zeleny},
abstract = {We have become accustomed to viewing MCDM as another OR/MS algorithm, characterized by a mere shift from k = 1 to k = n with respect to number k of objective functions or criteria. MCDM research and applications has therefore neglected the search for organizational embedding of MCDM: what types of organizations and under what conditions have the propensity to operate under multiple and which under single criteria? Organizations which derive their structure, strategy and motivation from the singleness of purpose will not and can not be conducive to the notions of multiple critera, no matter how skillfully or forcefully presented, or mathematically complete and computationally user-friendly. The organization, its structure and motivational culture have to change first. In short, traditional hierarchy of command, based on extreme specialization and little autonomy of employees and their departments will not be as open to the multiplicity of criteria as the self-managing teams of non-hierarchical companies which integrate task, labor and knowledge and which are only now starting to dominate certain business and management cultures.}
}
@article{HASSANNEZHAD2022116338,
title = {Virtual Net Propagator: A cloud-based computational tool for systemic decision propagation analysis},
journal = {Expert Systems with Applications},
volume = {191},
pages = {116338},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.116338},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421016365},
author = {Mohammad Hassannezhad and Behzad Farahany and Fatemeh Barzegar},
keywords = {Change propagation, Complex networks, Computational intelligence, Systems design and analysis, Socio-technical systems, Web-based decision support system},
abstract = {Today’s organizations are witnessing a growing complexity in making interconnected decisions. Where individuals have a wider range of decisions to influence, the consequence of decisions far more propagate across the system, and the business environment continually influences the status of the system. Predicting the cascading effects of decisions in such situations would be very problematic yet can have several implications for managers and executives to think beyond organizational silos and make local decision with a bigger picture of emergent consequences in mind. A prominent challenge within this realm is the ever-increasing complexity of decision propagations, especially when incorporating the role and influence of people involved in decision-making. This paper tackles this challenge from an engineering change perspective, with the focus on computing the compound risk of decisions when their consequences concurrently propagate across the system. We introduce an interactive tool called Virtual Net Propagator, which incorporates organizational dynamics into decision analysis, with the aim to identify change opportunities and effective set of interventions. Illustrated by a field engineering case study, it is demonstrated that the proposed tool can provide detailed knowledge on how decisions are interconnected and how systemic (cascading) effects of a decision propagate through causal pathways, so highlighting key influencers along with role and influence of interfacing (hidden) players.}
}
@article{MARUYAMA20181037,
title = {Investigation into Parents’ Concerns about the Introduction of Programming Education into Japanese Primary School},
journal = {Procedia Computer Science},
volume = {126},
pages = {1037-1045},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.08.040},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918313188},
author = {Yukiko Maruyama},
keywords = {Programming education, primary school, parents’ concerns, computing thinking},
abstract = {The introduction of computational thinking into primary/secondary or K-12 education has been widely attempted. In Japan, programming education will be introduced into primary school in 2020. The role of parents in primary education is highly important, and their attitude towards education has a considerable influence on children’s attitudes. To investigate parents’ concerns regarding programming education in primary school, a preliminary questionnaire survey has been conducted as a first step of the study.}
}
@article{FLETCHER2023100061,
title = {Narrative creativity training: A new method for increasing resilience in elementary students},
journal = {Journal of Creativity},
volume = {33},
number = {3},
pages = {100061},
year = {2023},
issn = {2713-3745},
doi = {https://doi.org/10.1016/j.yjoc.2023.100061},
url = {https://www.sciencedirect.com/science/article/pii/S2713374523000201},
author = {Angus Fletcher and Patricia Enciso and Mike Benveniste},
keywords = {Narrative, Creativity, Education, Resilience, Self-efficacy, Counterfactual thinking},
abstract = {Narrative creativity training has recently shown promise as a tool for increasing self-efficacy and resilience in adult learners. The training employs dramatic and literary techniques such as perspective-shifting, counterfactual (i.e., what-if) thinking, and causal (i.e., why) thinking to improve real-world problem solving. To explore whether narrative creativity training could have similar benefits for younger populations, this study piloted a test on elementary students. A five-minute randomized controlled trial conducted with 32 third, fourth, and fifth grade students yielded increased self-efficacy and creative problem-solving, and a five-day longitudinal trial conducted with 28 students from the same population was associated with increased resilience. The results suggest the potential practical benefits of incorporating theater, literature, comics, and other story-based art into elementary school curricula.}
}
@article{TIKHONOV199898,
title = {The Sensing and Control Strategies of Thin-Film Growth Process Based on Visual Thinking Prototyping Cellular Neural Network},
journal = {IFAC Proceedings Volumes},
volume = {31},
number = {29, Supplement 1},
pages = {98-99},
year = {1998},
note = {7th IFAC Symposium on Artificial Intelligence in Real Time Control 1998. Extended Abstracts, Grand Canyon National Park, USA, 5-8 October},
issn = {1474-6670},
doi = {https://doi.org/10.1016/S1474-6670(17)38368-4},
url = {https://www.sciencedirect.com/science/article/pii/S1474667017383684},
author = {Nikolai I. Tikhonov}
}
@article{SUN2022102991,
title = {Lake algal bloom monitoring via remote sensing with biomimetic and computational intelligence},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {113},
pages = {102991},
year = {2022},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2022.102991},
url = {https://www.sciencedirect.com/science/article/pii/S1569843222001820},
author = {Zhibin Sun and Ni-Bin Chang and Chi-Farn Chen and Wei Gao},
keywords = {Eutrophication, Biomimetic intelligence, Computational intelligence, Ensemble learning, Food-water nexus, Decision level fusion, Water quality monitoring},
abstract = {Traditional supervised classifications for remote sensing-based water quality monitoring count on a set of classifiers to retrieve features and improve their prediction accuracies based on ground truth samples. However, many existing feature extraction methods in remote sensing are unable to exhibit multiple-instance nonlinear spatial pattern recognition at scales via ensemble learning. This paper designed for lake algal bloom monitoring presents intelligent feature extraction for harmonizing local and global features via tensor flow-based ensemble learning with integrated biomimetic and computational intelligence. To explore such complexity, an Integrated Biomimetic and Ensemble Learning Algorithm (IBELA) was developed to synthesize the contribution from different classifiers associated with the biomimetic philosophy of integrated bands. It leads to strengthened multiple-instance spatial pattern recognition in lake algal bloom monitoring via image fusion at the decision level. With the implementation of IBELA, a case study of a eutrophic freshwater lake, Lake Managua, for water quality monitoring leads to demonstrate six input visual senses showing different impacts on retrieving Chl-a concentrations in the dry and wet season, respectively. The input of total nitrogen from the watershed plays the most important role in water quality variations in both seasons in a watershed-based food–water nexus. Although ultraviolet and microwave bands are important in the dry season, Secchi disk depth is critical in the wet season for water quality monitoring.}
}
@incollection{SHAW2004295,
title = {Chapter 22 - The Spatial-Temporal Thinking Machine},
editor = {Gordon L. Shaw},
booktitle = {Keeping Mozart in Mind (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {295-299},
year = {2004},
isbn = {978-0-12-639061-2},
doi = {https://doi.org/10.1016/B978-012639061-2/50026-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780126390612500264},
author = {Gordon L. Shaw},
abstract = {Publisher Summary
This chapter discusses ideas and dreams of building a computer that can think and reason based on the spatial-temporal reasoning methods used in the brain. The enormous impact that electronic computers have had on our lives is well known. If one could combine the speed of the present computer with the ability of the brain to think using families of symmetry patterns developing in space and time, a whole new era would be here. Moreover, cortical columns are organized in a very highly structured manner to form a cortical area. It is this higher-level architecture that has been examined in order to explore the further consequences of the concepts concerning computation by symmetry operations. It is suggested that a hardware analog-digital implementation of this higher-level cortical area architecture of trion cortical columns should be “straightforward” owing to the localized and structured connectivity, and the discreteness of the firing levels. It is noted that, high-speed parallel computations would allow one to look for symmetry operations in a cortical area.}
}
@article{CSIZMADIA2024108765,
title = {Exploring the role of working memory gate opening process in creativity: An ERP study using the reference-back paradigm},
journal = {Biological Psychology},
volume = {187},
pages = {108765},
year = {2024},
issn = {0301-0511},
doi = {https://doi.org/10.1016/j.biopsycho.2024.108765},
url = {https://www.sciencedirect.com/science/article/pii/S0301051124000243},
author = {Petra Csizmadia and Boglárka Nagy and Lili Kővári and Zsófia Anna Gaál},
keywords = {Divergent/convergent thinking, Working memory, Reference-back paradigm, Gate opening, ERP},
abstract = {We investigated the relationship between the gate opening process of working memory and an individual's proficiency in divergent (DT) and convergent thinking (CT) using the reference-back paradigm. Event-related potentials and reaction times were measured across groups with varying DT (N = 40, 27.35 ± 5.05 years) and CT levels (N = 40, 27.88 ± 4.95 years). Based on the role of striatal dopamine in supporting cognitive flexibility, which facilitates DT, and considering the significance of phasic dopamine activity as the gate opening signal originating from the basal ganglia, we assumed that the gate opening process may contribute differently to DT and CT. Despite the absence of behavioural differences in gate opening costs, distinct neural patterns emerged. In the early time windows (P1, N1), gate opening effects were detected in both DT and CT groups, with a notable interaction influenced by the level of DT, resulting in significant effects within the lower DT group. The P2 component showed a gate opening effect only in the higher DT group. In the P3 time window, the process unfolded comparably in all groups. Our results suggest that groups with different levels of convergent thinking (based on Matrix reasoning) and those with lower DT (based on Creativity Index) tend to select and activate the prefrontal cortex representation containing the required task information at an earlier stage, compared to those with better DT. This could be beneficial especially in the early phase of idea generation, as more elements become available to create associations and original ideas.}
}
@article{AHMADI201627,
title = {Computational cognitive assistants for futures studies: Toward vision based simulation},
journal = {Futures},
volume = {81},
pages = {27-39},
year = {2016},
note = {Modelling and Simulation in Futures Studies},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2016.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S0016328716300829},
author = {Meisam Ahmadi and Mohammadreza {Jahed Motlagh} and Adel Torkaman Rahmani and Mohammad Mahdi Zolfagharzadeh and Peyman Shariatpanahi},
keywords = {Futures studies, Quantitative and qualitative methods, HCI design, Cognitive architecture, Artificial intelligent agents},
abstract = {Many foresight researchers believe that quantitative simulations have a very restricted contribution in futures studies due to their simplicity and lack of creativity. While qualitative methods, taking advantage of the human cognitive system, have a great potential in addressing a wide range of problems in futures studies, this potential is mostly due to the human visual logic that can handle the task of imagining future scenarios much better than mathematical logic. On the other hand, computational methods benefit from the advantages of silicon-based systems namely speed, large memory, rapid networking, and communication. Hence, it would be extremely beneficial to come up with a solution that combines the positive sides of both qualitative and computational approaches. Cognitive artificial agents are computational units that make use of the human cognitive system. Their interaction with foresight and futures researchers can result in promising solutions for the problems addressed in futures studies. In addition, these agents can serve as a great source of inspiration for taking the first step towards vision based computers that can simulate humans’ imaginations of the future. This paper reviews some of the previous attempts in this field and finally sheds light on the main issues where methods in futures studies can play a key role in the future of Human Computer Interaction systems. Our suggested architecture for a future studies interactions-based system along with its justifications and specifications is provided in the form of a request for proposal.}
}
@article{HANI2023102968,
title = {Computational intelligence modeling of nanomedicine preparation using advanced processing: Solubility of fludrocortisone acetate in supercritical carbon dioxide},
journal = {Case Studies in Thermal Engineering},
volume = {45},
pages = {102968},
year = {2023},
issn = {2214-157X},
doi = {https://doi.org/10.1016/j.csite.2023.102968},
url = {https://www.sciencedirect.com/science/article/pii/S2214157X23002745},
author = {Umme Hani and Zainab {Ali Bu sinnah} and Ahmad J. Obaidullah and Bader Huwaimel and Muteb Alanazi and Tareq {Nafea Alharby} and Ahmed A. Lahiq and Abdullah {Ali Alshehri}},
keywords = {Nanomedicine, Multilayer perceptron, Support vector machine, Multi linear regression, Drug solubility},
abstract = {The method of green technology which is based on supercritical solvent has been studied in this work for analysis of nanomedicine preparation of solid dosage oral medications. Given that the poor drug solubility in aqueous media is a big challenge in pharmaceutical industry, nanomedicines would help improve the drug solubility in aqueous media. The solubility of fludrocortisone acetate in supercritical carbon dioxide is modelled in this research using various machine learning methods because it is a crucial aspect of the expansion of the pharmaceutical business. For this purpose, the accessible data have two input features: a pressure range of 120–300 (bar) and a temperature range of 308–338 (K). MLP, v-SVR and MLR are the basic models used in this research, but not their raw versions. They are improved for modeling drug solubility and coupled with the grey wolf optimization (GWO) in order to optimize the models. The models optimized by GWO showed acceptable results, but among these models, MLP regression has shown better results when coupled with this optimization algorithm. This model has the RMSE error rate of 2.98 × 10−2 and its R2 score is 0.9797 in correlating the solubility data of the medicine.}
}
@article{CHIARAMONTI2013101,
title = {Review of energy balance in raceway ponds for microalgae cultivation: Re-thinking a traditional system is possible},
journal = {Applied Energy},
volume = {102},
pages = {101-111},
year = {2013},
note = {Special Issue on Advances in sustainable biofuel production and use - XIX International Symposium on Alcohol Fuels - ISAF},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2012.07.040},
url = {https://www.sciencedirect.com/science/article/pii/S0306261912005624},
author = {David Chiaramonti and Matteo Prussi and David Casini and Mario R. Tredici and Liliana Rodolfi and Niccolò Bassi and Graziella Chini Zittelli and Paolo Bondioli},
keywords = {Microalgae, Biofuel, Raceway ponds, Head losses, Energy, Mixing},
abstract = {The present work addresses energy consumption in raceway ponds (RWPs). This kind of systems are today the most utilized industrial plant for outdoor algae cultivation. The problem has been addressed combining theoretical correlations and experimental data. Head losses for conventional raceway ponds were evaluated, and the results were compared with data available in literature. Computational fluid dynamics was used to support the theoretical analysis. This study suggested possible improvements to the traditional RWP design: an Innovative Raceway Pond (IRP II) was therefore designed, built and operated in parallel with a reference pilot RWP in a test site. Several modifications to traditional RWP design were implemented in the IRP II: the paddle wheel was substituted by a propeller, the water head was reduced and baffle boards were installed in the curves. To validate the new design, head losses and therefore energy consumption in the different systems were evaluated, during cultivation experiments, with two microalgae strains. The theoretical and experimental study allowed a validated calculation, which showed the importance of concentrated head losses towards distributed ones. The analysis highlighted how these losses weight at different pond scales, suggesting possible improvements of the RWP energy performance – as achieved in the IRP II – through revised design for optimized mixing.}
}
@article{DEPASQUALE2023631,
title = {The centrality of population-level factors to network computation is demonstrated by a versatile approach for training spiking networks},
journal = {Neuron},
volume = {111},
number = {5},
pages = {631-649.e10},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.007},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322010807},
author = {Brian DePasquale and David Sussillo and L.F. Abbott and Mark M. Churchland},
keywords = {artificial neural networks, factor models, population dynamics, dimensionality reduction, spiking networks, recurrent neural networks, network training, FORCE learning, motor system, dynamical systems},
abstract = {Summary
Neural activity is often described in terms of population-level factors extracted from the responses of many neurons. Factors provide a lower-dimensional description with the aim of shedding light on network computations. Yet, mechanistically, computations are performed not by continuously valued factors but by interactions among neurons that spike discretely and variably. Models provide a means of bridging these levels of description. We developed a general method for training model networks of spiking neurons by leveraging factors extracted from either data or firing-rate-based networks. In addition to providing a useful model-building framework, this formalism illustrates how reliable and continuously valued factors can arise from seemingly stochastic spiking. Our framework establishes procedures for embedding this property in network models with different levels of realism. The relationship between spikes and factors in such networks provides a foundation for interpreting (and subtly redefining) commonly used quantities such as firing rates.}
}
@article{WALTERS199115,
title = {Critical thinking, rationality, and the vulcanization of students},
journal = {Journal of Accounting Education},
volume = {9},
number = {1},
pages = {15-31},
year = {1991},
issn = {0748-5751},
doi = {https://doi.org/10.1016/0748-5751(91)90020-R},
url = {https://www.sciencedirect.com/science/article/pii/074857519190020R},
author = {Kerry S. Walters}
}
@article{LIU1996435,
title = {Is designing one search or two? A model of design thinking involving symbolism and connectionism},
journal = {Design Studies},
volume = {17},
number = {4},
pages = {435-449},
year = {1996},
note = {Special Issue: Design Cognition and Computation},
issn = {0142-694X},
doi = {https://doi.org/10.1016/S0142-694X(96)00018-X},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X9600018X},
author = {Yu-Tung Liu},
keywords = {design cognition, design process, symbolism, connectionism},
abstract = {In this paper, designing is interpreted as a combination of two searches: a shape restructuring search and a knowledge transforming search. During the first phase, designers or computer-aided design systems search for alternative ways to interpret for the current design state by restructuring shapes in terms of emergent subshapes; it is close to the connectionist processing which we can only slightly sense. During the second phase, designers or computer systems search for alternative rule applications in order to transform the interpreted current state into the next one that matches the formal and functional requirements; it is close to symbolic processing which we can sense, clearly and cognitively.}
}
@article{SHAH2025e00881,
title = {Integration of phytochemical profiling and computational approaches to evaluate the neuroprotective potential of Nardostachys jatamansi in Alzheimer's disease},
journal = {Biotechnology Reports},
volume = {45},
pages = {e00881},
year = {2025},
issn = {2215-017X},
doi = {https://doi.org/10.1016/j.btre.2025.e00881},
url = {https://www.sciencedirect.com/science/article/pii/S2215017X25000086},
author = {Abdul Jalil Shah and Mohammad Younis Dar and Mohd Adnan and Tanmaykumar Varma and Dhairiya Agarwal and Prabha Garg and Reyaz Hassan Mir and Rampratap Meena and Mubashir Hussain Masoodi},
keywords = {, GCMS, Molecular docking, Network pharmacology, MD simulations},
abstract = {Despite broad spectrum utility of Nardostachys jatamansi (D. Don) DC, little is known about the molecular processes that underlie its anti-Alzheimer action. To investigate the molecular targets and therapeutic potential of N. jatamansi for Alzheimer's disease (AD), we used Gas Chromatography-Mass Spectrometry (GC-MS), ADMET analysis, network pharmacology, differential gene expression analysis, molecular docking, and molecular dynamics (MD) simulations. The STITCH database was used for network creation and protein-protein interaction analysis, while Cytoscape was used for network visualization and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway enrichment and Gene Ontology (GO) for term enrichment. Additionally, to investigate the intermolecular interactions between the active chemicals and target proteins, molecular docking experiments were conducted using the Blind docking on the Achilles server. The stability of the PS1 gene complex with Spirojatamol, was further evaluated using MD simulations. With Spirojatamol showing the highest binding energy scores against PS1 (−6.9 kcal/mol), molecular docking confirmed the activity of this metabolite against AD targets PS1 and Spirojatamol formed a stable complex at 100 nanoseconds, according to additional investigation using MD simulations. Significant ligand-protein interactions were verified by binding free energy calculations using the MM/GBSA technique. The PS1-Spirojatamol complex had a binding energy of ΔG: −36.95 ± 5.00 kcal/mol. By focusing on several genes and pathways, involved in AD, this work reveals the molecular underpinnings behind N. jatamansi possible use in the treatment of AD.}
}
@article{ZENGAFFINEN2023100159,
title = {“Computational analysis on verbal fluency reveals heterogeneity in subjective language interests and brain structure”},
journal = {Neuroimage: Reports},
volume = {3},
number = {1},
pages = {100159},
year = {2023},
issn = {2666-9560},
doi = {https://doi.org/10.1016/j.ynirp.2023.100159},
url = {https://www.sciencedirect.com/science/article/pii/S2666956023000041},
author = {Francilia Zengaffinen and Antje Stahnke and Stephan Furger and Roland Wiest and Thomas Dierks and Werner Strik and Yosuke Morishima},
keywords = {Language, SyNoPsis, Computational analysis, LSA, VBM, Healthy cohort, Psychosis},
abstract = {Language is an essential higher cognitive function in humans and is often affected by psychiatric and neurological disorders. Objective measures like the verbal fluency test are often used to determine language dysfunction. Recent applications of computational approaches broaden insights into language-related functions. In addition, individuals diagnosed with a psychiatric or neurological disorder also often report subjective difficulties in language-related functions. Therefore, we investigated the association between objective and subjective measures of language functioning, on the one hand, and inter-individual structural variations in language-related brain areas, on the other hand. We performed a Latent Semantic analysis (LSA) on a semantic verbal fluency task in 101 healthy adult participants. To investigate if these objective measures are associated with a subjective one, we examined assessed subjective natural tendency of interest in language-related activity with a study-specific questionnaire. Lastly, a voxel-based brain morphometry (VBM) was conducted to reveal associations between objective (LSA) measures and structural changes in language-related brain areas. We found a positive correlation between the LSA measure cosine similarity and the subjective interest in language. Furthermore, we found that higher cosine similarity corresponds to higher gray matter volume in the right cerebellum. The results suggest that people with higher interests in language access semantic knowledge in a more organized way exhibited by higher cosine similarity and have larger gray matter volume in the right cerebellum, when compared to people with lower interests. In conclusion, we demonstrate that there is inter-individual diverseness of accessing the semantic knowledge space and that it is associated with subjective language interests as well as structural differences in the right cerebellum.}
}
@article{CHEN2009191,
title = {Towards an explanatory and computational theory of scientific discovery},
journal = {Journal of Informetrics},
volume = {3},
number = {3},
pages = {191-209},
year = {2009},
note = {Science of Science: Conceptualizations and Models of Science},
issn = {1751-1577},
doi = {https://doi.org/10.1016/j.joi.2009.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S1751157709000236},
author = {Chaomei Chen and Yue Chen and Mark Horowitz and Haiyan Hou and Zeyuan Liu and Donald Pellegrino},
keywords = {Theory of scientific discovery, Transformative scientific discoveries, Theory of structural holes, Intellectual brokerage, Knowledge diffusion, Information foraging},
abstract = {We propose an explanatory and computational theory of transformative discoveries in science. The theory is derived from a recurring theme found in a diverse range of scientific change, scientific discovery, and knowledge diffusion theories in philosophy of science, sociology of science, social network analysis, and information science. The theory extends the concept of structural holes from social networks to a broader range of associative networks found in science studies, especially including networks that reflect underlying intellectual structures such as co-citation networks and collaboration networks. The central premise is that connecting otherwise disparate patches of knowledge is a valuable mechanism of creative thinking in general and transformative scientific discovery in particular. In addition, the premise consistently explains the value of connecting people from different disciplinary specialties. The theory not only explains the nature of transformative discoveries in terms of the brokerage mechanism but also characterizes the subsequent diffusion process as optimal information foraging in a problem space. Complementary to epidemiological models of diffusion, foraging-based conceptualizations offer a unified framework for arriving at insightful discoveries and optimizing subsequent pathways of search in a problem space. Structural and temporal properties of potentially high-impact scientific discoveries are derived from the theory to characterize the emergence and evolution of intellectual networks of a field. Two Nobel Prize winning discoveries, the discovery of Helicobacter pylori and gene targeting techniques, and a discovery in string theory demonstrated such properties. Connections to and differences from existing approaches are discussed. The primary value of the theory is that it provides not only a computational model of intellectual growth, but also concrete and constructive explanations of where one may find insightful inspirations for transformative scientific discoveries.}
}
@incollection{MAYER2023229,
title = {Problem solving},
editor = {Robert J Tierney and Fazal Rizvi and Kadriye Ercikan},
booktitle = {International Encyclopedia of Education (Fourth Edition)},
publisher = {Elsevier},
edition = {Fourth Edition},
address = {Oxford},
pages = {229-234},
year = {2023},
isbn = {978-0-12-818629-9},
doi = {https://doi.org/10.1016/B978-0-12-818630-5.14023-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128186305140230},
author = {Richard E. Mayer},
keywords = {Cognitive processing, Higher-order cognition, Insight, Problem representation, Problem solving, Reasoning, Rigidity in thinking, Solution plan, Thinking, Transfer},
abstract = {A problem occurs when a situation is in one state, the problem solver wants it to be in another state, and there are obstacles preventing a smooth transition from the given state to the goal state. Problem solving refers to cognitive processing aimed at overcoming a problem. This entry examines the definitions of key terms, types of problems, phases in problem solving, and types of knowledge involved in problem solving. This entry also explores findings about problem solving that are most relevant to education including research on rigidity in thinking, problem solving transfer, productive thinking, insight, computer simulation of problem solving, problem solving in realistic situations, and teaching of thinking.}
}
@article{CANBALOGLU202251,
title = {Computational modeling of organisational learning by self-modeling networks},
journal = {Cognitive Systems Research},
volume = {73},
pages = {51-64},
year = {2022},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2021.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S1389041721000978},
author = {Gülay Canbaloğlu and Jan Treur and Peter H.M.P. Roelofsma},
keywords = {Organisational learning, Network model, Mental model, Second-order adaptive, Control of adaptation},
abstract = {Within organisational learning literature, mental models are considered a vehicle for both individual learning and organizational learning. By learning individual mental models (and making them explicit), a basis for formation of shared mental models for the level of the organization is created, which after its formation can then be adopted by individuals. This provides mechanisms for organizational learning. These mechanisms have been used as a basis for an adaptive computational network model. The model is illustrated by a not too complex but realistic case study.}
}
@article{KVISTBORG2015591,
title = {Thinking Outside the Gate: Single-Cell Assessments in Multiple Dimensions},
journal = {Immunity},
volume = {42},
number = {4},
pages = {591-592},
year = {2015},
issn = {1074-7613},
doi = {https://doi.org/10.1016/j.immuni.2015.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S1074761315001351},
author = {Pia Kvistborg and Cécile Gouttefangeas and Nima Aghaeepour and Angelica Cazaly and Pratip K. Chattopadhyay and Cliburn Chan and Judith Eckl and Greg Finak and Sine Reker Hadrup and Holden T. Maecker and Dominik Maurer and Tim Mosmann and Peng Qiu and Richard H. Scheuermann and Marij J.P. Welters and Guido Ferrari and Ryan R. Brinkman and Cedrik M. Britten}
}
@article{YAO2022113,
title = {Symbols-Meaning-Value (SMV) space as a basis for a conceptual model of data science},
journal = {International Journal of Approximate Reasoning},
volume = {144},
pages = {113-128},
year = {2022},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2022.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X2200024X},
author = {Yiyu Yao},
keywords = {Three-way decision, Thinking in threes, Triadic thinking, Trilelvel thinking, Data science, Granular computing},
abstract = {By applying the principles of three-way decision as thinking in threes, in this paper I introduce a conceptual model of data science in three steps. First, I examine examples of triadic thinking in general and trilevel thinking in specific in data science. Then, based on Weaver's trilevel categorization of communications problems, I propose the concept of the symbols-meaning-value (SMV) space and discuss three perspectives on the SMV space from the viewpoints of information science and management science, cognitive science, and computer science. I label the operations on the SMV three levels metaphorically as seeing, knowing, and doing. Finally, I put forward a SMV-space-based conceptual model of data science, in which data are a resource, the power of data is the knowledge embedded in data, and the value of data is the wise decision and the best course of action supported by data. The goals and functions of data science at the SMV three levels are, respectively, making data available, making data meaningful, and making data valuable. To demonstrate the potential contributions of the conceptual model, I comment on some of its practical values and implications.}
}
@article{LOCKWOOD2020100783,
title = {A case for combinatorics: A research commentary},
journal = {The Journal of Mathematical Behavior},
volume = {59},
pages = {100783},
year = {2020},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2020.100783},
url = {https://www.sciencedirect.com/science/article/pii/S073231232030047X},
author = {Elise Lockwood and Nicholas H. Wasserman and Erik S. Tillema},
keywords = {Research commentary, Combinatorics, Discrete mathematics, Curricula},
abstract = {In this commentary, we make a case for the explicit inclusion of combinatorial topics in mathematics curricula, where it is currently essentially absent. We suggest ways in which researchers might inform the field’s understanding of combinatorics and its potential role in curricula. We reflect on five decades of research that has been conducted since a call by Kapur (1970) for a greater focus on combinatorics in mathematics education. Specifically, we discuss the following five assertions: 1) Combinatorics is accessible, 2) Combinatorics problems provide opportunities for rich mathematical thinking, 3) Combinatorics fosters desirable mathematical practices, 4) Combinatorics can contribute positively to issues of equity in mathematics education, and 5) Combinatorics is a natural domain in which to examine and develop computational thinking and activity. Ultimately, we make a case for the valuable and unique ways in which combinatorics might effectively be leveraged within K-16 curricula.}
}
@article{JOSWICK2025104908,
title = {Opportunities to collectively reason about numbers while building connections to key conceptual ideas in mathematics: Examining the questions used by teachers studying and implementing Number Talks},
journal = {Teaching and Teacher Education},
volume = {155},
pages = {104908},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104908},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24004414},
author = {Candace Joswick and Brandon G. McMillan and Kimberly A. Conner},
keywords = {Number Talks, Questioning},
abstract = {Teachers' questioning practices play a pivotal role in shaping classroom discussions. Analysis of 30 Number Talks from classrooms across the US reveals the majority of teachers' questions helped to surface student strategies (confirm, elaborate, invite questions), but did not provide opportunities for students to collectively reason about numbers while building connections to key conceptual ideas in mathematics (connect, justify, orient questions). Data excerpts illustrate how questions can be used to support this reasoning. Implications include the need to focus on pedagogical and content knowledge centered in student mathematical thinking within professional development to develop teachers’ ability to support this reasoning.}
}
@article{PSYCHARIS201490,
title = {The impact of the computational inquiry based experiment on metacognitive experiences, modelling indicators and learning performance},
journal = {Computers & Education},
volume = {72},
pages = {90-99},
year = {2014},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S0360131513002789},
author = {Sarantos Psycharis and Evi Botsari and Panagiotis Mantas and Dionisios Loukeris},
keywords = {Metacognition, Modelling, Computational experiment, Inquiry based science education},
abstract = {Computational experiment approach considers modelling as the essential feature of Inquiry Based Science Education (IBSE), where the model and the computer take the place of the “classical” experimental set-up and simulation replaces the experiment (Landau, Pαez, & Bordeianu, 2008). Modelling, as a pedagogical tool, involves the model construction, the exploration of model characteristics and the model application to a specific problem, resembling authentic activities of scientists and mathematicians (Herbert, 2003). Recent developments in strategy instruction research suggest that learning in a particular discipline is enhanced by guiding students through the development of content-relevant metacognitive strategies (Wosnitza & Volet, 2009). Problem-solving is a complex process, which involves several cognitive operations such as collecting and selecting information, heuristic strategy and metacognition (De Corte, 2003, Garofalo and Lester, 1985, Schoenfeld, 1994). The purpose of this study was to explore the impact of the Computational Experiment Methodology on learners' cognitive performance, use of modelling indicators and shift of the metacognitive experiences during problem solving using computational models. Sixty prospective primary school teachers volunteered to participate in the study. Students were exposed by the Instructor to a number of computational experiments, while during the course they developed their own models of simulation. The results of the experiment show that the use of the computational experiment approach has a substantial effect on the metacognitive experiences and the use of modelling indicators.}
}
@article{GARCIA201325,
title = {A constructivist computational platform to support mathematics education in elementary school},
journal = {Computers & Education},
volume = {66},
pages = {25-39},
year = {2013},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2013.02.004},
url = {https://www.sciencedirect.com/science/article/pii/S036013151300033X},
author = {I. Garcia and C. Pacheco},
keywords = {Elementary education, Constructivist theory, Interactive computational tools, Simulated environments, Process improvement},
abstract = {Many courses for elementary school are based upon teacher presentation and explanation of basic topics, rather than allowing students to develop their own knowledge. This traditional model may turn elementary-level lessons into an extremely theoretical, boring and non-effective process. In this context, research in mathematics elementary education in Mexico indicates the need to analyze alternative pedagogic practices and to find different ways to make mathematics education in early ages less difficult and more attractive. Constructivist theory can provide an alternative for developing pedagogic proposals. The objectives of this research were: (1) develop a computational platform to support the traditional Mexican method of education with practical mathematics problems simulated as part of the daily world environment and to increase the level of students' social involvement through direct collaboration, and (2) analyze how this computational tool affects student motivation, collaboration and discussion. An exploratory case study concerning dimensions of mathematics problem-solving using computer simulations was conducted with 6–8 year old elementary school children. After a theoretical class the children were involved in solving a series of verbal problems, using our computational platform. Sixty third-grade children participated in this case study and data were collected from their responses to questions and interviews in order to explore attitudes toward learning mathematics and assess self-efficacy in this area. The results obtained in this research indicate that the integration of computational tools into conventional method courses provides elements to improve student motivation, collaboration and discussion based on their own exploratory experiences. These results can assist other education programs to incorporate positive attitudes and their own knowledge creation from a constructivist approach using technology.}
}
@article{PANSKYI2019100593,
title = {Out-of-school assistance in the teaching of visual creative programming in the game-based environment – Case study: Poland},
journal = {Thinking Skills and Creativity},
volume = {34},
pages = {100593},
year = {2019},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2019.100593},
url = {https://www.sciencedirect.com/science/article/pii/S187118711930104X},
author = {Taras Panskyi and Zdzislawa Rowinska and Sebastian Biedron},
keywords = {Out-of-school education, Creative programming, Game-based learning, ICT},
abstract = {The paper presents effects of out-of-school teaching of computer science in a visual creative programming course (Scratch) for children aged 9–14, held at the Lodz University of Technology. The research was carrying out during 2016–2018 school years. The study sample consists of 265 primary and secondary students from Lodz Voivodeship (province) in central Poland. The results were obtained from anonymous questionnaires completed by 221 course participants and their parents. The answers confirm that this type of course becomes a new fascinating manner of spending spare time by children. Moreover, quantitative analysis of student’s finals projects also has been performed. In the process of creative programming in the game-based environment, children develop the computational thinking skills, problem-solving strategies, and abstract thinking. Moreover, children are supported by their parents, who notice how important these competences are and how great opportunities they will present for children in future. Authors continue to grow Scratch programming course to democratize access to new technologies and education, preparing future generation for a world in which computational and algorithmic thinking is a central part of problem-solving. Perhaps some of the course participants will continue their study of programming and make it a career for their life.}
}
@article{FENG2025100831,
title = {Construction of teaching game evaluation model based on ISSA-BPNN},
journal = {Entertainment Computing},
volume = {52},
pages = {100831},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100831},
url = {https://www.sciencedirect.com/science/article/pii/S187595212400199X},
author = {Bibo Feng and Lingli Zhang and Jing Yin and Rong Wang},
keywords = {Sparrow search algorithm, Back propagation neural network, Teaching games, Evaluating indicator},
abstract = {Teaching games are an effective teaching organization activity. In response to the evaluation and prediction problem of teaching games, a teaching game evaluation model based on improved sparrow search algorithm and back propagation neural network was studied and constructed. Firstly, a situational teaching game was designed and an evaluation index system was constructed. Then, a teaching game evaluation prediction model based on the improved method was established. Finally, the expert consultation method is adopted to collect opinions from experts in the field of education and construct an evaluation index system for teaching games. And based on the evaluation index system of teaching games, evaluate students’ mathematical thinking ability before and after experiencing teaching games to verify the application effect of teaching games. The scenario based teaching game designed in this study has a certain effect on improving students’ mathematical thinking ability. Students’ mathematical thinking has significantly improved (P<0.05), and the teaching effect is the same for students of different genders (P>0.1). The improved sparrow search algorithm has a faster convergence rate than other algorithms, and tends to be stable when iteration is about 100 when solving the single peak benchmark function. When solving the multimodal benchmark test function, it tends to stabilize when iteration is around 20. The teaching game evaluation prediction price model based on the improved method shows a trend of first increasing and then decreasing with hidden units increasing. When the hidden unit is 16, the area index under model curve is the highest, around 0.962, and its prediction accuracy is relatively high. In summary, the model constructed in this study is applicating good in teaching game evaluation prediction, and can promote education industry developing.}
}
@article{BIAN2019136,
title = {Statistical thinking, machine learning},
journal = {Journal of Clinical Epidemiology},
volume = {116},
pages = {136-137},
year = {2019},
issn = {0895-4356},
doi = {https://doi.org/10.1016/j.jclinepi.2019.08.003},
url = {https://www.sciencedirect.com/science/article/pii/S0895435619304950},
author = {Jiang Bian and Iain Buchan and Yi Guo and Mattia Prosperi}
}
@article{HAO2024102662,
title = {Exploring collaborative decision-making: A quasi-experimental study of human and Generative AI interaction},
journal = {Technology in Society},
volume = {78},
pages = {102662},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102662},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24002100},
author = {Xinyue Hao and Emrah Demir and Daniel Eyers},
keywords = {ChatGPT, Artificial intelligence, Human intuition, Decision-making, Cognitive biases},
abstract = {This paper explores the effects of integrating Generative Artificial Intelligence (GAI) into decision-making processes within organizations, employing a quasi-experimental pretest-posttest design. The study examines the synergistic interaction between Human Intelligence (HI) and GAI across four group decision-making scenarios within three global organizations renowned for their cutting-edge operational techniques. The research progresses through several phases: identifying research problems, collecting baseline data on decision-making, implementing AI interventions, and evaluating the outcomes post-intervention to identify shifts in performance. The results demonstrate that GAI effectively reduces human cognitive burdens and mitigates heuristic biases by offering data-driven support and predictive analytics, grounded in System 2 reasoning. This is particularly valuable in complex situations characterized by unfamiliarity and information overload, where intuitive, System 1 thinking is less effective. However, the study also uncovers challenges related to GAI integration, such as potential over-reliance on technology, intrinsic biases particularly ‘out-of-the-box’ thinking without contextual creativity. To address these issues, this paper proposes an innovative strategic framework for HI-GAI collaboration that emphasizes transparency, accountability, and inclusiveness.}
}
@article{GOOD201778,
title = {Programming language, natural language? Supporting the diverse computational activities of novice programmers},
journal = {Journal of Visual Languages & Computing},
volume = {39},
pages = {78-92},
year = {2017},
note = {Special Issue on Programming and Modelling Tools},
issn = {1045-926X},
doi = {https://doi.org/10.1016/j.jvlc.2016.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S1045926X16301963},
author = {Judith Good and Kate Howland},
keywords = {Novice programming languages, Natural language, Design, Empirical evaluation},
abstract = {Given the current focus on teaching computational concepts to all from an early age, combined with the growing trend to empower end users to become producers of technology rather than mere consumers, we consider the issue of “computational notation”. Specifically, where the goal is to help individuals develop their understanding of computation and/or use computation in real world settings, we question whether natural language might be a preferred notation to traditional programming languages, given its familiarity and ubiquity. We describe three empirical studies investigating the use of natural language for computation in which we found that although natural language provides support for understanding computational concepts, it introduces additional difficulties when used for coding. We distilled our findings into a set of design guidelines for novice programming environments which consider the ways in which different notations, including natural language, can best support the various activities that comprise programming. These guidelines were embodied in Flip, a bi-modal programming language used in conjunction with the Electron toolset, which allows young people to create their own commercial quality, narrative based role- playing games. Two empirical studies on the use of Flip in three different real world contexts considered the extent to which the design guidelines support ease of use and an understanding of computation. The guidelines have potential to be of use both in analysing the use of natural language in existing novice programming environments, and in the design of new ones.}
}
@article{TUHKALA201954,
title = {Technology Comprehension — Combining computing, design, and societal reflection as a national subject},
journal = {International Journal of Child-Computer Interaction},
volume = {20},
pages = {54-63},
year = {2019},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2019.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S2212868918301016},
author = {Ari Tuhkala and Marie-Louise Wagner and Ole Sejer Iversen and Tommi Kärkkäinen},
keywords = {Technology comprehension, Digital fabrication, Making, Design, Computing, Computational thinking, Education, Teachers, National, Scaling, Subject},
abstract = {This article considers the implementation of a new learning subject ”Technology Comprehension” into lower secondary schools in Denmark, as part of an initiative by the Danish Ministry of Education. The subject consists of learning objectives related to computing, design, and societal reflection and was first introduced as an elective course in 13 schools to investigate how it could be integrated into the Danish education system. We present four key findings based on school visits, interviews, an electronical survey, two questionnaires, and workshops including theme discussions: (1) teachers did not perceive Technology Comprehension as a distinct subject, but rather as a set of skills that can be integrated into other subjects; (2) teachers pointed out that Technology Comprehension opens up for interdisciplinary and engaging learning activities, but they need more scaffolding and support; (3) Technology Comprehension challenges teachers’ existing competencies and there is a need for a framework that takes into account computing, design, and societal reflection as a whole; (4) Technology Comprehension appealed to various kind of students, not only those who are enthusiastic about technical matters. This study contributes to the previous research on making and digital fabrication by addressing how these endeavours are implemented on a national level through engaging with local teachers. We call for more research on scaffolding and supporting teachers to orchestrate meaningful learning activities to successfully integrate Technology Comprehension into the Danish national education.}
}
@article{FUGELSANG20051204,
title = {Brain-based mechanisms underlying complex causal thinking},
journal = {Neuropsychologia},
volume = {43},
number = {8},
pages = {1204-1213},
year = {2005},
issn = {0028-3932},
doi = {https://doi.org/10.1016/j.neuropsychologia.2004.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S002839320400274X},
author = {Jonathan A. Fugelsang and Kevin N. Dunbar},
keywords = {Scientific reasoning, Learning, Error detection, Conflict monitoring, fMRI},
abstract = {We use functional magnetic resonance imaging (fMRI) and behavioral analyses to study the neural roots of biases in causal reasoning. Fourteen participants were given a task requiring them to interpret data relative to plausible and implausible causal theories. Encountering covariation-based data during the evaluation of a plausible theory as opposed to an implausible theory selectively recruited neural tissue in the prefrontal and occipital cortices. In addition, the plausibility of a causal theory modulated the recruitment of distinct neural tissue depending on the extent to which the data were consistent versus inconsistent with the theory provided. Specifically, evaluation of data consistent with a plausible causal theory recruited neural tissue in the parahippocampal gyrus, whereas evaluating data inconsistent with a plausible theory recruited neural tissue in the anterior cingulate, left dorsolateral prefrontal cortex, and precuneus. We suggest that these findings provide a neural instantiation of the mechanisms by which working hypotheses and evidence are integrated in the brain.}
}
@article{HADAS2024101549,
title = {Using large language models to evaluate alternative uses task flexibility score},
journal = {Thinking Skills and Creativity},
volume = {52},
pages = {101549},
year = {2024},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101549},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124000877},
author = {Eran Hadas and Arnon Hershkovitz},
keywords = {Creativity, Divergent thinking, Alternative uses task, Flexibility, Large language models},
abstract = {In the Alternative Uses Task (AUT) test, a group of participants is asked to list as many uses as possible for a simple object. The test measures Divergent Thinking (DT), which involves exploring possible solutions in various semantic domains. In this study we employ a Machine Learning approach to automatically generate suitable categories for object uses and classify given responses into them. We show that the results yielded by this automated approach are correlated with results given by humans and can be used to predict expected behavior in the field. Educators and researchers may utilize this approach to address the limitations of subjective scoring, save time, and use the AUT as a tool for cultivating creativity.}
}
@incollection{ISMAIL2024219,
title = {Chapter 7 - High throughput screening of phytochemicals: Application of computational methods},
editor = {Satyajit D. Sarker and Lutfun Nahar},
booktitle = {Computational Phytochemistry (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {219-253},
year = {2024},
isbn = {978-0-443-16102-5},
doi = {https://doi.org/10.1016/B978-0-443-16102-5.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443161025000080},
author = {Fyaz M.D. Ismail and Lutfun Nahar and Satyajit D. Sarker},
keywords = {High throughput screening (HTS), Robotics, Dereplication, Liquid handling systems, Screening /, Natural product prototypes, Drug discovery and development, Machine learning, , , },
abstract = {This chapter examines the history and development of high-throughput screening (HTS) using the knowledge and expertise of the writers, who have worked as consultants or trainers for several pharmaceutical companies. It focuses on the function of HTS in drug development and screening for natural products (phytochemicals). It emphasizes the use of computational tools in HTS for phytochemicals. To guarantee that researchers can set up and effectively use HTS in their natural product research, common problems and solutions are covered along with a few ‘how to’ protocols. Also described are pertinent failures and accomplishments in finding intriguing natural products.}
}