@article{SHYJA2023100465,
title = {Link quality and energy efficient optimal simplified cluster based routing scheme to enhance lifetime for wireless body area networks},
journal = {Nano Communication Networks},
volume = {37},
pages = {100465},
year = {2023},
issn = {1878-7789},
doi = {https://doi.org/10.1016/j.nancom.2023.100465},
url = {https://www.sciencedirect.com/science/article/pii/S1878778923000315},
author = {V. Irine Shyja and G. Ranganathan and V. Bindhu},
keywords = {WBAN, Clustering, Cluster head, Multipath routing scheme, Link quality},
abstract = {Monitoring of patient’s health in the medical industry can be enabled using wireless body area networks (WBANs), which are already used for various purposes, including assisting in human safety. It is imperative to use better power management strategies since the body sensors are small and the battery cannot hold a charge for a long time. Due to the vast amounts of information generated by medical sensors, resource-constrained networks face a significant challenge when guaranteeing the specified quality of service (QoS). Moreover, the WBAN regularly meets the primary hassle of QoS degradation because of congestion WBAN structure can easily compromise heterogeneous and complex networks. Either inappropriate data collection or using energy effectively to transmit medical data without the expense of travel and length has become an important one. To address this issue, the present research work ‘Link Quality and Energy Efficient Optimal Clustering-Multipath (LEOC-MP)’ scheme tries to explore an answer. The main goals of the LEOC-MP (Optimal Link Quality and Energy Efficient Optimal Clustering-Multipath) system are to guarantee node-to-node link quality, lengthen network life, and compute high-performing cluster heads to guarantee reliable multi path data transfer. This work was executed in three phases. First, an optimal simplified clustering technique for data collection from body sensors using an improved pelican optimization (ICO) algorithm is introduced. Next, multiple design constraints for node rank computation, energy efficiency, link quality, path loss, distance, and delay are used. Besides, an Auto-Regressive Probabilistic Neural Network (AR-PNN) is introduced to optimize those design constraints and compute the cluster head (CH) of each cluster. Multipath firing is then performed using a moderated puffer-fish optimization (MPO) algorithm that finds the closest optimal and shortest node to transmit optimal drug data. The work is simulated using an NS-3 environment, and the results are obtained. The outcome of this work is analyzed with existing methodologies, and the results prove that the present work consistently outperforms the existing methodologies.}
}
@article{ARORA2022108615,
title = {Music as a blend of spirituality, culture, and mind mollifying drug},
journal = {Applied Acoustics},
volume = {189},
pages = {108615},
year = {2022},
issn = {0003-682X},
doi = {https://doi.org/10.1016/j.apacoust.2021.108615},
url = {https://www.sciencedirect.com/science/article/pii/S0003682X2100709X},
author = {Shefali Arora and Abhinav Tyagi},
keywords = {Music, Science, Emotions, Society, Health, COVID-19 etc},
abstract = {Science inspires music more often than human imagination. Music is an integral part of all societies, including animal ones. It is behaving like an instrument for digesting information. It has been proven to help in healing the body, mind, and culture. Music can maintain and regulate emotion. It is a common thread among large social groups and is used as a tool to navigate through life. Real science and real music require a steady thinking process. It is a way of finding compatibility within a society as well as developing a link with other societies. Music plays a developmental role in a person’s identity, cultural worldview and permeates through life. In nutshell “Science explains Music and Music makes us The Human”}
}
@article{BURRIS1992175,
title = {Discriminator varieties and symbolic computation},
journal = {Journal of Symbolic Computation},
volume = {13},
number = {2},
pages = {175-207},
year = {1992},
issn = {0747-7171},
doi = {https://doi.org/10.1016/S0747-7171(08)80089-2},
url = {https://www.sciencedirect.com/science/article/pii/S0747717108800892},
author = {Stanley Burris},
abstract = {We look at two aspects of discriminator varieties which could be of considerable interest in symbolic computation:1.discriminator varieties are unitary (i.e., there is always a most general unifier of two unifiable terms), and2.every mathematical problem can be routinely cast in the form†p1 ≈ q1, …, pk ≈ qk implies the equation x ≈ y. Item (l) offers possibilities for implementations in computational logic, and (2) shows that Birkhoff's five rules of inference for equational logic are all one needs to prove theorems in mathematics.}
}
@article{SCHAEFER2024108796,
title = {GPT-4 as a biomedical simulator},
journal = {Computers in Biology and Medicine},
volume = {178},
pages = {108796},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108796},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524008813},
author = {Moritz Schaefer and Stephan Reichl and Rob {ter Horst} and Adele M. Nicolas and Thomas Krausgruber and Francesco Piras and Peter Stepper and Christoph Bock and Matthias Samwald},
keywords = {Biomedical simulation, Large language models, GPT-4, Computational biology, Artificial intelligence},
abstract = {Background
Computational simulation of biological processes can be a valuable tool for accelerating biomedical research, but usually requires extensive domain knowledge and manual adaptation. Large language models (LLMs) such as GPT-4 have proven surprisingly successful for a wide range of tasks. This study provides proof-of-concept for the use of GPT-4 as a versatile simulator of biological systems.
Methods
We introduce SimulateGPT, a proof-of-concept for knowledge-driven simulation across levels of biological organization through structured prompting of GPT-4. We benchmarked our approach against direct GPT-4 inference in blinded qualitative evaluations by domain experts in four scenarios and in two quantitative scenarios with experimental ground truth. The qualitative scenarios included mouse experiments with known outcomes and treatment decision support in sepsis. The quantitative scenarios included prediction of gene essentiality in cancer cells and progression-free survival in cancer patients.
Results
In qualitative experiments, biomedical scientists rated SimulateGPT's predictions favorably over direct GPT-4 inference. In quantitative experiments, SimulateGPT substantially improved classification accuracy for predicting the essentiality of individual genes and increased correlation coefficients and precision in the regression task of predicting progression-free survival.
Conclusion
This proof-of-concept study suggests that LLMs may enable a new class of biomedical simulators. Such text-based simulations appear well suited for modeling and understanding complex living systems that are difficult to describe with physics-based first-principles simulations, but for which extensive knowledge is available as written text. Finally, we propose several directions for further development of LLM-based biomedical simulators, including augmentation through web search retrieval, integrated mathematical modeling, and fine-tuning on experimental data.}
}
@article{NAWAZ2024102806,
title = {Grappling with a sea change: Tensions in expert imaginaries of marine carbon dioxide removal},
journal = {Global Environmental Change},
volume = {85},
pages = {102806},
year = {2024},
issn = {0959-3780},
doi = {https://doi.org/10.1016/j.gloenvcha.2024.102806},
url = {https://www.sciencedirect.com/science/article/pii/S0959378024000104},
author = {Sara Nawaz and Javier Lezaun},
abstract = {While research on marine carbon dioxide removal (mCDR) expands apace, significant unknowns persist regarding the risks and benefits of individual mCDR options. This paper analyses the assumptions and expectations that animate expert understandings of mCDR, with a focus on issues that are central to the responsible governance of this emerging field of climate action. Drawing upon interviews with experts involved in mCDR research projects both academic and entrepreneurial, we highlight four thematic tensions that orient their thinking but are often unstated or left implicit in scientific and technical assessments: (1) the relevance of ‘naturalness’ as a criterion of evaluation for mCDR approaches; (2) the perceived need to accelerate research and development activities via alternative paradigms of evidence-building; (3) a framing of mCDR as a form of waste management that will, in turn, generate new (and currently poorly understood) forms of environmental pollutants; and (4) a commitment to inclusive governance mixed with difficulty in identifying specific stakeholders or constituencies in mCDR interventions. Although expert consensus on these four issues is unlikely, we suggest ways of ensuring that consideration of these themes enriches debate on the responsible development of novel mCDR capabilities.}
}
@article{THOMPSON2024100094,
title = {Alzheimer’s disease and the mathematical mind},
journal = {Brain Multiphysics},
volume = {6},
pages = {100094},
year = {2024},
issn = {2666-5220},
doi = {https://doi.org/10.1016/j.brain.2024.100094},
url = {https://www.sciencedirect.com/science/article/pii/S2666522024000054},
author = {Travis B. Thompson and Bradley Z. Vigil and Robert S. Young},
keywords = {Alzheimer’s disease, Mathematical modeling, Scientific computing},
abstract = {Throughout the 19th and 20th centuries, aided by advances in medical imaging, discoveries in physiology and medicine have added nearly 25 years to the average life expectancy. This resounding success brings with it a need to understand a broad range of age-related health conditions, such as dementia. Today, mathematics, neuroimaging and scientific computing are being combined with fresh insights, from animal models, to study the brain and to better understand the etiology and progression of Alzheimer’s disease, the most common cause of age-related dementia in humans. In this manuscript, we offer a brief primer to the reader interested in engaging with the exciting field of mathematical modeling and scientific computing to advance the study of the brain and, in particular, human AD research. Statement of Significance Modeling Alzheimer’s disease is a highly interdisciplinary field and finding an effective starting point can be a considerable challenge. To address this challenge, this manuscript briefly highlights some central components of AD related protein pathology, useful classes of mathematical models for brain and AD research and effective computational resources for the practical prospective practitioner.}
}
@article{WOLFENGAGEN2016359,
title = {Migration of the Individuals},
journal = {Procedia Computer Science},
volume = {88},
pages = {359-364},
year = {2016},
note = {7th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2016, held July 16 to July 19, 2016 in New York City, NY, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2016.07.449},
url = {https://www.sciencedirect.com/science/article/pii/S1877050916317057},
author = {Viacheslav E. Wolfengagen and Larisa Yu. Ismailova and Sergey V. Kosikov and Irina A. Parfenova and Mikhail Yu. Ermak and Vasiliy D. Petrov and Ilya A. Nikulin and Victor A. Kholodov},
keywords = {data model, computational model, conceptual modeling, stage-by-stage cognition model, variable domains, Big Data, Thick Data},
abstract = {The individuals are modeled by the elements of variable domains. The primitive frame to detect the individual migration from domain to domain is proposed. The supporting computational model is based on a separation of individuals into actual, possible and virtual ones. As was shown, this leads to an adoption of the stage-by-stage cognition model with a pair of evolvents to capture dynamics of the domains – the 2-dimensions model. The first evolvent reflects the generation of the individuals in a domain, the beginning of and canceling out their existence in a domain. The second evolvent reflects the shifts in properties of the individuals. As awaited this unified data model will have the applications to a wide range of models in computer science and Information Technologies.}
}
@incollection{STAPLETON2014127,
title = {8.07 - Administrative Evil and Patient Health: A Critique of the Impact of Manufacturing Systems on Health Care},
editor = {Saleem Hashmi and Gilmar Ferreira Batalha and Chester J. {Van Tyne} and Bekir Yilbas},
booktitle = {Comprehensive Materials Processing},
publisher = {Elsevier},
address = {Oxford},
pages = {127-150},
year = {2014},
isbn = {978-0-08-096533-8},
doi = {https://doi.org/10.1016/B978-0-08-096532-1.00813-X},
url = {https://www.sciencedirect.com/science/article/pii/B978008096532100813X},
author = {L. Stapleton},
keywords = {AMAT, Health, Manufacturing},
abstract = {Manufacturing systems principles underpin enterprise information systems. Nowadays these principles, and the systems that accompany them, are widely applied across various sectors, including health services management systems. The question arises: To what extent are these principles appropriate for health care management applications? This chapter explores the question from a human-centered systems perspective by examining the rationalities and assumptions that underpin manufacturing systems and applying these ideas to health care contexts. Human-centered systems have a long theoretical tradition within the automation and control community stretching back at least into the 1970s. It is a particularly strong theme in manufacturing systems research. As automation and control systems are increasingly important outside the factory, many researchers are revisiting core concepts within this tradition. One particularly important sector is health care, which, in recent years, has implemented a range of AMAT (automation and machine-assisted thinking)-type solutions not the least of which are enterprise resource planning systems (ERPs). These implementations have been accompanied by highly publicized systems failures. Ethical problems have also arisen. The chapter exposes an ‘administrative evil’ that relegates the patient to the status of a subassembly, a component in an ever-more complex health care production line. Humans are dehumanized in the rationality of our health care administrative systems. The chapter concludes that health care systems projects should adopt a human-centered approach that draws on research in manufacturing, automation, and control engineering as well as other disciplines.}
}
@article{VIDENOVIK2024100616,
title = {Game-based learning approach in computer science in primary education: A systematic review},
journal = {Entertainment Computing},
volume = {48},
pages = {100616},
year = {2024},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2023.100616},
url = {https://www.sciencedirect.com/science/article/pii/S187595212300071X},
author = {Maja Videnovik and Ana {Madevska Bogdanova} and Vladimir Trajkovik},
keywords = {Educational game, Game-based learning, Computer science, Primary education},
abstract = {This paper reviews the current situation concerning the implementation of game-based learning in computer science in primary education, providing insight into current trends, identifying strengths and potential research topics. Articles published in four databases from 2017 to 2021 are included in the analysis and an in-depth analysis of 32 articles is done. Different types of games, implemented in various educational contexts, are presented in these articles. Most of them describe implemented methodology, game-based environment or are evaluating the effectiveness of the created game or the approach. The possibility of implementing a game-based approach while learning other computer science topics or measuring the effectiveness of learning by designing a game as a pedagogical strategy are some areas for future research.}
}
@article{LIU2022102936,
title = {A review of spatially-explicit GeoAI applications in Urban Geography},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {112},
pages = {102936},
year = {2022},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2022.102936},
url = {https://www.sciencedirect.com/science/article/pii/S1569843222001339},
author = {Pengyuan Liu and Filip Biljecki},
keywords = {Urban studies, Deep learning, Socio-economics, Location encoder, Graph neural network},
abstract = {Urban Geography studies forms, social fabrics, and economic structures of cities from a geographic perspective. Catalysed by the increasingly abundant spatial big data, Urban Geography seeks new models and research paradigms to explain urban phenomena and address urban issues. Recent years have witnessed significant advances in spatially-explicit geospatial artificial intelligence (GeoAI), which integrates spatial studies and AI, primarily focusing on incorporating spatial thinking and concept into deep learning models for urban studies. This paper provides an overview of techniques and applications of spatially-explicit GeoAI in Urban Geography based on 581 papers identified using a systematic review approach. We examined and screened papers in three scopes of Urban Geography (Urban Dynamics, Social Differentiation of Urban Areas, and Social Sensing) and found that although GeoAI is a trending topic in geography and the applications of deep neural network-based methods are proliferating, the development of spatially-explicit GeoAI models is still at their early phase. We identified three challenges of existing models and advised future research direction towards developing multi-scale explainable spatially-explicit GeoAI. This review paper acquaints beginners with the basics of GeoAI and state-of-the-art and serve as an inspiration to attract more research in exploring the potential of spatially-explicit GeoAI in studying the socio-economic dimension of the city and urban life.}
}
@article{GRIFFIN1977127,
title = {On the application of boundary conditions to time dependent computations for quasi one-dimensional fluid flows},
journal = {Computers & Fluids},
volume = {5},
number = {3},
pages = {127-137},
year = {1977},
issn = {0045-7930},
doi = {https://doi.org/10.1016/0045-7930(77)90019-6},
url = {https://www.sciencedirect.com/science/article/pii/0045793077900196},
author = {Michael D. Griffin and Anderson {John D.}},
abstract = {A study is made of the influence of boundary and initial conditions on time-dependent finite-difference solutions of quasi-one-dimensional duct flows. Several questions are addressed: (1) Under what conditions will a time-dependent solution converge to a steady-state supersonic flow, (2) Under what conditions will it converge to subsonic flow and (3) What conditions are necessary to insure a particular unique solution for subsonic flows. The results provide an orientation, or way of thinking, about the role of such conditions in time-dependent solutions of steady-state flows. The results also show that supersonic solutions are readily obtained by holding only pressure and temperature fixed at the duct inlet, and allowing velocity to float. However, subsonic solutions require pressure, temperature and velocity to be fixed at both the duct inlet and exit. If no conditions are held fixed at the exit, the results always converge to the supersonic solution, even if the fixed inlet mass flow is less than critical. In such a case, the program appears to generate additional mass flow between the inlet and throat, sufficient to choke the flow. These results also have some impact on two- and three-dimensional time-dependent solutions where subsonic flow is present on some or all portions of the flow boundaries.}
}
@article{SAMSONOVICH2022824,
title = {Key Advanced Research Initiative: A Manifesto for the New-Generation Artificial Intelligence},
journal = {Procedia Computer Science},
volume = {213},
pages = {824-831},
year = {2022},
note = {2022 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: The 13th Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.140},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922018397},
author = {Alexei V. Samsonovich and Sergey A. Shumsky and Valery E. Karpov and Artemy A. Kotov and Anton G. Kolonin},
keywords = {AGI, humanlike AI, strong AI, virtual evolution, machine learning, evolutionary computation, artificial creativity, anthropocentric AI},
abstract = {The goal here is to identify key directions for the future advanced research initiatives in Artificial Intelligence (AI) and beyond. The following areas are identified as having particular importance: (1) socially emotional, ethical, and moral AI, (2) self-developing and self-sustainable AI, and (3) human-analogous AI, inspired by the human psychology. As a result, a general concept is formulated with the intent to clarify and unify the currently popular slogans, including Artificial General Intelligence (AGI), Strong AI, Human-Level or Humanlike AI (HLAI), Brain-Inspired or Biologically Inspired Cognitive Architectures (BICA), and more. The key idea of the proposed concept is that future AI must open a new angle of view and new perspectives to humans, thereby enriching and transforming the society, helping it to solve its problems and taking the civilization to a new level. While being created by humans, for humans, and fully compatible with humans at the social level, it will not be “a human in silicon”, but rather an “alien”: intelligent, friendly, and welcome. Its principles will combine preprogrammed basic functions and its own natural ontogeny in a virtual social environment. Forms of implementation will range from virtual entities to wearable electronics and autonomous robots. The expected impact on the society will be immense and crucial for its survival.}
}
@article{WANG20221,
title = {The past and future of mapping the biomarkers of psychosis},
journal = {Current Opinion in Behavioral Sciences},
volume = {43},
pages = {1-5},
year = {2022},
issn = {2352-1546},
doi = {https://doi.org/10.1016/j.cobeha.2021.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352154621001261},
author = {Ling-Ling Wang and Simon SY Lui and Raymond CK Chan},
abstract = {Biomarker research has investigated the neurobiological basis for individual differences in liability to psychosis. However, few biomarkers for psychosis have been consistently found to be useful. This paper reviews several previous approaches to identify putative biomarkers of liability to psychosis, and then highlights the lessons that we have learned. We argue that limiting our research to clinical patients at the extreme of the psychosis continuum would likely obscure our knowledge as to how a minority of the general population would develop psychosis. Research on putative neurobiological origins of inter-individual differences in personality traits may be useful in mapping the biomarkers of psychosis. To identify biomarkers applicable to the general population, we advocate the transdiagnostic and psychosis continuum approach. We also advocate the use of multivariate analyses and computational modelling to tackle complex multi-modal datasets. More research should be conducted to study intra-individual variations over different ranges of timescale.}
}
@article{BRANASGARZA2012254,
title = {Cognitive effort in the Beauty Contest Game},
journal = {Journal of Economic Behavior & Organization},
volume = {83},
number = {2},
pages = {254-260},
year = {2012},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2012.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0167268112001278},
author = {Pablo Brañas-Garza and Teresa García-Muñoz and Roberto Hernán González},
keywords = {Beauty Contest Game, Raven, Cognitive Reflection Test},
abstract = {This paper analyzes cognitive effort in 6 different oneshot p-beauty games. We use both Raven and Cognitive Reflection tests to identify subjects’ abilities. We find that the Raven test does not provide any insight on Beauty Contest Game playing but CRT does: subjects with higher scores on this test are more prone to play dominant strategies. The results are confirmed when levels of reasoning instead of entries in the BCG are used.}
}
@article{WORTMANN2017173,
title = {Differentiating parametric design: Digital workflows in contemporary architecture and construction},
journal = {Design Studies},
volume = {52},
pages = {173-197},
year = {2017},
note = {Parametric Design Thinking},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2017.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X17300352},
author = {Thomas Wortmann and Bige Tunçer},
keywords = {parametric design, design automation, architectural design, software design, parametric master model},
abstract = {This paper examines Parametric Design (PD) in contemporary architectural practice. It considers three case studies: The Future of Us pavilion, the Louvre Abu Dhabi and the Morpheus Hotel. The case studies illustrate how, compared to non-parametrically and older parametrically designed projects, PD is employed to generate, document and fabricate designs with a greater level of detail and differentiation, often at the level of individual building components. We argue that such differentiation cannot be achieved with conventional Building Information Modelling and without customizing existing software. We compare the case studies' PD approaches (objected-oriented programming, functional programming, visual programming and distributed visual programming) and decomposition, algorithms and data structures as crucial factors for the practical viability of complex parametric models and as key aspects of PD thinking.}
}
@incollection{TIN1994299,
title = {Baby-Sit: Towards a situation-theoretic computational environment},
editor = {Carlos Martín-Vide},
series = {North-Holland Linguistic Series: Linguistic Variations},
publisher = {Elsevier},
volume = {56},
pages = {299-308},
year = {1994},
booktitle = {Current Issues in Mathematical Linguistics},
issn = {0078-1592},
doi = {https://doi.org/10.1016/B978-0-444-81693-1.50034-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780444816931500348},
author = {Erkan Tin and Varol Akman},
abstract = {Publisher Summary
This chapter provides an overview of a situation-theoretic computational environment. Situation theory was first formulated in detail by Jon Barwise and John Perry in 1983. Various versions of the theory have been applied to a number of linguistic issues, resulting in what is commonly known as situation semantics. Individuals, properties, relations, spatio-temporal locations, and situations are the basic constructs of situation theory. The world is viewed as a collection of objects, sets of objects, properties, and relations. Infons are discrete items of information and situations are first-class objects that describe parts of the real world. Information flow is made possible by a network of abstract links among high-order uniformities, viz. situation types. The chapter presents a computational approach to situation theory and its associated environment (called BABY-SIT). The environment is dubbed BABY-SIT because it is believed that presently it includes far too many provisional, make-shift design decisions. The chapter highlights that compared to existing approaches, BABY-SIT enhances the basic features of situation theory.}
}
@article{HORWICH201323622,
title = {Chaperonin-mediated Protein Folding},
journal = {Journal of Biological Chemistry},
volume = {288},
number = {33},
pages = {23622-23632},
year = {2013},
issn = {0021-9258},
doi = {https://doi.org/10.1074/jbc.X113.497321},
url = {https://www.sciencedirect.com/science/article/pii/S0021925820452524},
author = {Arthur L. Horwich},
keywords = {Protein Folding, Chaperone Chaperonin, Molecular Chaperone, Yeast, Protein Misfolding, Polypeptide},
abstract = {We have been studying chaperonins these past twenty years through an initial discovery of an action in protein folding, analysis of structure, and elucidation of mechanism. Some of the highlights of these studies were presented recently upon sharing the honor of the 2013 Herbert Tabor Award with my early collaborator, Ulrich Hartl, at the annual meeting of the American Society for Biochemistry and Molecular Biology in Boston. Here, some of the major findings are recounted, particularly recognizing my collaborators, describing how I met them and how our great times together propelled our thinking and experiments.}
}
@article{FESTA2024,
title = {Incidence of circular refurbishment measures on indoor air quality and comfort conditions in two real buildings: Experimental and numerical analysis},
journal = {Energy and Built Environment},
year = {2024},
issn = {2666-1233},
doi = {https://doi.org/10.1016/j.enbenv.2024.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S2666123324000394},
author = {Valentino Festa and Silvia Ruggiero and Sara Riccardi and Margarita- Niki Assimakopoulos and Dimitra Papadaki},
keywords = {Energy building refurbishment, Experimental campaign, Indoor air quality, Thermal comfort, Computational fluid dynamics analysis},
abstract = {The application of Circular Economy to construction sector is a key to attain carbon neutrality, since it is responsible of 40 % of natural resource consumption. In this frame the importance of an efficient building refurbishment process throughout recycled material and renewable energy is fundamental. From an overview about building refurbishment emerges the need to investigate aspects related to Indoor Environmental Quality and the comparison between in-field measurements with output of dynamic simulation models. The present study aims to fill these two gaps by means an energy renovation of two real buildings in Greece. The work develops within the European project “Drive 0″, born to promote deep environmentally friendly retrofitting by means of circular renovation concepts. The methodological approach involves on-site monitoring of a series of parameters describing the energy, microclimate environmental and air quality, before and after the energy requalification. In addition, a numerical model developed in Building Energy Simulation program is calibrated and a Computational Fluid Dynamics is developed. From the in-field measurements emerges that, on one hand, the refurbishment of heating system shows a great improvement of indoor thermal conditions, with Total Volatile Organic Compounds concentration that sometimes exceed 3.0 mg/m3; on the other hand an integrated thermal insulation reduces infiltrations and changes the envelope behaviour, with a global energy saving of 30 % during winter and autumn periods. Another result of the study shows that a numerical model developed in Building Energy Simulation program and calibrated on energy consumption can greatly fit the local thermal comfort distribution of the occupant zone and predict the indoor air quality, if it outputs are used as input data in a Computational Fluid Dynamics study. These results can be beneficial to decision makers and designers for evaluating emitters positioning, opening design and mechanical ventilation strategies, aimed at reducing energy costs.}
}
@article{KISELEV2022e09664,
title = {Predicting verbal reasoning from virtual community membership in a sample of Russian young adults},
journal = {Heliyon},
volume = {8},
number = {6},
pages = {e09664},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e09664},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022009525},
author = {Pavel Kiselev and Valeriya Matsuta and Artem Feshchenko and Irina Bogdanovskaya and Boris Kiselev},
keywords = {Verbal reasoning, Social networking site, Virtual community, Machine learning},
abstract = {Predicting personality traits from social networking site profiles can help to assess individual differences in verbal reasoning without using long questionnaires. Inspired by earlier studies, which investigated whether abstract-thinking ability are predictable by social networking sites data, we used supervised machine learning to predict verbal-reasoning ability based on a proposed set of features extracted from virtual community membership. A large sample (N = 3,646) of Russian young adults aged 18–22 years approved access to the data from their social networking accounts and completed an online test on verbal reasoning. We experimented with binary classification machine-learning models for verbal-reasoning prediction. Prediction performance was tested on isolated control subsamples for men and women. The results of prediction on AUC-ROC metrics for control subsamples over 0.7 indicated reasonably good performance on predicting verbal-reasoning level. We also investigated the contribution of virtual community's genres to verbal reasoning level prediction for male and female participants. Theoretical interpretations of results stemming from both Vygotsky's sociocultural theory and behavioural genomics are discussed, including the implication that virtual communities make up a non-shared environment that can cause variance in verbal reasoning. We intend to conduct studies to explore the implications of the results further.}
}
@article{ROSSI2011820,
title = {MAPIT: a pedagogical-relational ITS},
journal = {Procedia Computer Science},
volume = {3},
pages = {820-826},
year = {2011},
note = {World Conference on Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2010.12.135},
url = {https://www.sciencedirect.com/science/article/pii/S1877050910005107},
author = {Pier Giuseppe Rossi and Simone Carletti},
keywords = {Teachers’ thinking, Intelligent tutoring system, Multi agent system, Learning management system, Tracking data, Chat-bot},
abstract = {The majority of Intelligent Tutoring System architectures are focused on supporting learners through content retrieval or in one or more given subject matters; examples of this can be found in Baghera [1], MyClass, Andes [2], Gramy, Advanced Geometry Tutor [7]. The implementation of such architectures are time-consuming and are generally not interoperable with other domains [3]. The presented research describes the experimentation of a Open Source, LMS enhanced with elements of AI aiming at supporting online teachers’ and tutors’ work by using a KB specific to relational and pedagogical aspects, not connected to a specific subject matter. Such implementation needs to be provided of an authoring tool easily and readily usable by tutors and teachers of different subjects and with medium level IT training. Starting point of our investigation has been a preliminary analysis of machine-mediated, human-human interactions (MM-HHI) and communications by using the Teachers’ thinking approach [4], [5], [6]. We considered messages exchanged between teachers/tutors and online students in three post-graduate, online courses running at the University of Macerata during 2008–2010 by the Faculty of Education. The study showed that about 30% of messages concerned structured information that could be straightforwardly retrieved by an artificial agent; almost all remaining messages were instead deeply bound to student’s learning path or required a significant input by the teacher/tutor, while the residual part of messages could — to some extents — be delegated to an intelligent agent having access to students’ tracking data in order to display visual information to users or trigger alarms to tutors. The investigation carried out prompted us for the deployment of an Open Source chat-bot system that would retrieve information already coded into the courses or originated by students through the analysis of their activity logs; the chat-bot agent uses this structured information in order to answer students’ most common questions hence relieving teachers and tutors from doing this repetitive task. The system is being implemented on a OLAT ver. 6.3 LMS loosely coupled to a JADE-based Multi Agent System in charge of processing user tracking data and running the ALICE chat-bot integrated with the platform messaging system.}
}
@article{KOLIBIUS2025,
title = {On the origin of memory neurons in the human hippocampus},
journal = {Trends in Cognitive Sciences},
year = {2025},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2025.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S1364661325000312},
author = {Luca D. Kolibius and Sheena A. Josselyn and Simon Hanslmayr},
keywords = {episodic memory, hippocampus, concept neurons, Indexing Theory, single neurons, conjunctive coding, memory trace, engram},
abstract = {The hippocampus is essential for episodic memory, yet its coding mechanism remains debated. In humans, two main theories have been proposed: one suggests that concept neurons represent specific elements of an episode, while another posits a conjunctive code, where index neurons code the entire episode. Here, we integrate new findings of index neurons in humans and other animals with the concept-specific memory framework, proposing that concept neurons evolve from index neurons through overlapping memories. This process is supported by engram literature, which posits that neurons are allocated to a memory trace based on excitability and that reactivation induces excitability. By integrating these insights, we connect two historically disparate fields of neuroscience: engram research and human single neuron episodic memory research.}
}
@article{WOLFENGAGEN2024101185,
title = {Semantic configuration model with natural transformations},
journal = {Cognitive Systems Research},
volume = {83},
pages = {101185},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2023.101185},
url = {https://www.sciencedirect.com/science/article/pii/S1389041723001195},
author = {Viacheslav Wolfengagen and Larisa Ismailova and Sergey Kosikov and Igor Slieptsov and Sebastian Dohrn and Alexander Marenkov and Vladislav Zaytsev},
keywords = {Information process, Configuration, Morphing, Cognitive preference, Semantic net, Functor, Natural transformation},
abstract = {In the present work, efforts have been made to create a configuration-based approach to knowledge extraction. The notion of granularity is developed, which allows fine-tuning the expressive possibilities of the semantic network. As known, the central issues for knowledge-based systems are what’s-in-a-node and what’s-in-a-link. As shown, the answer can be obtained from the functor-as-object representation. Then the nodes are functors, and the main links are natural transformations. Such a model is applicable to represent morphing, and the object is considered as a process, which is in a harmony with current ideas on computing. It is possible to represent information channels that carry out the transformations of processes. The possibility of generating displaced concepts and the generation of families of their morphs is shown, the evolvent of stages of knowledge and properties of the process serve as parameters.}
}
@article{FALOMIR201931,
title = {Special issue on problem-solving, creativity and spatial reasoning},
journal = {Cognitive Systems Research},
volume = {58},
pages = {31-34},
year = {2019},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2019.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S138904171930261X},
author = {Zoe Falomir and Ana-Maria Olteţeanu},
keywords = {Cognitive systems, Problem-solving, Creativity, Computational creativity, Spatial reasoning, Cognition, General artificial intelligence, Spatial cognition},
abstract = {Problem-solving, creativity and spatial reasoning are high level abilities of cognitive systems with high potential for synergies. However, they have been treated separately by different fields. This special issue presents research work on these topics, aiming to observe their interrelations in order to create theoretical approaches, methodologies and computational tools to advance work on creativity and spatial problem-solving in cognitive systems.}
}
@article{CAMARGO20181116,
title = {A method for integrated process simulation in the mining industry},
journal = {European Journal of Operational Research},
volume = {264},
number = {3},
pages = {1116-1129},
year = {2018},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2017.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0377221717306409},
author = {Luis Felipe Riehs Camargo and Luis Henrique Rodrigues and Daniel Pacheco Lacerda and Fabio Sartori Piran},
keywords = {O.R. in natural resources, Production, Simulation, Systems thinking},
abstract = {This paper proposes a method of Integrated Process Simulation (MIPS), which considers the dynamic, stochastic and systemic characteristics of mining operations to support investment decisions in this industry. This MIPS supports development of a Decision Support System (DSS) that considers product quality, process productivity and production costs. A case study is described that used the MIPS to make better investment decisions. The MIPS has proven, in practice, to be effective in several applications; for example, in defining the maintenance policy for critical equipment in an iron ore concentration plant; the process for removing impurities and simulating the company's budget to evaluate the viability of different business plans.}
}
@article{WOZNIAK2023489,
title = {BiLSTM deep neural network model for imbalanced medical data of IoT systems},
journal = {Future Generation Computer Systems},
volume = {141},
pages = {489-499},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22004095},
author = {Marcin Woźniak and Michał Wieczorek and Jakub Siłka},
keywords = {Medical informatics, Deep learning, Multi-optimization learning, BiLSTM, IoT},
abstract = {Health informatics is one of the most developed field in recent time. Computational Intelligence is among the most influential factors that may help to improve patient oriented and secure decision support model. In this article we present a model of IoT system, which combines BiLSTM deep learning with Decision Tree model and data balancing strategy used to help in automated diagnosis support. Presented solution include experimental series of data preprocessing using well established balancing algorithms with custom parameters and modifications in order to best prepare the data for the network training. Such algorithms are ADASYN, SMOTE-Tomek, etc. The system helps to evaluate questionnaires and securely exchange documents between patient and corresponding medical team. From the level of system patient and doctors are able to see automated diagnosis provided by deep learning model. The model gives an important advance to help patients faster. Results show that proposed BiLSTM deep learning with decision tree mode detects diseases from questionnaires with accuracy above 96%, precision above 88% and recall above 96% which proves efficiency of our proposed model.}
}
@article{FAYEZ2023105905,
title = {Moringa extract reverses pilocarpine-induced hippocampal sclerosis in rats with temporal lobe epilepsy},
journal = {Journal of Functional Foods},
volume = {111},
pages = {105905},
year = {2023},
issn = {1756-4646},
doi = {https://doi.org/10.1016/j.jff.2023.105905},
url = {https://www.sciencedirect.com/science/article/pii/S1756464623005054},
author = {Shaimaa Fayez and Nourhan {Hisham Shady} and Iten M. Fawzy and Sherif A. Maher and Entesar {Ali saber} and Mahmoud Elrehany and Alaa M. Alqahtani and Esam S. Allehyani and Ahmed M. Shawky and Usama {Ramadan Abdelmohsen} and Nada M. Mostafa},
keywords = {, Moringinine A, Computational studies, Epilepsy},
abstract = {The horseradish tree “Moringa oleifera” is the most nutritious terrestrial plant around the globe. Although native to India, its fast growth and drought resistance ability enabled the plant to be cultivated worldwide. In the current study, we report on the isolation of a new phenolic methyl ester namely moringinine A (1) along with four other known compounds viz. caffeic acid (2), ferulic acid (3), 4-hydroxybenzonitrile (4), and 4-hydroxyphenyl acetic acid (5) from Moringa seeds. The later compound was first to be isolated from family Moringaceae. Compounds identification was guided by interplay of NMR and HR-ESI-MS analysis. Anti-epileptic studies conducted in vivo showed that the extract attenuates convulsions by suppressing stress–induced pro-inflammatory markers TNF-α, IL-1β, IL-6, and IFN-ɣ whereas upregulating the anti-inflammatory markers TGF-β and IL-10 in the hippocampal tissues of epileptic rats. The isolated compounds were subjected to computational studies through docking on lactate dehydrogenase A(LDH) and interleukin-6 (IL-6), where all showed binding modes and interaction energies comparable to those of the reference drug diazepam. ADME investigation revealed good pharmacokinetic and drug-likeness properties. These results show that Moringa oleifera seeds could potentially be used as adjuvant in the management of epilepsy.}
}
@article{XIE2024,
title = {Wide human-like neural network incorporating driving styles for human-like driving intention analysis},
journal = {Journal of Intelligent Transportation Systems},
year = {2024},
issn = {1547-2450},
doi = {https://doi.org/10.1080/15472450.2024.2425304},
url = {https://www.sciencedirect.com/science/article/pii/S1547245024000471},
author = {Jiming Xie and Yan Zhang and Yaqin Qin and Ke Li and Shuai Dong and Siyu Liu and Yulan Xia},
keywords = {autonomous vehicle, decision making, driving intention, human driving vehicle, width human-like neural network},
abstract = {Enhancing the synergy between autonomous and human-driven vehicles at the societal level requires understanding drivers’ behaviors and cognitive patterns, as well as conducting human-like driving intention analysis. To achieve this goal, this study designs a novel framework for analyzing human-like driving intention. Firstly, a spectral clustering method is employed to characterize driving styles. Secondly, a misclassification cost matrix is tailored to different driving needs. Finally, inspired by the complex neural networks found in the human brain, we develop a specialized lightweight neural network, termed the Width Human-like Neural Network (WNN), aimed at realizing personalized cognition and facilitating human-like decision-making in driving intention. Experimental studies and validation based on natural driving trajectory data from Kunming, China, demonstrate that the method accurately infers internal implicit driving intention from external explicit and observable driving behaviors, achieving a prediction accuracy of 99.8%. This framework strategically allocates limited computational resources to critical areas for autonomous vehicles and exemplifies best practices for improving neural network performance in driving intention analysis tasks.}
}
@incollection{OGRADY2020135,
title = {Cyber Security},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {135-141},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10532-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955105323},
author = {Nathaniel O'Grady and Andrew C. Dwyer},
keywords = {Computing, Cybersecurity, Cyberspace, Digital, Infrastructure, Networks, Privacy, Software, Surveillance},
abstract = {As computation has become increasingly integrated into everyday life, critical infrastructure, state defense, and cybersecurity has become a new, crucial area of inquiry for geographers. This is due to the fast-changing, new securities that are being formed and enabled through, by and because of the growing role of computation. Geographers have studied cybersecurity as collectively constituted through a complex mixture of technologies, materialities, cultures, knowledges. In so doing, they have probed a range of phenomena crucial to cybersecurity; from technical processes such as encryption, malware infection, and threat detection, to the social arrangements and negotiations between various organizations and states, the implications of surveillance and big data on privacy, and how threats affect various infrastructure that support ways of life across the globe. Nevertheless, geographers do not simply consider cybersecurity as a mode of security imposed “online” or through digital technologies. Rather, in its practice, geographers have demonstrated how cybersecurity involves and invokes socio-political complications around criminality, protection, inequalities, privacy, surveillance, private enterprise, and the role of the state in the life of citizens.}
}
@article{FORREST19901,
title = {Emergent computation: Self-organizing, collective, and cooperative phenomena in natural and artificial computing networks: Introduction to the proceedings of the ninth annual CNLS conference},
journal = {Physica D: Nonlinear Phenomena},
volume = {42},
number = {1},
pages = {1-11},
year = {1990},
issn = {0167-2789},
doi = {https://doi.org/10.1016/0167-2789(90)90063-U},
url = {https://www.sciencedirect.com/science/article/pii/016727899090063U},
author = {Stephanie Forrest}
}
@article{BYLANDER1994165,
title = {The computational complexity of propositional STRIPS planning},
journal = {Artificial Intelligence},
volume = {69},
number = {1},
pages = {165-204},
year = {1994},
issn = {0004-3702},
doi = {https://doi.org/10.1016/0004-3702(94)90081-7},
url = {https://www.sciencedirect.com/science/article/pii/0004370294900817},
author = {Tom Bylander},
abstract = {I present several computational complexity results for propositional STRIPS planning, i.e., STRIPS planning restricted to ground formulas. Different planning problems can be defined by restricting the type of formulas, placing limits on the number of pre-and postconditions, by restricting negation in pre- and postconditions, and by requiring optimal plans. For these types of restrictions, I show when planning is tractable (polynomial) and intractable (NP-hard). In general, it is PSPACE-complete to determine if a given planning instance has any solutions. Extremely severe restrictions on both the operators and the formulas are required to guarantee polynomial time or even NP-completeness. For example, when only ground literals are permitted, determining plan existence is PSPACE-complete even if operators are limited to two preconditions and two postconditions. When definite Horn ground formulas are permitted, determining plan existence is PSPACE-complete even if operators are limited to zero preconditions and one postcondition. One of the interesting tractable problems is if each operator is restricted to positive preconditions and one postcondition (only ground literals). The blocks-world problem, slightly modified, is a subproblem of this restricted planning problem. These results in combination with previous analyses are not encouraging for domain-independent planning.}
}
@article{CHEN2024132899,
title = {A novel offshore wind power prediction model based on TCN-DANet-sparse transformer and considering spatio-temporal coupling in multiple wind farms},
journal = {Energy},
volume = {308},
pages = {132899},
year = {2024},
issn = {0360-5442},
doi = {https://doi.org/10.1016/j.energy.2024.132899},
url = {https://www.sciencedirect.com/science/article/pii/S0360544224026732},
author = {Juntao Chen and Xueying Fu and Lingli Zhang and Haoye Shen and Jibo Wu},
keywords = {Dual attention network, Temporal convolutional network, Offshore wind power prediction, Sparse transformer, Spatio-temporal coupling},
abstract = {Offshore wind power capacity is growing, leading to larger clustered farms. Accurately predicting offshore wind power capacity is crucial for power system stability; however, current studies often overlook neighbouring installations. To address this, this study presents the Temporal Convolutional Network-Dual Attention Network-Sparse Transformer (TCN-DANet-Sparse Transformer) model, which considers the spatiotemporal coupling of multiple wind farms. Before detailing our model, we review the existing prediction methods, noting their limitations in capturing interconnected adjacent wind farms. Our model integrates spatial information from nearby farms to enhance prediction reliability. Through Pearson Correlation Coefficient analysis, we explore the temporal and spatial coupling features. Using overlapping sliding windows, we partition farms into subsequences, processed with TCN-DANet for efficient spatio-temporal feature extraction. These features are then input into the Sparse Transformer to improve the computational efficiency. Validated using a dataset from Kächele et al., our model outperforms the baseline on the London Wind Farm. In spring, for Case 1, the mean square error (MSE) of the main model decreased by 43.19 % compared to that of the TCN-DANet-transformer model. Similarly, for Case 2, the MSE of the main model is reduced by 41.69 %.}
}
@article{PEZZULO2013270,
title = {Action simulation in the human brain: Twelve questions},
journal = {New Ideas in Psychology},
volume = {31},
number = {3},
pages = {270-290},
year = {2013},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2013.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X13000263},
author = {Giovanni Pezzulo and Matteo Candidi and Haris Dindo and Laura Barca},
keywords = {Action simulation, Internal model, Forward model, Motor control, Action understanding},
abstract = {Although the idea of action simulation is nowadays popular in cognitive science, neuroscience and robotics, many aspects of the simulative processes remain unclear from empirical, computational, and neural perspectives. In the first part of the article, we provide a critical review and assessment of action simulation theories advanced so far in the wider literature of embodied and motor cognition. We focus our analysis on twelve key questions, and discuss them in the context of human and (occasionally) primate studies. In the second part of the article, we describe an integrative neuro-computational account of action simulation, which links the neural substrate (as revealed in neuroimaging studies of action simulation) to the components of a computational architecture that includes internal modeling, action monitoring and inhibition mechanisms.}
}
@incollection{DAS2025193,
title = {Chapter 15 - Systems pharmacology – principles, methods and applications},
editor = {Babak Sokouti},
booktitle = {Systems Biology and In-Depth Applications for Unlocking Diseases},
publisher = {Academic Press},
pages = {193-206},
year = {2025},
isbn = {978-0-443-22326-6},
doi = {https://doi.org/10.1016/B978-0-443-22326-6.00015-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780443223266000158},
author = {Arpan Jyoti Das and Habeeb {Shaik Mohideen}},
keywords = {CADD, Computational biology, Molecular network, Omics networking, Systems biology, Systems pharmacology},
abstract = {Socializing has become much easier with the advent of scintillating discoveries and technological advancements in computer science, information technology applications, and of course, the indispensable Internet. Historical and unimaginable success has been achieved by breaking horizons in almost all the fields, but biology. Biological phenomena are so difficult to understand because of the complex cross-talks between different entities such as DNA, RNA, proteins, lipids, carbohydrates, and their relevant downstream postprocessing modifications. The dance and interplay involving these moieties as a function of a drug is called as Systems Pharmacology. The multiscale modeling and simulation approach of systems pharmacology employ computational models to simulate drug effects at various levels, from molecular interactions to organ-level responses, allowing for a more comprehensive understanding of drug action. In this chapter, we will delve into the historical landscapes, methods and principles, tools, applications, frameworks, and benefits of systems pharmacology that will give a beginner a comprehensive understanding of the field.}
}
@article{SHRYANE2020112806,
title = {Is cognitive behavioural therapy effective for individuals experiencing thought disorder?},
journal = {Psychiatry Research},
volume = {285},
pages = {112806},
year = {2020},
issn = {0165-1781},
doi = {https://doi.org/10.1016/j.psychres.2020.112806},
url = {https://www.sciencedirect.com/science/article/pii/S0165178119302793},
author = {Nick Shryane and Richard Drake and Anthony P. Morrison and Jasper Palmier-Claus},
keywords = {Psychosis, Cognitive behavioural therapy, Thought disorder, Randomized Controlled Trial},
abstract = {Various clinical guidelines recommend cognitive behavioural therapy (CBT) to treat psychosis without reference to patients’ thought disorder. However, there is a risk that disorganized thinking hampers CBT. We tested the prediction that thought disorder would interfere with the effectiveness of CBT for hallucinations and delusions, compared to treatment as usual and supportive counselling, in secondary data from two large, single blind randomised controlled trials. We fitted latent growth curve models separately for the development of frequency and distress of symptoms. CBT was significantly more successful than counselling in reducing delusional frequency in the short term and hallucinatory distress at any point, even in those with relatively high thought disorder. We found little evidence that clinicians should restrict CBT in this subgroup of patients. Nevertheless, the findings highlight the importance of effective initial treatment of thought disorder in maximising the benefit of CBT for psychosis, particularly for reducing distress from hallucinations.}
}
@article{JOHNSON1989319,
title = {Exploiting parallelism in computational science},
journal = {Future Generation Computer Systems},
volume = {5},
number = {2},
pages = {319-337},
year = {1989},
note = {Grand Challenges to Computational Science},
issn = {0167-739X},
doi = {https://doi.org/10.1016/0167-739X(89)90050-2},
url = {https://www.sciencedirect.com/science/article/pii/0167739X89900502},
author = {Gary M. Johnson},
abstract = {The full exploitation of numerical simulation as an independent approach to the solution of engineering and scientific problems requires computing capability far exceeding that which is presently available. In this paper, the computing requirements posed by challenging problems in several disciplines are examined and contrasted with contemporary supercomputer resources. Of the means available to help fill the gap between the demands of computational science and the performance level of present-generation supercomputer systems, parallel processing appears to have the greatest potential for near-term success. Parallel computer architectures are reviewed and categorized according to processing units, memory, and interconnection scheme. Philosophies of parallel processing are discussed. They are distinguished by the number and size of the parallel tasks which they employ. Scientific problems are examined for parallelism inherent at the physical level. Typical algorithms and their mappings onto parallel architectures are discussed. Computational examples are presented to document the performance of scientific applications on present-generation parallel processors. Projections are made concerning software developments and machine architectures.}
}
@article{ARORA1990131,
title = {Computational design optimization: A review and future directions},
journal = {Structural Safety},
volume = {7},
number = {2},
pages = {131-148},
year = {1990},
issn = {0167-4730},
doi = {https://doi.org/10.1016/0167-4730(90)90063-U},
url = {https://www.sciencedirect.com/science/article/pii/016747309090063U},
author = {Jasbir S. Arora},
keywords = {optimization methods, nonlinear problems, review, computational aspects, engineering design},
abstract = {A mathematical model for design optimization of engineering systems is defined. Computational algorithms to treat the model are reviewed and their features are discussed. The attributes of a good algorithm are given. Sequential quadratic programming algorithms that generate and use the approximate Hessian of the Lagrange function to calculate the search direction are the most recent methods. They are the most reliable methods among the available ones. Several other computational aspects, such as robust implementation of algorithms, use of a knowledge base, interactive use of optimization, and use of a database and database management system, are discussed. Recent developments in the field and future directions are presented.}
}
@article{FATH2005485,
title = {Elucidating public perceptions of environmental behavior: a case study of Lake Lanier},
journal = {Environmental Modelling & Software},
volume = {20},
number = {4},
pages = {485-498},
year = {2005},
note = {Vulnerability of Water Quality in Intensively Developing Urban Watersheds},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2004.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1364815204000611},
author = {Brian D. Fath and M.B. Beck},
keywords = {Cultural theory, Integrated environmental assessment, Stakeholder participation},
abstract = {Participation of stakeholders in stewardship of the aquatic environment, including participation from members of the general public, has become much more widespread than was the case a decade or so ago. With this shift, from a former predominantly technocratic stance to something of a democratic stance on the style of management, it becomes important to elucidate public perceptions of environmental behavior. The paper examines this issue: from a rather specific perspective, where the role of time is significant; with a specific purpose in mind—for defining illustrative stakeholder aspirations for the future, whose plausibility is to be assessed against a computational model of lake behavior; and for a specific case study, Lake Lanier in the Chattahoochee watershed of Georgia, USA. Perturbations and variation in the behavior of the aquatic environment span many time frames, from the very short-term response associated with storms, infrastructure failure, transient pollution events, and so on, to the much longer-term, for instance, the biogeochemical ‘ageing’ of a lake over many decades and more. Our analysis is devoted to data from a survey of stakeholder imagination and perceptions of how the future state of Lake Lanier may evolve in the relatively short term (2–5 years) and in the long term, defined as 25+ years (the span of a generation). Overall, stakeholders are pessimistic and fear that things will be worse in the longer term. Guided largely by thinking on the perspectives of the social solidarities of Cultural Theory, extraction and analysis of sub-samples of the survey responses show that this outlook over the two frames of time is persistent, irrespective of what are, in principle, rather different ‘global’ attitudes towards the man-environment relationship. Of interest inter alia to the foresight generating procedure, by which the ‘reachability’ of stakeholder-derived futures for the lake is to be assessed using a computational model of the relevant parts of the science base, is the question of whether the same small number of priorities for further research on lake behavior is robust in the face of the rich variety of aspirations for the future inevitable in a democratic community of stakeholders.}
}
@incollection{MILLER2020181,
title = {Chapter eight - Data science and the exposome},
editor = {Gary W. Miller},
booktitle = {The Exposome (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
pages = {181-209},
year = {2020},
isbn = {978-0-12-814079-6},
doi = {https://doi.org/10.1016/B978-0-12-814079-6.00008-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128140796000080},
author = {Gary W. Miller},
keywords = {Bioinformatics, systems biology, models, computational biology, machine learning, Bayesian methods, artificial intelligence, causal inference},
abstract = {Data science is focused on extracting meaningful value from complex datasets. Exposome-related data are certainly complex with information coming from a myriad of sources. The huge amounts of data must be organized in some manner that allows appropriate interpretations and associations to be drawn. It is unlikely that unsupervised approaches will allow for causal associations to be made, but with proper study design and appropriate statistical and computational models, it should be possible to derive meaningful connections between complex exposures and specific health outcomes. The complex types of data will undoubtedly require sophistical mathematical approaches, including bioinformatics, computational, machine learning, and systems biology-based techniques. This chapter reviews some of the possible strategies that can be used to keep track of the diverse and massive datasets that will result from exposome research.}
}
@article{CHEN201217,
title = {Data-Brain driven systematic human brain data analysis: A case study in numerical inductive reasoning centric investigation},
journal = {Cognitive Systems Research},
volume = {15-16},
pages = {17-32},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2010.12.014},
url = {https://www.sciencedirect.com/science/article/pii/S138904171100012X},
author = {Jianhui Chen and Ning Zhong and Peipeng Liang},
keywords = {Data-Brain, Systematic human brain data analysis, Provenance, Brain Informatics},
abstract = {As a crucial step in understanding human intelligence, Brain Informatics (BI) focuses on thinking centric investigations of human cognitive functions with respect to multiple activated brain areas and neurobiological processes for a given task. Although it has been recognized that systematic human brain data analysis is an important issue of BI methodology, the existing expert-driven multi-aspect data analysis excessively depends on individual capabilities and cannot be widely adopted in BI community. In this paper, we propose a Data-Brain driven approach for systematic brain data analysis, which is implemented by using the Data-Brain, Data-Brain based BI provenances and Global Learning Scheme for BI. Furthermore, a human numerical inductive reasoning centric investigation is described to demonstrate significance and usefulness of the proposed approach. Such a Data-Brain driven approach reduces the dependency on individual capabilities and provides a practical way for realizing the systematic human brain data analysis of BI methodology.}
}
@article{BESOLD201597,
title = {Towards integrated neural–symbolic systems for human-level AI: Two research programs helping to bridge the gaps},
journal = {Biologically Inspired Cognitive Architectures},
volume = {14},
pages = {97-110},
year = {2015},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2015.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X15000468},
author = {Tarek R. Besold and Kai-Uwe Kühnberger},
keywords = {Research program, Neural–symbolic integration, Complexity theory, Cognitive architectures, Agent architectures},
abstract = {After a human-level AI-oriented overview of the status quo in neural–symbolic integration, two research programs aiming at overcoming long-standing challenges in the field are suggested to the community: The first program targets a better understanding of foundational differences and relationships on the level of computational complexity between symbolic and subsymbolic computation and representation, potentially providing explanations for the empirical differences between the paradigms in application scenarios and a foothold for subsequent attempts at overcoming these. The second program suggests a new approach and computational architecture for the cognitively-inspired anchoring of an agent’s learning, knowledge formation, and higher reasoning abilities in real-world interactions through a closed neural–symbolic acting/sensing–processing–reasoning cycle, potentially providing new foundations for future agent architectures, multi-agent systems, robotics, and cognitive systems and facilitating a deeper understanding of the development and interaction in human-technological settings.}
}
@article{PITTAPANTAZI2007301,
title = {Secondary school students’ levels of understanding in computing exponents},
journal = {The Journal of Mathematical Behavior},
volume = {26},
number = {4},
pages = {301-311},
year = {2007},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2007.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S0732312307000508},
author = {Demetra Pitta-Pantazi and Constantinos Christou and Theodossios Zachariades},
keywords = {Exponents, Prototype, Conceptual change},
abstract = {The aim of this study is to describe and analyze students’ levels of understanding of exponents within the context of procedural and conceptual learning via the conceptual change and prototypes’ theory. The study was conducted with 202 secondary school students with the use of a questionnaire and semi-structured interviews. The results suggest that three levels of understanding can be identified. At the first level students’ interpretation of exponents is based upon exponents that symbolize natural numbers. At Level 2, students’ knowledge acquisition process is a process of enrichment of the existing conceptual structures. Students at this level are able to compute exponents with negative numbers by extending the application of prototype examples. Finally, at Level 3 students not only extend the prototype examples but also reorganize their thinking in order to compute and compare exponents with roots, a concept which is quite different from the concept of exponents with natural numbers.}
}
@article{WEI2021189,
title = {Multi-core-, multi-thread-based optimization algorithm for large-scale traveling salesman problem},
journal = {Alexandria Engineering Journal},
volume = {60},
number = {1},
pages = {189-197},
year = {2021},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2020.06.055},
url = {https://www.sciencedirect.com/science/article/pii/S1110016820303227},
author = {Xin Wei and Liang Ma and Huizhen Zhang and Yong Liu},
keywords = {Multi-core, Multi-thread, Traveling Salesman Problem, Optimization Algorithm},
abstract = {With the rapid development of general hardware technology, microcomputers with multi-core CPUs have been widely applied in commercial services and household usage in the last ten years. Multi-core chips could, theoretically, lead to much better performance and computational efficiency than single-core chips. But so far, they have not shown general advantages for users, other than for operating systems and some specialized software. It is not easy to transform traditional single-core-based algorithms into multi-core-, multi-thread-based algorithms that can greatly improve efficiency, because of difficulties in computation and scheduling of hardware kernels, and because some programming languages cannot support multi-core, multi-thread programming. Therefore, a kind of multi-core-, multi-thread-based fast algorithm was designed and coded with Delphi language for the medium- and large-scale traveling salesman problem instances from TSPLIB, which can fully speed up the searching process without loss of quality. Experimental results show that the algorithm proposed can, under the given hardware limitations, take full advantage of multi-core chips and effectively balance the conflict between increasing problem size and computational efficiency and thus acquire satisfactory solutions.}
}
@article{LIEVENS2021128,
title = {A service design perspective on the stakeholder engagement journey during B2B innovation: Challenges and future research agenda},
journal = {Industrial Marketing Management},
volume = {95},
pages = {128-141},
year = {2021},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2021.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0019850121000791},
author = {Annouk Lievens and Vera Blažević},
keywords = {Stakeholder engagement, B2B innovation process, Stakeholder engagement journey, Innovation networks, Service design},
abstract = {Innovation in business-to-business (B2B) contexts deals with highly dynamic, complex, and heterogeneous constellations of stakeholders with a diversity of goals, motives, and capabilities that further challenge successful management of B2B innovation processes and outcomes. Complex challenges, such as sustainability and digitization trends, push these B2B firms to embrace new innovation methods that help them manage disruptive change. Service design thinking has emerged as an innovation management practice emphasizing a human-centered innovation process of user interactions, creativity, and learning mindsets. In this article, we aim to evaluate the challenges and develop a research agenda on how service design can effectively enable stakeholders' engagement during the B2B innovation process. We argue that to advance service design opportunities for stakeholder engagement, we need to address the unique complexities and challenges of stakeholder engagement during innovation from a systemic and dynamic process perspective. From a systemic perspective, we zoom in on the building blocks of stakeholder engagement and address multi-level stakeholder engagement platforms (i.e., innovation networks). From a dynamic process perspective, we treat stakeholder engagement as an emerging process and zoom in on the temporal and relational connections and hybrid orchestration to allow for both structural and emerging stakeholder engagement during innovation. We develop a stakeholder engagement journey in which we integrate service and innovation stages and propose how service design activities can support and facilitate the aforementioned challenges and complexities. Finally, we identify concrete research questions and, accordingly, develop a research agenda for future research on stakeholder engagement in B2B innovation trajectories.}
}
@article{CRILLY2021333,
title = {The Evolution of “Co-evolution” (Part II): The Biological Analogy, Different Kinds of Co-evolution, and Proposals for Conceptual Expansion},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {7},
number = {3},
pages = {333-355},
year = {2021},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2021.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S2405872621000927},
author = {Nathan Crilly},
keywords = {Design process, Design thinking, Creativity, Biological analogy, Interdisciplinarity},
abstract = {Descriptions of problem-solution “co-evolution” either explicitly or implicitly draw an analogy between processes of design and processes of biological evolution. Analogies of this kind are common in research because of their potential to assist in explanation and discovery. However, reviewing the design literature reveals that the discussion of design co-evolution has become disconnected from the biological analogy on which it is founded, and from which other disciplines draw. Here, I explore the function of the co-evolution analogy, provide an illustrative example from biology, and explore the varieties of co-evolution to which design might be compared. By doing so, I propose two possible directions for expanding the design co-evolution concept: (i) examining what co-evolves in addition to, or instead of, problems and solutions, and (ii) examining the different levels at which co-evolution occurs. Both of these proposals are illustrated with a variant of the design co-evolution diagram.}
}
@article{RANGANATHAN201958,
title = {Emotion Mining in Social Media Data},
journal = {Procedia Computer Science},
volume = {159},
pages = {58-66},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.160},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919313389},
author = {Jaishree Ranganathan and Angelina Tzacheva},
keywords = {Data Mining, Emotion, Microblog, Sentiment Analysis, Twitter},
abstract = {Emotions are known to influence the perception of human beings along with their memory, thinking and imagination. Human perception is important in today’s world in a wide range of factors including but not limited to business, education, art, and music. Microblogging and Social networking sites like Twitter, Facebook are challenging sources of information that allow people to share their feelings and thoughts on a daily basis. In this paper we propose an approach to automatically detect emotions on Twitter messages that explores characteristics of the tweets and the writer’s emotion using Support Vector Machine LibLinear model and achieve 98% accuracy. Emotion mining gained attraction in the field of computer science due to the vast variety of systems that can be developed and promising applications like remote health care system, customer care services, smart phones that react based on users’s emotion, vehicles that sense emotion of the driver. These emotions help understand the current state of user. In order to perform suitable actions or provide suggestions on how user’s can enhance their feeling for a better healthy life-style we use actionable recommendations. In this work we extract action rules with respect to the user emotions that help provide suggestions for user’s.}
}
@article{XIAO1996292,
title = {On the effects of ampoule tilting during vertical Bridgman growth: three-dimensional computations via a massively parallel, finite element method},
journal = {Journal of Crystal Growth},
volume = {167},
number = {1},
pages = {292-304},
year = {1996},
issn = {0022-0248},
doi = {https://doi.org/10.1016/0022-0248(96)00231-X},
url = {https://www.sciencedirect.com/science/article/pii/002202489600231X},
author = {Qiang Xiao and Satheesh Kuppurao and Andrew Yeckel and Jeffrey J. Derby},
abstract = {Three-dimensional convection and asymmetric radial segregation, caused by ampoule tilting during the vertical Bridgman growth, are analyzed using a novel, massively parallel, finite element model. The growth of cadmium telluride with a dilute dopant is considered and found to be surprisingly sensitive to the amount of tilt - as little as one degree of misalignment of the ampoule axis from the gravitational vector produces a significant three-dimensional flow and a concomitant skewing of the dopant distribution along the surface of the growing solid. This indicates the need for precise ampoule axis alignment to ensure process reproducibility. Analysis of the dopant distribution along the solid-liquid interface of the tilted system reveals a surface region more uniform in dopant concentration than any corresponding region of the interface of the perfectly aligned system. For systems in which low radial segregation is very important, growth with an intentional axis offset may be beneficial.}
}
@article{SCHULTZ2010174,
title = {Models and methods in motion: Declining the dogma dance},
journal = {Futures},
volume = {42},
number = {2},
pages = {174-176},
year = {2010},
note = {Epistemological pluralism in futures studies},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2009.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0016328709001736},
author = {Wendy Schultz},
abstract = {I take a communicative pragmatist and realist approach to futures studies. This implies a sensitivity to understanding what the audience can absorb and using futures methods effectively to create spaces for new futures. While Wilber's work affords us with new insights to engage with methodology, is not the only path. Indeed, it is intellectual bigotry to demand that everyone master the tools one personally deems most appropriate. Critical conversations about futures must remain open, where post-modernist and integral thinking widen our horizons, they are welcomed, where they straitjacket our thoughts, they are not.}
}
@article{CORPONI2021,
title = {Frontal lobes dysfunction across clinical clusters of acute schizophrenia},
journal = {Revista de Psiquiatría y Salud Mental},
year = {2021},
issn = {1888-9891},
doi = {https://doi.org/10.1016/j.rpsm.2021.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1888989121001324},
author = {Filippo Corponi and Yana Zorkina and Daniel Stahl and Andrea Murru and Eduard Vieta and Alessandro Serretti and Аnna Morozova and Alexander Reznik and Georgiy Kostyuk and Vladimir Pavlovich Chekhonin},
keywords = {Schizophrenia, Frontal lobe, Precision medicine, Cluster analysis, Machine learning},
abstract = {Introduction
Schizophrenia is a clinical construct comprising manifold phenotypes underlying heterogeneous biological underpinnings. The Positive and Negative Syndrome Scale (PANSS) represents the standard tool in the clinical characterization of patients affected by schizophrenia, allowing to detect different clinical profiles within the disorder. Frontal lobes are a key area of brain dysfunction in schizophrenia. We investigated whether different clinical profiles in acute schizophrenia show differences in frontal lobes dysfunction or not.
Methods
We defined PANSS-derived principal components in a sample of 516 acute patients. These components were used as clustering variables in a finite-mixture model. Frontal lobe impairment, measured with the frontal assessment battery (FAB) score, was adjusted for disease duration and compared across the clinical clusters with ANCOVA. A supervised-learning approach was then implemented to reveal most informative PANSS items.
Results
A three-cluster solution emerged: a first profile with high-moderate expression for the positive and excitability/hostility component; a second profile scoring high on depression/anxiety and low on other components; a third profile, comprising the majority of the study population (74%), with a heavy affection on the negative-disorganization dimensions. After controlling for disease duration, frontal lobe impairment significantly differed across the aforementioned clusters, with the third cluster being the most affected. Two PANSS items presented the highest predictive value for FAB total score.
Conclusions
Among negative and disorganization symptoms, “difficulty in abstract thinking” and “lack of spontaneity/flow in conversation” are specifically mapped to higher levels of frontal lobes dysfunction, hinting at similar features with other neurological disorders involving frontal lobes.}
}
@article{WANG2020256,
title = {Fine-grained neural decoding with distributed word representations},
journal = {Information Sciences},
volume = {507},
pages = {256-272},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2019.08.043},
url = {https://www.sciencedirect.com/science/article/pii/S0020025519307820},
author = {Shaonan Wang and Jiajun Zhang and Haiyan Wang and Nan Lin and Chengqing Zong},
keywords = {Neural decoding, fMRI word decoding, Word class, Stimuli paradigm, Word embedding models, Informative voxels},
abstract = {fMRI word decoding refers to decode what the human brain is thinking by interpreting functional Magnetic Resonance Imaging (fMRI) scans from people watching or listening to words, representing a sort of mind-reading technology. Existing works decoding words from imaging data have been largely limited to concrete nouns from a relatively small number of semantic categories. Moreover, such studies use different word-stimulus presentation paradigms and different computational models, lacking a comprehensive understanding of the influence of different factors on fMRI word decoding. In this paper, we present a large-scale evaluation of eight word embedding models and their combinations for decoding fine-grained fMRI data associated with three classes of words recorded from three stimulus-presentation paradigms. Specifically, we investigate the following research questions: (1) How does the brain-image decoder perform on different classes of words? (2) How does the brain-image decoder perform in different stimulus-presentation paradigms? (3) How well does each word embedding model allow us to decode neural activation patterns in the human brain? Furthermore, we analyze the most informative voxels associated with different classes of words, stimulus-presentation paradigms and word embedding models to explore their neural basis. The results have shown the following: (1) Different word classes can be decoded most effectively with different word embedding models. Concrete nouns and verbs are more easily distinguished than abstract nouns and verbs. (2) Among the three stimulus-presentation paradigms (picture, sentence and word clouds), the picture paradigm achieves the highest decoding accuracy, followed by the sentence paradigm. (3) Among the eight word embedding models, the model that encodes visual information obtains the best performance, followed by models that encode textual and contextual information. (4) Compared to concrete nouns, which activate mostly vision-related brain regions, abstract nouns activate broader brain regions such as the visual, language and default-mode networks. Moreover, both the picture paradigm and the model that encodes visual information have stronger associations with vision-related brain regions than other paradigms and word embedding models, respectively.}
}
@article{MAHMUD20233933,
title = {Detection of Different Stages of Alzheimer’s Disease Using CNN Classifier},
journal = {Computers, Materials and Continua},
volume = {76},
number = {3},
pages = {3933-3948},
year = {2023},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.039020},
url = {https://www.sciencedirect.com/science/article/pii/S1546221823000450},
author = {S M Hasan Mahmud and Md Mamun Ali and Mohammad Fahim Shahriar and Fahad Ahmed Al-Zahrani and Kawsar Ahmed and Dip Nandi and Francis M. Bui},
keywords = {Alzheimer’s disease, early detection, convolutional neural network, data augmentation, random oversampling, machine learning},
abstract = {Alzheimer’s disease (AD) is a neurodevelopmental impairment that results in a person’s behavior, thinking, and memory loss. The most common symptoms of AD are losing memory and early aging. In addition to these, there are several serious impacts of AD. However, the impact of AD can be mitigated by early-stage detection though it cannot be cured permanently. Early-stage detection is the most challenging task for controlling and mitigating the impact of AD. The study proposes a predictive model to detect AD in the initial phase based on machine learning and a deep learning approach to address the issue. To build a predictive model, open-source data was collected where five stages of images of AD were available as Cognitive Normal (CN), Early Mild Cognitive Impairment (EMCI), Mild Cognitive Impairment (MCI), Late Mild Cognitive Impairment (LMCI), and AD. Every stage of AD is considered as a class, and then the dataset was divided into three parts binary class, three class, and five class. In this research, we applied different preprocessing steps with augmentation techniques to efficiently identify AD. It integrates a random oversampling technique to handle the imbalance problem from target classes, mitigating the model overfitting and biases. Then three machine learning classifiers, such as random forest (RF), K-Nearest neighbor (KNN), and support vector machine (SVM), and two deep learning methods, such as convolutional neuronal network (CNN) and artificial neural network (ANN) were applied on these datasets. After analyzing the performance of the used models and the datasets, it is found that CNN with binary class outperformed 88.20% accuracy. The result of the study indicates that the model is highly potential to detect AD in the initial phase.}
}
@article{AVEN201633,
title = {On the use of conservatism in risk assessments},
journal = {Reliability Engineering & System Safety},
volume = {146},
pages = {33-38},
year = {2016},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2015.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0951832015002938},
author = {Terje Aven},
keywords = {Conservatism, Risk assessments, Knowledge},
abstract = {It is common to use conservatism in risk assessments, replacing uncertain quantities with values that lead to a higher level of risk. It is argued that the approach represents a practical method for dealing with uncertainties and lack of knowledge in risk assessment. If the computed probabilities meet the pre-defined criteria with the conservative quantities, there is strong support for the “real risk” to meet these criteria. In this paper we look more closely into this practice, the main aims being to clarify what it actually means and what the implications are, as well as providing some recommendations. The paper concludes that conservatism should be avoided in risk assessments – “best judgements” should be the ruling thinking, to allow for meaningful comparisons of options. By incorporating sensitivity analyses and strength of knowledge judgements for the background knowledge on which the assigned probabilities are based, the robustness of the conclusions can be more adequately assessed.}
}
@article{BERNABEI2023100172,
title = {Students’ use of large language models in engineering education: A case study on technology acceptance, perceptions, efficacy, and detection chances},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100172},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100172},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000516},
author = {Margherita Bernabei and Silvia Colabianchi and Andrea Falegnami and Francesco Costantino},
keywords = {LLM, ChatGPT, Higher education, Essay generation},
abstract = {The accessibility of advanced Artificial Intelligence-based tools, like ChatGPT, has made Large Language Models (LLMs) readily available to students. These LLMs can generate original written content to assist students in their academic assessments. With the rapid adoption of LLMs, exemplified by the popularity of OpenAI's ChatGPT, there is a growing need to explore their application in education. Few studies examine students' use of LLMs as learning tools. This paper focuses on the application of ChatGPT in engineering higher education through an in-depth case study. It investigates whether engineering students can generate high-quality university essays with LLMs assistance, whether existing LLMs identification systems can detect essays produced with LLMs, and how students perceive the usefulness and acceptance of LLMs in learning. The research adopts a deductive/inductive approach, combining conceptualization and empirical evidence analysis. The study involves mechanical and management engineering students, who compose essays using LLMs. The essay assessment showed good results, but some recommendations emerged for teachers and students. Thirteen LLMs detectors were tested without achieving satisfactory results, suggesting to avoid LLMs ban. In addition, students were administered a questionnaire based on constructs and items that follow the technology acceptance models available in the literature. The results contribute to qualitative evidence by highlighting possible future research and educational practices.}
}
@article{COWLEY2019104025,
title = {Wide coding: Tetris, Morse and, perhaps, language},
journal = {Biosystems},
volume = {185},
pages = {104025},
year = {2019},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2019.104025},
url = {https://www.sciencedirect.com/science/article/pii/S0303264719301820},
author = {S J Cowley},
keywords = {Organic codes, Distributed language, Adaptors, Wide cognition, Reading, Languaging},
abstract = {Code biology uses protein synthesis to pursue how living systems fabricate themselves. Weight falls on intermediary systems or adaptors that enable translated DNA to function within a cellular apparatus. Specifically, code intermediaries bridge between independent worlds (e.g. those of RNAs and proteins) to grant functional lee-way to the resulting products. Using this Organic Code (OC) model, the paper draws parallels with how people use artificial codes. As illustrated by Tetris and Morse, human players/signallers manage code functionality by using bodies as (or like) adaptors. They act as coding intermediaries who use lee-way alongside “a small set of arbitrary rules selected from a potentially unlimited number in order to ensure a specific correspondence between two independent worlds” (Barbieri, 2015). As with deep learning, networked bodily systems mesh inputs from a coded past with current inputs. Received models reduce ‘use’ of codes to a run-time or program like process. They overlook how molecular memory is extended by living apparatuses that link codes with functioning adaptors. In applying the OC model to humans, the paper connects Turing’s (1937) view of thinking to Wilson’s (2004) appeal to wide cognition. The approach opens up a new view of Kirsh and Maglio’s (1994) seminal studies on Tetris. As players use an interface that actualizes a code or program, their goal-directed (i.e. ‘pragmatic’) actions co-occur with adaptor-like ‘filling in’ (i.e. ‘epistemic’ moves). In terms of the OC model, flexible functions derive from, not actions, but epistemic dynamics that arise in the human-interface-computer system. Second, I pursue how a Morse radio operator uses dibs and dabs that enable the workings of an artificial code. While using knowledge (‘the rules’) to resemiotize by tapping on a transmission key, bodily dynamics are controlled by adaptor-like resources. Finally, turning to language, I sketch how the model applies to writing and reading. Like Morse operators, writers resemiotize a code-like domain of alphabets, spelling-systems etc. by acting as (or like) bodily adaptors. Further, in attending to a text-interface (symbolizations), a reader relies on filling-in that is (or feels) epistemic. Given that humans enact or mimic adaptor functions, it is likely that the OC model also applies to multi-modal language.}
}
@article{GAN2021101212,
title = {Translating novel HPC techniques into efficient geoscience solutions},
journal = {Journal of Computational Science},
volume = {52},
pages = {101212},
year = {2021},
note = {Case Studies in Translational Computer Science},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2020.101212},
url = {https://www.sciencedirect.com/science/article/pii/S1877750320305135},
author = {Lin Gan and Haohuan Fu and Guangwen Yang},
keywords = {Computational geoscience application, Numerical simulation, High performance computing, Translational computer science},
abstract = {Computational geoscience is an established field for better understanding and protecting our planet. It covers a wide range of different fields that are closely related to Earth systems. As a popular research area that largely relies on high performance computing, the efficient translation of novel techniques from computer science to practical geoscience solutions has emerged as an important and challenging problem. Based on a series of efforts in conducting interdisciplinary research in computer science and geoscience, this paper summarizes the measures we have taken and the lessons we have learned to successfully translate selected computational laboratory innovations into practical solutions.}
}
@article{HAREL201758,
title = {Field-based hypotheses on advancing standards for mathematical practice},
journal = {The Journal of Mathematical Behavior},
volume = {46},
pages = {58-68},
year = {2017},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2017.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S0732312317300457},
author = {Guershon Harel},
keywords = {Common Core State Standards in Mathematics (CCSSM), Standards for mathematical practice},
abstract = {The Common Core State Standards in Mathematics (CCSSM, 2010) are organized around two types of standards: the standards for mathematical content and standards for mathematical practice. The central goal of this paper is to present cognitive and instructional analyses of standards for mathematical practice through a discussion of field-based activities with inservice secondary mathematics teachers and students. A potential value of the study is that it provides researchers with specific field-based hypotheses on advancing standards for mathematical practice.}
}
@article{FUJISHIRO2025103006,
title = {Chromatin domains in the cell: Phase separation and condensation},
journal = {Current Opinion in Structural Biology},
volume = {91},
pages = {103006},
year = {2025},
issn = {0959-440X},
doi = {https://doi.org/10.1016/j.sbi.2025.103006},
url = {https://www.sciencedirect.com/science/article/pii/S0959440X25000247},
author = {Shin Fujishiro and Masaki Sasai and Kazuhiro Maeshima},
abstract = {Negatively charged genomic DNA wraps around positively charged core histone octamers to form nucleosomes, which, along with proteins and RNAs, self-organize into chromatin within the nucleus. In eukaryotic cells, chromatin forms loops that collapse into chromatin domains and serve as functional units of the genome. Chromatin domains vary in physical properties based on gene activity and are assembled into A (euchromatin) and B (heterochromatin) compartments. Since various factors—such as chromatin-binding proteins, histone modifications, transcriptional states, depletion attraction, and cations—can significantly impact chromatin organization, the formation processes of these hierarchical structures remain unclear. No single imaging, genomics, or modeling method can provide a complete picture of the process. Beautiful models can sometimes fool our thinking. In this short review, we critically discuss the formation mechanisms of the chromatin domain in the cell from a physical point of view, including phase separation and condensation.}
}
@article{LIU2025113288,
title = {Knowledge-based natural answer generation via effective graph learning},
journal = {Knowledge-Based Systems},
pages = {113288},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113288},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125003351},
author = {Zedong Liu and Jianxin Li and Yongle Huang and Ningning Cui and Lili Pei},
keywords = {Natural answer generation, Adaptive multi-hop retrieval, Graph-based Mamba, Prompt optimization},
abstract = {Objectives:
Natural Answer Generation (NAG) aims to generate natural and fluent answers to user questions. Existing NAG methods typically employ fixed-hop retrieval to construct knowledge graphs and utilize attention-based networks for answer generation. However, these approaches lack interpretability, struggle to filter out redundant information in the graph, and are computationally intensive.
Methods:
To address these issues, this paper introduces an innovative approach AdaptQA model. Initially, AdaptQA constructs a knowledge graph from the knowledge base (KB) using an adaptive multi-hop retrieval algorithm. Subsequently, it generates answers through the Graph-based Mamba module (GBM), effectively filtering out redundant information. Finally, the answers are optimized using a pre-trained large language model to enhance their fluency and accuracy.
Novelty:
The proposed AdaptQA model introduces a new approach to NAG by improving the completeness of the knowledge graph and optimizing question answers. This method overcomes the limitations of existing NAG techniques by reducing the complexity of model inference.
Findings:
Through extensive experiments on two benchmark datasets, HotpotQA and WikiHop, AdaptQA demonstrates superior performance, significantly outperforming existing NAG methods. Specifically, AdaptQA achieves an accuracy of 94.47% on the HotpotQA dataset and 91.38% on the WikiHop dataset.}
}
@article{ZALL2024101285,
title = {Towards emotion-aware intelligent agents by utilizing knowledge graphs of experiences},
journal = {Cognitive Systems Research},
volume = {88},
pages = {101285},
year = {2024},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2024.101285},
url = {https://www.sciencedirect.com/science/article/pii/S1389041724000792},
author = {Raziyeh Zall and Mohammad Reza Kangavari},
keywords = {Affective computing, Intelligent agent, Cognitive architecture, Appraisal theory, Emotional mental state},
abstract = {Because of the increasing presence of intelligent agents in various aspects of human social life, social skills play a vital role in ensuring these systems exhibit acceptable and realistic behavior in social communication. The importance of emotional intelligence in social capabilities is noteworthy, so incorporating emotions into the behaviors of intelligent agents is essential. Therefore, some computational models of emotions have been presented to develop intelligent agents that exhibit emotional human-like behaviors. However, most current computational models of emotions neglect the dynamic learning of the affective meaning of events based on agents’ experiences. Such models evaluate the events in the environment according to emotional aspects without considering the context of the situations. Also, these models capture the emotional states of agents by using predefined rules determined according to psychological theories. Therefore, they disregard the data-driven methods that can obtain the relationships between appraisal variables and emotions based on natural human data with fewer assumptions on the nature of such relationships. To address these issues, we proposed a novel and unified affective-cognitive framework (EIAEC) to facilitate the development of emotion-aware intelligent agents. EIAEC uses appraisal theories to acquire the emotional states of the agent in various situations. This paper contains four main contributions: 1- We have designed an efficient episodic memory that uses events and their conditional contexts to store and retrieve knowledge and experiences. This memory facilitates emotional expressions and decision-making adapted to the situations of the agent. 2- A novel method has been proposed that learns context-dependent affective values associated with events by using the agent’s experiences in various contexts. Subsequently, we acquired appraisal variables using the elements and related meta-data in episodic memory. 3- We have proposed a new data-driven method that maps appraisal variables to emotional states. 4- Moreover, a method has been developed to update the activation values regarding actions by using the emotional states of the agent. This method models the influence of emotions on the agent’s decision-making. Finally, we simulate a driving scenarios in our proposed framework to manifest the generated emotions in different situations and conditions. Moreover, we show how the proposed method learns the affective meaning of events and actions used in appraisal computing.}
}
@article{OMRAN2022114806,
title = {Valorization of agro-industrial biowaste to green nanomaterials for wastewater treatment: Approaching green chemistry and circular economy principles},
journal = {Journal of Environmental Management},
volume = {311},
pages = {114806},
year = {2022},
issn = {0301-4797},
doi = {https://doi.org/10.1016/j.jenvman.2022.114806},
url = {https://www.sciencedirect.com/science/article/pii/S0301479722003796},
author = {Basma A. Omran and Kwang-Hyun Baek},
keywords = {Green synthesis, Zero-cost, Nanomaterials, Wastewater treatment, Sustainability},
abstract = {Water pollution is one of the most critical issues worldwide and is a priority in all scientific agendas. Green nanotechnology presents a plethora of promising avenues for wastewater treatment. This review discusses the current trends in the valorization of zero-cost, biodegradable, and readily available agro-industrial biowaste to produce green bio-nanocatalysts and bio-nanosorbents for wastewater treatment. The promising roles of green bio-nanocatalysts and bio-nanosorbents in removing organic and inorganic water contaminants are discussed. The potent antimicrobial activity of bio-derived nanodisinfectants against water-borne pathogenic microbes is reviewed. The bioactive molecules involved in the chelation and tailoring of green synthesized nanomaterials are highlighted along with the mechanisms involved. Furthermore, this review emphasizes how the valorization of agro-industrial biowaste to green nanomaterials for wastewater treatment adheres to the fundamental principles of green chemistry, circular economy, nexus thinking, and zero-waste manufacturing. The potential economic, environmental, and health impacts of valorizing agro-industrial biowaste to green nanomaterials are highlighted. The challenges and future outlooks for the management of agro-industrial biowaste and safe application of green nanomaterials for wastewater treatment are summarized.}
}
@article{SHIBATA2021436,
title = {Sensitivity – Local index to control chaoticity or gradient globally –},
journal = {Neural Networks},
volume = {143},
pages = {436-451},
year = {2021},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2021.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0893608021002471},
author = {Katsunari Shibata and Takuya Ejima and Yuki Tokumaru and Toshitaka Matsuki},
keywords = {Sensitivity, Sensitivity adjustment learning (SAL), Edge of chaos, Recurrent neural network (RNN), Deep feedforward neural network (DFNN), Vanishing gradient problem},
abstract = {Here, we introduce a fully local index named “sensitivity” for each neuron to control chaoticity or gradient globally in a neural network (NN). We also propose a learning method to adjust it named “sensitivity adjustment learning (SAL)”. The index is the gradient magnitude of its output with respect to its inputs. By adjusting its time average to 1.0 in each neuron, information transmission in the neuron changes to be moderate without shrinking or expanding for both forward and backward computations. That results in moderate information transmission through a layer of neurons when the weights and inputs are random. Therefore, SAL can control the chaoticity of the network dynamics in a recurrent NN (RNN). It can also solve the vanishing gradient problem in error backpropagation (BP) learning in a deep feedforward NN or an RNN. We demonstrate that when applying SAL to an RNN with small and random initial weights, log-sensitivity, which is the logarithm of RMS (root mean square) sensitivity over all the neurons, is equivalent to the maximum Lyapunov exponent until it reaches 0.0. We also show that SAL works with BP or BPTT (BP through time) to avoid the vanishing gradient problem in a 300-layer NN or an RNN that learns a problem with a lag of 300 steps between the first input and the output. Compared with manually fine-tuning the spectral radius of the weight matrix before learning, SAL’s continuous nonlinear learning nature prevents loss of sensitivities during learning, resulting in a significant improvement in learning performance.}
}
@incollection{ROCAVERT202065,
title = {Arts Bias},
editor = {Mark Runco and Steven Pritzker},
booktitle = {Encyclopedia of Creativity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {65-68},
year = {2020},
isbn = {978-0-12-815615-5},
doi = {https://doi.org/10.1016/B978-0-12-809324-5.23612-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128093245236122},
author = {Carla Rocavert},
keywords = {Algorithm, Arts, Bias, Creativity, Capitalism, Elite, Neoliberalism, Permanence, Technology, Utility},
abstract = {This entry posits that current debates around ‘arts bias’ are indicative of evolving definitions of creativity. It discusses themes of utility and permanence to illuminate tensions between historical conceptions of artistic creativity and newer fields, especially those which are driving the global economy toward an increasingly technologically-oriented paradigm under neoliberal capitalism. The arrival of computational creativity and the practice of applying algorithmic data technologies to artmaking are discussed.}
}
@article{RUTER2000519,
title = {Analysis, finite element computation and error estimation in transversely isotropic nearly incompressible finite elasticity},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {190},
number = {5},
pages = {519-541},
year = {2000},
issn = {0045-7825},
doi = {https://doi.org/10.1016/S0045-7825(99)00286-8},
url = {https://www.sciencedirect.com/science/article/pii/S0045782599002868},
author = {Marcus Rüter and Erwin Stein},
abstract = {In this paper we present constitutive models for nearly incompressible, transversely isotropic materials in finite hyperelasticity, particularly for reinforced rubber-like materials, which are of essential engineering interest. The theory is developed using a convected curvilinear coordinate system based on a mixed two-field displacement–pressure energy functional. Furthermore, an a posteriori error estimator without multiplicative constants is derived for non-linear anisotropic problems, which measures the discretization error in the first Piola–Kirchhoff stresses in the L2-norm by solving local Neumann problems with equilibrated tractions. Illustrative numerical examples demonstrate the anisotropic material behaviour of reinforced materials and the efficiency of using adaptive finite element methods.}
}
@article{MCCOWN201233,
title = {Farmers use intuition to reinvent analytic decision support for managing seasonal climatic variability},
journal = {Agricultural Systems},
volume = {106},
number = {1},
pages = {33-45},
year = {2012},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2011.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X11001557},
author = {R.L. McCown and P.S. Carberry and N.P. Dalgliesh and M.A. Foale and Z. Hochman},
keywords = {Decision support, Simulation, Information system, Cognitive system, Intuition, Climatic risk},
abstract = {The FARMSCAPE Information System emerged in a long-running research program aimed at making simulation models useful to Australian farmers in managing climatic variability. This paper is about how well it has worked. This is reported in relation to two standards: (1) the value to thinking and action expressed by farmers and their consultants, (2) correspondence with theory about learning and judgement in uncertain external environments. The former utilises recorded narrative interviews with participants over many years. The latter uses a cognitive framework drawn from theory of judgment and decision making featuring the relationship between intuition and analysis (McCown, 2011). The cognitive theory framework makes sense of several evaluation surprises. The first was high enthusiasm by largely-intuitive farmers for an analytic approach to soil water in conjunction with a newly-appreciated “bucket” metaphor for water balance. The second surprise was the virtual absence of soil water measurement 10years later. This had been replaced by various intuitive estimates, calibrated to maintain a heuristic relationship with regard to the “bucket” as a resource. Farmers and their advisers were facilitated in using simulation for thought experiments and planning under climatic uncertainty. Benchmarking enabled problem solving in documented conditions. Scenario analysis using historical climate records supported thought experiments by providing probability distributions that were valued for shaping expectations as a “history of the future”. In retrospective evaluation interviews, researchers were surprised to find that yield forecasting and tactical decision making, anticipated to be analyses that were both site- and season-specific forecasts, had served farmers as “management gaming” simulations to aid formulating action rules for such conditions, thus reducing the need for an on-going decision-aiding service. Equipped with their soil monitoring techniques and with their heuristic rules, farmers still reserved a place for simulation “when you’ve got a planting situation out of the ordinary.”}
}
@article{CHRISTENSEN2025102467,
title = {perms: Likelihood-free estimation of marginal likelihoods for binary response data in Python and R},
journal = {Journal of Computational Science},
volume = {84},
pages = {102467},
year = {2025},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2024.102467},
url = {https://www.sciencedirect.com/science/article/pii/S1877750324002606},
author = {Dennis Christensen and Per August Jarval Moen},
keywords = {Binary classification, Bioassay, Marginal likelihood estimation, Permutation counting},
abstract = {In Bayesian statistics, the marginal likelihood (ML) is the key ingredient needed for model comparison and model averaging. Unfortunately, estimating MLs accurately is notoriously difficult, especially for models where posterior simulation is not possible. Recently, the idea of permutation counting was introduced, which provides an estimator which can accurately estimate MLs of models for exchangeable binary responses. Such data arise in a multitude of statistical problems, including binary classification, bioassay and sensitivity testing. Permutation counting is entirely likelihood-free and works for any model from which a random sample can be generated, including nonparametric models. Here we present perms, a package implementing permutation counting. Following optimisation efforts, perms is computationally efficient and can handle large data problems. It is available as both an R package and a Python library. A broad gallery of examples illustrating its usage is provided, which includes both standard parametric binary classification and novel applications of nonparametric models, such as changepoint analysis. We also cover the details of the implementation of perms and illustrate its computational speed via a simple simulation study.}
}
@article{ROBINSON2021,
title = {Development of the Organonitrogen Biodegradation Database: Teaching Bioinformatics and Collaborative Skills to Undergraduates during a Pandemic},
journal = {Journal of Microbiology & Biology Education},
volume = {22},
number = {1},
year = {2021},
issn = {1935-7877},
doi = {https://doi.org/10.1128/jmbe.v22i1.2351},
url = {https://www.sciencedirect.com/science/article/pii/S1935787721000745},
author = {Serina L. Robinson and Troy Biernath and Caleb Rosenthal and Dean Young and Lawrence P. Wackett and Betsy M. Martinez-Vaz},
abstract = {Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology.
ABSTRACT
Physical distancing and inaccessibility to laboratory facilities created an opportunity to transition undergraduate research experiences to remote, digital platforms, adding another level of pedagogy to their training. Basic bioinformatics skills together with critical analysis of scientific literature are essential for addressing research questions in modern biology. The work presented here describes a fully online, collaborative research experience created to allow undergraduate students to learn those skills. The research experience was focused on the development and implementation of the Organonitrogen Biodegradation Database (ONDB, z.umn.edu/ondb). The ONDB was developed to catalog information about the cost, chemical properties, and biodegradation potential of commonly used organonitrogen compounds. A cross-institutional team of undergraduate researchers worked in collaboration with two faculty members and a postdoctoral fellow to develop the database. Students carried out extensive online literature searches and used a biodegradation prediction website to research and represent the microbial catabolism of different organonitrogen compounds. Participants employed computational tools such as R, Shiny, and flexdashboard to construct the database pages and interactive web interface for the ONDB. Worksheets and forms were created to encourage other students and researchers to gather information about organonitrogen compounds and expand the database. Student progress was evaluated through biweekly project meetings, presentations, and a final reflection. The ONDB undergraduate research experience provided a platform for students to learn bioinformatics skills while simultaneously developing a teaching and research tool for others.}
}
@article{EBEL2024104612,
title = {Cooperative object transportation with differential-drive mobile robots: Control and experimentation},
journal = {Robotics and Autonomous Systems},
volume = {173},
pages = {104612},
year = {2024},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2023.104612},
url = {https://www.sciencedirect.com/science/article/pii/S0921889023002518},
author = {Henrik Ebel and Mario Rosenfelder and Peter Eberhard},
keywords = {Cooperative manipulation, Non-prehensile manipulation, Robotic networks, Distributed optimization, Non-holonomic robots, Hardware validation},
abstract = {Non-prehensile cooperative object transportation is a challenging model problem for distributed control and organization methods but also has practical applications. Therefore, it is widely studied in distributed robotics research. This paper describes and evaluates a novel transportation scheme for differential-drive mobile robots that is, to the authors’ best knowledge, the most versatile scheme of its kind successfully evaluated with real-world hardware. The proposed scheme can conceptually deal with any number of robots and arbitrary polygonal objects, including non-convex ones, without having to retune, retrain, or reconfigure any of the control parameters between different scenarios. This is achieved by splitting the task into a formation control and a formation finding task, both of which are tackled with model-based approaches using distributed optimization. Formation control and formation finding are complicated by the robots’ non-holonomic kinematic constraints. Therefore, a tailored distributed model predictive controller is used for formation control. Finding formations relies on a multibody-dynamics representation of the robots-object system to properly account for contact and non-holonomic constraints. Due to these measures, the transportation scheme achieves a very satisfactory performance and dexterity in real-world hardware experiments utilizing network communication and distributed computation.}
}
@article{KWON2019109608,
title = {Towards codification of thunderstorm/downburst using gust front factor: Model-based and data-driven perspectives},
journal = {Engineering Structures},
volume = {199},
pages = {109608},
year = {2019},
issn = {0141-0296},
doi = {https://doi.org/10.1016/j.engstruct.2019.109608},
url = {https://www.sciencedirect.com/science/article/pii/S0141029619306315},
author = {Dae Kun Kwon and Ahsan Kareem},
keywords = {Wind loads, Nonstationary process, Gust front, Gust front factor, Downburst, Thunderstorm, Codes and standards},
abstract = {Winds associated with gust fronts originating from a thunderstorm/downburst exhibit rapid changes during a short time period which may be accompanied by changes in direction. For several decades, a number of studies have been focused on identifying the characteristics of such nonstationary gust front winds in a variety of manners such as experimental/numerical methods and full-scale measurements. Yet, beginning the dialogue on any guidelines for design practice has thus far not evolved, in part due to a limited consensus on such characteristics among studies in conjunction with paucity of available data needed for vetting and corroborating, which is further impacted by the presence of nonstationarity. In an effort to establishing a new design procedure for this type of wind load effect on structures, the gust front factor (GFF) framework has been proposed by authors that encapsulates both the kinematic and dynamic features of gust front induced wind effects on structures, which distinguish themselves from those experienced in conventional boundary layer flows. This study revisits the gust front factor framework seeking to take the next step toward a possible initial framework for codification of gust front winds from model-based and data-driven perspectives. A modular and extensible web-enabled framework to estimate gust front related wind load effects is envisaged to rationally and holistically quantify design loads. This would promote design practice to enhance disaster resilience of the built environment. In this context, a closed-form expression concerning nonstationary fluctuations for a case of a long pulse duration is derived to facilitate rapid evaluation of nonstationary turbulence effects. A preliminary uncertainty analysis is also carried out to assess the influence of uncertainties associated with the load effects of gust front winds and the reliability of GFF. In addition, a comparison of the model-based gust front factor with a recently introduced thunderstorm response spectrum technique to assess their relative performance is carried out. In view of the lessons learned from the history of the gust loading factor on codes and standards, a possible living codification concept through a learning and updating invoking the emerging “Design Thinking” approach is discussed.}
}
@article{VALLVERDU20146,
title = {What are Simulations? An Epistemological Approach},
journal = {Procedia Technology},
volume = {13},
pages = {6-15},
year = {2014},
note = {SLACTIONS 2013: Research conference on virtual worlds – Learning with simulations},
issn = {2212-0173},
doi = {https://doi.org/10.1016/j.protcy.2014.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S2212017314000139},
author = {Jordi Vallverdú},
keywords = {model, computer, simulation, epistemology, representation},
abstract = {Contemporary sciences use a wide and diverse range of computational simulations, including in the areas of aeronautics, chemistry, bioinformatics, social sciences, AI, the physics of elementary particles and most other scientific fields. A simulation is a mathematical model that describes or creates computationally a system process. Simulations are our best cognitive representation of complex reality, that is, our deepest conception of what reality is. In this paper we defend that a simulation is equivalent epistemologically and ontologically with all other types of cognitive models of elements of reality. Therefore, simulations cannot be considered secondary nor weak instruments to approach to the reality analysis.}
}
@article{BALMER2024105411,
title = {Design Space Exploration and Explanation via Conditional Variational Autoencoders in Meta-Model-Based Conceptual Design of Pedestrian Bridges},
journal = {Automation in Construction},
volume = {163},
pages = {105411},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105411},
url = {https://www.sciencedirect.com/science/article/pii/S092658052400147X},
author = {Vera Balmer and Sophia V. Kuhn and Rafael Bischof and Luis Salamanca and Walter Kaufmann and Fernando Perez-Cruz and Michael A. Kraus},
keywords = {Computational design, Design space exploration, Generative AI, Conditional Variational Autoencoder, Explainable AI, Pedestrian bridge},
abstract = {Today, engineers rely on conventional iterative (often manual) techniques for conceptual design. Emerging parametric models facilitate design space exploration based on quantifiable performance metrics, yet remain time-consuming and computationally expensive, leaving room for improvement. This paper provides a design exploration and explanation framework to augment the designer via a Conditional Variational Autoencoder (CVAE), which serves as a forward performance predictor as well as an inverse design generator conditioned on a set of performance requests. Hence, the CVAE overcomes the limitations of traditional iterative techniques by learning a differentiable mapping for a highly nonlinear design space, thus enabling sensitivity analysis. These methods allow for informing designers about (i) relations of the model between features and performances and (ii) structural improvements under user-defined objectives. The framework is tested on a case-study and proves its potential to serve as a future co-pilot for conceptual design studies of diverse civil structures and beyond.}
}
@article{NOURANI2015891,
title = {Predictive Control, Competitive Model Business Planning, and Innovation ERP},
journal = {Procedia Computer Science},
volume = {65},
pages = {891-900},
year = {2015},
note = {International Conference on Communications, management, and Information technology (ICCMIT'2015)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.09.048},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915028781},
author = {Cyrus F. Nourani and Codrina Lauth},
keywords = {Competitive Models, Innovation Management, ERP. Multiplayer Games, Game Trees Computing, Predictive Modeling, Planning, Competitive Models, Dynamic Programming},
abstract = {New optimality principles are put forth based on competitive model business planning. A Generalized MinMax local optimum dynamic programming algorithm is presented and applied to business model computing where predictive techniques can determine local optima. Based on a systems model an enterprise is not viewed as the sum of its component elements, but the product of their interactions. The paper starts with introducing a systems approach to business modeling. A competitive business modeling technique, based on the author's planning techniques is applied. Systemic decisions are based on common organizational goals, and as such business planning and resource assignments should strive to satisfy higher organizational goals. It is critical to understand how different decisions affect and influence one another. Here, a business planning example is presented where systems thinking technique, using Causal Loops, are applied to complex management decisions. Predictive modeling specifics are briefed. A preliminary optimal game modeling technique is presented in brief with applications to innovation and R&D management. Conducting gap and risk analysis can assist with this process. Example application areas to e-commerce with management simulation models are examined.}
}
@article{RITCHIE2012649,
title = {Styles for philosophers of science},
journal = {Studies in History and Philosophy of Science Part A},
volume = {43},
number = {4},
pages = {649-656},
year = {2012},
note = {Part Special Issue: Styles of Thinking},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2012.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0039368112000490},
author = {Jack Ritchie},
keywords = {Ian Hacking, Styles of Thinking, Realism, Self-authentication},
abstract = {In this paper I discuss the bearing of Hacking’s ideas about Scientific Styles on traditional debates in the philosophy of science concerning rationality and realism. I argue that a kind of deflationary position with regard to realism debates is a natural consequence of Hacking’s claim that styles are self-authenticating. I then go on to argue, using an example of van Fraassen’s, that Hacking should allow a methodological role for realism debates and hence they are not idle, as he has claimed, although their resolution may not be important.}
}
@article{ZHANG2017123,
title = {Collective decision optimization algorithm: A new heuristic optimization method},
journal = {Neurocomputing},
volume = {221},
pages = {123-137},
year = {2017},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2016.09.068},
url = {https://www.sciencedirect.com/science/article/pii/S0925231216311183},
author = {Qingyang Zhang and Ronggui Wang and Juan Yang and Kai Ding and Yongfu Li and Jiangen Hu},
keywords = {Collective decision optimization algorithm, Artificial neural networks, Meta-heuristic, Decision-making},
abstract = {Recently, inspired by nature, diversiform successful and effective optimization methods have been proposed for solving many complex and challenging applications in different domains. This paper proposes a new meta-heuristic technique, collective decision optimization algorithm (CDOA), for training artificial neural networks. It simulates the social behavior of human based on their decision-making characteristics including experience-based phase, others'-based phase, group thinking-based phase, leader-based phase and innovation-based phase. Different corresponding operators are designed in the methodology. Experimental results carried out on a comprehensive set of benchmark functions and two nonlinear function approximation examples demonstrate that CDOA is competitive with respect to other state-of-art optimization algorithms.}
}
@article{LI2024120889,
title = {Hierarchical fuzzy inference based on Bandler-Kohout subproduct},
journal = {Information Sciences},
volume = {677},
pages = {120889},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120889},
url = {https://www.sciencedirect.com/science/article/pii/S002002552400803X},
author = {Dechao Li and Zhisong Liu and Qiannan Guo},
keywords = {Fuzzy implication, Fuzzy inference, Bandler-Kohout subproduct, Hierarchical system, T-norm},
abstract = {Fuzzy inference with the Bandler-Kohout subproduct (BKS) has been successfully applied in many fields such as fuzzy control, artificial intelligence, image processing, data mining, decision-making, prediction, classification and so on. However, one has to face with the rule explosion in these applications. To deal with this problem, hierarchical fuzzy systems with the compositional rule of inference (CRI) method have been constructed by a series of low-dimensional sub fuzzy systems. And it has been proved that hierarchical fuzzy inference method can efficiently restrain the explosion of fuzzy rules. Therefore, in order to increase the computational efficiency of the fuzzy inference based on the BKS when multi-input-single-output (MISO) fuzzy rules are involved, this paper mainly constructs two hierarchical fuzzy inference methods based on the BKS in which the if-then rules are respectively interpreted by fuzzy implications and ML-implications. Moreover, the validity of the two BKS hierarchical fuzzy inferences is studied with the GMP rules. Finally, two examples are employed to illustrate the computational efficiency of our proposed BKS hierarchical inference methods.}
}
@incollection{WARE20081,
title = {Chapter 1 - Visual Queries},
editor = {Colin Ware},
booktitle = {Visual Thinking},
publisher = {Morgan Kaufmann},
address = {San Francisco},
pages = {1-22},
year = {2008},
isbn = {978-0-12-370896-0},
doi = {https://doi.org/10.1016/B978-0-12-370896-0.00001-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780123708960000019},
author = {Colin Ware},
abstract = {Publisher Summary
This book about graphic design provides a channel for clear communication that supports visual thinking and acts as an interface to the vast information resources of the modern world. Visual thinking is a process that has the allocation of attention as its very essence. Attention, however, is multifaceted. Making an eye movement is an act of attending. Eye movements are executed to satisfy the need for information and can be thought of as a sequence of visual queries on the visual world. The idea of the visual query is shorthand for what one does when obtaining information either from the world at large or from some kind of information display. Understanding what visual queries are easily executed is a critical skill for the designer. The special skill of designers is not so much skill with drawing or graphic design software, although these are undoubtedly useful, but the talent to analyze a design in terms of its ability to support the visual queries of others. One reason why design is difficult is that the designer already has the knowledge expressed in the design and has seen it develop from inception and therefore cannot see it with fresh eyes. The solution is to be analytic and this is where this book is intended to have value. Effective design should start with a visual task analysis, determine the set of visual queries to be supported by a design, and then use color, form, and space to efficiently serve those queries.}
}
@article{CHANDRA2018306,
title = {New narratives of development work? Making sense of social entrepreneurs’ development narratives across time and economies},
journal = {World Development},
volume = {107},
pages = {306-326},
year = {2018},
issn = {0305-750X},
doi = {https://doi.org/10.1016/j.worlddev.2018.02.033},
url = {https://www.sciencedirect.com/science/article/pii/S0305750X18300780},
author = {Yanto Chandra},
keywords = {Development narrative, Development, Social enterprise, Social entrepreneur, Computational linguistics},
abstract = {This article views social entrepreneurship as a relatively new model for achieving sustainable development. It also identifies development narratives that social entrepreneurs (SEs) construct to represent and promote their work as an important research gap in development studies. Drawing on the development and narratology literature, and employing computational linguistics (CL) techniques, this article compares the development narratives of 1076 Ashoka SEs across two periods (2009–2013 and 1994–1998) and two economies (developing and developed). CL analyses reveal important themes that characterize the identity, framing and orientations of development SEs across time and economies. The findings demonstrate how SE development narratives i) tend to be more pragmatic and solution-centric, and contain less political ideology than conventional development narratives, ii) combine extant development ideas and models but reframe them in new ways to address contemporary, complex development challenges, and iii) reflect a ‘bottom-up’ approach that encourages local ownership and collaborations with various social and economic sectors to achieve development goals. Overall, this study identifies the increasing importance of SEs in the development industry and reveals new aspects of SEs—their latent political framing, collective-utilitarian identities, and topical areas—that require further research via development narratives.}
}
@article{GALLISTEL199243,
title = {Preverbal and verbal counting and computation},
journal = {Cognition},
volume = {44},
number = {1},
pages = {43-74},
year = {1992},
note = {Numerical Cognition},
issn = {0010-0277},
doi = {https://doi.org/10.1016/0010-0277(92)90050-R},
url = {https://www.sciencedirect.com/science/article/pii/001002779290050R},
author = {C.R. Gallistel and Rochel Gelman},
abstract = {We describe the preverbal system of counting and arithmetic reasoning revealed by experiments on numerical representations in animals. In this system, numerosities are represented by magnitudes, which are rapidly by inaccurately generated by the Meck and Church (1983) preverbal counting mechanism. We suggest the following. (1) The preverbal counting mechanisms is the source of the implicit principles that guide the acquisition of verbal counting. (2) The preverbal system of arithmetic computation provides the framework for the assimilation of the verbal system. (3) Learning to count involves, in part, learning a mapping from the preverbal numerical magnitudes to the verbal and written number symbols and the inverse mappings from these symbols to the preverbal magnitudes. (4) Subitizings is the use of the preverbal counting process and the mapping from the resulting magnitudes to number words in order to generate rapidly the number words for small numerosities. (5) The retrieval of the number facts, which plays a central role in verbal computation, is mediated via the inverse mappings from verbal and written numbers to the preverbal magnitudes and the use of these magnitudes to find the appropriate cells in tabular arrangements of the answers. (6) This model of the fact retrieval process accounts for the salient features of the reaction time differences and error patterns revealed by expriments on mental arithmetic. (7) The application of verbal and written computational algorithms goes on in parallel with, and is to some extent guided by, preverbal computations, both in the child and in the adult.}
}
@article{JAHANIFAR2024103132,
title = {Mitosis detection, fast and slow: Robust and efficient detection of mitotic figures},
journal = {Medical Image Analysis},
volume = {94},
pages = {103132},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103132},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524000574},
author = {Mostafa Jahanifar and Adam Shephard and Neda Zamanitajeddin and Simon Graham and Shan E. Ahmed Raza and Fayyaz Minhas and Nasir Rajpoot},
keywords = {Mitosis, Detection, Segmentation, Breast cancer, MIDOG, TUPAC, Computational pathology, Deep learning},
abstract = {Counting of mitotic figures is a fundamental step in grading and prognostication of several cancers. However, manual mitosis counting is tedious and time-consuming. In addition, variation in the appearance of mitotic figures causes a high degree of discordance among pathologists. With advances in deep learning models, several automatic mitosis detection algorithms have been proposed but they are sensitive to domain shift often seen in histology images. We propose a robust and efficient two-stage mitosis detection framework, which comprises mitosis candidate segmentation (Detecting Fast) and candidate refinement (Detecting Slow) stages. The proposed candidate segmentation model, termed EUNet, is fast and accurate due to its architectural design. EUNet can precisely segment candidates at a lower resolution to considerably speed up candidate detection. Candidates are then refined using a deeper classifier network, EfficientNet-B7, in the second stage. We make sure both stages are robust against domain shift by incorporating domain generalization methods. We demonstrate state-of-the-art performance and generalizability of the proposed model on the three largest publicly available mitosis datasets, winning the two mitosis domain generalization challenge contests (MIDOG21 and MIDOG22). Finally, we showcase the utility of the proposed algorithm by processing the TCGA breast cancer cohort (1,124 whole-slide images) to generate and release a repository of more than 620K potential mitotic figures (not exhaustively validated).}
}
@article{WANG2025100834,
title = {Toward bridging the gap between machine intelligence and machine wisdom: Dilemmas and conjectures},
journal = {The Innovation},
pages = {100834},
year = {2025},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2025.100834},
url = {https://www.sciencedirect.com/science/article/pii/S2666675825000372},
author = {Rui Wang and Shixuan Liu and Changjun Fan and Guozheng Li and Jincai Huang and Zhong Liu and Gang Zhou},
abstract = {In recent years, artificial intelligence (AI) has achieved tremendous development, akin to a significant leap, similar to progressing from 1 to 100. However, a significant gap still exists between current machine intelligence and human wisdom: machine intelligence is constrained to post hoc inference based on existing data, lacking the ability for genuine exploratory innovation and possessing no prospective reasoning inherent to human wisdom. Drawing inspiration from human wisdom, this article presents conjectures for overcoming the four dilemmas faced by machine intelligence: neglect of silicon-based cognition, lack of artistry, pitfall of perfectionism, and obsession with uniformity. These conjectures aim to propel machine intelligence toward machine wisdom, achieving a great leap from 1 to i.}
}
@article{MEHRYAR2024109812,
title = {AI and climate resilience governance},
journal = {iScience},
volume = {27},
number = {6},
pages = {109812},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.109812},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224010344},
author = {Sara Mehryar and Vahid Yazdanpanah and Jeffrey Tong},
keywords = {Natural sciences, Earth sciences, Environmental science, Environmental policy, Social sciences},
abstract = {Summary
While artificial intelligence (AI) offers promising solutions to address climate change impacts, it also raises many application limitations and challenges. A risk governance perspective is used to analyze the role of AI in supporting decision-making for climate adaptation, spanning risk assessment, policy analysis, and implementation. This comprehensive review combines expert insights and systematic literature review. The study’s findings indicate a large emphasis on applying AI to climate “risk assessments,” particularly regarding hazard and exposure assessment, but a lack of innovative approaches and tools to evaluate resilience and vulnerability as well as prioritization and implementation process, all of which involve subjective, qualitative, and context-specific elements. Additionally, the study points out challenges such as difficulty of simulating complex long-term changes, and evolving policies and human behavior, reliance on data quality and computational resources, and the need for improved interpretability of results as areas requiring further development.}
}
@incollection{BRAME201915,
title = {Chapter 2 - Course Design: Making Choices About Constructing Your Course},
editor = {Cynthia J. Brame},
booktitle = {Science Teaching Essentials},
publisher = {Academic Press},
pages = {15-28},
year = {2019},
isbn = {978-0-12-814702-3},
doi = {https://doi.org/10.1016/B978-0-12-814702-3.00002-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128147023000020},
author = {Cynthia J. Brame},
keywords = {Undergraduate, science, education, course design, learning goals, learning objectives, guiding questions, formative assessment},
abstract = {Designing or redesigning a course can be a creative and rewarding effort, but it is always a challenge. Science is characterized by continuous change and an ever-growing (and already large!) body of knowledge, and our courses often seek to help students understand the core knowledge, experimental tools, and ways of thinking in a field. It’s a big task. Further, a course may play a particular role in the curriculum, serving as a prerequisite, a capstone, or the course in which students learn a particular skill. How do you pick on what to focus, and how do you organize your course to help your students be able to transfer their knowledge to a new setting? How can you design the course to help your students build a conceptual framework that can expand and grow as their understanding grows? This chapter describes six principles to guide your course design and provides suggestions for more detailed resources.}
}
@incollection{VARGHESE202275,
title = {Chapter 4 - Principles in action},
editor = {George Varghese and Jun Xu},
booktitle = {Network Algorithmics (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {75-107},
year = {2022},
isbn = {978-0-12-809927-8},
doi = {https://doi.org/10.1016/B978-0-12-809927-8.00009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128099278000099},
author = {George Varghese and Jun Xu},
keywords = {Buffer validation, Dijkstra's algorithm, virtual circuit, transport protocols},
abstract = {Part 2 of the book begins a detailed look at specific network bottlenecks such as data copying and control transfer. While the principles are used in these later chapters, the focus of these later chapters is on the specific bottleneck being examined. Given that network algorithmics is as much a way of thinking as it is a set of techniques, it seems useful to round out Part 1 by seeing the principles in action on small, self contained, but nontrivial network problems. Thus this chapter provides examples of applying the principles in solving specific networking problems. The examples are drawn from real problems, and some of the solutions are used in real products. Unlike subsequent chapters, this chapter is not a collection of new material followed by a set of exercises. Instead, this chapter can be thought of as an extended set of exercises. In Section 4.1 to Section 4.15, 15 problems are motivated and described. Each problem is followed by a hint that suggests specific principles, which is then followed by a solution sketch. There are also a few exercises after each solution. In classes and seminars on the topic of this chapter, the audience enjoyed inventing solutions by themselves (after a few hints were provided), rather than directly seeing the final solutions.}
}
@article{LIN2022104649,
title = {Towards a cross-level understanding of Bayesian inference in the brain},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {137},
pages = {104649},
year = {2022},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2022.104649},
url = {https://www.sciencedirect.com/science/article/pii/S0149763422001385},
author = {Chin-Hsuan Sophie Lin and Marta I. Garrido},
keywords = {Probabilistic inference, Bayesian decision theory, Uncertainty, Sampling, Variational approximation, Neural codes, Marr’s level of analysis},
abstract = {Perception emerges from unconscious probabilistic inference, which guides behaviour in our ubiquitously uncertain environment. Bayesian decision theory is a prominent computational model that describes how people make rational decisions using noisy and ambiguous sensory observations. However, critical questions have been raised about the validity of the Bayesian framework in explaining the mental process of inference. Firstly, some natural behaviours deviate from Bayesian optimum. Secondly, the neural mechanisms that support Bayesian computations in the brain are yet to be understood. Taking Marr’s cross level approach, we review the recent progress made in addressing these challenges. We first review studies that combined behavioural paradigms and modelling approaches to explain both optimal and suboptimal behaviours. Next, we evaluate the theoretical advances and the current evidence for ecologically feasible algorithms and neural implementations in the brain, which may enable probabilistic inference. We argue that this cross-level approach is necessary for the worthwhile pursuit to uncover mechanistic accounts of human behaviour.}
}
@article{THIEDE201536,
title = {Can teachers accurately predict student performance?},
journal = {Teaching and Teacher Education},
volume = {49},
pages = {36-44},
year = {2015},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2015.01.012},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X1500013X},
author = {Keith W. Thiede and Jonathan L. Brendefur and Richard D. Osguthorpe and Michele B. Carney and Amanda Bremner and Sam Strother and Steven Oswalt and Jennifer L. Snow and John Sutton and Dan Jesse},
keywords = {Teacher judgment, Judgment accuracy, Mathematics achievement},
abstract = {In two studies, we examined the effect of professional development to improve mathematics instruction on the accuracy of teachers' monitoring of student learning. Study 1 was conducted with 36 teachers participating in three years of professional development. Judgment accuracy was influenced by the fidelity with which what was learned in the professional development. Study 2 was conducted with 64 teachers from 8 schools, which were randomly assigned to receive professional development or serve as a control. Judgment accuracy was greater for teachers receiving professional development than for teachers who did not and teachers were better to predict students' computational skills.}
}
@article{MACLEOD2019101201,
title = {Mesoscopic modeling as a cognitive strategy for handling complex biological systems},
journal = {Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences},
volume = {78},
pages = {101201},
year = {2019},
issn = {1369-8486},
doi = {https://doi.org/10.1016/j.shpsc.2019.101201},
url = {https://www.sciencedirect.com/science/article/pii/S1369848618300839},
author = {Miles MacLeod and Nancy J. Nersessian},
keywords = {Mesoscopic modeling, Middle-out strategy, Systems biology, Model building, Mental modeling, Distributed cognition, Bounded rationality},
abstract = {In this paper we aim to give an analysis and cognitive rationalization of a common practice or strategy of modeling in systems biology known as a middle-out modeling strategy. The strategy in the cases we look at is facilitated through the construction of what can be called mesoscopic models. Many models built in computational systems biology are mesoscopic (midsize) in scale. Such models lack the sufficient fidelity to serve as robust predictors of the behaviors of complex biological systems, one of the signature goals of the field. This puts some pressure on the field to provide reasons for why and how these practices are warranted despite not meeting the stated goals of the field. Using the results of ethnographic study of problem-solving practices in systems biology, we aim to examine the middle-out strategy and mesoscopic modeling in detail and to show that these practices are rational responses to complex problem solving tasks on cognitive grounds in particular. However making this claim requires us to update the standard notion of bounded rationality to take account of how human cognition is coupled to computation in these contexts. Our account fleshes out the idea that has been raised by some philosophers on the “hybrid” nature of computational modeling and simulation. What we call “coupling” both extends modelers’ capacities to handle complex systems, but also produces various cognitive and computational constraints which need to be taken into account in any computational problem solving strategy seeking to maintain insight and control over the models produced.}
}
@article{GAO2023106199,
title = {Letter to the Editor on a shallow water wave equation in Results Phys. 43, 106048 (2022) and its generalization},
journal = {Results in Physics},
volume = {44},
pages = {106199},
year = {2023},
issn = {2211-3797},
doi = {https://doi.org/10.1016/j.rinp.2022.106199},
url = {https://www.sciencedirect.com/science/article/pii/S2211379722008208},
author = {Xin-Yi Gao and Yong-Jiang Guo and Wen-Rui Shan},
keywords = {Generalized shallow water wave equation, Similarity reductions, Symbolic computation},
abstract = {Results Phys. 43, 106048 (2022) has amusingly retrieved some solitonic and other analytic solutions for a shallow water wave equation presented there. In this Letter, we suggest that such an equation be moreover studied in line with Results Phys. 43, 106048 (2022). Employing symbolic computation, for a generalization of that equation, with respect to the displacement and velocity of the water, we construct a family of the similarity reductions, to a known ordinary differential equation. Our results depend on the gravitational force and wave height.}
}
@article{HE2023112111,
title = {Predicting thermodynamic stability of magnesium alloys in machine learning},
journal = {Computational Materials Science},
volume = {223},
pages = {112111},
year = {2023},
issn = {0927-0256},
doi = {https://doi.org/10.1016/j.commatsci.2023.112111},
url = {https://www.sciencedirect.com/science/article/pii/S0927025623001052},
author = {Xi He and Jinde Liu and Chen Yang and Gang Jiang},
keywords = {Machine learning, DFT, Thermodynamic stability, Magnesium alloy},
abstract = {Density functional theory (DFT) have been widely used to screen thermodynamically stable material; however, its high computational cost limits its use. In this paper, we explore the use of DFT data from high-throughput calculations to create faster machine learning (ML) models that can be used to screen thermodynamically stable magnesium alloy materials. Our methods work by utilizing the kernel ridge regression (KRR) algorithm, as well as Deep Potential Molecular Dynamics (DeePMD) to train ML models for predicting the formation energy of magnesium alloys. The accuracy, stability, and generalization ability of the ML models created under both methods are evaluated in detail. Meanwhile, we have conducted in-depth comparative analysis of the two methods, which concluded that the accuracy of DeePMD model performs better and time efficiency of KRR model has more advantages. The results show that the best performing DeePMD model and KRR model achieve the RMSE of 0.43 meV/atom and 6.80 meV/atom, indicating that our methods provide a reliable idea for obtaining the formation energy of magnesium alloys.}
}
@incollection{GOMILA201219,
title = {3 - The Relevance of Language for Thought: A Continuum of Possibilities},
editor = {Antoni Gomila},
booktitle = {Verbal Minds},
publisher = {Elsevier},
address = {London},
pages = {19-33},
year = {2012},
isbn = {978-0-12-385200-7},
doi = {https://doi.org/10.1016/B978-0-12-385200-7.00003-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780123852007000035},
author = {Antoni Gomila},
keywords = {Cognitive restructuring, linguistic relativism, Whorf, Vygotsky, thinking for speaking, modular interphase, social scaffolding, categorical effect, perceptual similarity},
abstract = {Publisher Summary
This chapter directs the influence and relevance of language on thoughts. Though there has been no outlined domain on how exactly language effects cognitive architecture, the chapter critically studies five most relevant positions that have attracted defenders, critics since twentieth century to contemporary proposals. It discuses relativism, cognitive restructuring, thinking for speaking, language as modular interface, and language as social scaffolding. Linguistic relativism finds its roots in Romanticism as a reaction to the supremacist attitudes of the “Enlightment thinkers,” who were in the business of establishing hierarchies of languages. Cognitive system, being linguistic, acquires a supplementary system of cognitive representation and processing, which transforms the basic capabilities of system and gives rise to new possibilities. Since language is an interface between the modules it attempts to concede to some cognitive impact without challenging the general cognitive architecture of modules of thought as a successful representational vehicle. Lastly, human minds are socially and culturally constituted minds and therefore linguistic symbols (like other kinds of symbols and other social tools in general) allow the individual to externally discharge cognitive processes through language.}
}
@article{REIS2024103184,
title = {Machine learning methods in physical therapy: A scoping review of applications in clinical context},
journal = {Musculoskeletal Science and Practice},
volume = {74},
pages = {103184},
year = {2024},
issn = {2468-7812},
doi = {https://doi.org/10.1016/j.msksp.2024.103184},
url = {https://www.sciencedirect.com/science/article/pii/S2468781224002790},
author = {Felipe J.J. Reis and Matheus Bartholazzi Lugão de Carvalho and Gabriela de Assis Neves and Leandro Calazans Nogueira and Ney Meziat-Filho},
keywords = {Artificial intelligence, Computational intelligence, Machine intelligence, Computer reason, Physical therapy modalities},
abstract = {Background
Machine learning (ML) efficiently processes large datasets, showing promise in enhancing clinical practice within physical therapy.
Objective
The aim of this scoping review is to provide an overview of studies using ML approaches in clinical settings of physical therapy.
Data sources
A scoping review was performed in PubMed, EMBASE, PEDro, Cochrane, Web of Science, and Scopus.
Selection criteria
We included studies utilizing ML methods. ML was defined as the utilization of computational systems to encode patterns and relationships, enabling predictions or classifications with minimal human interference.
Data extraction and data synthesis
Data were extracted regarding methods, data types, performance metrics, and model availability.
Results
Forty-two studies were included. The majority were published after 2020 (n = 25). Fourteen studies (33.3%) were in the musculoskeletal physical therapy field, nine (21.4%) in neurological, and eight (19%) in sports physical therapy. We identified 44 different ML models, with random forest being the most used. Three studies reported on model availability. We identified several clinical applications for ML-based tools, including diagnosis (n = 14), prognosis (n = 7), treatment outcomes prediction (n = 7), clinical decision support (n = 5), movement analysis (n = 4), patient monitoring (n = 3), and personalized care plan (n = 2).
Limitation
Model performance metrics, costs, model interpretability, and explainability were not reported.
Conclusion
This scope review mapped the emerging landscape of machine learning applications in physical therapy. Despite the growing interest, the field still lacks high-quality studies on validation, model availability, and acceptability to advance from research to clinical practice.}
}
@article{BLACUTT2025586,
title = {Bias toward escape responding during reinforcement learning among those with suicidal ideation},
journal = {Journal of Psychiatric Research},
volume = {181},
pages = {586-595},
year = {2025},
issn = {0022-3956},
doi = {https://doi.org/10.1016/j.jpsychires.2024.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S0022395624007222},
author = {Miguel Blacutt and Caitlin M. O'Loughlin and Brooke A. Ammerman},
keywords = {Suicide, Avoidance, Computational, Impulsivity, Drift diffusion},
abstract = {Self-injury and suicide can be characterized by reward system dysfunction and self-reports of active efforts to escape unpleasant emotional states. Therefore, individuals with histories of suicidal ideation (SI) should exhibit a preference for active escape from unpleasant states, which exceed the effects of impulsive behavior under distress and lack of premeditation. Participants made active (Go) or passive (No-Go) choices in response to stimuli to escape or avoid an unpleasant state in a behavioral task. A drift-diffusion reinforcement learning model was used to estimate latent biases for active escape and avoidance in people with and without SI history. Bayesian logistic regression was used to examine the relationship between escape and avoid bias with SI. Escape bias predicted SI history, whereas avoidance bias did not. Escape bias remained a significant predictor of SI when controlling for negative urgency and lack of premeditation. Those with histories of SI demonstrate a decision-making bias favoring escape from aversive states. This bias remains significant after adjusting for facets of impulsivity linked to hasty decisions under distress and lack of premeditation. A heightened escape response may help clinicians to identify SI risk and develop targeted treatments to attenuate the escape bias.}
}
@article{JAGER2021133,
title = {Using agent-based modelling to explore behavioural dynamics affecting our climate},
journal = {Current Opinion in Psychology},
volume = {42},
pages = {133-139},
year = {2021},
note = {Psychology of Climate Change (2021)},
issn = {2352-250X},
doi = {https://doi.org/10.1016/j.copsyc.2021.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2352250X21000968},
author = {Wander Jager},
keywords = {Agent based modelling, Social complexity, Computational social science, Social simulation, Artificial societies, Environmental behaviour, Climate, Psychology},
abstract = {This article introduces the methodology of agent-based modelling (ABM), explains how it contributes to understanding the dynamics of climate-relevant behaviour and discusses the challenges to implementing behavioural theory in ABMs. Next, an overview will be given on recent advances in environmentally relevant ABMs. The conclusions address the future of the ABM tool in the context of environmentally relevant behaviour in research and education.}
}
@article{XIE2015262,
title = {Evolutionary sampling: A novel way of machine learning within a probabilistic framework},
journal = {Information Sciences},
volume = {299},
pages = {262-282},
year = {2015},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2014.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0020025514011384},
author = {Zhenping Xie and Jun Sun and Vasile Palade and Shitong Wang and Yuan Liu},
keywords = {Evolutionary sampling, Support sample model, Monte Carlo Markov chain, Rejection sampling, Online learning, Particle swarm optimization},
abstract = {In many traditional machine learning methods, sampling is only a process of acquiring training data. However, some studies (on sequential Markov chains and particle filters) have demonstrated that sampling can be used for solving some intractable optimization problems in classical learning methods. Along this line of thinking, the relationships between sampling and learning are theoretically exploited in this paper, wherein the key feature of the sampling process is selecting representative samples from original data that can be modeled by a probability distribution. In theory, acquiring reliable samples is not an easy task for an arbitrary probability distribution. Motivated by approaches in evolutionary computation, rejection sampling and function approximation, a novel sampling strategy, called the evolutionary sampling, is proposed in this paper, and a machine learning method, called the evolutionary sampling approach (ESA), is put forward afterwards. Within ESA, a computing model, called the support sample model (SSM), is presented as well and is used to approximate an original density function. Accordingly, a concrete implementation of an evolutionary sampling approach (ESA) is proposed to seek the optimal model parameters of the SSM. Benefiting from the combination of rejection sampling and evolutionary searching, the ESA can theoretically converge to the optimal solution by minimizing the total variation distance, and can do this with high computational efficiency. Moreover, the normalized factor of a density function can be automatically estimated with high precision within the ESA. As a result, the ESA may be suitable for machine learning problems that could be transformed into density function approximation problems within a probabilistic framework. In addition, derived from the rejection sampling strategy, the ESA can also have online learning abilities required by large-scale data stream processing tasks. Theoretical analyses and application studies are carried out in this paper, and the results demonstrate that the ESA, as a novel way of machine learning, has several prominent merits aspired by past researches in machine learning.}
}
@article{WEISSLER19991061,
title = {A Perspective on Standardizing the Predictive Power of Noninvasive Cardiovascular Tests by Likelihood Ratio Computation: 1. Mathematical Principles},
journal = {Mayo Clinic Proceedings},
volume = {74},
number = {11},
pages = {1061-1071},
year = {1999},
issn = {0025-6196},
doi = {https://doi.org/10.4065/74.11.1061},
url = {https://www.sciencedirect.com/science/article/pii/S0025619611650933},
author = {Arnold M. Weissler},
abstract = {The current practice of reporting positive and negative predictive value (PV), sensitivity (Se), and specificity (Sp) as measures of the power of noninvasive cardiovascular tests has significant limitations. A test result's PV and its comparison with other test results are highly dependent on the pretest disease prevalence at which it is determined; the citation of sensitivity and specificity provides no succinct or explicit quantitation of the rule-in and rule-out power of a test. This article presents a rationale for the use of an alternative standard for expressing predictive power in the form of positive and negative likelihood ratios, (+)LR and (-)LR. The likelihood ratios are composite expressions of test power, which incorporate the Se and Sp and their respective complements [(1 - Se) and (1 - Sp)], thus yielding single unambiguous measures of positive and negative predictive power. The likelihood ratios are calculated as follows: (+)LR = Se(l- Sp) and (-)LR = Sp/(I- Se). On analysis of the predictive value equations, the likelihood ratios equal the quotients of the posttest predictive value odds to the pretest prevalence odds for disease and no disease, respectively, as follows: (+)LR = (+)PVOd/POD and (-)LR = (-)PVOn/PON, where (+)PVO d is positive predictive value odds for disease, POD is prevalence odds for disease, (-)PVOn is negative predictive value odds for no disease, and PON is prevalence odds for no disease. Thus, the likelihood ratios are measures of the odds advantage in posttest probability of disease or no disease relative to pretest probability, independent of disease prevalence in the tested population. The quotients of the (+)LR or the (-)LR among test results studied in a common population are direct expressions of their relative predictive power in that population, The likelihood ratio principle is applicable to the evaluation of the predictive power of multiple tests performed in a common population and to estimating predictive power at multiple test thresholds.}
}
@article{BERZ1990473,
title = {Computational aspects of optics design and simulation: COSY INFINITY},
journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
volume = {298},
number = {1},
pages = {473-479},
year = {1990},
issn = {0168-9002},
doi = {https://doi.org/10.1016/0168-9002(90)90649-Q},
url = {https://www.sciencedirect.com/science/article/pii/016890029090649Q},
author = {Martin Berz},
abstract = {The new differential algebraic (DA) techniques allow very efficient treatment and understanding of nonlinear motion in optical systems as well as circular accelerators. To utilize these techniques in their most general way, a powerful software environment is essential. A language with structure elements similar to Pascal was developed. It has object oriented features to allow for a direct utilization of the elementary operations of the DA package. The compiler of the language is written in Fortran 77 to guarantee wide portability. The language was used to write a very general beam optics code, COSY INFINITY. At its lowest level, it allows the computation of the maps of standard beam line elements including fringe fields and system parameters to arbitrary order. The power of the DA approach coupled with an adequate language environment reveals itself in the very limited length of COSY INFINITY of only a few hundred lines. Grouping of elements as well as structures for optimization and study are readily available through the features of the language. Because of the openness of the approach, it offers a lot of power for more advanced purposes. For example, it is very easy to construct new particle optical elements. There are also many ways to efficiently manipulate and analyze the maps.}
}
@article{CHERRIER2023104497,
title = {Household heterogeneity in macroeconomic models: A historical perspective},
journal = {European Economic Review},
volume = {158},
pages = {104497},
year = {2023},
issn = {0014-2921},
doi = {https://doi.org/10.1016/j.euroecorev.2023.104497},
url = {https://www.sciencedirect.com/science/article/pii/S0014292123001265},
author = {Beatrice Cherrier and Pedro Garcia Duarte and Aurélien Saïdi},
keywords = {History of macroeconomics, Heterogeneous agents, Bewley models, Permanent income hypothesis, Aggregation, Equity premium puzzle, Precautionary savings},
abstract = {In this paper, we trace the rise of heterogeneous household models in mainstream macroeconomics from the turn of the 1980s to the early 2000s, when these models evolved into an identifiable and consistent literature. We show that different communities across the US and Europe considered heterogeneous agents for various reasons and developed models that differed in their theoretical and empirical strategies. Minnesota economists primarily focused on incorporating stochastic heterogeneity into general equilibrium models. Other researchers refined growth models or tried to find alternatives to the permanent income hypothesis, leading them to explore more structural heterogeneity. We also document the computational challenges that some of these communities faced, how they gradually became aware of each other's work, and how they faced criticisms from macro- and microeconomists, many of them trained in European countries and dissatisfied with the theoretical and empirical aggregation strategies underlying these models.}
}
@article{HICKS2007233,
title = {Lean information management: Understanding and eliminating waste},
journal = {International Journal of Information Management},
volume = {27},
number = {4},
pages = {233-249},
year = {2007},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2006.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S0268401206001435},
author = {B.J. Hicks},
keywords = {Information management, SMEs, Waste, Information systems infrastructure, Strategy, Process improvement},
abstract = {This paper deals with the development of a new approach for supporting the improvement of information management and the overall information systems infrastructure. In particular, the paper discusses the application of lean thinking to information management; where information management can be considered to involve adding value to information by virtue of how it is organised, visualised and represented; and enabling information (value) to flow to the end-user (customer) through the processes of exchange, sharing and collaboration. The potential benefits of lean thinking are discussed and the fundamental barriers for its application to information management are highlighted. These include the need to characterise the nature of waste and establish the five principles of; value, value streams, flow, pull and continuous improvement in the context of information management. It follows that the core contribution of this paper is the development of an understanding of these critical elements and the creation of a conceptual framework for a set of lean principles within the context of information management. This framework offers a unique and arguably generic approach for supporting the retrospective improvement of information management systems and the overall information systems infrastructure.}
}
@article{WILSON1997575,
title = {Computation and controversy: Value conflicts and social choices: R. KLING (Ed.) 2nd ed. Academic Press, New York (1996). xxiv + 961 pp., ISBN 0-12-415040-3},
journal = {Information Processing & Management},
volume = {33},
number = {4},
pages = {575-577},
year = {1997},
issn = {0306-4573},
doi = {https://doi.org/10.1016/S0306-4573(97)82727-6},
url = {https://www.sciencedirect.com/science/article/pii/S0306457397827276},
author = {Tom Wilson}
}
@article{ADAMS201731,
title = {Patternlets — A teaching tool for introducing students to parallel design patterns},
journal = {Journal of Parallel and Distributed Computing},
volume = {105},
pages = {31-41},
year = {2017},
note = {Keeping up with Technology: Teaching Parallel, Distributed and High-Performance Computing},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2017.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S074373151730014X},
author = {Joel C. Adams},
keywords = {Design patterns, Education, MPI, Multiprocessing, Multithreading, OpenMP, Parallel, Patternlets, Teaching, Threads},
abstract = {Thanks to the ubiquity of multicore processors, today’s CS students must be introduced to parallel computing or they will be ill prepared as modern software developers. Professional developers of parallel software think in terms of parallel design patterns, which are markedly different from traditional (sequential) design patterns. It follows that the more we can teach students to think in terms of parallel patterns, the more their thinking will resemble that of parallel software professionals. In this paper, we present patternlets—minimalist, scalable, syntactically correct programs, each designed to introduce students to a particular parallel design pattern. The collection currently includes 44 patternlets (16 MPI, 17 OpenMP, 9 Pthreads, and 2 heterogeneous), of which we present a representative sample. We also present data that indicate the use of patternlets to introduce parallelism in CS2 produced a modest improvement in student understanding of parallel concepts.}
}
@incollection{KAKKAR2025215,
title = {Chapter 11 - A neuroinspired journey: Tracing the evolution and objectives of neuromorphic systems},
editor = {Harish Garg and Jyotir {Moy Chatterjee} and R. Sujatha and Shatrughan Modi},
booktitle = {Primer to Neuromorphic Computing},
publisher = {Academic Press},
pages = {215-238},
year = {2025},
isbn = {978-0-443-21480-6},
doi = {https://doi.org/10.1016/B978-0-443-21480-6.00009-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443214806000092},
author = {Mohit Kumar Kakkar},
keywords = {Neuromorphic computing, Von Neumann Model, Neural network architecture, Artificial neural networks, Neuromorphic framework},
abstract = {A subfield of computing known as “neuromorphic computing” (NC) develops cutting-edge and effective computing platforms by drawing inspiration from the anatomy and physiology of the human brain. The potential for energy savings offered by NC is one of its primary benefits. Neuromorphic systems aim to replicate the brain's remarkable energy efficiency by utilizing specialized hardware designs and algorithms that optimize computation and minimize data movement to reduce power consumption. This work presents a thorough investigation of the development and goals of neuromorphic frameworks, taking motivation from the complicated functions of the human mind. It investigates the motives and driving forces behind the pursuit of NC, such as the search for highly parallel and energy-efficient computing architectures. In addition, this work has discussed the thematic areas and benchmarks for progress in NC as well. This chapter serves as a guide through the neuroinspired journey of neuromorphic systems, revealing insight into their past, present, and future.}
}
@article{MOGILNER2019R915,
title = {Alex Mogilner},
journal = {Current Biology},
volume = {29},
number = {19},
pages = {R915-R917},
year = {2019},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2019.07.077},
url = {https://www.sciencedirect.com/science/article/pii/S0960982219309571},
author = {Alex Mogilner}
}
@article{TAKAMA20151263,
title = {NFC-based Tangible User Interface for Information Curation and Its Application to Analogy Game},
journal = {Procedia Computer Science},
volume = {60},
pages = {1263-1270},
year = {2015},
note = {Knowledge-Based and Intelligent Information & Engineering Systems 19th Annual Conference, KES-2015, Singapore, September 2015 Proceedings},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2015.08.192},
url = {https://www.sciencedirect.com/science/article/pii/S1877050915023194},
author = {Yasufumi Takama and Tomohiro Ito and Hiroshi Ishikawa},
keywords = {Tangible user interface (TUI), Near field communication (NFC), Smartphone, Information curation, Analogy game},
abstract = {This paper applies a Tangible User Interface (TUI) for information curation using Near Field Communication (NFC) to an analogy game. The increase in text data is more remarkable in current IT society. Although those are usually accessed with using Graphical User Interface (GUI), users except experienced computer users have difficulty in reading and organizing data with GUI. In particular, information curation such as grouping related data / information and finding relationship among them is difficult. In order to solve this problem, an interface that can access text data intuitively is expected. We are developing a TUI based on NFC, by which a user can move and group text data in a similar manner when handling paper documents. As one of the promising applications of the proposed TUI, this paper focuses on creative thinking support, for which touching externalized thought by hand is expected to be effective. An experiment is conducted, in which test participants did an analogy game with using the proposed TUI. The experimental result shows experience of using the TUI affects the participants’ self-evaluation about idea creation.}
}