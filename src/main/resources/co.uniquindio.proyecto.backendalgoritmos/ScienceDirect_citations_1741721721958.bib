@article{RASUL2024101041,
title = {Enhancing academic integrity among students in GenAI Era:A holistic framework},
journal = {The International Journal of Management Education},
volume = {22},
number = {3},
pages = {101041},
year = {2024},
issn = {1472-8117},
doi = {https://doi.org/10.1016/j.ijme.2024.101041},
url = {https://www.sciencedirect.com/science/article/pii/S1472811724001125},
author = {Tareq Rasul and Sumesh Nair and Diane Kalendra and M.S. Balaji and Fernando de Oliveira Santini and Wagner Junior Ladeira and Raouf Ahmad Rather and Naveed Yasin and Raul V. Rodriguez and Panagiotis Kokkalis and Md Wahid Murad and Md Uzir Hossain},
keywords = {Generative AI, Academic integrity, Higher education, Students, Stakeholders},
abstract = {The introduction of Artificial Intelligence (AI), specifically Generative AI (GenAI), has significantly transformed the higher education landscape. Despite the opportunities GenAI offers to students, they pose significant challenges for academic integrity. Thus, it is crucial for higher education institutions (HEI) to balance the use of GenAI for enhancing the learning experience of students with its ethical and responsible use in their educational journey. The present study proposes a comprehensive academic integrity framework focusing on three key stakeholders: students, educators, and institutions. We propose eight strategies ranging from collaborative learning for students to developing a comprehensive GenAI policy for institutions in maintaining academic integrity among students in HEI. Furthermore, we identified four challenges, namely financial, strategic, operational, and cultural, in the implementing a comprehensive academic integrity framework in the GenAI era. This study offers significant insights for HEI to maintain academic integrity among students in the GenAI era.}
}
@article{WU2018127,
title = {Single dose testosterone administration modulates emotional reactivity and counterfactual choice in healthy males},
journal = {Psychoneuroendocrinology},
volume = {90},
pages = {127-133},
year = {2018},
issn = {0306-4530},
doi = {https://doi.org/10.1016/j.psyneuen.2018.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S0306453017312532},
author = {Yin Wu and Luke Clark and Samuele Zilioli and Christoph Eisenegger and Claire M. Gillan and Huihua Deng and Hong Li},
keywords = {Testosterone, Reward, Regret, Emotion, Human male, Dual process},
abstract = {Testosterone has been implicated in the regulation of emotional responses and risky decision-making. However, the causal effect of testosterone upon emotional decision-making, especially in non-social settings, is still unclear. The present study investigated the role of testosterone in counterfactual thinking: regret is an intense negative emotion that arises from comparison of an obtained outcome from a decision against a better, non-obtained (i.e. counterfactual) alternative. Healthy male participants (n = 64) received a single-dose of 150 mg testosterone Androgel in a double-blind, placebo-controlled, between-participants design. At 180 min post-administration, participants performed the counterfactual thinking task. We applied a computational model derived from behavioral economic principles to uncover latent decision-making mechanisms that may be invisible in simple choice analyses. Our data showed that testosterone increased the ability to use anticipated regret to guide choice behavior, while reducing choice based on expected value. On affective ratings, testosterone increased sensitivity to both obtained and counterfactual outcomes. These findings provide evidence that testosterone causally modulates emotional decision-making, and highlight the role of testosterone in affective sensitivity.}
}
@incollection{CRUZQUIROGA2016103,
title = {Chapter 5 - Neurobiological Computation and Neural Networks},
editor = {Munish Puri and Yashwant Pathak and Vijay Kumar Sutariya and Srinivas Tipparaju and Wilfrido Moreno},
booktitle = {Artificial Neural Network for Drug Design, Delivery and Disposition},
publisher = {Academic Press},
address = {Boston},
pages = {103-120},
year = {2016},
isbn = {978-0-12-801559-9},
doi = {https://doi.org/10.1016/B978-0-12-801559-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128015599000053},
author = {Luis Fernando {Cruz Quiroga} and Wilfrido Alejandro Moreno},
keywords = {Complex problem solving, Neural networks, Neurobiology, Neuroscience},
abstract = {This chapter presents the neurobiological basis for the convergence of interdisciplinary work (Nano-Bio-Info-Cogno) in the research of artificial neural networks. The neurobiological study was conducted from neuroscience and technology; the topics explained are genetics and cognition, complexity of information, information processing, brain and problem solving, emotions, and solutions as well as the relationship between the nervous system cells and biological synthesis of information as part of studies to the given problems. The most specific cognitive functions related to decision making and problem solving—attention, time, process, motion, relevance of information, and memory—as well as reasoning processes not typically associated with solving complex problems are reviewed.}
}
@article{LOONG2014237,
title = {Tourism and Simulacrum: The Computational Economy of Algorithmic Destinations},
journal = {Procedia - Social and Behavioral Sciences},
volume = {144},
pages = {237-246},
year = {2014},
note = {5th Asia-Euro Conference 2014 in Tourism, Hospitality & Gastronomy},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.07.292},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814042207},
author = {Bernard Lew Shian Loong},
keywords = {gamified tourism, algorithmic destinations, simulacrum, computational economics, tourism computability, reflexivity},
abstract = {The paper establishes a conceptual and methodological link between destinations and simulacrum through gamified tourism. As a paradigm, gamified tourism provides a rationale and a setting within which to apply computational economics to tourism, an approach amounting to tourism computability. Algorithmic destinations serve as “petri dishes” for real destinations. Utilizing rule sets that embody destination growth dynamics and visitor behavioural norms, seeding points in a cellular automata model (CA) were grown into algorithmic destinations. This is followed by a morphological transformation of geo-tagged satellite images into spatial points. The overlap of this additive and subtractive approach is at the core of tourism computability. Finally, the spatio-temporal dynamics of economic resilience was traced out through a visual phenomenology of algorithmic destinations. The gamification of tourism should be embraced as it holds up a flicker of hope for mature destinations, amidst the onset of museumification and increased commoditization of heritage sites. Gamification is treated as part of the reflexive cycle for destination authenticity; a notion that that Cohen (1988) alluded to in his discussion of emergent authenticity in destination image formation. Seen in this light, the museumification of Venice and the proliferation of its simulacrum, such as the Venetian Hotel in Macao and Venice-themed hotels across the globe, are prefigures and archetypes of a glorious age of gamified tourism.}
}
@article{PHANG2019100837,
title = {How to derive causal insights for digital commerce in China? A research commentary on computational social science methods},
journal = {Electronic Commerce Research and Applications},
volume = {35},
pages = {100837},
year = {2019},
issn = {1567-4223},
doi = {https://doi.org/10.1016/j.elerap.2019.100837},
url = {https://www.sciencedirect.com/science/article/pii/S1567422319300146},
author = {David C.W. Phang and Kanliang Wang and Qiuhong Wang and Robert J. Kauffman and Maurizio Naldi},
keywords = {Big data, Business insights, Causal inference, Causal methods, Computational social science (CSS), Consumer behavior, China, Data analytics, Digital economy, E-commerce, Emerging markets, Empirical research, Information systems (IS) research, Machine learning (ML), M-commerce, Policy analytics, Research design, Secondary data, Sensor data, Streaming data, Social insights, Theory testing},
abstract = {The transformation of empirical research due to the arrival of big data analytics and data science, as well as the new availability of methods that emphasize causal inference, are moving forward at full speed. In this Research Commentary, we examine the extent to which this has the potential to influence how e-commerce research is conducted. China offers the ultimate in data-at-scale settings, and the construction of real-world natural experiments. Chinese e-commerce includes some of the largest firms involved in e-commerce, mobile commerce, social media and social networks. This article was written to encourage young faculty and doctoral students to engage in research that can be carried out in near real-time, with truly experimental or quasi-experimental research designs, and with the clear intention of establishing causal inferences that relate the precursors and drivers of observable outcomes through various kinds of processes. We discuss: the relevant data sources and research contexts; the methods perspectives that are appropriate which blend Computer Science, Statistics and Econometrics, how the research can be made relevant for China; and what kinds of findings and research directions are available. This article is not a tutorial on big data analytics methods in general though, nor does it cover just those published works that demonstrate big data methods and empirical causality in other disciplines. Instead, the empirical research covered is mostly taken from Electronic Commerce Research and Applications, which has published many articles on Chinese e-commerce. This Research Commentary invites researchers in China and the Asia Pacific region to expand their coverage to bring into their empirical work the new methods and philosophy of causal data science.}
}
@article{NAKHLEH2013719,
title = {Computational approaches to species phylogeny inference and gene tree reconciliation},
journal = {Trends in Ecology & Evolution},
volume = {28},
number = {12},
pages = {719-728},
year = {2013},
issn = {0169-5347},
doi = {https://doi.org/10.1016/j.tree.2013.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0169534713002139},
author = {Luay Nakhleh},
abstract = {An intricate relation exists between gene trees and species phylogenies, due to evolutionary processes that act on the genes within and across the branches of the species phylogeny. From an analytical perspective, gene trees serve as character states for inferring accurate species phylogenies, and species phylogenies serve as a backdrop against which gene trees are contrasted for elucidating evolutionary processes and parameters. In a 1997 paper, Maddison discussed this relation, reviewed the signatures left by three major evolutionary processes on the gene trees, and surveyed parsimony and likelihood criteria for utilizing these signatures to elucidate computationally this relation. Here, I review progress that has been made in developing computational methods for analyses under these two criteria, and survey remaining challenges.}
}
@article{JARAETTINGER2016589,
title = {The Naïve Utility Calculus: Computational Principles Underlying Commonsense Psychology},
journal = {Trends in Cognitive Sciences},
volume = {20},
number = {8},
pages = {589-604},
year = {2016},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2016.05.011},
url = {https://www.sciencedirect.com/science/article/pii/S1364661316300535},
author = {Julian Jara-Ettinger and Hyowon Gweon and Laura E. Schulz and Joshua B. Tenenbaum},
abstract = {We propose that human social cognition is structured around a basic understanding of ourselves and others as intuitive utility maximizers: from a young age, humans implicitly assume that agents choose goals and actions to maximize the rewards they expect to obtain relative to the costs they expect to incur. This ‘naïve utility calculus’ allows both children and adults observe the behavior of others and infer their beliefs and desires, their longer-term knowledge and preferences, and even their character: who is knowledgeable or competent, who is praiseworthy or blameworthy, who is friendly, indifferent, or an enemy. We review studies providing support for the naïve utility calculus, and we show how it captures much of the rich social reasoning humans engage in from infancy.}
}
@article{KEITZER20161322,
title = {Thinking outside of the lake: Can controls on nutrient inputs into Lake Erie benefit stream conservation in its watershed?},
journal = {Journal of Great Lakes Research},
volume = {42},
number = {6},
pages = {1322-1331},
year = {2016},
issn = {0380-1330},
doi = {https://doi.org/10.1016/j.jglr.2016.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0380133016300958},
author = {S. Conor Keitzer and Stuart A. Ludsin and Scott P. Sowa and Gust Annis and Jeff G. Arnold and Prasad Daggupati and August M. Froehlich and Matt E. Herbert and Mari-Vaughn V. Johnson and Anthony M. Sasson and Haw Yen and Mike J. White and Charles A. Rewa},
keywords = {Best management practices, SWAT, Non-point source pollution, Great Lakes, Ecosystem-based management, Index of Biotic Integrity},
abstract = {Investment in agricultural conservation practices (CPs) to address Lake Erie's re-eutrophication may offer benefits that extend beyond the lake, such as improved habitat conditions for fish communities throughout the watershed. If such conditions are not explicitly considered in Lake Erie nutrient management strategies, however, this opportunity might be missed. Herein, we quantify the potential for common CPs that will be used to meet nutrient management goals for Lake Erie to simultaneously improve stream biological conditions throughout the western Lake Erie basin (WLEB) watershed. To do so, we linked a high-resolution watershed-hydrology model to predictive biological models in a conservation scenario framework. Our modeling simulations showed that the implementation of CPs on farm acres in critical and moderate need of treatment, representing nearly half of the watershed, would be needed to reduce spring/early summer total phosphorus loads from the WLEB watershed to acceptable levels. This widespread CP implementation also would improve potential stream biological conditions in >11,000km of streams and reduce the percentage of streams where water quality is limiting biological conditions, from 31% to 20%. Despite these improvements, we found that even with additional treatment of acres in low need of CPs, degraded water quality conditions would limit biological conditions in >3200streamkm. Thus, while we expect CPs to play an important role in mitigating eutrophication problems in the Lake Erie ecosystem, additional strategies and emerging technologies appear necessary to fully reduce water quality limitation throughout the watershed.}
}
@article{ALANZI201713,
title = {Inferring rooted species trees from unrooted gene trees using approximate Bayesian computation},
journal = {Molecular Phylogenetics and Evolution},
volume = {116},
pages = {13-24},
year = {2017},
issn = {1055-7903},
doi = {https://doi.org/10.1016/j.ympev.2017.07.017},
url = {https://www.sciencedirect.com/science/article/pii/S1055790317305390},
author = {Ayed R.A. Alanzi and James H. Degnan},
keywords = {Multispecies coalescent, Outgroup, Midpoint rooting, Molecular clock, Identifiability, Sufficiency},
abstract = {Methods for inferring species trees from gene trees motivated by incomplete lineage sorting typically use either rooted gene trees to infer a rooted species tree, or use unrooted gene trees to infer an unrooted species tree, which is then typically rooted using one or more outgroups. Theoretically, however, it has been known since 2011 that it is possible to consistently infer the root of the species tree directly from unrooted gene trees without assuming an outgroup. Here, we use approximate Bayesian computation to infer the root of the species tree from unrooted gene trees assuming the multispecies coalescent model. It is hoped that this approach will be useful in cases where an appropriate outgroup is difficult to find and gene trees do not follow a molecular clock. We use approximate Bayesian computation to infer the root of the species tree from unrooted gene trees. This approach could also be useful when there is prior information that makes a small number of root locations plausible in an unrooted species tree.}
}
@article{ORTEGA2010171,
title = {Parallel drainage network computation on CUDA},
journal = {Computers & Geosciences},
volume = {36},
number = {2},
pages = {171-178},
year = {2010},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0098300409002970},
author = {L. Ortega and A. Rueda},
keywords = {GPU, GPGPU, CUDA, Drainage network, D8 algorithm},
abstract = {Drainage networks determination from digital elevation models (DEM) has been a widely studied problem in the last three decades. During this time, satellite technology has been improving and optimizing digitalized images, and computers have been increasing their capabilities to manage such a huge quantity of information. The rapid growth of CPU power and memory size has concentrated the discussion of DEM algorithms on the accuracy of their results more than their running times. However, obtaining improved running times remains crucial when DEM dimensions and their resolutions increase. Parallel computation provides an opportunity to reduce run times. Recently developed graphics processing units (GPUs) are computationally fast not only in Computer Graphics but in General Purpose Computation, the so-called GPGPU. In this paper we explore the parallel characteristics of these GPUs for drainage network determination, using the C-oriented language of CUDA developed by NVIDIA. The results are simple algorithms that run on low-cost technology with a high performance response, obtaining CPU improvements of up to 8×.}
}
@article{GOK201249,
title = {A philosophical assessment of computational models of consciousness},
journal = {Cognitive Systems Research},
volume = {17-18},
pages = {49-62},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2011.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041711000635},
author = {Selvi Elif Gök and Erdinç Sayan},
keywords = {Consciousness, Computational cognitive modeling, Clarion, LIDA, ACT-R, Neuronal Work Space Model, ART, GMU-BICA},
abstract = {There has been a recent flurry of activity in consciousness research. Although an operational definition of consciousness has not yet been developed, philosophy has come to identify a set of features and aspects that are thought to be associated with the various elements of consciousness. On the other hand, there have been several recent attempts to develop computational models of consciousness that are claimed to capture or illustrate one or more aspects of consciousness. As a plausible substitute to evaluating how well the current computational models model consciousness, this study examines how the current computational models fare in modeling those aspects and features of consciousness identified by philosophy. Following a review of the literature on the philosophy of consciousness, this study constructs a list of features and aspects that would be expected in any successful model of consciousness. The study then evaluates, from the viewpoint of that list, some of the current self-claimed and implemented computational models of consciousness. The computational models studied are evaluated with respect to each identified aspect and feature of consciousness.}
}
@incollection{BODEN2008741,
title = {INFORMATION, COMPUTATION, AND COGNITIVE SCIENCE},
editor = {Pieter Adriaans and Johan {van Benthem}},
booktitle = {Philosophy of Information},
publisher = {North-Holland},
address = {Amsterdam},
pages = {741-761},
year = {2008},
series = {Handbook of the Philosophy of Science},
issn = {18789846},
doi = {https://doi.org/10.1016/B978-0-444-51726-5.50023-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780444517265500236},
author = {Margaret A. Boden}
}
@article{SHI2018117,
title = {Toward automated reasoning for analog IC design by symbolic computation – A survey},
journal = {Integration},
volume = {60},
pages = {117-131},
year = {2018},
issn = {0167-9260},
doi = {https://doi.org/10.1016/j.vlsi.2017.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167926017304182},
author = {Guoyong Shi},
keywords = {Analog integrated circuit (IC), Computer-aided reasoning (CAR), Formal information processing, Graph-pair decision diagram (GPDD), Knowledge representation, Operational amplifier (opamp), Symbolic computation},
abstract = {Analog integrated circuit (IC) design highly depends on reasoning, which distinguishes itself from other areas of IC design. Most of its innovation arises from qualitative reasoning by a pencil and paper. Innovation on the circuit structure needs quick analytical justification. Circuit-level reduced-scale modeling is a popular reasoning means. Circuit simulation tools can only serve partial justification on a design, while design insight still has to be acquired via manual analysis. A basic question has been in existence for many decades: how can we automate the analog IC design process? Many analog synthesis tools proposed decades ago could not make it to this date in the design practice. In this survey the major reason is attributed to the black-box style of the tool design. Human designer's creativity is shielded away from the tool operation while the formal design knowledge hardcoded in those tools remains at a very primitive level. By analyzing the defects of those existing tools, this survey advocates an open tool development philosophy whose major goal is to support human-machine interaction. On the one side a design automation tool is mainly aimed at providing aid for tasks that require analytical deduction while on the other side designers are expected to exercise their creativity based on the machine-generated results. Such human-machine co-working style is believed to be a more feasible solution to analog IC design automation based on the currently available computation technology. In this survey the art of symbolic computation is promoted to be the enabling technology for computer-aided analytical generation. The symbolic computation technology today can support topological and analytical reasoning that is the most demanding need in the analog IC design practice. This survey further calls for more research on the formal methods that are applicable to design knowledge representation, human-machine interaction, and design inference. Some preliminary research results are reviewed and future research directions are pointed out.}
}
@article{KHAN2022200147,
title = {An effective approach to address processing time and computational complexity employing modified CCT for lung disease classification},
journal = {Intelligent Systems with Applications},
volume = {16},
pages = {200147},
year = {2022},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2022.200147},
url = {https://www.sciencedirect.com/science/article/pii/S2667305322000849},
author = {Inam Ullah Khan and Sami Azam and Sidratul Montaha and Abdullah Al Mahmud and A.K.M. Rakibul Haque Rafid and Md. Zahid Hasan and Mirjam Jonkman},
keywords = {COVID-19, Chest X-rays, Image Preprocessing, Modified compact convolutional transformer, Deep convolutional GAN, Hyper-parameter Tuning},
abstract = {Early identification and adequate treatment can help prevent lung disorders from becoming chronic, severe, and life-threatening. X-ray images are commonly used and an automated and effective method involving deep learning techniques can potentially contribute to quick and accurate diagnosis of lung disorders. However, in the study of medical imaging using deep learning, two obstacles limit interpretability. One is an insufficient and imbalanced number of training samples in most medical datasets. The other is excessive training time. Although training time can be reduced by decreasing the number of pixels in the images, training with low resolution images tends to result in poor performance. This study represents a solution to overcome these impediments by balancing the number of images and reducing overall processing time while preserving accuracy. The dataset used in this research contains an unequal number of images in the different classes. The quantity of data in the classes is balanced by creating synthetic images based on the patterns and characteristics of the original images, using a Deep Convolutional Generative Adversarial Network (DCGAN). Unwanted regions are removed from the X-ray images, the brightness and contrast of the images are enhanced, and the abnormalities are highlighted by using different artifact removal, noise reduction, and enhancement techniques. We propose a Modified Compact Convolutional Transformer (MCCT) model using 32 × 32 sized images for the categorization of lung disorders into four classes. An ablation study of eleven cases is employed to adjust several hyper parameters and layer topologies. This reduces training time while preserving accuracy. Six transfer learning models, VGG19, VGG16, ResNet152, ResNet50, ResNet50V2, and MobileNet are applied with the same image size the performance is compared with the proposed MCCT model. Our MCCT model records the greatest test accuracy of 95.37%, requiring a short training time, 10-12 s/epoch, whereas the other models only reach near-moderate performance with accuracies ranging from 43% to 79% and training times of 80-90 s/epoch. The robustness of the model with regards to the number of training samples is validated by training the model multiple times reducing the number of training images gradually from 49621 images to 6204 images. Results suggest that even with a smaller dataset, the performance is sustained. Our proposed approach may contribute to an effective CAD based diagnostic system by addressing the issues of insufficient and imbalanced numbers of medical images, excessive training times and low-resolution images.}
}
@article{BEGGS20091311,
title = {Computations via Newtonian and relativistic kinematic systems},
journal = {Applied Mathematics and Computation},
volume = {215},
number = {4},
pages = {1311-1322},
year = {2009},
note = {Physics and Computation},
issn = {0096-3003},
doi = {https://doi.org/10.1016/j.amc.2009.04.052},
url = {https://www.sciencedirect.com/science/article/pii/S0096300309004214},
author = {E.J. Beggs and J.V. Tucker},
keywords = {Foundations of computation, Computable functions and sets, Newtonian kinematic systems, Relativistic kinematic systems, Foundations of mechanics, Theory of Gedanken experiments, Non-computable physical systems},
abstract = {We are developing a rigorous methodology to analyse experimental computation, by which we mean the idea of computing a set or function by experimenting with some physical equipment. Here we consider experimental computation by kinematic systems under both Newtonian and relativistic kinematics. An experimental procedure, expressed in a language similar to imperative programming languages, is applied to equipment, having the form of a bagatelle, and is interpreted using the two theories. We prove that for any set A of natural numbers there exists a two-dimensional kinematic system BA with a single particle P whose observable behaviour decides n∈A for all n∈N. The procedure can operate under (a) Newtonian mechanics or (b) relativistic mechanics. The proofs show how any information (coded by some A) can be embedded in the structure of a simple kinematic system and retrieved by simple observations of its behaviour. We reflect on the methodology, which seeks a formal theory for performing abstract experiments with physical restrictions on the construction of systems. We conclude with some open problems.}
}
@article{KANAMORI2024103319,
title = {Kunen the expositor},
journal = {Annals of Pure and Applied Logic},
volume = {175},
number = {1, Part B},
pages = {103319},
year = {2024},
note = {Kenneth Kunen (1943-2020)},
issn = {0168-0072},
doi = {https://doi.org/10.1016/j.apal.2023.103319},
url = {https://www.sciencedirect.com/science/article/pii/S0168007223000763},
author = {Akihiro Kanamori},
keywords = {Handbook chapters, Set theory text, Late texts},
abstract = {Kunen's expository work is described, bringing out both his way of assimilating and thinking about set theory and how it had a meaningful hand in its promulgation into the next generations.}
}
@article{NEUMANN2020281,
title = {Parametrised second-order complexity theory with applications to the study of interval computation},
journal = {Theoretical Computer Science},
volume = {806},
pages = {281-304},
year = {2020},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.05.009},
url = {https://www.sciencedirect.com/science/article/pii/S0304397519302889},
author = {Eike Neumann and Florian Steinberg},
keywords = {Second-order complexity, Type two complexity, Interval computation, Computable analysis},
abstract = {We extend the framework for complexity of operators in analysis devised by Kawamura and Cook (2012) to allow for the treatment of a wider class of representations. The main novelty is to endow represented spaces of interest with an additional function on names, called a parameter, which measures the complexity of a given name. This parameter generalises the size function which is usually used in second-order complexity theory and therefore also central to the framework of Kawamura and Cook. The complexity of an algorithm is measured in terms of its running time as a second-order function in the parameter, as well as in terms of how much it increases the complexity of a given name, as measured by the parameters on the input and output side. As an application we develop a rigorous computational complexity theory for interval computation. In the framework of Kawamura and Cook the representation of real numbers based on nested interval enclosures does not yield a reasonable complexity theory. In our new framework this representation is polytime equivalent to the usual Cauchy representation based on dyadic rational approximation. By contrast, the representation of continuous real functions based on interval enclosures is strictly smaller in the polytime reducibility lattice than the usual representation, which encodes a modulus of continuity. Furthermore, the function space representation based on interval enclosures is optimal in the sense that it contains the minimal amount of information amongst those representations which render evaluation polytime computable.}
}
@article{SANGALLI2018117,
title = {Matrix-free weighted quadrature for a computationally efficient isogeometric k-method},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {338},
pages = {117-133},
year = {2018},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2018.04.029},
url = {https://www.sciencedirect.com/science/article/pii/S0045782518302081},
author = {G. Sangalli and M. Tani},
keywords = {Isogeometric analysis, 
               -method, Matrix-free, Weighted quadrature, Preconditioner},
abstract = {The k-method is the isogeometric method based on splines (or NURBS, etc.) with maximum regularity. When implemented following the paradigms of classical finite element methods, the computational resources required by the k-method are prohibitive even for moderate degree. In order to address this issue, we propose a matrix-free strategy combined with weighted quadrature, which is an ad-hoc strategy to compute the integrals of the Galerkin system. Matrix-free weighted quadrature (MF-WQ) speeds up matrix operations, and, perhaps even more important, greatly reduces memory consumption. Our strategy also requires an efficient preconditioner for the linear system iterative solver. In this work we deal with an elliptic model problem, and adopt a preconditioner based on the Fast Diagonalization method, an old idea to solve Sylvester-like equations. Our numerical tests show that the isogeometric solver based on MF-WQ is faster than standard approaches (where the main cost is the matrix formation by standard Gaussian quadrature) even for low degree. But the main achievement is that, with MF-WQ, the k-method gets orders of magnitude faster by increasing the degree, given a target accuracy. Therefore, we are able to show the superiority, in terms of computational efficiency, of the high-degree k-method with respect to low-degree isogeometric discretizations. What we present here is applicable to more complex and realistic differential problems, but its effectiveness will depend on the preconditioner stage, which is as always problem-dependent. This situation is typical of modern high-order methods: the overall performance is mainly related to the quality of the preconditioner.}
}
@article{DUKHANOV20141433,
title = {Double-degree Master's Program in Computational Science: Experiences of ITMO University and University of Amsterdam},
journal = {Procedia Computer Science},
volume = {29},
pages = {1433-1445},
year = {2014},
note = {2014 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2014.05.130},
url = {https://www.sciencedirect.com/science/article/pii/S187705091400307X},
author = {Alexey V. Dukhanov and Valeria V. Krzhizhanovskaya and Anna Bilyatdinova and Alexander V. Boukhanovsky and Peter M.A. Sloot},
keywords = {teaching computational science, M aster's program, double degree, curriculum, enrollment, student research, funding opportunities},
abstract = {We present a new double-degree graduate (Master's) programme developed together by the ITMO University, Russia and University of Amsterdam, The Netherlands. First, we look into the global aspects of integration of d ifferent educational systems and list some funding opportunities fro m European foundations. Then we describe our double-degree program curricu lu m, suggest the time line of enrollment and studies, and give some e xa mples of student research topics. Finally, we d iscuss the peculiarities of joint progra ms with Russia, re flect on the first lessons learnt, and share our thoughts and experiences that could be of interest to the international community e xpanding the educational ma rkets to the vast countries like Russia, Ch ina or India. The paper is written for education professionals and contains useful information for potential students.}
}
@article{BURTONROBERTS20112089,
title = {On the grounding of syntax and the role of phonology in human cognition},
journal = {Lingua},
volume = {121},
number = {14},
pages = {2089-2102},
year = {2011},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2011.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S002438411100146X},
author = {Noel Burton-Roberts},
keywords = {Syntactic grounding, Interface interpretation, Language faculty, Language of thought, Phonology-free generativity, Phonology in human cognition},
abstract = {Chomskyan generative grammar has long been committed to the ‘double-interface’ assumption that the faculty of language (FL) serves two interfaces, PF and LF, and correlatively that expressions have phonological and semantic properties. The paper argues this gives rise to (a) a grounding problem for syntax – i.e. for the interpretable content of syntax – and (b) a problem for the assumption that FL is a generative computation. It is argued these problems are resolved if we think of syntax as grounded exclusively in semantic/conceptual properties. Since this implies that FL is phonology-free, it is argued that FL should not be distinguished from a generative computation describable as ‘the language of thought’ (LOT). The paper explores to what extent this (FL=LOT) thesis is consistent with Chomsky's thinking. Chomsky's recent work can be seen as pointing in that direction but it is not consistent with the double-interface assumption, which he continues to regard as conceptually necessary. In the light of discussion of the issues, the paper concludes with a speculation on the role of phonology in human cognition and its evolution.}
}
@article{HODGMAN2012261,
title = {Cell-free synthetic biology: Thinking outside the cell},
journal = {Metabolic Engineering},
volume = {14},
number = {3},
pages = {261-269},
year = {2012},
note = {Synthetic Biology: New Methodologies and Applications for Metabolic Engineering},
issn = {1096-7176},
doi = {https://doi.org/10.1016/j.ymben.2011.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S1096717611000929},
author = {C. Eric Hodgman and Michael C. Jewett},
keywords = {Cell-free biology,  protein synthesis, Metabolic engineering, Synthetic biology, Synthetic enzymatic pathways, Biocatalysis},
abstract = {Cell-free synthetic biology is emerging as a powerful approach aimed to understand, harness, and expand the capabilities of natural biological systems without using intact cells. Cell-free systems bypass cell walls and remove genetic regulation to enable direct access to the inner workings of the cell. The unprecedented level of control and freedom of design, relative to in vivo systems, has inspired the rapid development of engineering foundations for cell-free systems in recent years. These efforts have led to programmed circuits, spatially organized pathways, co-activated catalytic ensembles, rational optimization of synthetic multi-enzyme pathways, and linear scalability from the micro-liter to the 100-liter scale. It is now clear that cell-free systems offer a versatile test-bed for understanding why nature's designs work the way they do and also for enabling biosynthetic routes to novel chemicals, sustainable fuels, and new classes of tunable materials. While challenges remain, the emergence of cell-free systems is poised to open the way to novel products that until now have been impractical, if not impossible, to produce by other means.}
}
@incollection{BONSIGNORE2019291,
title = {Chapter 14 - Device Design and Computational Simulation},
editor = {Christopher P. Cheng},
booktitle = {Handbook of Vascular Motion},
publisher = {Academic Press},
pages = {291-312},
year = {2019},
isbn = {978-0-12-815713-8},
doi = {https://doi.org/10.1016/B978-0-12-815713-8.00014-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128157138000140},
author = {C. Bonsignore},
keywords = {Device design, boundary conditions, simulation, stress and strain, finite element analysis, nitinol, prototyping, iteration, design control},
abstract = {Medical device development consists of ideation, prototyping, simulation, preclinical testing, and clinical trials. In the early stages, design and test iterations offer insights to incorporate into subsequent iterations and should be repeated often with only as much complexity as necessary. Computational simulations, in the form of analytic calculations or finite element analysis (FEA), can be utilized for design concept screening all the way to design verification testing under design control. For FEA, while the mathematics is complicated, and the programming is intricate, the utility of the simulation is only as good as the realism of the anatomic loading boundary conditions. While boundary conditions may not be able to be prescribed exactly as they happen in vivo, good engineering intuition and judgment are invaluable for making reasonable approximations.}
}
@article{STENROOS2019116159,
title = {Real-time computation of the TMS-induced electric field in a realistic head model},
journal = {NeuroImage},
volume = {203},
pages = {116159},
year = {2019},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2019.116159},
url = {https://www.sciencedirect.com/science/article/pii/S1053811919307505},
author = {Matti Stenroos and Lari M. Koponen},
keywords = {Transcranial magnetic stimulation (TMS), Navigated transcranial magnetic stimulation, Electric field calculation, Coil model, Volume conductor model},
abstract = {Transcranial magnetic stimulation (TMS) is often targeted using a model of TMS-induced electric field (E). In such navigated TMS, the E-field models have been based on spherical approximation of the head. Such models omit the effects of cerebrospinal fluid (CSF) and gyral folding, leading to potentially large errors in the computed E-field. So far, realistic models have been too slow for interactive TMS navigation. We present computational methods that enable real-time solving of the E-field in a realistic five-compartment (5-C) head model that contains isotropic white matter, gray matter, CSF, skull and scalp. Using reciprocity and Geselowitz integral equation, we separate the computations to coil-dependent and -independent parts. For the Geselowitz integrals, we present a fast numerical quadrature. Further, we present a moment-matching approach for optimizing dipole-based coil models. We verified and benchmarked the new methods using simulations with over 100 coil locations. The new quadrature introduced a relative error (RE) of 0.3–0.6%. For a coil model with 42 dipoles, the total RE of the quadrature and coil model was 0.44–0.72%. Taking also other model errors into account, the contribution of the new approximations to the RE was 0.1%. For comparison, the RE due to omitting the separation of white and gray matter was >11%, and the RE due to omitting also the CSF was >23%. After the coil-independent part of the model has been built, E-fields can be computed very quickly: Using a standard PC and basic GPU, our solver computed the full E-field in a 5-C model in 9000 points on the cortex in 27 coil positions per second (cps). When the separation of white and gray matter was omitted, the speed was 43–65 cps. Solving only one component of the E-field tripled the speed. The presented methods enable real-time solving of the TMS-induced E-field in a realistic head model that contains the CSF and gyral folding. The new methodology allows more accurate targeting and precise adjustment of stimulation intensity during experimental or clinical TMS mapping.}
}
@article{GOLLISCH2010150,
title = {Eye Smarter than Scientists Believed: Neural Computations in Circuits of the Retina},
journal = {Neuron},
volume = {65},
number = {2},
pages = {150-164},
year = {2010},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2009.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0896627309009994},
author = {Tim Gollisch and Markus Meister},
abstract = {We rely on our visual system to cope with the vast barrage of incoming light patterns and to extract features from the scene that are relevant to our well-being. The necessary reduction of visual information already begins in the eye. In this review, we summarize recent progress in understanding the computations performed in the vertebrate retina and how they are implemented by the neural circuitry. A new picture emerges from these findings that helps resolve a vexing paradox between the retina's structure and function. Whereas the conventional wisdom treats the eye as a simple prefilter for visual images, it now appears that the retina solves a diverse set of specific tasks and provides the results explicitly to downstream brain areas.}
}
@incollection{PETRUZZELLI20121,
title = {1 - Re-thinking the innovation approach},
editor = {ANTONIO MESSENI PETRUZZELLI and VITO ALBINO},
booktitle = {When Tradition Turns Into Innovation},
publisher = {Chandos Publishing},
pages = {1-18},
year = {2012},
isbn = {978-1-84334-664-7},
doi = {https://doi.org/10.1016/B978-1-84334-664-7.50007-0},
url = {https://www.sciencedirect.com/science/article/pii/B9781843346647500070},
author = {ANTONIO MESSENI PETRUZZELLI and VITO ALBINO},
keywords = {triple crisis, innovation, tradition},
abstract = {Abstract
This chapter presents a review and criticism of the actual innovation approaches, highlighting how the social and economic scenario imposes the necessity of rethinking innovation and consumption models. Specifically, we discuss how the recent crises – which together affect finance, food and climate change and their implications for human development – are forcing organisations to find new solutions and models for responding to emerging needs and expectations. In this regard, we elaborate on the important role that may be played by traditional knowledge as a source of inspiration for innovation, since creativity can find a reliable support in what society has found to be suitable in the past for its development needs.}
}
@article{HALEEM2024100006,
title = {Perspective of leadership 4.0 in the era of fourth industrial revolution: A comprehensive view},
journal = {Journal of Industrial Safety},
volume = {1},
number = {1},
pages = {100006},
year = {2024},
issn = {2950-2764},
doi = {https://doi.org/10.1016/j.jinse.2024.100006},
url = {https://www.sciencedirect.com/science/article/pii/S2950276424000060},
author = {Abid Haleem and Mohd Javaid and Ravi Pratap Singh},
keywords = {Leadership 4.0, Industry 4.0, Industrial Safety, Technologies, Management},
abstract = {Leadership 4.0 focuses on leaders developing their digital transformation strategy and ensuring alignment with the organization’s business and development ambitions. This is accomplished by successfully displaying disruptive digital leadership characteristics, which include emotional and social intelligence abilities such as empathy and relationship management, cognitive preparedness, critical thinking, inventive thinking, agility, and resilience. Academics and consultants increasingly use Leadership 4.0 to describe the new leadership style required for the Fourth Industrial Revolution (Industry 4.0). It strategically addresses people’s concerns, which are crucial for the effective integration of Industry 4.0, and plays a significant and crucial role in integrating Industry 4.0 into modern workplaces. The primary purpose of this paper is to explore Leadership 4.0 and its needs. Several quality characteristics associated with Digital Leadership 4.0 are investigated, and two-dimensional style matrix presentations for Leadership 4.0 are briefed. Finally, this study identifies and addresses the role of Leadership 4.0 in upcoming industrial management systems. Because digital technologies now impact the entire business, advancing digital strategies requires strong leadership at all levels. With the increasing prevalence of digital transformation in the business sector and the intensification of the "battle for talent," organizations need to consider a more methodical approach to building a solid leadership pipeline with the capabilities required to lead in the digital era. They may place future leaders in positions that require them to go beyond their current competencies and skills to instruct and motivate them to promptly acquire new digital skills. In a new working setting, effectively managing the dynamic interactions between machines, technology, and people is essential for influential digital leaders. Leadership 4.0 is expected to foster an open and innovative culture that welcomes change and progress. This will encourage and inspire their teams to adapt to the ongoing changes in the market.}
}
@article{DALLACHIARA201894,
title = {A many-valued approach to quantum computational logics},
journal = {Fuzzy Sets and Systems},
volume = {335},
pages = {94-111},
year = {2018},
note = {Special Issue: Selected Papers from the 36th Linz Seminar on Fuzzy Set Theory},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2016.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0165011416304560},
author = {M.L. {Dalla Chiara} and R. Giuntini and G. Sergioli and R. Leporini},
keywords = {Quantum logics, Quantum tomography, Logical gates},
abstract = {Quantum computational logics are special examples of quantum logic where formulas are supposed to denote pieces of quantum information (qubit-systems or mixtures of qubit-systems), while logical connectives are interpreted as reversible quantum logical gates. Hence, any formula of the quantum computational language represents a synthetic logical description of a quantum circuit. We investigate a many-valued approach to quantum information, where the basic notion of qubit has been replaced by the more general notion of qudit. The qudit-semantics allows us to represent as reversible gates some basic logical operations of Łukasiewicz many-valued logics. In the final part of the article we discuss some problems that concern possible implementations of gates by means of optical devices.}
}
@article{QUIANQUIROGA2020994,
title = {No Pattern Separation in the Human Hippocampus},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {12},
pages = {994-1007},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.09.012},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320302278},
author = {Rodrigo {Quian Quiroga}},
keywords = {episodic memory, Concept Cells, engram, conjunctive coding, neural coding, human intelligence},
abstract = {Pattern separation is a basic principle of neuronal coding that precludes memory interference in the hippocampus. Its existence is supported by numerous theoretical, computational, and experimental findings in different species. However, I argue that recent evidence from single-neuron recordings suggests that pattern separation may not be present in the human hippocampus and that memories are instead coded by the coactivation of invariant and context-independent engrams. This alternative model prompts a reassessment of the definition of episodic memory and its distinction from semantic memory. Furthermore, I propose that a lack of pattern separation in memory coding may have profound implications that could explain cognitive abilities that are uniquely developed in humans, such as our power of generalization and of creative and abstract thinking.}
}
@article{KARPOVA2016v,
title = {Editorial overview: Neurobiology of cognitive behavior: Complexity of neural computation and cognition},
journal = {Current Opinion in Neurobiology},
volume = {37},
pages = {v-viii},
year = {2016},
note = {Neurobiology of cognitive behavior},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2016.03.003},
url = {https://www.sciencedirect.com/science/article/pii/S0959438816300125},
author = {Alla Karpova and Roozbeh Kiani}
}
@article{GUPTA2024102882,
title = {“Wayfinding” through the AI wilderness: Mapping rhetorics of ChatGPT prompt writing on X (formerly Twitter) to promote critical AI literacies},
journal = {Computers and Composition},
volume = {74},
pages = {102882},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102882},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000586},
author = {Anuj Gupta and Ann Shivers-McNair},
keywords = {AI, ChatGPT, Prompt writing, Prompt engineering, Machine learning, Computational methods, Algorithms, Critical AI literacy, Digital rhetoric},
abstract = {In this paper, we demonstrate how studying the rhetorics of ChatGPT prompt writing on social media can promote critical AI literacies. Prompt writing is the process of writing instructions for generative AI tools like ChatGPT to elicit desired outputs and there has been an upsurge of conversations about it on social media. To study this rhetorical activity, we build on four overlapping traditions of digital writing research in computers and composition that inform how we frame literacies, how we study social media rhetorics, how we engage iteratively and reflexively with methodologies and technologies, and how we blend computational methods with qualitative methods. Drawing on these four traditions, our paper shows our iterative research process through which we gathered and analyzed a dataset of 32,000 posts (formerly known as tweets) from X (formerly Twitter) about prompt writing posted between November 2022 to May 2023. We present five themes about these emerging AI literacy practices: (1) areas of communication impacted by prompt writing, (2) micro-literacy resources shared for prompt writing, (3) market rhetoric shaping prompt writing, (4) rhetorical characteristics of prompts, and (5) definitions of prompt writing. In discussing these themes and our methodologies, we highlight takeaways for digital writing teachers and researchers who are teaching and analyzing critical AI literacies.}
}
@article{ZETTERLUND2023104508,
title = {Computational modelling to advise and inform optimization for aeration and nutrient-dosing in wastewater treatment: Case study from pulp and paper mill in south-central Sweden},
journal = {Journal of Water Process Engineering},
volume = {56},
pages = {104508},
year = {2023},
issn = {2214-7144},
doi = {https://doi.org/10.1016/j.jwpe.2023.104508},
url = {https://www.sciencedirect.com/science/article/pii/S2214714423010280},
author = {Selma Zetterlund and Olivia Schwartz and Maria Sandberg and G. Venkatesh},
keywords = {Aeration, Biological wastewater treatment, Energy use optimisation, Nutrients, Pulp and paper mills},
abstract = {Sweden's pulp and paper sector accounts for a significant proportion of national energy usage, besides generating wastewater that causes eutrophication of nearby sinks. In this paper, the possibility of optimizing biological wastewater treatment at the Stora Enso Skoghall mill south of the city of Karlstad in central Sweden, with respect to electricity usage and the addition of nutrients, has been investigated. A computational model of the treatment process was developed, based on process data obtained from the said mill, and nine different scenarios were compared subsequently, with energy use, environmental impacts and operational expenses, as criteria. The most energy-efficient and cost-effective alternative was a combination of measures such as lowering the oxygen level in the MBBR (Moving Bed Bio-Reactor) from 3 mg/l to 2 mg/l and using the Hyperclassic aerator in the aerated lagoon. This arrangement yielded a 48.5 % reduction in operational expenses, and a 60 % decrease in the energy use, vis-à-vis the reference case, without affecting the efficiency of the treatment process. This also uncovered an opportunity to mitigate the annual global warming and eutrophication impacts, by approximately 100 tons CO2-eq. and 140 kg PO43−-eq. respectively. All attempts to optimise the use of resources and decrease the anthropogenic environmental footprint ought to be made to come closer to the targets set by the United Nations' sustainable development goals (SDGs). The authors' conclusion predicated on the results of the modelling and analysis done in this study is that the potential of seemingly small process modifications, such as lowering the oxygen level in the MBBR, and applying a more optimal dosage of nutrient salts, must not be overlooked by wastewater treatment plants in general (and those in pulp and paper mills in particular).}
}
@incollection{MAERTENS2025352,
title = {Green Toxicology},
editor = {Béla Török},
booktitle = {Encyclopedia of Green Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {352-357},
year = {2025},
isbn = {978-0-443-28923-1},
doi = {https://doi.org/10.1016/B978-0-443-15742-4.00098-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443157424000983},
author = {Alexandra Maertens and Thomas Hartung},
keywords = {Exposomics, In Silico, In Vitro, QSAR, SAR},
abstract = {Green toxicology is an emerging discipline that seeks to make toxicology a partner in the field of green chemistry, by providing chemists and toxicologists the tools necessary to identify potential hazards based on chemical structure alone, test efficiently for bioactivity, and better predict the human health impacts of chemicals. It seeks to make toxicology a data-driven, 21st century science by incorporating advanced techniques such as computational modeling, high-throughput screening, and alternative testing methods to assess chemical safety.}
}
@article{KHANUM2022131890,
title = {Synthesis, single crystal, characterization and computational study of 2-amino-N-cyclopropyl-5-ethyl-thiophene-3-carboxamide},
journal = {Journal of Molecular Structure},
volume = {1250},
pages = {131890},
year = {2022},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2021.131890},
url = {https://www.sciencedirect.com/science/article/pii/S0022286021020123},
author = {Ghazala Khanum and Aysha Fatima and Nazia Siddiqui and D.D. Agarwal and R.J. Butcher and Sanjay Kumar Srivastava and Saleem Javed},
keywords = {DFT studies, Fukui function, MEP, ELF, Hirshfeld, Molecular docking},
abstract = {2-amino-N-cyclopropyl-5-ethylthiophene-3-carboxamide (ACPETC) (C10H14N2OS) has been synthesized, characterized via single-crystal X-ray diffraction at 296 K and studied theoretically via DFT approach. The compound crystallizes in tetragonal crystal system, space group I-4 with Z = 8 and the following unit cell dimensions: a = 16.0892(4) Å, b = 16.0892(4) Å, c = 8.4059(2) Å. ACPETC was experimentally characterized by 1H, 13C NMR, FT-IR, UV–Vis and ESI-MS analysis. The molecular structure, vibrational spectra, MEP, ELF, NLO, NBO, NHO, and FMO analysis of ACPETC (C10H14N2OS) in the ground state were estimated using HF, MP2, DFT/B3LYP using the 6–311++G(d,p) basis set. Computed NMR chemical shifts (1H and 13C), as well as discrete regions in IR active vibrations, are in good concurrence with their experimental counterparts. FT-IR spectra of ACPETC were obtained in the ranges of 4000−450 cm−1. The UV–vis spectrum as well as the effects of solvents has been studied. The estimated HOMO and LUMO energies reveal that charge transfer happens within the molecule and MEP surface to be a chemically reactive region suitable for drug action. The O1-atom appears to be more vulnerable to electrophilic assault. The NBO analysis was also performed. It indicates that the greatest second order perturbation energy E(2) = 50.11 kcal/mol associated with electron delocalization from the donor (N15) → π* (C10-O14) acceptor interaction. On the atomic charges of the title chemical, the Fukui function and Mulliken analysis have been calculated. 3-D and 2-D interactions in crystals were studies and Hirshfeld surface analysis was used. To discover the optimum ligand-protein interactions, molecular docking was used using eight protein receptors.}
}
@article{AHLQUIST201584,
title = {Development of a digital framework for the computation of complex material and morphological behavior of biological and technological systems},
journal = {Computer-Aided Design},
volume = {60},
pages = {84-104},
year = {2015},
note = {Material Ecology},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2014.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S0010448514000141},
author = {Sean Ahlquist and Tim Kampowski and Omid {Oliyan Torghabehi} and Achim Menges and Thomas Speck},
keywords = {Material behavior, Spring-based simulation, Computational design, Biomimetic research},
abstract = {Research in material behavior involves the study of relationships between material composition and capacities to negotiate internal and external pressures. Tuning material composition for performance allows for the integration of multifaceted functionality and embedded responsiveness within minimal material means. The relationships of material composition and system performance can be dissected into properties of topology (in count, type and association), forces (as the simulation of contextual pressures), and materiality (material properties and constraints of fabrication). When resourcing information about these aspects of material behavior from biological or technological systems, the physical precedents, as specimens and/or models, serve as the primary, and often sole, exemplar. While this is necessary to initiate the study of material make-up as it relates to specific morphological performance, there is an inherent limit when asking how and to what degree the knowledge resourced from that instance applies when alterations from the norm are generated. This research proposes the possibility for testing variants of a morphological system using physical models as the precedent while incorporating multiple means of computational analysis for extensive exploration. The framework begins with the initial stage of deducing principles, regarding material organization and behavior, through comparative physical and computational study. Subsequently, through methods of abduction, new vocabularies of form and potentials in performance are generated primarily through computational exploration. The framework is shaped by research into the design and materialization of complex pre-stressed form- and bending-active architectures. A novel aspect of this framework is the development of a software environment called springFORM. In this environment, material behavior is simulated using basic spring-based (particle system) methods. The novel contribution of this software is in providing means for both manual and algorithmic manipulations of mesh topologies and material properties during the form-finding process. A series of architectural prototypes, which range in scale, define rules for the relationship between topological-material complexity and the sequencing of particular exploratory methods. The studies define the value of the physical precedent as it engenders further material prototypes, spring-based explorations and simulations with finite element analysis. These rules and methods are further elaborated upon through studying the particularly fascinating structural capacity of banana leaf stalks, a material system which is stiff in bending yet highly flexible in torsion. Of interest is a functional robustness which allows for the negotiation of both self-weight and wind loading for a large and fully integrated leaf structure. Methods of simulation and meta-heuristics are developed to address the continual material and topological differentiation of the banana leaf stalk. Case studies are based upon examination of specimens from the species Musa acuminata and Ensete ventricosum. Mechanical properties and geometric descriptions of isolated moments within the stalk provide the basis for computational comparison. Fundamental properties and behaviors are extracted from the plant specimens, yet a full description is not possible because of the plant’s intricate spatial structure. In this case, the computational means serve to elucidate upon the behavior of the complete system as well as provide avenues for exploring its variants. This paper describes an extensible and calibrated framework which can foster enhanced biomimetic insights by explorations which are based upon but extend well beyond initial biological and/or technological precedents.}
}
@article{OESCH2021990,
title = {How REM sleep shapes hypothalamic computations for feeding behavior},
journal = {Trends in Neurosciences},
volume = {44},
number = {12},
pages = {990-1003},
year = {2021},
issn = {0166-2236},
doi = {https://doi.org/10.1016/j.tins.2021.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S0166223621001831},
author = {Lukas T. Oesch and Antoine R. Adamantidis},
keywords = {sleep, feeding, goal-directed behavior, hypothalamus, population coding},
abstract = {The electrical activity of diverse brain cells is modulated across states of vigilance, namely wakefulness, non-rapid eye movement (NREM) sleep, and rapid eye movement (REM) sleep. Enhanced activity of neuronal circuits during NREM sleep impacts on subsequent awake behaviors, yet the significance of their activation, or lack thereof, during REM sleep remains unclear. This review focuses on feeding-promoting cells in the lateral hypothalamus (LH) that express the vesicular GABA and glycine transporter (vgat) as a model to further understand the impact of REM sleep on neural encoding of goal-directed behavior. It emphasizes both spatial and temporal aspects of hypothalamic cell dynamics across awake behaviors and REM sleep, and discusses a role for REM sleep in brain plasticity underlying energy homeostasis and behavioral optimization.}
}
@incollection{VOINOV202427,
title = {Participatory Modeling for Sustainability},
editor = {Martin A. Abraham},
booktitle = {Encyclopedia of Sustainable Technologies (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {27-35},
year = {2024},
isbn = {978-0-443-22287-0},
doi = {https://doi.org/10.1016/B978-0-323-90386-8.00020-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323903868000206},
author = {Alexey Voinov},
keywords = {Biases, Modeling process, Social media, Stakeholders, Wicked problem},
abstract = {Sustainability is a wicked problem, which is hard to define in a unique way. It cannot be solved and should be treated in a participatory approach involving as many stakeholders in the process as possible. Participatory modeling is an efficient method for dealing with wicked problems. It involves stakeholders in an open-ended process of shared learning and can be essential for developing sustainable technologies. While there may be various levels of participation, the process evolves around a model of the system at stake. The model is built in interaction with the stakeholders, it provides to formalism to synchronize stakeholder thinking and knowledge about the system and to move towards consensus about the possible decision-making.}
}
@article{MEACHAM2023103902,
title = {Fire safety of existing residential buildings: Building regulatory system gaps and needs},
journal = {Fire Safety Journal},
volume = {140},
pages = {103902},
year = {2023},
issn = {0379-7112},
doi = {https://doi.org/10.1016/j.firesaf.2023.103902},
url = {https://www.sciencedirect.com/science/article/pii/S0379711223001704},
author = {Brian J. Meacham},
keywords = {Regulatory system, Existing buildings, Fire risk, Systems thinking},
abstract = {Considerable cost and effort are invested in government and private-sector activities aimed at providing a societally tolerable level of fire safety of the built environment. This is particularly true with respect to fire safety of new building construction. On the government side, this includes activities associated with building and fire regulations, material performance and test standards, design guidance, competency requirements, review and approvals, and more. On the private side, activities include product development, analysis and design, construction and installation, as well as education and training of practitioners. In some cases there are overlaps (e.g., private building control). However, once buildings become occupied, the system faces several challenges. Oversight of building use and modification often gets lost. Different actors come into play. Competing objectives become more significant. Occupants often lack understanding and ability to recognize problems and make adjustments. The net result is an increase in fire safety risk over the life of a building, with less opportunities for the regulatory system to make interventions prior to an unwanted fire event. However, this can be changed if the approach to regulating existing buildings changes, and importantly, embodies whole-of-life, multi-agency, holistic, systems-based thinking.}
}
@article{DENEF201893,
title = {Computational complexity of the landscape II—Cosmological considerations},
journal = {Annals of Physics},
volume = {392},
pages = {93-127},
year = {2018},
issn = {0003-4916},
doi = {https://doi.org/10.1016/j.aop.2018.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S000349161830068X},
author = {Frederik Denef and Michael R. Douglas and Brian Greene and Claire Zukowski},
keywords = {Computational complexity, String theory, Multiverse, Measures},
abstract = {We propose a new approach for multiverse analysis based on computational complexity, which leads to a new family of “computational” measure factors. By defining a cosmology as a space–time containing a vacuum with specified properties (for example small cosmological constant) together with rules for how time evolution will produce the vacuum, we can associate global time in a multiverse with clock time on a supercomputer which simulates it. We argue for a principle of “limited computational complexity” governing early universe dynamics as simulated by this supercomputer, which translates to a global measure for regulating the infinities of eternal inflation. The rules for time evolution can be thought of as a search algorithm, whose details should be constrained by a stronger principle of “minimal computational complexity”. Unlike previously studied global measures, ours avoids standard equilibrium considerations and the well-known problems of Boltzmann Brains and the youngness paradox. We also give various definitions of the computational complexity of a cosmology, and argue that there are only a few natural complexity classes.}
}
@article{CAI2024102329,
title = {Student learning and instructional tasks in different curricular contexts: A longitudinal study},
journal = {International Journal of Educational Research},
volume = {125},
pages = {102329},
year = {2024},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2024.102329},
url = {https://www.sciencedirect.com/science/article/pii/S0883035524000168},
author = {Jinfa Cai and John C. Moyer and Chuang Wang and Ning Wang and Bikai Nie},
keywords = {Longitudinal study, Problem solving, Instructional tasks, Mathematics learning, Curricular effect},
abstract = {This paper compares the longitudinal effect of instructional tasks on algebra learning that used a Standards-based curriculum [Connected Mathematics Project (CMP)] to that of classrooms that used a traditional curriculum (non-CMP). CMP was developed based on the National Council of Teachers of Mathematics (NCTM) Standards and can be characterized as a problem-based curriculum. CMP teachers were more than three times as likely to implement high-level instructional tasks than non-CMP teachers. Increases in the cognitive demand were associated with enhanced growth rates in problem solving, computation, and equation solving. Notably, when controlling for the cognitive demand of the instructional tasks, the advantage of the CMP curriculum over the non-CMP curricula on students’ growth in problem solving disappeared. However, non-CMP curricula had an advantage on students’ growth over the CMP curriculum after the cognitive demand of the instructional tasks was controlled.}
}
@article{KESICI2011472,
title = {Self-regulated learning strategies in relation with statistics anxiety},
journal = {Learning and Individual Differences},
volume = {21},
number = {4},
pages = {472-477},
year = {2011},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2011.02.006},
url = {https://www.sciencedirect.com/science/article/pii/S1041608011000203},
author = {Şahin Kesici and Mustafa Baloğlu and M. Engin Deniz},
keywords = {Statistical anxiety, Statistics learning, Learning strategies, Metacognition},
abstract = {Dealing with students' attitudinal problems related to statistics is an important aspect of statistics instruction. Employing the appropriate learning strategies may have a relationship with anxiety during the process of statistics learning. Thus, the present study investigated multivariate relationships between self-regulated learning strategies and statistical anxiety using canonical correlation analysis (CCA). Three hundred twenty Turkish college students responded to the Motivated Strategies for Learning Questionnaire and the Statistical Anxiety Rating Scale. Of the group, 189 (59.1%) were women and 131 (40.9%) were men. Participants' ages ranged from 18 to 33years with a mean of 21.28years (SD=1.53). Bivariate correlation coefficients showed significant relationships between the dimensions of learning strategies and statistical anxiety. CCA showed that students who used more rehearsal, elaboration, organization, critical thinking, metacognitive regulation, time and study environment management, and effort regulation strategies experienced lower computational anxiety and had more positive attitudes toward statistics. Additionally, a combination of effort regulation and help seeking strategies is associated with test/class anxiety.}
}
@article{SCHEZSOBRINO2024100648,
title = {MR-LEAP: Mixed-Reality Learning Environment for Aspirational Programmers},
journal = {Software Impacts},
volume = {20},
pages = {100648},
year = {2024},
issn = {2665-9638},
doi = {https://doi.org/10.1016/j.simpa.2024.100648},
url = {https://www.sciencedirect.com/science/article/pii/S2665963824000368},
author = {Santiago Schez-Sobrino and Francisco M. García and Javier A. Albusac and Carlos Glez-Morcillo and Jose J. Castro-Schez and David Vallejo},
keywords = {Programming learning, Mixed reality, Gamification, Computational thinking, Problem solving},
abstract = {This paper presents MR-LEAP (Mixed-Reality Learning Environment for Aspirational Programmers), a framework developed for learning programming through Mixed Reality and gamification mechanics. MR-LEAP’s architecture is designed to facilitate the understanding of basic programming concepts while allowing the gradual incorporation of more complex concepts. The framework provides a simple visual level editor. MR-LEAP is supported by the Mixed Reality Toolkit framework to promote portability to new Mixed Reality devices. Our goal is to facilitate programming education using Mixed Reality technology. MR-LEAP has already been used in both research and educational.}
}
@article{BRAMLEY2023105471,
title = {Active inductive inference in children and adults: A constructivist perspective},
journal = {Cognition},
volume = {238},
pages = {105471},
year = {2023},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2023.105471},
url = {https://www.sciencedirect.com/science/article/pii/S0010027723001051},
author = {Neil R. Bramley and Fei Xu},
keywords = {Hypothesis generation, Active learning, Inductive inference, Developmental change, Concept learning, Program induction},
abstract = {A defining aspect of being human is an ability to reason about the world by generating and adapting ideas and hypotheses. Here we explore how this ability develops by comparing children’s and adults’ active search and explicit hypothesis generation patterns in a task that mimics the open-ended process of scientific induction. In our experiment, 54 children (aged 8.97±1.11) and 50 adults performed inductive inferences about a series of causal rules through active testing. Children were more elaborate in their testing behavior and generated substantially more complex guesses about the hidden rules. We take a ‘computational constructivist’ perspective to explaining these patterns, arguing that these inferences are driven by a combination of thinking (generating and modifying symbolic concepts) and exploring (discovering and investigating patterns in the physical world). We show how this framework and rich new dataset speak to questions about developmental differences in hypothesis generation, active learning and inductive generalization. In particular, we find children’s learning is driven by less fine-tuned construction mechanisms than adults’, resulting in a greater diversity of ideas but less reliable discovery of simple explanations.}
}
@article{BOSSE201239,
title = {A computational model for dynamics of desiring and feeling},
journal = {Cognitive Systems Research},
volume = {19-20},
pages = {39-61},
year = {2012},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2012.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041712000228},
author = {Tibor Bosse and Mark Hoogendoorn and Zulfiqar A. Memon and Jan Treur and Muhammad Umair},
keywords = {Desire, Feeling, Computational model},
abstract = {In this paper a computational model is presented for how a desire triggers responses and feelings. The model shows how these feelings can be biased, for example due to addicting experiences in the past. Both the strength of a response and of the associated feeling result from a converging dynamic pattern modeled by reciprocal causal interactions between the two. The model has been used to conduct a number of simulation experiments under varying circumstances. Moreover, it has been evaluated by formal analysis of emerging patterns entailed by the model. Furthermore, it has been pointed out how the computational model can be applied within an ambient agent system supporting a human in not being tempted. In a simple example scenario it is shown such an ambient agent system is able to predict and assess a human’s desire state, and use this assessment to suggest alternatives to avoid falling for certain temptations.}
}
@article{YAO2018107,
title = {Three-way decision and granular computing},
journal = {International Journal of Approximate Reasoning},
volume = {103},
pages = {107-123},
year = {2018},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2018.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X18302809},
author = {Yiyu Yao},
keywords = {Three-way decision, Three-way computing, Granular computing in threes, Thinking in threes, Magical number three},
abstract = {Based on results from cognitive science, this paper examines the two fields of three-way decision and granular computing, as well as their interplay. The ideas from one field shed new light on the other field. The integration of the two gives rise to three-way granular computing, that is, thinking, problem solving, and information processing in threes. We discuss a wide sense of three-way decision and propose a trisecting–acting–outcome (TAO) model. We explain fundamental notions of granular computing based on the philosophy of three-way decision as thinking in threes. We discuss a model of three-way granular computing by making use of two particular types of granular structures represented, respectively, by three granules and three levels. We use examples across different disciplines to demonstrate the values of the two types. Our investigation suggests that, in many situations, the power of granular computing is indeed the power of three-way decision, i.e., thinking in threes.}
}
@article{AGUIRRE2024101196,
title = {Mathematizing the world: A routine to advance mathematizing in the elementary classroom},
journal = {The Journal of Mathematical Behavior},
volume = {76},
pages = {101196},
year = {2024},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2024.101196},
url = {https://www.sciencedirect.com/science/article/pii/S0732312324000737},
author = {Julia M. Aguirre and Erin E. Turner and Elzena McVicar and Amy Roth McDuffie and Mary Q. Foote and Erin Carll},
keywords = {Mathematizing, Elementary, Mathematical thinking, Problem posing, Culturally responsive},
abstract = {The Mathematizing-the-World routine (MWR) is an efficient culturally responsive instructional routine for mathematizing that explicitly supports problem posing using an image or object. Given the under-representation of problem-posing studies in elementary school settings, our qualitative study analyzed student responses from 56 MWR enactments in grade 3–5 classrooms in two regions of the United States. Our findings include detailed examples of the MWR in action, including how three open-ended prompts engaged younger students in mathematizing and posing problems related to authentic, real-world situations. We summarize findings across the 56 MWR classroom enactments focusing on the understandings about the context and the mathematical ideas evidenced in student responses. Our findings demonstrate the potential of the MWR as a catalyst for eliciting and communicating diverse student ideas while engaged in the problem-posing process. We discuss research and practice implications for this routine to support mathematizing, and specifically problem posing in the elementary classroom.}
}
@article{CHEN2021101001,
title = {Instructed concept appropriation for developing knowledge of second language academic discourse context},
journal = {Journal of English for Academic Purposes},
volume = {52},
pages = {101001},
year = {2021},
issn = {1475-1585},
doi = {https://doi.org/10.1016/j.jeap.2021.101001},
url = {https://www.sciencedirect.com/science/article/pii/S147515852100045X},
author = {Jing Chen and Danli Li},
keywords = {Concept-based language instruction, , Mediation, Concept appropriation, Writing activity, Academic literacy},
abstract = {Recent studies from sociocultural perspectives have explored the effects of Concept-based Language Instruction (C-BLI) on L2 development through the explicit teaching of scientific concepts. However, there has been little research into the effects of C-BLI on the development of L2 academic literacy. This article reports on a case study of how C-BLI mediated a Chinese doctoral student's development of conceptual knowledge of context and subsequent context-specific performance in academic writing. Drawing on data from writing tutorials and interviews, the learner's drafts and invited comments, and think-aloud protocols, the study revealed that the C-BLI interventions that integrated symbolic and dialogic mediation helped the learner attain and enhance awareness of contextual components. The learner appropriated the concept as a tool for thinking in judging appropriateness of rules of thumb and choices of exclusive discourse features in specific contexts of use, which consequently mediated his planning for writing and resulted in the development of performance. The study demonstrates the potential of C-BLI as a driving force for the development of conceptual knowledge and context-specific performance in the academic literacy of L2 learners. It has pedagogical implications for curriculum design, C-BLI-informed literacy and concept-based materials, and teacher development to stimulate teacher awareness in C-BLI.}
}
@article{HUANG201727,
title = {A computational cognitive modeling approach to understand and design mobile crowdsourcing for campus safety reporting},
journal = {International Journal of Human-Computer Studies},
volume = {102},
pages = {27-40},
year = {2017},
note = {Special Issue on Mobile and Situated Crowdsourcing},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916301549},
author = {Yun Huang and Corey White and Huichuan Xia and Yang Wang},
keywords = {Mobile crowdsourcing, Cognitive computational method, Public safety, User contribution, Drift-diffusion decision model, Nudge mechanism},
abstract = {The under-reporting of public safety incidents is a long-standing issue. In this paper, we propose a computational cognitive modeling approach to understand and design a mobile crowdsourcing system for improving campus safety reporting. In particular, we adopt drift-diffusion models (DDMs) from cognitive psychology to investigate the effect of various factors on users’ reporting tendency for public safety. Our lab experiment and online study show consistent results on how location context impacts people's reporting decisions. This finding informs the design of a novel location-based nudge mechanism, which is tested in another lab experiment with 84 participants and proved to be effective in changing users’ reporting decisions. Our follow-up interview study further suggests that the influence of people's mobility patterns (e.g., expected walking distance) could explain why the nudge design is effective. Our work not only informs the design of mobile crowdsourcing for public safety reporting but also demonstrates the value of applying a computational cognitive modeling approach to address HCI research questions more broadly.}
}
@article{TELIKANI2020318,
title = {A survey of evolutionary computation for association rule mining},
journal = {Information Sciences},
volume = {524},
pages = {318-352},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2020.02.073},
url = {https://www.sciencedirect.com/science/article/pii/S002002552030164X},
author = {Akbar Telikani and Amir H. Gandomi and Asadollah Shahbahrami},
keywords = {Data mining, Association rule mining, Evolutionary computation, Swarm intelligent},
abstract = {Association Rule Mining (ARM) is a significant task for discovering frequent patterns in data mining. It has achieved great success in a plethora of applications such as market basket, computer networks, recommendation systems, and healthcare. In the past few years, evolutionary computation-based ARM has emerged as one of the most popular research areas for addressing the high computation time of traditional ARM. Although numerous papers have been published, there is no comprehensive analysis of existing evolutionary ARM methodologies. In this paper, we review emerging research of evolutionary computation for ARM. We discuss the applications on evolutionary computations for different types of ARM approaches including numerical rules, fuzzy rules, high-utility itemsets, class association rules, and rare association rules. Evolutionary ARM algorithms were classified into four main groups in terms of the evolutionary approach, including evolution-based, swarm intelligence-based, physics-inspired, and hybrid approaches. Furthermore, we discuss the remaining challenges of evolutionary ARM and discuss its applications and future topics.}
}
@article{SLOOT2010189,
title = {Computational science: A kaleidoscopic view into science},
journal = {Journal of Computational Science},
volume = {1},
number = {4},
pages = {189},
year = {2010},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2010.11.001},
url = {https://www.sciencedirect.com/science/article/pii/S1877750310000694},
author = {Peter M.A. Sloot}
}
@article{FERNYHOUGH20231180,
title = {Inner speech as language process and cognitive tool},
journal = {Trends in Cognitive Sciences},
volume = {27},
number = {12},
pages = {1180-1193},
year = {2023},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2023.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661323002103},
author = {Charles Fernyhough and Anna M. Borghi},
keywords = {inner dialogue, inner monologue, verbal thinking, self-talk, self-regulation, phenomenology},
abstract = {Many people report a form of internal language known as inner speech (IS). This review examines recent growth of research interest in the phenomenon, which has broadly supported a theoretical model in which IS is a functional language process that can confer benefits for cognition in a range of domains. A key insight to have emerged in recent years is that IS is an embodied experience characterized by varied subjective qualities, which can be usefully modeled in artificial systems and whose neural signals have the potential to be decoded through advancing brain–computer interface technologies. Challenges for future research include understanding individual differences in IS and mapping form to function across IS subtypes.}
}
@article{DOGAN2018464,
title = {Differing instructional modalities and cognitive structures: Linear algebra},
journal = {Linear Algebra and its Applications},
volume = {542},
pages = {464-483},
year = {2018},
note = {Proceedings of the 20th ILAS Conference, Leuven, Belgium 2016},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0024379517304172},
author = {Hamide Dogan},
keywords = {Mathematics education, Linear algebra, Thinking modes, Instructional modalities, Cognitive schemes},
abstract = {This paper discusses the aspects of twelve first-year linear algebra students' thinking modes displayed on their interview responses to questions addressing linear independence ideas. Studying thinking modes allowed us to make inferences about the role of differing instructional modalities in shaping one's cognitive structures.}
}
@article{DEUTSCH2018156,
title = {Computational mechanisms in genetic regulation by RNA},
journal = {Journal of Theoretical Biology},
volume = {458},
pages = {156-168},
year = {2018},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2018.09.016},
url = {https://www.sciencedirect.com/science/article/pii/S0022519318304466},
author = {J.M. Deutsch},
abstract = {The evolution of the genome has led to very sophisticated and complex regulation. Because of the abundance of non-coding RNA (ncRNA) in the cell, different species will promiscuously associate with each other, suggesting collective dynamics similar to artificial neural networks. A simple mechanism is proposed allowing ncRNA to perform computations equivalent to neural network algorithms such as Boltzmann machines and the Hopfield model. The quantities analogous to the neural couplings are the equilibrium constants between different RNA species. The relatively rapid equilibration of RNA binding and unbinding is regulated by a slower process that degrades and creates new RNA. The model requires that the creation rate for each species be an increasing function of the ratio of total to unbound RNA. Similar mechanisms have already been found to exist experimentally for ncRNA regulation. With the overall concentration of RNA regulated, equilibrium constants can be chosen to store many different patterns, or many different input–output relations. The network is also quite insensitive to random mutations in equilibrium constants. Therefore one expects that this kind of mechanism will have a much higher mutation rate than ones typically regarded as being under evolutionary constraint.}
}
@article{ZBOINSKA2019675,
title = {Influence of a hybrid digital toolset on the creative behaviors of designers in early-stage design},
journal = {Journal of Computational Design and Engineering},
volume = {6},
number = {4},
pages = {675-692},
year = {2019},
issn = {2288-4300},
doi = {https://doi.org/10.1016/j.jcde.2018.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S228843001830174X},
author = {Malgorzata A. Zboinska},
keywords = {Early-stage design, Digital design, Computational design, Architectural design, Hybrid digital design systems, Intelligent human-machine integration},
abstract = {The purpose of this research was to investigate how diversification of the repertoire of digital design techniques affects the creative behaviors of designers in the early design phases. The principal results of practice-based pilot experiments on the subject indicate three key properties of the hybrid digital tooling strategy. The strategy features intelligent human-machine integration, facilitating three different types of synergies between the designer and the digital media: human-dominated, machine-dominated, and a balanced human-machine collaboration. This strategy also boosts the cognitive behaviors of the designer by triggering divergent, transformative and convergent design activities and allowing for work on various abstraction levels. In addition, the strategy stimulates the explorative behaviors of the designer by encouraging the production of and interaction with a wide range of design representations, including physical and digital, dynamic and static objects. Thus, working with a broader range of digital modeling techniques can positively influence the creativity of designers in the early conception stages.}
}
@article{GARFIELD19844,
title = {Artificial intelligence: Using computers to think about thinking, part I: Representing knowledge},
journal = {Computer Compacts},
volume = {2},
number = {1},
pages = {4-9},
year = {1984},
issn = {0167-7136},
doi = {https://doi.org/10.1016/0167-7136(84)90071-4},
url = {https://www.sciencedirect.com/science/article/pii/0167713684900714},
author = {Eugene Garfield}
}
@article{NUGRAHA2023406,
title = {A SEM-neural network approach for understanding the entrepreneurial competence development of freshmen engineering and computing students},
journal = {Procedia Computer Science},
volume = {216},
pages = {406-414},
year = {2023},
note = {7th International Conference on Computer Science and Computational Intelligence 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.152},
url = {https://www.sciencedirect.com/science/article/pii/S187705092202230X},
author = {Rendika Nugraha and Nanang Ali Sutisna and Adhi Setyo Santoso and Ihsan Hadiansah and Johan Krisnanto Runtuk},
keywords = {Entrepreneurial competence, techno-entrepreneurship, creativity, ethical, sustainable thinking, motivation, perseverance, mobilizing others, learning through experience taking initiative, cope with uncertainty},
abstract = {The discussion of enhancing entrepreneurial competence in Higher Education Institution (HEI), especially in engineering and computing major, has increased for the recent years. This study aims to propose and test a structural model of relationship of Indonesian HEI entrepreneurship education with entrepreneurship competence to assess student entrepreneurship competences especially in undergraduate level. Thus, this study provides the contribution in this stream by creating a subject specialized that fit with specific study program to enhance entrepreneurial competence for freshmen student called Integrative Survival Experience especially in engineering and computing major. We measure its output by using EntreComp questionnaires framework from European Commission. A combination of Structural Equation Modelling (SEM) and neural network was implemented as analytic approach in this study. The results show that the freshmen engineering and computing students develop entrepreneurial competence by enhancing the specific sets of ideas and opportunities as well as the capability to manage resources for taking the action afterwards. Apparently, the entrepreneurial competence development process of engineering and computing students differs with that of business and management students.}
}
@article{PENG2025109960,
title = {LMCodec2: Ultra-low bit rate codec with causal multiple transformers},
journal = {Computers and Electrical Engineering},
volume = {122},
pages = {109960},
year = {2025},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2024.109960},
url = {https://www.sciencedirect.com/science/article/pii/S0045790624008851},
author = {Dingwei Peng and Qizhen Weng and Ningze Zhong and Ting Xie and Can Gong and Xiangwei Zhu and Xuelin Yuan and Mingjun Ouyang},
keywords = {End-to-end codec, VQ-VAE, GAN, Transformer model, Huffman coding},
abstract = {In recent years, the bandwidth constraints in satellite Internet of Things (IoT) applications have spurred the development of novel methods for compressing transmitted speech. For satellite voice communications, it is essential to achieve high-quality codecs with a bit rate below 1 kbps, particularly for channels such as Beidou-3, which often operate under such limitations. Neural network-based vocoders have emerged as a promising solution within the AI community, offering high-fidelity audio compression. In this paper, we propose LMCodec2, a causal speech codec designed to operate across a range of bit rates while delivering high-quality audio at extremely low bit rates, specifically tailored for satellite voice transmission. LMCodec2 utilizes a Transformer-based language model to predict tokens frame by frame, achieving a 25 % reduction in bit rate without compromising decoded audio quality. Our experimental evaluations demonstrate that LMCodec2 produces high-quality decoded audio at 0.76 kbps and 1.15 kbps. Notably, at 0.76 kbps, LMCodec2 achieves a MUSHRA (Multi-Stimulus Test with Hidden Reference and Anchor) score that surpasses Encodec's performance at 1.5 kbps. Audio demonstrations, including real-world self-recorded speech datasets, are available at https://dingweipeng.github.io/JACK.github.io. LMCodec2 provides a new way of thinking to addressing the challenges of bandwidth-limited satellite voice communications.}
}
@article{YAO199959,
title = {Evolutionary computation comes of age},
journal = {Cognitive Systems Research},
volume = {1},
number = {1},
pages = {59-64},
year = {1999},
issn = {1389-0417},
doi = {https://doi.org/10.1016/S1389-0417(99)00006-6},
url = {https://www.sciencedirect.com/science/article/pii/S1389041799000066},
author = {Xin Yao},
abstract = {Evolutionary computation is a field of study of computational systems which uses ideas and gets inspirations from natural evolution and adaptation. Although the history of evolutionary computation can be traced back to 1950s, it was only in the last decade or so that the field started to grow rapidly. In recent years, there have been many successful applications of various evolutionary computation techniques in artificial intelligence, machine learning, numerical optimization, combinatorial optimization, etc. The theory of evolutionary computation has also been enriched greatly. There is a much better understanding of why and how evolutionary computation techniques work (or do not work) than five or six years ago. This article reports some of the latest developments presented at the recent 1999 Congress on Evolutionary Computation (CEC '99).}
}
@article{SHARIF2025101979,
title = {Innovative computation to detect stress in working people based on mode of commute},
journal = {Journal of Transport & Health},
volume = {41},
pages = {101979},
year = {2025},
issn = {2214-1405},
doi = {https://doi.org/10.1016/j.jth.2024.101979},
url = {https://www.sciencedirect.com/science/article/pii/S2214140524002251},
author = {Mhd Saeed Sharif and Madhav Raj Theeng Tamang and Cynthia Fu and Ahmed Ibrahim Alzahrani and Fahad Alblehai},
keywords = {Stress assessment, Blood pressure, Wearable sensors, Commuting, Intelligent transport system, Machine learning},
abstract = {Introduction:
Commuting is an integral part of modern life for many people, shaping daily routines and impacting overall well-being. With various transportation options, including driving, public transport, walking, and cycling, commuters encounter various experiences and challenges in their everyday journeys. Understanding how different modes of commuting affect stress levels is essential for improving public health and informing transportation planning. This study develops advanced machine-learning techniques to explore the connection between commuting methods and stress levels.
Methods:
This research examines how different commuting modes affect stress levels using machine learning methods. The study analyses data collected from 45 individuals who regularly commute to work, focusing on driving, cycling, and public transport modes. Non-invasive wearable sensors were utilised to gather electroencephalography (EEG), blood pressure (BP), and heart rate (HR) data for five consecutive days for each participant. Additionally, qualitative data was collected using the Positive and Negative Affect Schedule (PANAS) questionnaire to assess participants’ emotional responses before and after their commute. The research focuses on developing a machine learning-based model to predict the commute’s impact and monitor the stress level due to the commute mode. In research, objective and subjective factors shape the research process and outcomes. Understanding the interaction between these factors is essential for conducting thorough and reliable research that produces valid results. Our study utilises datasets incorporating qualitative and quantitative data from questionnaires and human bio-signals.
Results:
This research developed various machine learning algorithms to detect stress levels based on commuting mode. The results indicate that the Linear Discriminant Analysis technique achieved an accuracy of 88%, while Logistic Regression reached 90.66% accuracy. The Boosted Tree algorithm produced the best performance, with an accuracy of 91.11%. Furthermore, incorporating personalised parameters into the data improved the accuracy of these algorithms in detecting stress levels. Cross-validation was also utilised to mitigate the risk of overfitting, ensuring robust and reliable model performance.
Conclusion:
The findings reveal that human bio-signals tend to increase following commuting, irrespective of the mode, with driving identified as the most stressful option. Commuters using passive modes of transport experience elevated stress levels compared to those using active modes. This research underscores the importance of understanding the connection between commuting modes and stress, providing key insights into the potential health impacts of daily travel. The development of an intelligent model to predict stress levels based on commuting mode offers valuable contributions to public health and transportation planning, with the goal of enhancing well-being and improving commuters’ quality of life.}
}
@article{LIU2024108212,
title = {Analysis of translation teaching skills in colleges and universities based on deep learning},
journal = {Computers in Human Behavior},
volume = {157},
pages = {108212},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108212},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000803},
author = {Yan Liu and Shuhua Li and Dan Cui},
keywords = {Deep learning, Colleges and universities, Translation education, Machine learning applications, Teaching strategy},
abstract = {With the progress of the times and the improvement of science and technique, network message technique has occupied a vital position in people's lives. At the same time, society has been implementing university English education reform in recent years, and the “internet plus” wisdom education model is the product of the improvement of the times. This new education model has gradually integrated into the education of various subjects. Introducing the concept of message technique and wisdom education into university translation education can innovate education mode, optimize education content, and integrate high-quality education resources. Cultivating applied translators has become the trend of educational reform. Based on deep learning, this paper studies translation education skills in universities. In-depth education enables learners to acquire systematic knowledge, critical spirit, creative thinking, etc. This kind of learning fully taps individual potential to cultivate a complete personality. According to the research in this paper, wisdom education is 12% better than traditional education, and it is suitable to be widely put into practice.}
}
@article{GERSTEIN200773,
title = {An interdepartmental Ph.D. program in computational biology and bioinformatics: The Yale perspective},
journal = {Journal of Biomedical Informatics},
volume = {40},
number = {1},
pages = {73-79},
year = {2007},
note = {Bio*Medical Informatics},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2006.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S1532046406000335},
author = {Mark Gerstein and Dov Greenbaum and Kei Cheung and Perry L. Miller},
keywords = {Bioinformatics, Computational biology, Educational programs, Curriculum},
abstract = {Computational biology and bioinformatics (CBB), the terms often used interchangeably, represent a rapidly evolving biological discipline. With the clear potential for discovery and innovation, and the need to deal with the deluge of biological data, many academic institutions are committing significant resources to develop CBB research and training programs. Yale formally established an interdepartmental Ph.D. program in CBB in May 2003. This paper describes Yale’s program, discussing the scope of the field, the program’s goals and curriculum, as well as a number of issues that arose in implementing the program. (Further updated information is available from the program’s website, www.cbb.yale.edu.)}
}
@article{BEDEWY2023101299,
title = {STEAM + X - Extending the transdisciplinary of STEAM-based educational approaches: A theoretical contribution},
journal = {Thinking Skills and Creativity},
volume = {48},
pages = {101299},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2023.101299},
url = {https://www.sciencedirect.com/science/article/pii/S187118712300069X},
author = {Shereen El Bedewy and Zsolt Lavicza},
keywords = {STEAM, Design-based research, Culture, Technology, Design principles},
abstract = {This design-based research methodological paper is proposing a theoretical understanding in the form of STEAM + X framework that emerged from the empirical findings of implementing transdisciplinary STEAM practices featuring architecture, culture, and history. This paper shows how the proposed STEAM practices, involving creativities, to promote the integration of various disciplines with multiple cross-cultural iterations. These STEAM practices allow teachers to integrate cultural, architectural, environmental, or technological options into mathematics teaching and learning. These STEAM practices foster creativity and thinking skills in connecting disciplines in a transdisciplinary learning approach. Moreover, this paper introduces the study outcomes including the developed design principles and a framework that connects the underlying theoretical framework with emerging themes from our qualitative data analysis.}
}
@article{DEBER200449,
title = {Medical savings accounts in a universal system: wishful thinking meets evidence},
journal = {Health Policy},
volume = {70},
number = {1},
pages = {49-66},
year = {2004},
issn = {0168-8510},
doi = {https://doi.org/10.1016/j.healthpol.2004.01.010},
url = {https://www.sciencedirect.com/science/article/pii/S0168851004000119},
author = {Raisa B Deber and Evelyn L Forget and Leslie L Roos},
keywords = {Medical savings accounts, Canada, Health care financing, Distribution of expenditures},
abstract = {Medical savings accounts (MSAs) and similar approaches based on flowing reimbursements through individuals/consumers rather than providers are unsuited for systems with universal coverage. Data from Manitoba, Canada reveal that, because expenditures for physician and hospital services are highly skewed in all age groups, MSAs would substantially increase both public expenditures and out-of-pocket costs for the most ill. The empirical distribution of health expenditures limits the potential impact of many current ‘demand-based’ approaches to cost control. Because most of the population is relatively healthy and uses few hospital and physician services, inducing the general population to spend less will not yield substantial savings.}
}
@article{STARK2021571,
title = {Autistic Cognition: Charting Routes to Anxiety},
journal = {Trends in Cognitive Sciences},
volume = {25},
number = {7},
pages = {571-581},
year = {2021},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2021.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1364661321000899},
author = {Eloise Stark and James Stacey and Will Mandy and Morten L. Kringelbach and Francesca Happé},
keywords = {autism, cognition, anxiety, predictive processing, intolerance of uncertainty, black and white thinking},
abstract = {Autism Spectrum Conditions are typified by a divergence in cognitive style from that of the non-autistic population. Cognitive differences in autism may underlie significant strengths, but also increase vulnerability to psychopathology such as anxiety, which is a major problem for many autistic people. Many autistic people also do not respond to typical psychotherapeutic interventions, suggesting that autism-specific models and interventions are needed. We advance a theoretical model explaining how three constructs, attenuated predictions, intolerance of uncertainty, and ‘black and white thinking’, may interact to lead to anxiety in autism. We hope to start a dialogue surrounding how we can best address specific autistic cognitive differences that may lead to distress by developing appropriate models, measurements, and psychotherapeutic interventions.}
}
@article{WANG2024119888,
title = {Progressive reinforcement learning for video summarization},
journal = {Information Sciences},
volume = {655},
pages = {119888},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2023.119888},
url = {https://www.sciencedirect.com/science/article/pii/S0020025523014731},
author = {Guolong Wang and Xun Wu and Junchi Yan},
keywords = {Video summarization, Progressive reinforcement learning, Hierarchical strategy},
abstract = {Video summarization addresses generating video summaries to help watchers grasp the content of a video without watching it entirely. Many methods have engaged in automatic video summarization. Although these methods have performed well, they still suffer from limited training data and sparse reward problems. We propose a Progressive Reinforcement Learning Video Summarization structure (PRLVS) with an unsupervised reward. The reward measures the information and quality the selected frames convey without annotations. Striving to earn higher rewards, our PRLVS adopts a “T”-type human thinking paradigm: choosing some key frames and checking if their adjacent frames are better than them. To simulate this paradigm, we decompose the flat strategy into a hierarchical strategy consisting of a horizontal policy and a vertical policy. These two policies are optimized alternatively, which densifies the reward while reducing the exploration space. Their cooperation also makes the agent capture the context information of the whole video at every step. Extensive experimental results on two benchmark databases (i.e., SumMe, TVSum) show that our PRLVS outperforms the comparisons and approaches the supervised methods, which indicates that it is significant to integrate our unsupervised reward into the progressive reinforcement learning structure to address limited annotation and sparse reward problems.}
}
@article{ROLLS2024e31965,
title = {The memory systems of the human brain and generative artificial intelligence},
journal = {Heliyon},
volume = {10},
number = {11},
pages = {e31965},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e31965},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024079969},
author = {Edmund T. Rolls},
keywords = {The brain and AI, Generative Pre-trained Transformer, Generative artificial intelligence, Episodic memory, Semantic memory, Hippocampal memory system, Chat-GPT},
abstract = {Generative Artificial Intelligence foundation models (for example Generative Pre-trained Transformer – GPT – models) can generate the next token given a sequence of tokens. How can this ‘generative AI’ be compared with the ‘real’ intelligence of the human brain, when for example a human generates a whole memory in response to an incomplete retrieval cue, and then generates further prospective thoughts? Here these two types of generative intelligence, artificial in machines and real in the human brain are compared, and it is shown how when whole memories are generated by hippocampal recall in response to an incomplete retrieval cue, what the human brain computes, and how it computes it, are very different from generative AI. Key differences are the use of local associative learning rules in the hippocampal memory system, and of non-local backpropagation of error learning in AI. Indeed, it is argued that the whole operation of the human brain is performed computationally very differently to what is implemented in generative AI. Moreover, it is emphasized that the primate including human hippocampal system includes computations about spatial view and where objects and people are in scenes, whereas in rodents the emphasis is on place cells and path integration by movements between places. This comparison with generative memory and processing in the human brain has interesting implications for the further development of generative AI and for neuroscience research.}
}
@incollection{WARE20221,
title = {Chapter 1 - Visual Queries},
editor = {Colin Ware},
booktitle = {Visual Thinking for Information Design (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
pages = {1-22},
year = {2022},
isbn = {978-0-12-823567-6},
doi = {https://doi.org/10.1016/B978-0-12-823567-6.00001-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012823567600001X},
author = {Colin Ware},
keywords = {Visual queries, visual search, distributed cognition, predictive cognition, visual system, visual thinking},
abstract = {The mechanisms and processes of visual thinking are introduced together with how this knowledge can help us make design decisions. We begin with a review of the evidence that we actually take in very little information with each glance and the implication that seeing is a process exquisitely tuned to our cognitive task of the moment. As a key part of this process, our brains execute visual queries using eye movements; visual features are detected in parallel to pick out just what is needed to resolve part of a cognitive problem and move on the next step. We begin to understand how seeing can be a distributed cognitive process executed partly in the brain and partly using a visualization as a tool. In particular, when the visualization is part of an interactive computer application, it provides the primary interface between cognitive operations in the human brain and computational operations. The theory of predictive cognition is introduced as a basis for how we should design presentations.}
}
@article{YON2021R1026,
title = {Precision and the Bayesian brain},
journal = {Current Biology},
volume = {31},
number = {17},
pages = {R1026-R1032},
year = {2021},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2021.07.044},
url = {https://www.sciencedirect.com/science/article/pii/S0960982221010344},
author = {Daniel Yon and Chris D. Frith},
abstract = {Summary
Scientific thinking about the minds of humans and other animals has been transformed by the idea that the brain is Bayesian. A cornerstone of this idea is that agents set the balance between prior knowledge and incoming evidence based on how reliable or ‘precise’ these different sources of information are — lending the most weight to that which is most reliable. This concept of precision has crept into several branches of cognitive science and is a lynchpin of emerging ideas in computational psychiatry — where unusual beliefs or experiences are explained as abnormalities in how the brain estimates precision. But what precisely is precision? In this Primer we explain how precision has found its way into classic and contemporary models of perception, learning, self-awareness, and social interaction. We also chart how ideas around precision are beginning to change in radical ways, meaning we must get more precise about how precision works.}
}
@article{COMPTON2018392,
title = {The aprosody of schizophrenia: Computationally derived acoustic phonetic underpinnings of monotone speech},
journal = {Schizophrenia Research},
volume = {197},
pages = {392-399},
year = {2018},
issn = {0920-9964},
doi = {https://doi.org/10.1016/j.schres.2018.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920996418300276},
author = {Michael T. Compton and Anya Lunden and Sean D. Cleary and Luca Pauselli and Yazeed Alolayan and Brooke Halpern and Beth Broussard and Anthony Crisafio and Leslie Capulong and Pierfrancesco Maria Balducci and Francesco Bernardini and Michael A. Covington},
keywords = {Acoustic resonance, Aprosody, Linguistics, Negative symptoms, Phonetics, Phonology, Psychosis, Schizophrenia},
abstract = {Objective
Acoustic phonetic methods are useful in examining some symptoms of schizophrenia; we used such methods to understand the underpinnings of aprosody. We hypothesized that, compared to controls and patients without clinically rated aprosody, patients with aprosody would exhibit reduced variability in: pitch (F0), jaw/mouth opening and tongue height (formant F1), tongue front/back position and/or lip rounding (formant F2), and intensity/loudness.
Methods
Audiorecorded speech was obtained from 98 patients (including 25 with clinically rated aprosody and 29 without) and 102 unaffected controls using five tasks: one describing a drawing, two based on spontaneous speech elicited through a question (Tasks 2 and 3), and two based on reading prose excerpts (Tasks 4 and 5). We compared groups on variation in pitch (F0), formant F1 and F2, and intensity/loudness.
Results
Regarding pitch variation, patients with aprosody differed significantly from controls in Task 5 in both unadjusted tests and those adjusted for sociodemographics. For the standard deviation (SD) of F1, no significant differences were found in adjusted tests. Regarding SD of F2, patients with aprosody had lower values than controls in Task 3, 4, and 5. For variation in intensity/loudness, patients with aprosody had lower values than patients without aprosody and controls across the five tasks.
Conclusions
Findings could represent a step toward developing new methods for measuring and tracking the severity of this specific negative symptom using acoustic phonetic parameters; such work is relevant to other psychiatric and neurological disorders.}
}
@incollection{CARLSON2017425,
title = {Chapter 20 - Computational Perspectives on Adult Neurogenesis},
editor = {Arjen {van Ooyen} and Markus Butz-Ostendorf},
booktitle = {The Rewiring Brain},
publisher = {Academic Press},
address = {San Diego},
pages = {425-441},
year = {2017},
isbn = {978-0-12-803784-3},
doi = {https://doi.org/10.1016/B978-0-12-803784-3.00020-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128037843000202},
author = {Kristofor D. Carlson and Fred Rothganger and James B. Aimone},
keywords = {Adult neurogenesis, structural plasticity, computational neural model, hippocampus, dentate gyrus},
abstract = {The continuous integration of young neurons into the adult brain represents a novel form of structural plasticity and has inspired the creation of numerous computational models to understand the functional role of adult neurogenesis. These computational models consist of abstract models that focus on the utility of new neurons in simple neural networks and biologically based models constrained by anatomical data that explore the role of new neurons in specific neural circuits such as the hippocampus. Simulation results from both classes of models have suggested a number of theoretical roles for neurogenesis such as increasing the capacity to learn novel information, promoting temporal context encoding, and influencing pattern separation. In this review, we discuss strategies and findings of past computational modeling efforts, current challenges and limitations, and new computational approaches pertinent to modeling adult neurogenesis.}
}
@article{SKRYD2024,
title = {ChatGPT as a Tool for Medical Education and Clinical Decision-Making on the Wards: Case Study},
journal = {JMIR Formative Research},
volume = {8},
year = {2024},
issn = {2561-326X},
doi = {https://doi.org/10.2196/51346},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X24002671},
author = {Anthony Skryd and Katharine Lawrence},
keywords = {ChatGPT, medical education, large language models, LLMs, clinical decision-making},
abstract = {Background
Large language models (LLMs) are computational artificial intelligence systems with advanced natural language processing capabilities that have recently been popularized among health care students and educators due to their ability to provide real-time access to a vast amount of medical knowledge. The adoption of LLM technology into medical education and training has varied, and little empirical evidence exists to support its use in clinical teaching environments.
Objective
The aim of the study is to identify and qualitatively evaluate potential use cases and limitations of LLM technology for real-time ward-based educational contexts.
Methods
A brief, single-site exploratory evaluation of the publicly available ChatGPT-3.5 (OpenAI) was conducted by implementing the tool into the daily attending rounds of a general internal medicine inpatient service at a large urban academic medical center. ChatGPT was integrated into rounds via both structured and organic use, using the web-based “chatbot” style interface to interact with the LLM through conversational free-text and discrete queries. A qualitative approach using phenomenological inquiry was used to identify key insights related to the use of ChatGPT through analysis of ChatGPT conversation logs and associated shorthand notes from the clinical sessions.
Results
Identified use cases for ChatGPT integration included addressing medical knowledge gaps through discrete medical knowledge inquiries, building differential diagnoses and engaging dual-process thinking, challenging medical axioms, using cognitive aids to support acute care decision-making, and improving complex care management by facilitating conversations with subspecialties. Potential additional uses included engaging in difficult conversations with patients, exploring ethical challenges and general medical ethics teaching, personal continuing medical education resources, developing ward-based teaching tools, supporting and automating clinical documentation, and supporting productivity and task management. LLM biases, misinformation, ethics, and health equity were identified as areas of concern and potential limitations to clinical and training use. A code of conduct on ethical and appropriate use was also developed to guide team usage on the wards.
Conclusions
Overall, ChatGPT offers a novel tool to enhance ward-based learning through rapid information querying, second-order content exploration, and engaged team discussion regarding generated responses. More research is needed to fully understand contexts for educational use, particularly regarding the risks and limitations of the tool in clinical settings and its impacts on trainee development.}
}
@article{RINGACH2009439,
title = {Spontaneous and driven cortical activity: implications for computation},
journal = {Current Opinion in Neurobiology},
volume = {19},
number = {4},
pages = {439-444},
year = {2009},
note = {Sensory systems},
issn = {0959-4388},
doi = {https://doi.org/10.1016/j.conb.2009.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S0959438809000786},
author = {Dario L Ringach},
abstract = {The traditional view of spontaneous neural activity as ‘noise’ has been challenged by recent findings suggesting that: (a) spontaneous activity in cortical populations is highly structured in both space and time, (b) the spatio-temporal structure of spontaneous activity is linked to the underlying connectivity of the cortical network, (c) spontaneous cortical activity interacts with external stimulation to generate responses to the individual presentations of a stimulus, (d) network connectivity is shaped in part by the statistics of natural signals and (e) ongoing cortical activity represents a continuous top-down prediction/expectation signal that interacts with incoming input to generate an updated representation of the world. These results can be integrated to provide a new framework for the study of cortical computation.}
}
@article{WANG2024102579,
title = {Artificial intelligence in dance education: Using immersive technologies for teaching dance skills},
journal = {Technology in Society},
volume = {77},
pages = {102579},
year = {2024},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2024.102579},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X24001271},
author = {Zheng Wang},
keywords = {Artificial intelligence, Dance education, Dance mobile applications, Educational ecosystem, Immersive technologies, Intelligent action recognition system, Interactive dance training, Virtual, Augmented and mixed reality, Virtual mentoring},
abstract = {Artificial intelligence (AI) has led to a shift in modern dance education. Immersive technologies have become increasingly common worldwide, helping educators to improve the quality of dance pedagogy and increase the effectiveness of dance training. The article investigates the ways of using immersive technologies powered by artificial intelligence in dance education. The research explores the theoretical literature on dance education and the use of artificial intelligence in dance education and dance choreography. The scholars examine the impact of innovative technology solutions used in dance pedagogical practice on the development of dance skills in students. The study also discusses the functionality of interactive and multimedia dance teaching systems, including AI-powered virtual mentoring and cognitive simulations of human mind operations. The research analysed the use of virtual reality (VR), augmented reality (AR), and mixed reality (MR) in dance education. This research also focuses on mobile applications used for teaching modern dance. The proposed framework for dance education is based on digital technologies, which help to develop dance skills and improve teaching practices. The scholars conclude that the development and improvement of dance skills are possible only if a teacher combines virtual and real environments in everyday practices. The findings can be used by dance teachers, professional dancers, software developers, and researchers who examine the innovative practices and the application of artificial intelligence in dance education. The ecosystem model reframes thinking about approaches to dance education and can serve as the basis for further development of dance courses and dance style teaching modes.}
}
@article{MILLER1990489,
title = {Towards a believable theory of planning: D. E. Wilkins. Practical Planning. San Mateo, CA: Morgan Kaufmann, 1988. Pp. xii + 205. $49.95. S. L. Friedman. E. K. Scholnick, and R. R. Cocking. Blueprints for Thinking, London/New York: Cambridge Univ. Press, 1987. Pp. xv + 559. $58.50 K. Hammond. Case-Based Planning. San Diego: Academic Press, 1989. Pp. xviii + 277. $34.95},
journal = {Journal of Mathematical Psychology},
volume = {34},
number = {4},
pages = {489-498},
year = {1990},
issn = {0022-2496},
doi = {https://doi.org/10.1016/0022-2496(90)90028-8},
url = {https://www.sciencedirect.com/science/article/pii/0022249690900288},
author = {David P. Miller}
}
@article{DAVIES2016617,
title = {Computational Screening of All Stoichiometric Inorganic Materials},
journal = {Chem},
volume = {1},
number = {4},
pages = {617-627},
year = {2016},
issn = {2451-9294},
doi = {https://doi.org/10.1016/j.chempr.2016.09.010},
url = {https://www.sciencedirect.com/science/article/pii/S2451929416301553},
author = {Daniel W. Davies and Keith T. Butler and Adam J. Jackson and Andrew Morris and Jarvist M. Frost and Jonathan M. Skelton and Aron Walsh},
keywords = {functional materials, computational chemistry, materials design, solar energy, high-throughput screening, water splitting, perovskites, structure prediction, SDG7: Affordable and clean energy},
abstract = {Summary
Forming a four-component compound from the first 103 elements of the periodic table results in more than 1012 combinations. Such a materials space is intractable to high-throughput experiment or first-principle computation. We introduce a framework to address this problem and quantify how many materials can exist. We apply principles of valency and electronegativity to filter chemically implausible compositions, which reduces the inorganic quaternary space to 1010 combinations. We demonstrate that estimates of band gaps and absolute electron energies can be made simply on the basis of the chemical composition and apply this to the search for new semiconducting materials to support the photoelectrochemical splitting of water. We show the applicability to predicting crystal structure by analogy with known compounds, including exploration of the phase space for ternary combinations that form a perovskite lattice. Computer screening reproduces known perovskite materials and predicts the feasibility of thousands more. Given the simplicity of the approach, large-scale searches can be performed on a single workstation.}
}
@article{SANTOS2015127,
title = {Phenotypic plasticity, the Baldwin effect, and the speeding up of evolution: The computational roots of an illusion},
journal = {Journal of Theoretical Biology},
volume = {371},
pages = {127-136},
year = {2015},
issn = {0022-5193},
doi = {https://doi.org/10.1016/j.jtbi.2015.02.012},
url = {https://www.sciencedirect.com/science/article/pii/S0022519315000715},
author = {Mauro Santos and Eörs Szathmáry and José F. Fontanari},
keywords = {Evolutionary search, Genetic algorithm, Learning, The Baldwin effect, Speed of evolution},
abstract = {An increasing number of dissident voices claim that the standard neo-Darwinian view of genes as ‘leaders’ and phenotypes as ‘followers’ during the process of adaptive evolution should be turned on its head. This idea is older than the rediscovery of Mendel’s laws of inheritance, with the turn-of-the-twentieth-century notion eventually labeled as the ‘Baldwin effect’ as one of the many ways in which the standard neo-Darwinian view can be turned around. A condition for this effect is that environmentally induced variation such as phenotypic plasticity or learning is crucial for the initial establishment of a trait. This gives the additional time for natural selection to act on genetic variation and the adaptive trait can be eventually encoded in the genotype. An influential paper published in the late 1980s claimed the Baldwin effect to happen in computer simulations, and avowed that it was crucial to solve a difficult adaptive task. This generated much excitement among scholars in various disciplines that regard neo-Darwinian accounts to explain the evolutionary emergence of high-order phenotypic traits such as consciousness or language almost hopeless. Here, we use analytical and computational approaches to show that a standard population genetics treatment can easily crack what the scientific community has granted as an unsolvable adaptive problem without learning. Evolutionary psychologists and linguists have invoked the (claimed) Baldwin effect to make wild assertions that should not be taken seriously. What the Baldwin effect needs are plausible case-histories.}
}
@article{LI20203666,
title = {The computational approaches of lncRNA identification based on coding potential: Status quo and challenges},
journal = {Computational and Structural Biotechnology Journal},
volume = {18},
pages = {3666-3677},
year = {2020},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2020.11.030},
url = {https://www.sciencedirect.com/science/article/pii/S2001037020304979},
author = {Jing Li and Xuan Zhang and Changning Liu},
keywords = {LncRNA identification, , Algorithm, Feature, Coding potential, sORF},
abstract = {Long noncoding RNAs (lncRNAs) make up a large proportion of transcriptome in eukaryotes, and have been revealed with many regulatory functions in various biological processes. When studying lncRNAs, the first step is to accurately and specifically distinguish them from the colossal transcriptome data with complicated composition, which contains mRNAs, lncRNAs, small RNAs and their primary transcripts. In the face of such a huge and progressively expanding transcriptome data, the in-silico approaches provide a practicable scheme for effectively and rapidly filtering out lncRNA targets, using machine learning and probability statistics. In this review, we mainly discussed the characteristics of algorithms and features on currently developed approaches. We also outlined the traits of some state-of-the-art tools for ease of operation. Finally, we pointed out the underlying challenges in lncRNA identification with the advent of new experimental data.}
}
@incollection{ELNAKIB202159,
title = {3 - Computational methods for identifying left ventricle heart pathologies},
editor = {Ayman S. El-Baz and Jasjit S. Suri},
booktitle = {Diabetes and Cardiovascular Disease},
publisher = {Elsevier},
pages = {59-93},
year = {2021},
volume = {3},
series = {Computer-Assisted Diagnosis},
isbn = {978-0-12-817428-9},
doi = {https://doi.org/10.1016/B978-0-12-817428-9.00003-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128174289000036},
author = {Ahmed Elnakib and Mohammed Ghazal and Fatma Taher and Ali H. Mahmoud and Ayman El-Baz},
keywords = {Computational methods, Left ventricle, Heart, Pathologies, Cardiac MRI (CMRI), Segmentation},
abstract = {Globally, the cardiovascular diseases are the first cause of death. The early detection and quantification of these diseases can significantly reduce the mortality rate. Recent advances in cardiac MRI (CMRI) enable the detection of the left ventricle (LV) wall pathologies and the estimation of different quantification metrics that characterize the working of the heart. Examples of these metrics include the area of pathological tissue in the LV wall, the transmural extent of pathology, and other indexes such as wall thickening, functional strain, and the ejection fraction metrics. In the literature, several computational methods have been proposed in order to estimate these metrics based on using different CMRI acquisition techniques, such as cardiac-enhanced CMRI (CE-CMRI) and cine CMRI. This chapter overviews these computational methods and explains their basic ideas, focusing on the metrics extracted using CE-CMRI and cine CMRI.}
}
@article{MAHMOUDZAKIALI2022100579,
title = {The computation intelligent in teaching using digital communication},
journal = {Measurement: Sensors},
volume = {24},
pages = {100579},
year = {2022},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2022.100579},
url = {https://www.sciencedirect.com/science/article/pii/S2665917422002136},
author = {Hossam {Mahmoud Zaki Ali} and Mohammed Hasan Ali Al-Abyadh},
keywords = {Computation intelligent, Digital communication, Skills, Non-verbal communication skills, School health promotion, Teachers},
abstract = {Teaching is all about communication. Teachers who sharpen their communication skills are prepared to instruct, advise, and mentor their students. They communicate well to effectively collaborate within a healthy educational process. This research aims to Make sure the communication scale prepared for the current research has statistical validity to be applied in the current research, identify the teachers' verbal non-verbal communication skills level, to explore the differences in these variables due to gender. A sample of (376) elementary and preparatory stage teachers, Minia Governorate, Egypt (188 male, 188 female) was chosen. For data collection, the researchers utilized the verbal and non-verbal communication scale (prepared by the researchers). They were applied electronically during the 2020 academic year. The research was a descriptive research design. Results demonstrated The communication scale prepared for the current research has statistical validity to be applied in the current research, there was a high level of verbal and nonverbal communication skills among the research sample. Besides, there were no statistically significant differences between male and female teachers in the levels of verbal communication skills, non-verbal communication skills. Some recommendations regarding the necessity to specify courses for pre-service teachers on verbal communication skills, nonverbal communication skills, were presented. Also, suggestions for those in charge of the educational administration process to improve teachers and school health promotion were illustrated.}
}
@article{MACCORMAC1984207,
title = {Men and machines: The computational metaphor},
journal = {Technology in Society},
volume = {6},
number = {3},
pages = {207-216},
year = {1984},
note = {Special Issue Technology and Philosophy},
issn = {0160-791X},
doi = {https://doi.org/10.1016/0160-791X(84)90033-2},
url = {https://www.sciencedirect.com/science/article/pii/0160791X84900332},
author = {Earl R. MacCormac},
abstract = {In the 20th century the interpretation of the human mind and brain as a computer has replaced the 18th century metaphor of “man as a machine”. This paper traces the development of the computational metaphor with some attention to its 18th century roots, and then argues that its employment need not lead to the mechanization of thinking and the autonomy of technique. An awareness of the metaphoric and, therefore, hypothetical status of the computational metaphor will prevent technique from escaping intentional human control. This is a shortened version of a paper included in C. Mitcham and Alois Huning, eds., Philosophy and Technology II: Information Technology and Computers in Theory and Practice (Boston: D. Reidel, in press), and is included here with permission.}
}
@article{BOHMANN2018185,
title = {Computational tools for topological coHochschild homology},
journal = {Topology and its Applications},
volume = {235},
pages = {185-213},
year = {2018},
issn = {0166-8641},
doi = {https://doi.org/10.1016/j.topol.2017.12.008},
url = {https://www.sciencedirect.com/science/article/pii/S0166864117306442},
author = {Anna Marie Bohmann and Teena Gerhardt and Amalie Høgenhaven and Brooke Shipley and Stephanie Ziegenhagen},
keywords = {Topological Hochschild homology, Coalgebra, Hochschild–Kostant–Rosenberg},
abstract = {In recent work, Hess and Shipley [18] defined a theory of topological coHochschild homology (coTHH) for coalgebras. In this paper we develop computational tools to study this new theory. In particular, we prove a Hochschild–Kostant–Rosenberg type theorem in the cofree case for differential graded coalgebras. We also develop a coBökstedt spectral sequence to compute the homology of coTHH for coalgebra spectra. We use a coalgebra structure on this spectral sequence to produce several computations.}
}
@article{BICER2021100823,
title = {Investigating creativity-directed tasks in middle school mathematics curricula},
journal = {Thinking Skills and Creativity},
volume = {40},
pages = {100823},
year = {2021},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2021.100823},
url = {https://www.sciencedirect.com/science/article/pii/S1871187121000389},
author = {Ali Bicer and Aylin Marquez and Karla Valesca Matute Colindres and Angela Ann Schanke and Libni Berenice Castellon and Luke M. Audette and Celal Perihan and Yujin Lee},
keywords = {Creativity-directed tasks, Creativity in mathematics textbooks, Creativity in mathematics curricula, Creative thinking in mathematics},
abstract = {Developing students’ creative thinking abilities while learning mathematics has been recently emphasized by many scholars, with many nations including creative thinking in mathematics as one of their overarching curriculum goals. The first purpose of the present study is to develop a framework to identify what type of mathematical tasks promote the mathematical creativity of students. The second purpose is to analyze to what degree the most commonly used three middle school curricula (i.e., Eureka, The Go Math!, and CPM) in the U.S. include creativity-directed tasks in their textbooks using this framework. Analyzing 1,500 mathematical tasks in each curriculum revealed that different curricula emphasize different dimensions of the creativity-directed tasks categories (i.e., open-ended tasks, problem-posing, connections, extensions, visualizations, and communication) presented in the framework. The result also revealed that open-ended problems are more common in the 6th grade textbooks than 7th and 8th grade textbooks regardless of the three selected middle school mathematics curricula. The implication of this study is to guide teachers with the strength and weakness of textbooks in terms of their inclusiveness of creativity-directed tasks to inform their teaching. Additionally, it is critical for curriculum developers to pay particular attention in including tasks that supporting each category and subcategory proportionately across the three years of middle school rather than emphasizing a few of them in one grade and almost completely ignoring them in previous or later years.}
}
@article{DOGANDUNLAP20102141,
title = {Linear algebra students’ modes of reasoning: Geometric representations},
journal = {Linear Algebra and its Applications},
volume = {432},
number = {8},
pages = {2141-2159},
year = {2010},
note = {Special issue devoted to the 15th ILAS Conference at Cancun, Mexico, June 16-20, 2008},
issn = {0024-3795},
doi = {https://doi.org/10.1016/j.laa.2009.08.037},
url = {https://www.sciencedirect.com/science/article/pii/S0024379509004728},
author = {Hamide Dogan-Dunlap},
keywords = {Mathematics education, Linear algebra, Thinking modes, Geometric representations},
abstract = {Main goal of our research was to document differences on the types of modes linear algebra students displayed in their responses to the questions of linear independence from two different assignments. In this paper, modes from the second assignment are discussed in detail. Second assignment was administered with the support of graphical representations through an interactive web-module. Additionally, for comparison purposes, we briefly talk about the modes from the first assignment. First assignment was administered with the support of computational devices such as calculators providing the row reduced echelon form (rref) of matrices. Sierpinska’s framework on thinking modes (2000) was considered while qualitatively documenting the aspects of 45 matrix algebra students’ modes of reasoning. Our analysis revealed 17 categories of the modes of reasoning for the second assignment, and 15 categories for the first assignment. In conclusion, the findings of our analysis support the view of the geometric representations not replacing one’s arithmetic or algebraic modes but encouraging students to utilize multiple modes in their reasoning. Specifically, geometric representations in the presence of algebraic and arithmetic modes appear to help learners begin to consider the diverse representational aspects of a concept flexibly.}
}
@article{ARASTOOPOURIRGENS2024100699,
title = {User experience testing and co-designing a digital game for broadening participation in computing with and for elementary school children},
journal = {International Journal of Child-Computer Interaction},
volume = {42},
pages = {100699},
year = {2024},
issn = {2212-8689},
doi = {https://doi.org/10.1016/j.ijcci.2024.100699},
url = {https://www.sciencedirect.com/science/article/pii/S2212868924000680},
author = {Golnaz {Arastoopour Irgens} and Cinamon Bailey and Tolulope Famaye and Atefeh Behboudi},
keywords = {Elementary education, User experience testing, Game-based learning, Culturally sustaining pedagogies, Intersectionality},
abstract = {Broadening participation in computing is more than providing access to computing for students; it requires reimagining and transforming teaching and learning to be more inclusive and culturally sustaining and it begins with elementary school children. In this study, we report on the fourth cycle of a participatory design-based research project in which researchers and children co-design culturally responsive-sustaining computational learning environments. We conducted user experience testing and co-design sessions with seven children on one level of a game-based learning environment in development. We model children's discourse through Epistemic Network Analysis models to investigate their feedback on character design, game narratives, and introductory activities. Our findings reveal 1) children's positive response to characters with counternarratives and visible intersectional identities in computing, 2) positive and negative experiences and feedback from children on game activities and narratives, and 3) suggestions for improvement.}
}
@article{KALELIOGLU2015200,
title = {A new way of teaching programming skills to K-12 students: Code.org},
journal = {Computers in Human Behavior},
volume = {52},
pages = {200-210},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.05.047},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215004288},
author = {Filiz Kalelioğlu},
keywords = {Improving classroom teaching, Programming and programming languages, Elementary education},
abstract = {This study attempts to investigate the effect of teaching code.org site on reflective thinking skills towards problem solving. More specifically, this study attempts to investigate whether there is a gender difference in terms of students’ reflective thinking skills towards problem solving. This triangulation study was conducted with 32 primary school students. The quantitative part of the study was conducted in pre-test/post-test comparison design of quasi-experimental design. The scores of reflective problem solving skills were gathered through the reflective thinking skill scale towards problem solving and the students’ performances in the code-org site were examined. In the qualitative part of the research, after the five-week experimental process, focus group interviews were conducted with ten students and a reflection paper from the IT teacher was analysed. According to the t-test results, teaching programming to primary school students in the code.org site did not cause any differences in reflective thinking skills towards problem solving. However, there is a slight increment in the means of female students’ reflective thinking skills towards problem solving over the males’ reflective thinking skills towards problem solving. On the other hand, qualitative data provided more information about the students’ experiences. Students developed a positive attitude towards programming, and female students showed that they were as successful as their male counterparts, and that programming could be part of their future plans.}
}
@article{PESKIN201213,
title = {Fostering symbolic interpretation during adolescence},
journal = {Journal of Applied Developmental Psychology},
volume = {33},
number = {1},
pages = {13-23},
year = {2012},
issn = {0193-3973},
doi = {https://doi.org/10.1016/j.appdev.2011.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S0193397311000931},
author = {Joan Peskin and Rebecca Wells-Jopling},
keywords = {Adolescence, Symbolic interpretation, Domain-specific knowledge, Poetry, Concrete scaffolds, Computational skills},
abstract = {Although by 11years children demonstrate impressive performance on various tasks that assess symbolic thinking in language development, research suggests that few young adolescents demonstrate evidence of symbolic processing when reading literature. This study investigated whether the difficulty might be due to a lack of adequate exposure to domain-specific knowledge. Students in the experimental groups in three age groups — preadolescence, middle adolescence and later adolescence — received concrete scaffolds designed to foster domain-specific knowledge of the symbolic process. A comparison of the experimental and control groups showed that students at all three ages who had experienced the scaffolds demonstrated significantly greater symbolic interpretation. Furthermore, despite concerns that the scaffolds might dampen the readers' personal response, the experimental groups at all three ages provided significantly higher enjoyment ratings of the test poems.}
}
@incollection{REIN2013199,
title = {Chapter 16 - Re-thinking Standardization for Interagency Information Sharing},
editor = {Babak Akhgar and Simeon Yates},
booktitle = {Strategic Intelligence Management},
publisher = {Butterworth-Heinemann},
pages = {199-211},
year = {2013},
isbn = {978-0-12-407191-9},
doi = {https://doi.org/10.1016/B978-0-12-407191-9.00016-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780124071919000168},
author = {Kellyn Rein},
keywords = {agencies, analysis, data, fusion, human, intelligence, language, management, national, security, sources, text},
abstract = {Abstracts:
The collection and analysis of data for intelligence purposes is vital to national security. There are a number of hurdles including the exponentially increasing volume of available data, the need for increased cooperation between national and international agencies due to the increasingly globalized nature of threats to citizens and nations, and the need to be flexible in identifying new threats. Increasing reliance on computers is necessary, but complications arise due to such issues as incompatible data formats, multiple natural languages, and data privacy concerns. However, a potential solution to solving some of these problems for national security and law enforcement agencies is C2LG (Command and Control Lexical Grammar), which was originally developed for use within NATO, and is being adapted for use in crisis management and the fight against international organized crime.}
}
@article{KUO201232,
title = {Conceptual study of micro-tab device in airframe noise reduction: (II) 3D computation},
journal = {Aerospace Science and Technology},
volume = {17},
number = {1},
pages = {32-39},
year = {2012},
issn = {1270-9638},
doi = {https://doi.org/10.1016/j.ast.2011.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S127096381100040X},
author = {Brian C. Kuo and Nesrin Sarigul-Klijn},
keywords = {Computational aeroacoustics, High-lift devices, Micro-tab, Airframe noise},
abstract = {A three-dimensional numerical study is conducted to better understand noise reduction results seen in the previous two-dimensional investigation of the acoustic effects of micro-tab device on airframe noise reduction. Without sacrificing the aerodynamic performance, it is possible to achieve high-lift noise reduction with the application of the micro-tab device attached to the pressure side of the flap surface near its trailing-edge. This study was carried out by numerical hybrid method, which combines Computational Fluid Dynamics and acoustic analogy to predict the farfield noise spectrum. The near-full-scale computational results show that the micro-tab device with reduced deflection of the high-lift devices achieves noise reduction in mid-to-high frequency domain, in particular the range that human beings are most sensitive to. In addition, a parametric study in terms of geometric variation of the micro-tab was also investigated and reported. The three-dimensional results obtained thus far show reduction in noise levels with use of micro-tab.}
}
@article{SAUNDERS20121024,
title = {Children without parents in the TANF caseload: Thinking beyond the child-only label},
journal = {Children and Youth Services Review},
volume = {34},
number = {5},
pages = {1024-1034},
year = {2012},
issn = {0190-7409},
doi = {https://doi.org/10.1016/j.childyouth.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0190740912000771},
author = {Correne Saunders and Andrea Hetling and Pamela C. Ovwigho and Catherine E. Born},
keywords = {Kinship care, Child-only cases, Temporary Assistance for Needy Families, Relative caregiver, Child welfare policy},
abstract = {Child welfare policy has historically emphasized the positive impact relative caregivers can have on foster children. This emphasis coupled with recent changes in the composition of the Temporary Assistance for Needy Families (TANF) caseload has led to interest in child-only, relative caregiver cases. Child-only research, however, ignores cases in which the relative caregiver is also receiving benefits. Using the universe of welfare cases in Maryland in October 2005, this article compares and contrasts the demographic and case characteristics of parental and relative caregiver cases, also analyzing differences between cases with and without an adult receiving benefits. Findings indicate that relative caregivers have service needs that differ from those of parents and that recipient relative caregivers are more disadvantaged than child-only cases.}
}
@article{ESTRELLA20221,
title = {Early statistics in kindergarten: analysis of an educator's pedagogical content knowledge in lessons promoting informal inferential reasoning},
journal = {International Journal for Lesson and Learning Studies},
volume = {11},
number = {1},
pages = {1-13},
year = {2022},
issn = {2046-8253},
doi = {https://doi.org/10.1108/IJLLS-07-2021-0061},
url = {https://www.sciencedirect.com/science/article/pii/S2046825322000348},
author = {Soledad Estrella and Maritza Mendez-Reina and Raimundo Olfos and Jocelyn Aguilera},
keywords = {Pedagogical content knowledge, Early statistics, Informal inferential reasoning, Lesson study},
abstract = {Purpose
This study aims to describe the pedagogical content knowledge (PCK) of a kindergarten educator who implements a lesson plan about informal inferential reasoning designed in a lesson study group.
Design/methodology/approach
To this end, we analyzed teaching interventions in two kindergarten lessons focused on the playful task of tossing two coins, associated with inferential statistical reasoning. The study highlights the importance of arguing and promoting this reasoning to develop statistical thinking. It is crucial to recognize how early students can be subject to learning experiences that promote a language of uncertainty, assess the evidence provided by the data, and make generalizations.
Findings
The results reveal that while the educator demonstrated knowledge and skills relevant to the curriculum and conceptual teaching strategies, the understanding of the content by the students and the integration of the PCK components still present a challenge.
Practical implications
The lesson study collaborative teaching practices that promote PCK have proven effective for informing the design and implementation of instructional practices supporting the development of early statistical thinking in young children.
Originality/value
The study enriches the knowledge regarding the potential of the lesson study (LS) in the professional learning of kindergarten educators. It also contributes to a comprehensive approach based on authentic playful experiences in grade K that supports the development of early statistical thinking in young children.}
}
@incollection{BOSSE2017311,
title = {Chapter 13 - On Computational Models of Emotion Regulation and Their Applications Within HCI},
editor = {Myounghoon Jeon},
booktitle = {Emotions and Affect in Human Factors and Human-Computer Interaction},
publisher = {Academic Press},
address = {San Diego},
pages = {311-337},
year = {2017},
isbn = {978-0-12-801851-4},
doi = {https://doi.org/10.1016/B978-0-12-801851-4.00013-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128018514000136},
author = {Tibor Bosse},
keywords = {emotion regulation, computational modeling, dynamics, virtual characters, simulation-based training},
abstract = {Emotion regulation, or the ability to regulate one’s own and other people’s emotions, is an important skill for human beings, enabling them to function adequately in their social environment. The development of computational models of emotion regulation opens up a range of interesting applications in human–computer interaction, varying from virtual characters to simulation-based training systems. To provide more insight in the underlying mechanisms as well as the application areas of computational emotion regulation models, the current chapter provides an overview of the state-of-the-art in this area. After briefly reviewing the psychological literature on emotion generation and regulation, I will explain how these phenomena can be formalized into computational models. Next, a computational model of emotion regulation is presented in detail, and a number of resulting simulation runs are shown. The chapter concludes with a discussion of potential applications of such models.}
}
@article{KOUZALIS2024105312,
title = {Advanced technologies and mathematical metacognition: The present and future orientation},
journal = {BioSystems},
volume = {245},
pages = {105312},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105312},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724001977},
author = {Alexios Kouzalis and Antonios Antoniou and Nicos Rossides and Rita Panaoura and Priyanka Yadav},
keywords = {Mathematical cognition, Metacognition, Cognition, Artificial intelligence, Machine learning, Robotics, Boolean logic, Bayesian inference, Fuzzy logic, Chemical artificial intelligence},
abstract = {The intersection of mathematical cognition, metacognition, and advanced technologies presents a frontier with profound implications for human learning and artificial intelligence. This paper traces the historical roots of these concepts from the Pythagoreans and Aristotle to modern cognitive science and explores their relevance to contemporary technological applications. We examine how the Pythagoreans' view of mathematics as fundamental to understanding the universe and Aristotle's contributions to logic and categorization have shaped our current understanding of mathematical cognition and metacognition. The paper investigates the role of Boolean logic in computational processes and its relationship to human logical reasoning, as well as the significance of Bayesian inference and fuzzy logic in modelling uncertainty in human cognition and decision-making. We also explore the emerging field of Chemical Artificial Intelligence and its potential applications. We argue for unifying mathematical metacognition with advanced technologies, including artificial intelligence and robotics, while identifying the multifaceted benefits and challenges of such unification. The present paper examines essential research directions for integrating cognitive sciences and advanced technologies, discussing applications in education, healthcare, and business management. We provide suggestions for developing cognitive robots using specific cognitive tasks and explore the ethical implications of these advancements. Our analysis underscores the need for interdisciplinary collaboration to realize the full potential of this integration while mitigating potential risks.}
}
@article{NEGI2022100096,
title = {A deep dive into metacognition: Insightful tool for moral reasoning and emotional maturity},
journal = {Neuroscience Informatics},
volume = {2},
number = {4},
pages = {100096},
year = {2022},
issn = {2772-5286},
doi = {https://doi.org/10.1016/j.neuri.2022.100096},
url = {https://www.sciencedirect.com/science/article/pii/S2772528622000589},
author = {Sunder Kala Negi and Yaisna Rajkumari and Minakshi Rana},
keywords = {Metacognitive thinking, Moral reasoning, Emotional maturity, Artificial intelligence},
abstract = {The impact of metacognition on pupils' moral ideals and emotional development was investigated as well as it highlights on a collaborative research between metacognition and artificial intelligence that can bridge the gap (emotional, ethical, moral reasoning, common sense) existing in AI. A total of 200 pupils were selected in the study's sample. Participants (100 high metacognitive students and 100 low metacognitive students) were chosen at random and ranged in age from 17 to 21 years old. The influence of metacognition on students' moral ideals and emotional development was studied using a t-test. The outcome reveals that the mean score of moral reasoning on high metacognitive students as 66.77 and for low metacognitive students as 63.08, t value = 3.21, at the 0.01 level, statistically highly significant. The mean emotional maturity score for high metacognitive students was 29.99, while for low metacognitive students was 33.01, t value as 2.81, shows statistically significant at the 0.05 level. This demonstrates that the higher the score, the less emotionally stable the pupils are. The current findings show that metacognitive thinking has a major impact on moral reasoning and emotional maturity, and that as metacognition levels rise, so do moral reasoning and emotional maturity. Metacognition can strengthen the humanistic qualities which are majorly lacking in AI. In addition, there are new avenues being opened in the study of artificial intelligence via metacognitive study which is significant and futuristic.}
}
@article{CHANG2024103484,
title = {Evaluating AI's impact on self-regulated language learning: A systematic review},
journal = {System},
volume = {126},
pages = {103484},
year = {2024},
issn = {0346-251X},
doi = {https://doi.org/10.1016/j.system.2024.103484},
url = {https://www.sciencedirect.com/science/article/pii/S0346251X24002665},
author = {Wenli-Li Chang and Jerry Chih-Yuan Sun},
keywords = {Self-regulated language learning, AI mediation, Learning partner, Systematic review},
abstract = {AI technology is reshaping language classrooms, prompting students to adopt flexible roles exhibiting linguistic competence and self-regulated learning (SRL) skills. Considerable studies explore the necessary integrated learning perspectives, emphasizing AI's adaptive role as a mind tool. In AI-mediated language learning, the technology's metacognitive importance enables students to learn with AI as a partner, encouraging independent critical thinking. Within Zimmerman's SRL model, AI as a mind tool is integrated for improving language students' strategic employment in a cyclical process. A systematic review, following PRISMA protocols, examines the intersection of AI and self-regulated language learning (SRLL) over 2000–2022. Findings highlight AI's evolving role, predominantly through algorithms and systems, aiming for micro and macro integration. Interactive AI has not fully engaged in two-way directions, despite a familiar process approach in reviewed studies. In the favored ESL/EFL research context, task-specific AI is utilized to encourage cyclical improvement with learner autonomy enhancement mainly among higher education students at intermediate level or above. Pedagogical values are possible when major SRL phases are fully practiced, even without highly autonomous AI. Future research is directed toward adaptive personalized technology by exploring the dynamic interplay between AI technologies and SRLL as educational practices under Education 4.0 principles.}
}
@article{AHMED20191,
title = {Computational intelligence based prediction of drilling rate of penetration: A comparative study},
journal = {Journal of Petroleum Science and Engineering},
volume = {172},
pages = {1-12},
year = {2019},
issn = {0920-4105},
doi = {https://doi.org/10.1016/j.petrol.2018.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S0920410518307824},
author = {Omogbolahan S. Ahmed and Ahmed A. Adeniran and Ariffin Samsuri},
keywords = {ROP prediction, Neural network, Least square support vector regression, Specific energy, Drilling efficiency, Extreme learning machine},
abstract = {Application of artificial intelligence in the accurate prediction of the rate of penetration (ROP), an important measure of drilling performance, has lately gained significant interest in oil and gas well drilling operations. Consequently, several computational intelligence techniques (CITs) for the prediction of ROP have been explored in the literature. This study explores the predictive capabilities of four commonly used CITs in the prediction of ROP and experimentally compare their predictive performance. The CIT algorithm utilizes predictors which are easily accessible continuous drilling data that have physical but complex relationship with ROP based on hydro-mechanical specific energy ROP model. The four CITs compared are the artificial neural network (ANN), extreme learning machine, support vector Regression and least-square support vector regression (LS-SVR). Two experiments were carried out; the first experiment investigates the comparative performance of the CITs while the second investigates the effect of reduced number of predictors on the performance of the models. The results show that all the CITs perform within acceptable accuracy with testing root mean square error range (RMSE) of 18.27–28.84 and testing correlation coefficient (CC) range of 0.71–0.94. LS-SVR has the best predictive performance in terms of accuracy with RMSE of 18.27 and CC of 0.94 while ANN has the best testing execution time at 0.03 s. Also utilizing the specific energy concept in chosen drilling parameters to be included among the predictors shows improved performance with five drilling parameters showing an improvement of 3%–9% in RMSE for LS-SVR in the two well studied. The utilization of the specific energy concept in the selection of the predictors in this study has demonstrated that the easily accessible drilling parameters have immense value to provide acceptable performance in the development of ROP model with CITs.}
}
@article{DAVELAAR2018175,
title = {Mechanisms of Neurofeedback: A Computation-theoretic Approach},
journal = {Neuroscience},
volume = {378},
pages = {175-188},
year = {2018},
note = {Neurofeedback and Functional Enhancement: Mechanisms, Methodology, Behavioral and Clinical Applications},
issn = {0306-4522},
doi = {https://doi.org/10.1016/j.neuroscience.2017.05.052},
url = {https://www.sciencedirect.com/science/article/pii/S030645221730386X},
author = {Eddy J. Davelaar},
keywords = {neurofeedback, electroencephalography, computational neuroscience, computer model},
abstract = {Neurofeedback training is a form of brain training in which information about a neural measure is fed back to the trainee who is instructed to increase or decrease the value of that particular measure. This paper focuses on electroencephalography (EEG) neurofeedback in which the neural measures of interest are the brain oscillations. To date, the neural mechanisms that underlie successful neurofeedback training are still unexplained. Such an understanding would benefit researchers, funding agencies, clinicians, regulatory bodies, and insurance firms. Based on recent empirical work, an emerging theory couched firmly within computational neuroscience is proposed that advocates a critical role of the striatum in modulating EEG frequencies. The theory is implemented as a computer simulation of peak alpha upregulation, but in principle any frequency band at one or more electrode sites could be addressed. The simulation successfully learns to increase its peak alpha frequency and demonstrates the influence of threshold setting – the threshold that determines whether positive or negative feedback is provided. Analyses of the model suggest that neurofeedback can be likened to a search process that uses importance sampling to estimate the posterior probability distribution over striatal representational space, with each representation being associated with a distribution of values of the target EEG band. The model provides an important proof of concept to address pertinent methodological questions about how to understand and improve EEG neurofeedback success.}
}
@article{CUADRA20161223,
title = {Computational intelligence in wave energy: Comprehensive review and case study},
journal = {Renewable and Sustainable Energy Reviews},
volume = {58},
pages = {1223-1246},
year = {2016},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2015.12.253},
url = {https://www.sciencedirect.com/science/article/pii/S1364032115016366},
author = {L. Cuadra and S. Salcedo-Sanz and J.C. Nieto-Borge and E. Alexandre and G. Rodríguez},
keywords = {Computational intelligence techniques, Wave energy, Renewable energy, Wave energy converters, Environmental impact},
abstract = {Wind-generated wave energy is a renewable energy source that exhibits a huge potential for sustainable growth. The design and deployment of wave energy converters at a given location require the prediction of the amount of available wave energy flux. This and other wave parameters can be estimated by means of Computational Intelligence techniques (Neural, Fuzzy, and Evolutionary Computation). This paper reviews those used in wave energy applications, both in the resource estimation and in the design and control of wave energy converters. In particular, most of the applications of Neural Computation techniques, considered here in a broad sense, focus on the prediction of a variety of wave energy parameters by means of Multilayer Perceptrons and, at a lesser extent, by Support Vector Machines, and Extreme Learning Machines. Fuzzy Computation is also applied to estimate wave parameters and control floating wave energy converter. Evolutionary Computation algorithms are used to estimate parameters and design wave energy collectors. We complete this paper with a case study that illustrates, for the first time to the best of our knowledge, the potential of hybridizing a Coral Reefs Optimization algorithm with an Extreme Learning Machine to tackle the problem of significant wave height reconstruction.}
}
@article{SAYHAN201714166,
title = {Computational investigation and comparison of hydrogen storage properties of B24N24 and Al24N24 nanocages},
journal = {International Journal of Hydrogen Energy},
volume = {42},
number = {20},
pages = {14166-14180},
year = {2017},
issn = {0360-3199},
doi = {https://doi.org/10.1016/j.ijhydene.2017.04.069},
url = {https://www.sciencedirect.com/science/article/pii/S0360319917314490},
author = {Sinan Sayhan and Armağan Kinal},
keywords = {Boron nitride nanocages, Aluminum nitride nanocages, Hyrdogen storage materials, BN, AlN, The DFT methods},
abstract = {In this study, hydrogen storage properties of the B24N24 and Al24N24 nanocages have been computationally investigated by the DFT method whose suitability was determined with a thorough methodological analysis. This analysis includes comparison of the performances of a number of DFT functionals against the CCSD(T) method for the determination of the best DFT method that is able to accurately model H2-BN and H2-AlN systems. The ɷB97X-D, B3LYP-D2, PBEPBE-D2, BHandH methods produced results close to that of the reference CCSD(T) method. Of all methods studied, ɷB97X-D, showing the best performance, is found to be the most appropriate DFT method for H2-B24N24 and Al24N24 systems including dispersive interactions between hydrogen and the host molecule. The ɷB97X-D calculations result in that H2 molecule make the tightest adsorptive bond with Al atom in Al24N24 having an adsorption energy of −0.116 eV, by forming much more stable complex than the H2-B24N24 one. This indicates that Al24N24 has better exohedral hydrogen storage properties. The calculations also revealed that H2 molecules cannot pass through hexagonal rings of B24N24 instead they chemisorb on the cage atoms by breaking BN bond while they can pass through hexagonal rings of Al24N24 without making any damage in the Al–N bond, leading the fact that the Al–N bond is stronger than the B–N bond. Moreover, endohedral addition of H2 molecules up to three can form thermodynamically stable nH2@Al24N24 complexes while endohedral hydrogen addition to B24N24 destabilizes the complexes. Thus, the Al24N24 nanocage is not only structurally more stable than B24N24 nanocage, but also it can accommodate more hydrogen molecules, so it is better candidate for both endohedrally and exohedrally hydrogen storage compared to B24N24.}
}
@article{NESI2024,
title = {Enactivism: A contemporary perspective of a reconceptualization of osteopathy},
journal = {Advances in Integrative Medicine},
year = {2024},
issn = {2212-9588},
doi = {https://doi.org/10.1016/j.aimed.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2212958824001186},
author = {Jacson Nesi and Michele Benites and Filipe Boeira Schedler},
keywords = {Enactivism, Osteopathy, Medical rationalities, Reconceptualization},
abstract = {Enactivism is a philosophical and scientific approach that emphasizes the role of the body and its interactions with the environment in shaping cognitive processes and subjective experiences. Meanwhile, osteopathy is a person-centered health care discipline, highlighting the structure-function interrelationship of the body and its selfregulation mechanisms. Both approaches value the body and the environment in health. Several authors have been discussing the urgent need for a reconceptualization of osteopathy and also suggesting integrate biological, psychological and social aspects. Thinking osteopathy as a Therapeutic Rationality, implies recognize its fundamental dimensions: Human Morphology, Vital Dynamics, Medical Doctrine, Diagnostic System and Therapeutic System, all integrated by a philosophical Cosmology, as the original term Medical rationality states, but also embrace a broader perspective allowing an individual and unique process of each person, reflecting the transformation of contemporary medicine to a person approach. Enactivism principles can serve as a basis for a reconceptualization of osteopathy, integrating environmental, psychological, social, and spiritual factors. Osteopathic concepts can probably be updated through the convergence between enactivism and osteopathy, promoting more meaningful and evidence-based clinical practice. Advancing in this direction requires a collaborative dialogue between researchers, health professionals and interested people, seeking an integrated understanding of the relationship between body, mind, environment and health.}
}
@article{GIOT2013788,
title = {Fast computation of the performance evaluation of biometric systems: Application to multibiometrics},
journal = {Future Generation Computer Systems},
volume = {29},
number = {3},
pages = {788-799},
year = {2013},
note = {Special Section: Recent Developments in High Performance Computing and Security},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2012.02.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X12000362},
author = {Romain Giot and Mohamad El-Abed and Christophe Rosenberger},
keywords = {Biometrics, Authentication, Error estimation, Access control},
abstract = {The performance evaluation of biometric systems is a crucial step when designing and evaluating such systems. The evaluation process uses the Equal Error Rate (EER) metric proposed by the International Organization for Standardization (ISO/IEC). The EER metric is a powerful metric which allows easily comparing and evaluating biometric systems. However, the computation time of the EER is, most of the time, very intensive. In this paper, we propose a fast method which computes an approximated value of the EER. We illustrate the benefit of the proposed method on two applications: the computing of non parametric confidence intervals and the use of genetic algorithms to compute the parameters of fusion functions. Experimental results show the superiority of the proposed EER approximation method in term of computing time, and the interest of its use to reduce the learning of parameters with genetic algorithms. The proposed method opens new perspectives for the development of secure multibiometrics systems by speeding up their computation time.}
}
@article{LORD2023490,
title = {The sustainability of the gig economy food delivery system (Deliveroo, UberEATS and Just-Eat): Histories and futures of rebound, lock-in and path dependency},
journal = {International Journal of Sustainable Transportation},
volume = {17},
number = {5},
pages = {490-502},
year = {2023},
issn = {1556-8318},
doi = {https://doi.org/10.1080/15568318.2022.2066583},
url = {https://www.sciencedirect.com/science/article/pii/S1556831822007018},
author = {Carolynne Lord and Oliver Bates and Adrian Friday and Fraser McLeod and Tom Cherrett and Antonio Martinez-Sykora and Andy Oakey},
keywords = {Gig economy couriers, path dependence, rebounds, sustainability, systems thinking},
abstract = {ABSTRACT
Online food delivery has transformed the last-mile of food and grocery delivery, with unnoticed yet often significant impacts upon the transport and logistics network. This new model of food delivery is not just increasing congestion in urban centers though, it is also changing the contours and qualities of those doing delivery—namely through gig economy work. This new system of food consumption and provision is rapidly gaining traction, but assessments around its current and future sustainability tend to hold separate the notions of social, environmental and economic sustainability—with few to date working to understand how these can interact, influence and be in conflict with one another. This paper seeks to work with this broader understanding of sustainability, whilst also foregrounding the perspectives of gig economy couriers who are often marginalized in such assessments of the online food delivery system. We make use of systems thinking and Campbell’s conflict model of sustainability to do this. In assessing the online food delivery in this way, we seek to not only provide a counternarrative to some of these previous assessments, but to also challenge those proposing the use of gig economy couriers as an environmentally sustainable logistics intervention in other areas of last-mile logistics to consider how this might impact the broader sustainability of their system, now and in the future.}
}