@article{HONG2024422,
title = {AF-FTTSnet: An end-to-end two-stream convolutional neural network for online quality monitoring of robotic welding},
journal = {Journal of Manufacturing Systems},
volume = {74},
pages = {422-434},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.04.006},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524000724},
author = {Yuxiang Hong and Xingxing He and Jing Xu and Ruiling Yuan and Kai Lin and Baohua Chang and Dong Du},
keywords = {Welding quality monitoring, Visual sensing, Molten pool, Defect prediction, Two-stream network},
abstract = {Online welding quality monitoring (WQM) is crucial for intelligent welding, and deep learning approaches considering spatiotemporal features for WQM tasks show great potential. However, one of the important challenges for existing approaches is to balance the spatiotemporal representation learning capability and computational efficiency, which makes it challenging to adapt welding processes with complex and drastic molten pool dynamic behavior. This paper proposes a novel approach for WQM using molten pool visual sensing and deep learning considering spatiotemporal features, the proposed deep learning network called attention fusion based frame-temporality two-stream network (AF-FTTSnet). Firstly, a passive vision sensor is used to acquire continuous dynamic molten pool images. Meanwhile, temporal difference images are computed to provide novel features and temporal representations. Then, a two-stream feature extraction module is designed to concurrently extract rich spatiotemporal features from molten pool images and temporal difference images. Finally, an attention fusion module with the ability to automatically identify and weight the most relevant features is designed to achieve optimal fusion of the two-stream features. The shop welding experimental results indicate that the proposed AF-FTTSnet model can effectively and robustly recognize five typical welding states during helium arc welding, with an accuracy of 99.26%. This model has been demonstrated to exhibit significant performance improvements compared to mainstream temporal sequence models. Available: https://github.com/Just199806/TSCNN/tree/master.}
}
@article{LAI2023101343,
title = {Optimization of urban and rural ecological spatial planning based on deep learning under the concept of sustainable development},
journal = {Results in Engineering},
volume = {19},
pages = {101343},
year = {2023},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2023.101343},
url = {https://www.sciencedirect.com/science/article/pii/S259012302300470X},
author = {Yilin Lai},
keywords = {Sustainable development, Spatial planning, Remote sensing images, CNN, GPU},
abstract = {At present, the speed of urbanization in China is constantly accelerating. At the same time, due to the severe situation of tight resource constraints, severe environmental pollution, and ecosystem degradation, vigorously promoting the construction of ecological civilization has become a key planning direction. However, traditional urban and rural ecological spatial planning is influenced by factors such as region, terrain, and spatial scale, which cannot adapt to the current spatial planning requirements. To achieve sustainable urban and rural ecological spatial planning, we propose a method that uses the optimized remote sensing images and convolutional neural networks to achieve spatial planning. In the analysis of the application effect of the usage method, the experimental results show that increasing the amount of data such as image size can improve the execution performance of the computer when the computer is not fully utilizing its resources and its computational volume fails to saturate the computational capacity. The parallel configuration designed in this experiment can accelerate the performance of the computer better, and the acceleration effect becomes more obvious as the difficulty of the algorithm increases. The Faster RCNN algorithm proposed in this experiment has the highest retrieval accuracy in the Flickr30K dataset and MS-COCO dataset compared with other algorithms. In Flickr30k data set, compared with other models in the table, the model used in this paper has the highest retrieval accuracy. The retrieval accuracy of R@1, R@5, R@10 increased by 23.1%, 8.1% and 5.3%, respectively. In MS-COCO data set, the retrieval accuracy increased by 19.2%, 13.1% and 8.3% respectively. The above results confirm that the combination of remote sensing images and convolutional neural network technology can perform simple ecological planning of a city's urban and rural areas, which proves that the method proposed in this experiment has practicality.}
}
@article{MULLER1987271,
title = {Computational problems in supernova simulations},
journal = {Computer Physics Communications},
volume = {44},
number = {3},
pages = {271-277},
year = {1987},
issn = {0010-4655},
doi = {https://doi.org/10.1016/0010-4655(87)90082-8},
url = {https://www.sciencedirect.com/science/article/pii/0010465587900828},
author = {Ewald Müller},
abstract = {Theoretical models of type I and type II supernova explosions are reviewed from a computational physics point of view. After discussing briefly the underlying physics the numerical problems and challenges encountered in the simulation of type I and type II supernova are addressed.}
}
@article{LAWRENCE2023100786,
title = {Translational argument technology: Engineering a step change in the argument web},
journal = {Journal of Web Semantics},
volume = {77},
pages = {100786},
year = {2023},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2023.100786},
url = {https://www.sciencedirect.com/science/article/pii/S157082682300015X},
author = {John Lawrence and Jacky Visser and Chris Reed},
keywords = {Argumentation, Argument analytics, Argument mining, Argument technology, Argument web, Debate technology},
abstract = {Following the establishment in 2006 of a representational standard for the computational handling of structures of argumentation, the Argument Interchange Format, it became possible to develop a vision for the coherent integration of multifarious services, components and tools that create, consume, navigate, analyse, evaluate and manipulate arguments and debates. This vision was the Argument Web with theoretical foundations laid by Rahwan et al. (2007), and practical engineering work described by Bex et al. (2013). Over the intervening period, the key challenge has been to demonstrate the practical and societal value of the Argument Web by taking its tools and applications to larger audiences. This paper lays out three approaches by which the Argument Web has been scaled up in this way, each in partnership with the BBC, and each with different kinds of evaluation and impact. Transitioning these technologies to large user groups paves the way for broader-scale uptake of the Argument Web and heralds the translation from lab to real-world application for a substantial research community working in argument technology.}
}
@article{1991202,
title = {Use of computational methods in drug design},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {11},
number = {2},
pages = {202-203},
year = {1991},
issn = {0169-7439},
doi = {https://doi.org/10.1016/0169-7439(91)80072-X},
url = {https://www.sciencedirect.com/science/article/pii/016974399180072X}
}
@article{PANESCU2013375,
title = {At the Crossroads between Western and Eastern Views on Psychotherapy: An Integrative Approach},
journal = {Procedia - Social and Behavioral Sciences},
volume = {78},
pages = {375-379},
year = {2013},
note = {PSIWORLD 2012},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2013.04.314},
url = {https://www.sciencedirect.com/science/article/pii/S1877042813008835},
author = {Oana Pănescu and Alexandra Timofte and Melania Macovei and Carmen Popescu},
keywords = {Psychoterapy, Body, Mind, Meditation, Transactional analysis},
abstract = {This paper aims at indicating the convergence points between what is habitually understood as a pair of opposing terms: mind (as in thinking) and body (as in sensation). Structural models in psychotherapy conceptualize human mind in terms of levels of information processing (both internal and external information). We suggest that a mental split between mind and body leads to a feeling of estrangement from self, as well as an estrangement from external world. Drawing on relational approaches on psychotherapy, we suggest that focusing on perceiving own sensations does not necessarily imply a state of personal isolation from outside world; rather, this simultaneously means the perceiving and acceptance of “otherness”.}
}
@article{CHEN2024e26409,
title = {Physiological records-based situation awareness evaluation under aviation context: A comparative analysis},
journal = {Heliyon},
volume = {10},
number = {5},
pages = {e26409},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e26409},
url = {https://www.sciencedirect.com/science/article/pii/S240584402402440X},
author = {Jun Chen and Anqi Chen and Bingkun Jiang and Xinyu Zhang},
keywords = {Situation awareness, Electroencephalogram, Brain electrical activity mapping, Convolutional neural network, Multi-class classification, Aviation decision-making},
abstract = {Situational Awareness (SA) assessment is of paramount importance in various domains, with particular significance in the military for safe aviation decision-making. It involves encompassing perception, comprehension, and projection levels in human beings. Accurate evaluation of SA statuses across these three levels is crucial for mitigating human false-positive and false-negative rates in monitoring complex scenarios in the aviation context. This study proposes a comprehensive comparative analysis by involving two types of physiological records: electroencephalogram (EEG) signals and brain electrical activity mapping (BEAM) images. These two modalities are leveraged to automate precise SA evaluation using both conventional machine learning and advanced deep learning techniques. Benchmarking experiments reveal that the BEAM-based deep learning models attain state-of-the-art performance scores of 0.955 for both SA perception and comprehension levels, respectively. Conversely, the EEG signals-based manual feature extraction, selection, and classification approach achieved a superior accuracy of 0.929 for the projection level of SA. These findings collectively highlight the potential of deploying diverse physiological records as valuable computational tools for enhancing SA evaluation throughout aviation decision-making safety.}
}
@article{SAYALI2023614,
title = {The costs and benefits of psychedelics on cognition and mood},
journal = {Neuron},
volume = {111},
number = {5},
pages = {614-630},
year = {2023},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2022.12.031},
url = {https://www.sciencedirect.com/science/article/pii/S0896627322011527},
author = {Ceyda Sayalı and Frederick S. Barrett},
keywords = {psychedelics, cognitive control, meta-control, creativity, cognitive flexibility, cognitive stability, dopamine, serotonin, dose-dependency, baseline dependency},
abstract = {Summary
Anecdotal evidence has indicated that psychedelic substances may acutely enhance creative task performance, although empirical support for this claim is mixed at best. Clinical research has shown that psychedelics might have enduring effects on mood and well-being. However, there is no neurocognitive framework that ties acute changes in cognition to long-term effects in mood. In this review, we operationalize creativity within an emerging cognitive control framework and assess the current empirical evidence of the effects of psychedelics on creativity. Next, we leverage insights about the mechanisms and computations by which other psychoactive drugs act to enhance versus impair cognition, in particular to those that act on catecholamines, the neurophysiological consequences of which are relatively well understood. Finally, we use the same framework to link the suggested psychedelic-induced improvements in creativity with enduring psychedelic-induced improvements in mood.}
}
@article{VERDECCHIA2022100767,
title = {The future of sustainable digital infrastructures: A landscape of solutions, adoption factors, impediments, open problems, and scenarios},
journal = {Sustainable Computing: Informatics and Systems},
volume = {35},
pages = {100767},
year = {2022},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2022.100767},
url = {https://www.sciencedirect.com/science/article/pii/S2210537922000889},
author = {Roberto Verdecchia and Patricia Lago and Carol {de Vries}},
keywords = {Sustainability, Green IT, Energy efficiency, Digital infrastructures, Data centers, Cloud, Landscape, Qualitative research},
abstract = {Background:
Digital infrastructures, i.e., ICT systems, or system-of-systems, providing digital capabilities, such as storage and computational services, are experiencing an ever-growing demand for data consumption, which is only expected to increase in the future. This trend leads to a question we need to answer: How can we evolve digital infrastructures to keep up with the increasing data demand in a sustainable way?
Objective:
The goal of this study is to understand what is the future of sustainable digital infrastructures, in terms of: which solutions are, or will be, available to sustainably evolve digital infrastructures, and which are the related adoption factors, impediments, and open problems.
Method:
We carried out a 3-phase mixed-method qualitative empirical study, comprising semi-structured interviews, followed by focus groups, and a plenary session with parallel working groups. In total, we conducted 13 sessions involving 48 digital infrastructure practitioners and researchers.
Results:
From our investigation emerges a landscape for sustainable digital infrastructures, composed of 30 solutions, 5 adoption factors, 4 impediments, and 13 open problems. We further synthesized our results in 4 incremental scenarios, which outline the future evolution of sustainable digital infrastructures.
Conclusions:
From an initial shift from on-premise to the cloud, as time progresses, digital infrastructures are expected to become increasingly distributed, till it will be possible to dynamically allocate resources by following time, space, and energy. Numerous solutions will support this change, but digital infrastructures are envisaged to be able to evolve sustainably only by (i) gaining a wider awareness of digital sustainability, (ii) holding every party accountable for their sustainability throughout value chains, and (iii) establishing cross-domain collaborations.}
}
@article{HUNT201645,
title = {Levels of participatory conception of fractional quantity along a purposefully sequenced series of equal sharing tasks: Stu's trajectory},
journal = {The Journal of Mathematical Behavior},
volume = {41},
pages = {45-67},
year = {2016},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2015.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S0732312315300122},
author = {Jessica H. Hunt and Arla Westenskow and Juanita Silva and Jasmine Welch-Ptak},
keywords = {Conceptions, Cognition, Learning disabilities, Rational number, Pedagogy, Constructivism},
abstract = {Current intervention research in special education focuses on children's responsiveness to teacher modeled strategies and not conceptual development within children's thinking. As a result, there is a need for research that provides a characterization of key understandings (KUs) of fractional quantity evidenced by children with learning disabilities (LD) and how growth of conceptual knowledge may occur within these children's mathematical activity. This case study extends current literature by presenting KUs of fractional quantity, evidenced through problem solving strategies, observable operations, and naming/quantification of one fifth grader with LD before, during, and after seven instructional sessions situated in equal sharing. The researchers utilized a characterization of evolving fraction conceptions developed from research of children without disabilities that was ultimately productive in facilitating conceptual advances of the child with LD. We hypothesize that the trajectory of the child's conceptions is a case of something more general. Pending future research, the trajectory may be a useful tool to practitioners wishing to plan thoughtful, conceptually-based fraction instruction that is responsive to all children's evolving conceptions of fractions as quantities built through their own mathematical activity.}
}
@article{YUAN2025129490,
title = {Global attention network with rain prior for real time single image deraining},
journal = {Neurocomputing},
volume = {625},
pages = {129490},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129490},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225001626},
author = {Yuan Yuan and Xuanbin Guo and Dandan Ma},
keywords = {Rain removal, Deep learning, Attention mechanism, Activation function},
abstract = {Poor visibility caused by rainy image can have a negative impact on the performance of computer vision applications. While several image deraining algorithms have been popularly adopted, most of them suffer from two main limitations: (1) they cannot well handle real and complex rain scenes by only focusing on one type of rain in images (e.g. raindrops or rain streaks) whereas the reality often coexists with both types, (2) they face significant difficulties in practical application because of ignoring the speed of inference. To address the above problems, we propose a global attention network (GANet) that can quickly and effectively separate rain streaks and raindrops. Inspired by the fact that rain in images often appears white, we leverage this prior to obtain an initial rain-free background image to guide neural network-based image deraining. Moreover, a new global attention block (GAB) is designed to simultaneously extract the rain features from spatial and channel dimensions. By cascading multiple GABs, the proposed method can effectively obtain the features of rain streaks and raindrops and progressively separates the rain-free image. Furthermore, owing to the nonlinear properties of GAB, the activation functions are omitted, which can speed up the inference time. And the depth-wise and point-wise convolutions are employed to promote computation efficiency as well. Extensive experiments on raindrop and rain streak datasets demonstrate that our method outperforms state-of-the-art methods, achieving up to 37.53 dB PSNR on Rain100L with an inference speed of 39 FPS, which is 2–30 times faster than competitors.}
}
@article{HUSSAIN2025109490,
title = {A neural network integrated mathematical model to analyze the impact of nutritional status on cognitive development of child},
journal = {Computers in Biology and Medicine},
volume = {185},
pages = {109490},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.109490},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524015750},
author = {Zakir Hussain and Malaya Dutta Borah},
keywords = {Cognitive development, Cognition, Nutritional status, Neural network, Mathematical model},
abstract = {Cognitive development is a crucial developmental aspect of children. It is a concise field of study in psychology and neuroscience that focuses on various developmental aspects of the brain. Among all other factors, nutritional status is believed to play a very important role in cognitive development. The purpose of this work is to analyze the impacts of different nutritional status levels on the child’s cognitive development. This work designs a model that uses a neural network and differential equations. The neural network is applied on a dataset called “Child Birth Weight Dataset” available at IEEE Dataport ( http://dx.doi.org/10.21227/dvd4-3232) for finding the nutritional status of a child. The different levels of nutritional status, such as low-nutritional status, normal-nutritional status, and over-nutritional status are integrated with the formulated differential equations. The model is computationally simulated considering four different sets of parameter values that represent four different perspectives such as ‘only positive’, ‘only negative’, ‘mix and unequal weight’, and ‘mix and equal weight’ of the influencing factors. The experimental results show that normal-nutritional status is the best nutritional status for cognitive development. However, the best cognitive development happens when all other influencing factors like environmental effects, socioeconomic status, heredity, learning opportunities, and use of experiences are given equal importance. The results also depict that the low- and over-nutritional status cannot restrict cognitive development for a long time. After a certain period, the development gets triggered and it happens. It may be slow and not up to the mark of the development under normal-nutritional status, but it happens. Simply it can be said that nutritional status alone does not have control over the cognitive development of a child. Along with nutritional status, other influencing factors are important too.}
}
@article{WU2020107246,
title = {miRNA-324/-133a essential for recruiting new synapse innervations and associative memory cells in coactivated sensory cortices},
journal = {Neurobiology of Learning and Memory},
volume = {172},
pages = {107246},
year = {2020},
issn = {1074-7427},
doi = {https://doi.org/10.1016/j.nlm.2020.107246},
url = {https://www.sciencedirect.com/science/article/pii/S1074742720300903},
author = {Ruixiang Wu and Shan Cui and Jin-Hui Wang},
keywords = {Associative learning, Memory cell, Neural circuit, Barrel cortex, Piriform cortex},
abstract = {After the integrative storage of associated signals, a signal induces the recollection of its associated signal, or the other way around. This associative memory is essential to associative thinking, logical reasoning, imagination and computation. In terms of cellular mechanisms underlying associative memory, new mutual synapse innervations are formed among those coactivated neurons, so that they are recruited to be associative memory cells or associative memory neurons. These associative memory cells receive new synapse innervations alongside innate synapse inputs and encode signals carried by these inputs. We proposed to examine microRNAs as initiative factors for recruiting new synapse innervations and associative memory cells. In a mouse model of associative memory characterized as the reciprocal retrieval of associated whisker and odor signals, barrel and piriform cortical neurons gain their ability to encode whisker and odorant signals based on the newly formed synapse innervations between these coactivated cortices besides innate synapse inputs. miRNA-324 and miRNA-133a are required for recruiting these new synapse innervations and associative memory cells as well as sufficient for facilitating their recruitments, but not for innate synapse inputs. Therefore, the coactivation of sensory cortices through microRNA as initiative factor to recruit new mutual synapse innervations and associative memory cells for associative memory.}
}
@article{KNIGHT20158,
title = {Making grammars: From computing with shapes to computing with things},
journal = {Design Studies},
volume = {41},
pages = {8-28},
year = {2015},
note = {Special Issue: Computational Making},
issn = {0142-694X},
doi = {https://doi.org/10.1016/j.destud.2015.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0142694X15000605},
author = {Terry Knight and George Stiny},
keywords = {computational model(s), design theory, perception, reflective practice, shape grammar},
abstract = {Recent interest in making and materiality spans from the humanities and social sciences to engineering, science, and design. Here, we consider making through the lens of a unique computational theory of design: shape grammars. We propose a computational theory of making based on the improvisational, perception and action approach of shape grammars and the shape algebras that support them. We modify algebras for the materials (basic elements) of shapes to define algebras for the materials of objects, or things. Then we adapt shape grammars for computing shapes to making grammars for computing things. We give examples of making grammars and their algebras. We conclude by reframing designing and making in light of our computational theory of making.}
}
@incollection{SARSANI2011231,
title = {Computers and Creativity},
editor = {Mark A. Runco and Steven R. Pritzker},
booktitle = {Encyclopedia of Creativity (Second Edition)},
publisher = {Academic Press},
edition = {Second Edition},
address = {San Diego},
pages = {231-240},
year = {2011},
isbn = {978-0-12-375038-9},
doi = {https://doi.org/10.1016/B978-0-12-375038-9.00041-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780123750389000418},
author = {M.R. Sarsani},
keywords = {Approaches to creativity, Computer applications, Computer functions, Computers, Computers and creativity, Creativity definitions, Metaphor, Problem solving, Productivity tools},
abstract = {Computers have entered all walks of human life across the world. Computers are being used by people of all ages and in every profession, in their work as well as in their leisure. There is growing interest in the application of computer-based productivity tools to support simulation effects, higher level thinking, metacognitive processes, maintaining interest, promoting learning, developing curiosity, and fostering creativity. The Internet has brought abort a revolution in the world of information technology by providing searching facilities for exploring or seeking information from all over the world (e.g., e-learning, e-shopping, e-mail, Telnet and Usenet, audio and video conferences, etc.). Different viewpoints have been put forward to explain the concept, emphasizing different aspects of creativity. Generally, creativity has been discussed in terms of its end product, creative person, creative process, and creative press or environments. There are no substantial researches directly measuring the effect of the computer simulation technology to support either uncreative drill or creative production. Some researchers speculate that computer simulation technology may have a positive effect on creativity. However, due to a lack of empirical research, the true effect of simulation technology on creativity is still unknown and inconclusive.}
}
@article{DING2012264,
title = {Finding MicroRNA Targets in Plants: Current Status and Perspectives},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {10},
number = {5},
pages = {264-275},
year = {2012},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2012.09.003},
url = {https://www.sciencedirect.com/science/article/pii/S1672022912000733},
author = {Jiandong Ding and Shuigeng Zhou and Jihong Guan},
keywords = {MicroRNA, Target prediction, Degradome-seq, Integration},
abstract = {MicroRNAs (miRNAs), a class of ∼20–24nt long non-coding RNAs, have critical roles in diverse biological processes including development, proliferation, stress response, etc. With the development and availability of experimental technologies and computational approaches, the field of miRNA biology has advanced tremendously over the last decade. By sequence complementarity, miRNAs have been estimated to regulate certain mRNA transcripts. Although it was once thought to be simple and straightforward to find plant miRNA targets, this viewpoint is being challenged by genetic and biochemical studies. In this review, we summarize recent progress in plant miRNA target recognition mechanisms, principles of target prediction, and introduce current experimental and computational tools for plant miRNA target prediction. At the end, we also present our thinking on the outlook for future directions in the development of plant miRNA target finding methods.}
}
@article{BACHMANN2020102937,
title = {Account of consciousness by Christof Koch: Review and questions},
journal = {Consciousness and Cognition},
volume = {82},
pages = {102937},
year = {2020},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2020.102937},
url = {https://www.sciencedirect.com/science/article/pii/S1053810020300143},
author = {Talis Bachmann},
keywords = {Consciousness, Integrated information, Cognitive computation, Microgenesis, Phenomenal experience},
abstract = {This review is set to present the gist of the theoretical account of consciousness recently presented by Christof Koch and pose a couple of questions instigated by this account. The expected answers to these questions would hopefully help to advance our understanding of the basic nature of the conscious mind.}
}
@article{ALI2024100170,
title = {A conceptual IoT framework based on Anova-F feature selection for chronic kidney disease detection using deep learning approach},
journal = {Intelligence-Based Medicine},
volume = {10},
pages = {100170},
year = {2024},
issn = {2666-5212},
doi = {https://doi.org/10.1016/j.ibmed.2024.100170},
url = {https://www.sciencedirect.com/science/article/pii/S2666521224000371},
author = {Md Morshed Ali and Md Saiful Islam and Mohammed Nasir Uddin and Md. Ashraf Uddin},
keywords = {IoT Framework, Machine learning, Deep learning, Feature selection techniques, ANOVA F-test, Healthcare technology, Medical diagnosis, Kidney disease prediction, Classification},
abstract = {Chronic kidney disease (CKD) is becoming an increasingly significant health issue, especially in low-income countries where access to affordable treatment is limited. Additionally, CKD is associated with various dietary factors, including liver failure, diabetes, anemia, nerve damage, inflammation, peroxidation, obesity, and other related conditions. Therefore, early prediction of CKD is important to progress the functionality of the kidney. In recent times, IoT has been widely used in a diversity of healthcare sectors through the incorporation of monitoring devices such as digital sensors and medical devices for patient monitoring from remote places. To overcome the problem, this research proposed a conceptual architecture for CKD detection. The sensor layer of the architecture includes IoT devices to collect data and the proposed classifier, MLP (Multi-Layer Perceptron), utilizes the Anova-F feature selection technique to effectively detect CKD (Chronic Kidney Disease). In addition to MLP, four other classifiers including ANN (Artificial Neural Network), Simple RNN (Recurrent Neural Network), GRU (Gated Recurrent Unit), and SVM (Support Vector Machine), are employed for comparative analysis of accuracy. Furthermore, three additional feature selection techniques, namely Chi-squared, SFFS (Sequential Floating Forward Selection), and SBFS (Sequential Backward Floating Selection), are utilized to evaluate their impact on the accuracy of CKD detection. Our proposed method outperforms all other approaches with a remarkable accuracy of 99 % while maintaining efficient computational time. This advancement is crucial in developing a highly accurate machine capable of predicting CKD in remote areas with ease.}
}
@article{HELBING2023102061,
title = {Democracy by Design: Perspectives for Digitally Assisted, Participatory Upgrades of Society},
journal = {Journal of Computational Science},
volume = {71},
pages = {102061},
year = {2023},
issn = {1877-7503},
doi = {https://doi.org/10.1016/j.jocs.2023.102061},
url = {https://www.sciencedirect.com/science/article/pii/S1877750323001217},
author = {Dirk Helbing and Sachit Mahajan and Regula Hänggli Fricker and Andrea Musso and Carina I. Hausladen and Cesare Carissimo and Dino Carpentras and Elisabeth Stockinger and Javier {Argota Sanchez-Vaquerizo} and Joshua C. Yang and Mark C. Ballandies and Marcin Korecki and Rohit K. Dubey and Evangelos Pournaras},
keywords = {Computational diplomacy, Digital democracy, Participation, Collective intelligence, Value-based engineering},
abstract = {The technological revolution, particularly the availability of more data and more powerful computational tools, has led to the emergence of a new scientific field called “Computational Diplomacy”. Our work tries to define its scope and focuses on a popular subarea of it, namely “Digital Democracy”. In recent years, there has been a surge of interest in using digital technologies to promote more participatory forms of democracy. While there are numerous potential benefits to using digital tools to enhance democracy, significant challenges must be addressed. It is essential to ensure that digital technologies are used in an accessible, equitable, and fair manner rather than reinforcing existing power imbalances. This paper investigates how digital tools can be used to help design more democratic societies by investigating three key research areas: (1) the role of digital technologies for facilitating civic engagement in collective decision-making; (2) the use of digital tools to improve transparency and accountability in governance; and (3) the potential for digital technologies to enable the formation of more inclusive and representative democracies. We argue that more research on how digital technologies can be used to support democracy upgrade is needed. Along these lines, we lay out a research agenda for the future.}
}
@article{ELIAZ2010304,
title = {Paying for confidence: An experimental study of the demand for non-instrumental information},
journal = {Games and Economic Behavior},
volume = {70},
number = {2},
pages = {304-324},
year = {2010},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2010.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0899825610000229},
author = {Kfir Eliaz and Andrew Schotter},
abstract = {This paper presents experimental evidence that when individuals are about to make a given decision under risk, they are willing to pay for information on the likelihood that this decision is ex-post optimal, even if this information will not affect their decision. Our findings suggest that this demand for non-instrumental information is caused by what we refer to as a “confidence effect”: the desire to increase one's posterior belief by ruling out “bad news”, even when such news would have no effect on one's decision. We conduct various treatments to show that our subjects' behavior is not likely to be caused by an intrinsic preference for information, failure of backward induction or an attempt to minimize thinking costs.}
}
@incollection{ZIELINSKI2024116,
title = {Coupled-Cluster Theories for Excited States},
editor = {Manuel Yáñez and Russell J. Boyd},
booktitle = {Comprehensive Computational Chemistry (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {116-140},
year = {2024},
isbn = {978-0-12-823256-9},
doi = {https://doi.org/10.1016/B978-0-12-821978-2.00035-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780128219782000350},
author = {Patrik Zielinski and Andreas Köhn},
keywords = {Accurate computations, Analytic gradients, Basis-set convergence, Benchmark computations, Cluster expansion, Coupled-cluster theory, Equation of motion, Excited-state properties, Gradient theory, Linear response, Multireference, Open-shell systems, Single-reference, Size consistency, Transition moments},
abstract = {Coupled-cluster theory offers a hierarchy of increasingly accurate methods and provides thus an important basis for accurate quantum chemistry, also for the computation of electronic excited states. This chapter explains and compares the two main approaches, equation-of-motion and linear-response theory and sketches the computation of transition moments and expectation values, as well as analytic geometric gradients. The basic approaches to arrive at approximations are discussed, and recent benchmark works are used to demonstrate their relative accuracy. Some challenges in coupled-cluster theory, like going to large systems, open-shell and multireference theory and the slow basis-set convergence are also covered.}
}
@article{SCHEFFLER201575,
title = {NeurOS™ and NeuroBlocks™ a neural/cognitive operating system and building blocks},
journal = {Biologically Inspired Cognitive Architectures},
volume = {11},
pages = {75-105},
year = {2015},
issn = {2212-683X},
doi = {https://doi.org/10.1016/j.bica.2014.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S2212683X14000747},
author = {Lee Scheffler},
keywords = {Cognition, Perception, Pattern recognition, Memory, Learning, Behavior},
abstract = {NeurOS is an open platform for accelerating research, development and hosting execution of intelligent applications. A NeurOS application is a directed “neural graph” of modular components connected by signal paths, similar to biological brain connectivity and functional block diagrams of neural pathways. Built-in reusable modules (NeuroBlocks) provide a wide range of general- and special-purpose capabilities: inputs/senses, outputs/effectors, processing, memory, pattern learning and recognition, visualization/instrumentation, custom module development, integrating external intelligence capabilities, and sub-graph reuse. NeurOS sub-graph assemblies address neural/cognitive functions including perception, pattern learning and recognition, working memory, imagination, prediction, context priming, attention, abstraction, classification, associational thinking and behavior. NeurOS applications are inherently portable, scalable, networkable, extensible and embeddable. NeurOS development tools provide simple intuitive graphical drag and drop application assembly from components without programming, along with testing, debugging, monitoring and visualization. Prototype NeurOS applications have begun to explore a wide range of intelligent functions in diverse areas, including aspects of pattern recognition, vision, music, reading, puzzle solving, reasoning, behavior. Building working intelligent systems using NeurOS and NeuroBlocks lets researchers and developers focus on their core functions and rapidly iterate and instrument working models, fostering both analytical and biological insight as well as usable systems.}
}
@article{SHARMA201524,
title = {Urban greenways: Operationalizing design syntax and integrating mathematics and science in design},
journal = {Frontiers of Architectural Research},
volume = {4},
number = {1},
pages = {24-34},
year = {2015},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2014.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2095263514000727},
author = {Archana Sharma},
keywords = {Design thinking, Syntax, Greenway, Urban, Planning, Landscape, STEM integrated design, Inter-disciplinary},
abstract = {The ubiquitous sameness of urban greenways prompts questions on generative design grammar and syntax, whether creative, critical rethinking at that level might be lacking. However the design syntax of urban greenways is not explicitly discussed thus leaving a critical gap in knowledge. This paper begins tackling the larger question by acting on the fundamental subset of it, by operationalizing the design syntax of urban greenways. This is done through mathematics-based graph studies to analyze patterns and shapes, photography based thermal, material and morphology studies, and section analyses to make imagery-derived deductions on the design syntax. Recommendation on approaches to diversify and enrich the design syntax includes a more direct reference from ecosystem science theories such for siting and planning the urban greenways at macro- to meso-scale, a mixed-method approach, combining mathematics, photography and drawings based frames for analyses at meso-, to micro-scale, and a turtle view scale for designing at meso- to micro-scale, with an emphasis on latter.}
}
@incollection{BUTTON199067,
title = {Chapter 4 - Going Up a Blind Alley: Conflating Conversation Analysis and Computational Modelling},
editor = {PAUL LUFF and NIGEL GILBERT and DAVID FROHLICH},
booktitle = {Computers and Conversation},
publisher = {Academic Press},
address = {London},
pages = {67-90},
year = {1990},
isbn = {978-0-08-050264-9},
doi = {https://doi.org/10.1016/B978-0-08-050264-9.50009-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780080502649500099},
author = {Graham Button},
abstract = {Publisher Summary
This chapter discusses the desirability of developing computational models of conversational phenomena, and the supportive role given to conversation analysis (CA) in the development of such models. The arguments presented in this chapter are not an attempt to restrict the range of creative resources that software designers might turn to for inspiration. In particular, it is implicitly endorsed in the attempts to develop descriptively adequate models of conversation for use in computer systems, and explicitly endorsed when it is argued that by providing a simulacrum of conversation one has naturally occurring conversation between computers and humans. The attraction of CA for people who want to develop rules of conversational organization that can be used to program computers is two-fold: (1) CA might seem to provide a ready-made package of conversational rules that they can use or adapt for their purposes; and (2) their models may be authorized by appealing to CA. However, CA is used to authorize computational models of conversation that misrepresent the details of how conversation works.}
}
@incollection{SANTOS2024,
title = {Data analysis on Decision-Making},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-13701-3.00018-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443137013000189},
author = {Eulália Santos and Margarida F. Oliveira},
keywords = {Artificial intelligence, Business, Data analysis, Decision making, Logistics, Machine learning, Mathematical modeling operations research, Mathematical programming, Optimization, Statistic, Strategic management, Technology},
abstract = {Today, data analysis plays a vital role in identifying market trends and supporting strategic decision-making in organizations. To make an effective decision in order to obtain positive results, it is necessary not only to carefully analyze various pieces of information but also to use artificial intelligence and critical thinking. Mathematics plays an essential role in making effective decisions and providing tools and methods for analyzing, modeling and solving both simple and more complex problems.}
}
@article{RULE2020900,
title = {The Child as Hacker},
journal = {Trends in Cognitive Sciences},
volume = {24},
number = {11},
pages = {900-915},
year = {2020},
issn = {1364-6613},
doi = {https://doi.org/10.1016/j.tics.2020.07.005},
url = {https://www.sciencedirect.com/science/article/pii/S1364661320301741},
author = {Joshua S. Rule and Joshua B. Tenenbaum and Steven T. Piantadosi},
keywords = {Learning and cognitive development, Language of thought, Hacking, Computational modeling, Program induction},
abstract = {The scope of human learning and development poses a radical challenge for cognitive science. We propose that developmental theories can address this challenge by adopting perspectives from computer science. Many of our best models treat learning as analogous to computer programming because symbolic programs provide the most compelling account of sophisticated mental representations. We specifically propose that children’s learning is analogous to a particular style of programming called hacking, making code better along many dimensions through an open-ended set of goals and activities. By contrast to existing theories, which depend primarily on local search and simple metrics, this view highlights the many features of good mental representations and the multiple complementary processes children use to create them.}
}
@article{CHERNYSHOV20151345,
title = {Information Support and Skill Evaluation of Human-Operators},
journal = {IFAC-PapersOnLine},
volume = {48},
number = {3},
pages = {1345-1350},
year = {2015},
note = {15th IFAC Symposium onInformation Control Problems inManufacturing},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2015.06.273},
url = {https://www.sciencedirect.com/science/article/pii/S2405896315005121},
author = {K.R. Chernyshov and E.Ph Jharko},
keywords = {Human-operator, Information support, Flexible simulation, Evaluation of skills, Random processes, Measures of dependence},
abstract = {The paper presents an approach to design an intelligent information support system to be used as a human-operator assistant to control large complex industrial plants. Tasks and structure of such an intelligent information support system (IISS), IISS design stages, methodology of IISS design, toolkits for IISS design are considered. A flexible simulation complex (FSC) as such an intelligent toolkit has been presented. The complex is used as a “kernel” of IISS for human-operators of a nuclear power plant. A new approach to abnormal situations with regard for the heuristic regularities of human-operator thinking process is proposed. The regularities are revealed on basis of recording the motions of the human- operator eyes over the information field of the control board and processing the experimental data obtained. For data processing, a probability theoretical approach is used based on involving the notion of consistency of measures of dependence of random variables.}
}
@article{SCHNEIDER2012475,
title = {Eye gaze reveals a fast, parallel extraction of the syntax of arithmetic formulas},
journal = {Cognition},
volume = {125},
number = {3},
pages = {475-490},
year = {2012},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2012.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S0010027712001357},
author = {Elisa Schneider and Masaki Maruyama and Stanislas Dehaene and Mariano Sigman},
keywords = {Arithmetic, Gestalt, Cognitive architecture, Language, Mathematical education},
abstract = {Mathematics shares with language an essential reliance on the human capacity for recursion, permitting the generation of an infinite range of embedded expressions from a finite set of symbols. We studied the role of syntax in arithmetic thinking, a neglected component of numerical cognition, by examining eye movement sequences during the calculation of arithmetic expressions. Specifically, we investigated whether, similar to language, an expression has to be scanned sequentially while the nested syntactic structure is being computed or, alternatively, whether this structure can be extracted quickly and in parallel. Our data provide evidence for the latter: fixations sequences were stereotypically organized in clusters that reflected a fast identification of syntactic embeddings. A syntactically relevant pattern of eye movement was observed even when syntax was defined by implicit procedural rules (precedence of multiplication over addition) rather than explicit parentheses. While the total number of fixations was determined by syntax, the duration of each fixation varied with the complexity of the arithmetic operation at each step. These findings provide strong evidence for a syntactic organization for arithmetic thinking, paving the way for further comparative analysis of differences and coincidences in the instantiation of recursion in language and mathematics.}
}
@article{NSSSN2024106769,
title = {VNSMAS: A constraint-based portfolio profit maximization},
journal = {Computers & Operations Research},
volume = {170},
pages = {106769},
year = {2024},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2024.106769},
url = {https://www.sciencedirect.com/science/article/pii/S0305054824002417},
author = {Usha Devi N.S.S.S.N. and R. Mohan},
keywords = {GAN, Reinforcement learning, Stock, Fuzzy},
abstract = {Stock trading has a more significant influence on the global economy. Stock trading with portfolio optimization became challenging due to the complexity of analyzing the high variance in time series stock data. Efficient portfolio management increases profit and avoids risky situations when investing. The present work aims to model a Variable Neighborhood Search Multi-Agent System for Portfolio Optimization (VNSMASPPO) to optimize the profit on defined trading constraints on buying, selling, and holding trading decisions. This work proposes a novel Variable Neighborhood Search-based Multi-Agent System (VNASMAS) algorithm for profit computation with a constraint-based multi-agent system. The stock price history experimental data sets are collected from 8th August 2016 to 31st March 2023 with 14,567 records. The proposed model achieved an RMSE of 10.11, MAE of 2.75, and MAPE of 0.017, outperforming the literature models. VNSMASPPO maximizes the portfolio profit and is a reliable, adaptable approach.}
}
@article{MARITAN2022167351,
title = {Building Structural Models of a Whole Mycoplasma Cell},
journal = {Journal of Molecular Biology},
volume = {434},
number = {2},
pages = {167351},
year = {2022},
issn = {0022-2836},
doi = {https://doi.org/10.1016/j.jmb.2021.167351},
url = {https://www.sciencedirect.com/science/article/pii/S002228362100588X},
author = {Martina Maritan and Ludovic Autin and Jonathan Karr and Markus W. Covert and Arthur J. Olson and David S. Goodsell},
keywords = {whole cell modeling, computational modeling, nucleoid structure, scientific visualization, mycoplasma genitalium},
abstract = {Building structural models of entire cells has been a long-standing cross-discipline challenge for the research community, as it requires an unprecedented level of integration between multiple sources of biological data and enhanced methods for computational modeling and visualization. Here, we present the first 3D structural models of an entire Mycoplasma genitalium (MG) cell, built using the CellPACK suite of computational modeling tools. Our model recapitulates the data described in recent whole-cell system biology simulations and provides a structural representation for all MG proteins, DNA and RNA molecules, obtained by combining experimental and homology-modeled structures and lattice-based models of the genome. We establish a framework for gathering, curating and evaluating these structures, exposing current weaknesses of modeling methods and the boundaries of MG structural knowledge, and visualization methods to explore functional characteristics of the genome and proteome. We compare two approaches for data gathering, a manually-curated workflow and an automated workflow that uses homologous structures, both of which are appropriate for the analysis of mesoscale properties such as crowding and volume occupancy. Analysis of model quality provides estimates of the regularization that will be required when these models are used as starting points for atomic molecular dynamics simulations.}
}
@article{SCHWABER1993126,
title = {Computational modeling of neuronal dynamics for systems analysis: application to neurons of the cardiorespiratory NTS in the rat},
journal = {Brain Research},
volume = {604},
number = {1},
pages = {126-141},
year = {1993},
issn = {0006-8993},
doi = {https://doi.org/10.1016/0006-8993(93)90359-U},
url = {https://www.sciencedirect.com/science/article/pii/000689939390359U},
author = {J.S. Schwaber and E.B. Graves and J.F.R. Paton},
keywords = {Nucleus tractus solitarii, Systems modeling, Cardiovascular reflex, Neuronal dynamics},
abstract = {The study constructs computational models of neurons in order to examine the contribution that their response dynamics may make to functional properties at the system level. As described in the accompanying study, neurons in the cardiorespiratory nucleus tractus solitarii (NTS) of the rat were recorded in vitro. When these cells were intracellularly injected with a constant current pulse, spike discharge patterns and subthreshold voltage trajectories were observed that were time- and voltage-dependent. The accompanying manuscript describes these dynamic responses in 4 classes of putative second-order cells that appear to receive direct primary afferent input, and a previous paper described two populations of rhythmically firing interneurons, one of which is intrinsically auto-active. In the present manuscript experimental neuronal voltage response data was collected across a current injection series for the S3 neuron type described in the accompanying study and for the auto-active neuron described previously. Using this data, computational model neurons have been constructed for these two neurons by using membrane ion channels to produce and match the observed neuronal voltage behavior. The channels were those implicated in the dynamic responses observed in the companion study, and include gNafast, gKdr, gKA, gKCa, gKAHP, gKM, gCaT and gCaL. The description of channel kinetics follows the Hodgkin-Huxley form. Different neuronal sources from the literature of channel kinetics were investigated and assembled into a ‘channel kinetics library’ from which both neuron models were tuned, primarily by adjusting the maximum channel densities, g¯, and time-dependence of kinetics. Methods are described for tuning the channel kinetics library to match various physiological responses. This approach created neuron models that were able to closely replicate the observed complex voltage and spiking responses of the two very different cardiorespiratory NTS neurons. The interaction of voltage- and calcium-dependent conductances were analyzed for their functional contributions by tuning their kinetics. Specific parameters are given that account for the behavior of each model. Sensitivity analyses by perturbing KCa and KA are are shown for both neurons, and I/F curves are presented for the auto-active neuron's simulated and recorded responses. The potential systems-level functional implications resulting from the different kinetics is demonstrated by driving the S3 model neuron in simulation with the pattern of input produced by model primary baroreceptor afferents. The limitations and significance of this approach are discussed. The present study of model neurons are being extended to the larger family of neurons found in the cardiorespiratory NTS (e.g. S1, S2 and S4), are being related to the baroreceptor vagal reflex by in vivo studies, and are being used to explore systems level computation, for example by creating networks reflecting baroreceptor reflex organization. The present kinetics library in principle could be used in this way for other neuronal systems.}
}
@article{BROWN19921,
title = {Some conceptual issues in the modeling and computational analysis of the Canada-U.S. Free Trade Agreement},
journal = {The North American Journal of Economics and Finance},
volume = {3},
number = {1},
pages = {1-20},
year = {1992},
issn = {1062-9408},
doi = {https://doi.org/10.1016/1062-9408(92)90009-G},
url = {https://www.sciencedirect.com/science/article/pii/106294089290009G},
author = {Drusilla K. Brown and Robert M. Stern},
abstract = {We present an interpretive history of the development of the computational analysis of the Canada-U.S. FTA. Several important conceptual issues are identified, including: perfect competition and national product differentiation; imperfect competition and increasing returns to scale; tariff liberalization and monopolistic competition; adjustment and dynamic effects; macroeconomic effects; and other pertinent aspects of market structure and firm behavior.}
}
@article{LAO2022,
title = {Analyzing Suicide Risk From Linguistic Features in Social Media: Evaluation Study},
journal = {JMIR Formative Research},
volume = {6},
number = {8},
year = {2022},
issn = {2561-326X},
doi = {https://doi.org/10.2196/35563},
url = {https://www.sciencedirect.com/science/article/pii/S2561326X22007910},
author = {Cecilia Lao and Jo Lane and Hanna Suominen},
keywords = {evaluation study, interdisciplinary research, linguistics, machine learning, mental health, natural language processing, social media, suicide risk},
abstract = {Background
Effective suicide risk assessments and interventions are vital for suicide prevention. Although assessing such risks is best done by health care professionals, people experiencing suicidal ideation may not seek help. Hence, machine learning (ML) and computational linguistics can provide analytical tools for understanding and analyzing risks. This, therefore, facilitates suicide intervention and prevention.
Objective
This study aims to explore, using statistical analyses and ML, whether computerized language analysis could be applied to assess and better understand a person’s suicide risk on social media.
Methods
We used the University of Maryland Suicidality Dataset comprising text posts written by users (N=866) of mental health–related forums on Reddit. Each user was classified with a suicide risk rating (no, low, moderate, or severe) by either medical experts or crowdsourced annotators, denoting their estimated likelihood of dying by suicide. In language analysis, the Linguistic Inquiry and Word Count lexicon assessed sentiment, thinking styles, and part of speech, whereas readability was explored using the TextStat library. The Mann-Whitney U test identified differences between at-risk (low, moderate, and severe risk) and no-risk users. Meanwhile, the Kruskal-Wallis test and Spearman correlation coefficient were used for granular analysis between risk levels and to identify redundancy, respectively. In the ML experiments, gradient boost, random forest, and support vector machine models were trained using 10-fold cross validation. The area under the receiver operator curve and F1-score were the primary measures. Finally, permutation importance uncovered the features that contributed the most to each model’s decision-making.
Results
Statistically significant differences (P<.05) were identified between the at-risk (671/866, 77.5%) and no-risk groups (195/866, 22.5%). This was true for both the crowd- and expert-annotated samples. Overall, at-risk users had higher median values for most variables (authenticity, first-person pronouns, and negation), with a notable exception of clout, which indicated that at-risk users were less likely to engage in social posturing. A high positive correlation (ρ>0.84) was present between the part of speech variables, which implied redundancy and demonstrated the utility of aggregate features. All ML models performed similarly in their area under the curve (0.66-0.68); however, the random forest and gradient boost models were noticeably better in their F1-score (0.65 and 0.62) than the support vector machine (0.52). The features that contributed the most to the ML models were authenticity, clout, and negative emotions.
Conclusions
In summary, our statistical analyses found linguistic features associated with suicide risk, such as social posturing (eg, authenticity and clout), first-person singular pronouns, and negation. This increased our understanding of the behavioral and thought patterns of social media users and provided insights into the mechanisms behind ML models. We also demonstrated the applicative potential of ML in assisting health care professionals to assess and manage individuals experiencing suicide risk.}
}
@article{BLAND2025,
title = {Quantal response equilibrium as a structural model for estimation: The missing manual},
journal = {Games and Economic Behavior},
year = {2025},
issn = {0899-8256},
doi = {https://doi.org/10.1016/j.geb.2025.02.008},
url = {https://www.sciencedirect.com/science/article/pii/S0899825625000211},
author = {James R. Bland and Theodore L. Turocy},
keywords = {Quantal response, Estimation, Computation, Experiments},
abstract = {One of the original objectives of the (logit) quantal response equilibrium (LQRE) model was to provide a method for structural estimation of behavior in games, when behavior deviated from Nash equilibrium predictions. To date, only Chapter 6 of the book on quantal response equilibrium by Goeree et al. (2016) focuses on how such estimation can be implemented. We build on that chapter to provide here a more detailed treatment of the methodological issues of implementing maximum likelihood estimation of QRE. We compare the equilibrium correspondence and empirical payoff approaches to estimation, and identify some considerations in interpreting the results of those approaches when applied to the same data on the same game. We also provide a more detailed “field guide” to using numerical continuation methods to accomplish estimation, including guidance on how to tailor implementations to games with different structures.}
}
@article{MUTHUSAMY2025112916,
title = {High-precision malware detection in android apps using quantum explainable hierarchical interaction network},
journal = {Knowledge-Based Systems},
volume = {310},
pages = {112916},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112916},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124015508},
author = {Ramnath Muthusamy and Yesubai Rubavathi Charles},
keywords = {Recommender system, Android applications, Real or fake app detection, Privacy, Feature interaction, Quantum superposition and entanglement},
abstract = {The exponential growth of Android applications has increased the prevalence of fraudulent and malicious apps, posing significant risks to user security and privacy. Existing detection methodologies often struggle with poor interpretability, scalability, and computational complexity, limiting their effectiveness. To address these challenges, this study introduces the Quantum Explainable Hierarchical Interaction Network (QEHIN), a novel framework designed to detect real and fake Android applications with superior accuracy and interpretability. QEHIN incorporates quantum computing principles such as superposition and entanglement to model high-order feature interactions effectively. Its innovative architecture includes a Quantum Embedding Layer for transforming input features into quantum states, a Quantum Hierarchical Interaction Network (QHIN) for capturing complex dependencies, a Quantum Deep Neural Network (QDNN) for enhanced feature processing, and a Quantum Cross-Hierarchical Unit (QCHU) to ensure seamless integration across hierarchical levels. This design achieves precise, transparent, and scalable detection of malicious applications, addressing the shortcomings of traditional methods. Evaluation on the Google Play Store Reviews, MobileRec, and Android-App-Recommendation datasets demonstrates the novelty and effectiveness of QEHIN. It achieves an accuracy of 98.86 %, precision of 98.78 %, recall of 98.82 %, and a kappa score of 98.54 %, significantly outperforming existing approaches.}
}
@article{PURWANTO2019118170,
title = {Using group model building to develop a causal loop mapping of the water-energy-food security nexus in Karawang Regency, Indonesia},
journal = {Journal of Cleaner Production},
volume = {240},
pages = {118170},
year = {2019},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2019.118170},
url = {https://www.sciencedirect.com/science/article/pii/S0959652619330409},
author = {Aries Purwanto and Janez Sušnik and F.X. Suryadi and Charlotte {de Fraiture}},
keywords = {Group model building, Causal loop diagram, Water-energy-food (WEF) security, Nexus modelling},
abstract = {This paper develops a qualitative causal model of a water, energy, and food (WEF) security nexus system to be used in analysing the interlinkages among those and other sectors that influence and are influenced by each other in a local context. Local stakeholder engagement through a group model building (GMB) approach was applied in Karawang Regency, Indonesia, to develop the model with the goals of improving problem understanding, raising consensus among participants, and building acceptance and commitment regarding the subsequent development of a quantitative nexus model. After recognizing the issues regarding water, energy and food sectors in the study area and eliciting opinions about nexus interactions, the next stage was to build a conceptual framework to describe the nexus system and to develop an integrated causal loop diagram (CLD) that describes critical system (inter-)linkages. The developed Karawang WEF security (K-WEFS) model is composed of six sub-models with water, energy and food sectors as endogenous factors. In addition, population, economic and ecosystem services were considered as exogenous drivers of the system. It is expected that all the major internal and external factors and drivers are covered, including possible feedback mechanisms, and key variables will be analysed further in the system. The future achievement of WEF security targets can be based on robust evaluation and planning processes underpinned by thorough understanding of whole system dynamics and the impacts of changes in the linked sectors, even in a qualitative way. In this way, a first step towards breaking silo thinking in regional planning may be attained.}
}
@article{DELI2021784,
title = {The thermodynamics of cognition: A mathematical treatment},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {784-793},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S200103702100012X},
author = {Eva Deli and James Peters and Zoltán Kisvárday},
keywords = {Consciousness, Free will, Mental energy, Intellect, Emotional regulation, Fermionic mind hypothesis, Carnot cycle, Landauer's principle},
abstract = {There is a general expectation that the laws of classical physics must apply to biology, particularly the neural system. The evoked cycle represents the brain's energy/information exchange with the physical environment through stimulus. Therefore, the thermodynamics of emotions might elucidate the neurological origin of intellectual evolution, and explain the psychological and health consequences of positive and negative emotional states based on their energy profiles. We utilized the Carnot cycle and Landauer's principle to analyze the energetic consequences of the brain's resting and evoked states during and after various cognitive states. Namely, positive emotional states can be represented by the reversed Carnot cycle, whereas negative emotional reactions trigger the Carnot cycle. The two conditions have contrasting energetic and entropic aftereffects with consequences for mental energy. The mathematics of the Carnot and reversed Carnot cycles, which can explain recent findings in human psychology, might be constructive in the scientific endeavor in turning psychology into hard science.}
}
@article{GHAVAM2021128776,
title = {The life cycle environmental impacts of a novel sustainable ammonia production process from food waste and brown water},
journal = {Journal of Cleaner Production},
volume = {320},
pages = {128776},
year = {2021},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2021.128776},
url = {https://www.sciencedirect.com/science/article/pii/S0959652621029747},
author = {Seyedehhoma Ghavam and Caroline M. Taylor and Peter Styring},
keywords = {Green ammonia, Waste utilization, Carbon capture and sequestration, Carbon capture and utilization, Greenhouse gas emissions, Life cycle assessment},
abstract = {To replace existing high impact ammonia production technologies, a new sustainability-driven waste-based technology producing green ammonia with and without urea was devised using life cycle thinking and sustainable design principles, targeting efficiency, carbon emissions, water, and power use competitiveness. We have used life cycle assessment to determine whether cradle-to-gate, multiple configurations of the core waste-based processes integrating several carbon capture/utilization options can compete environmentally with other available ammonia technologies. Our waste-to-ammonia processes reduce potential impacts from abiotic depletion, human toxicity, and greenhouse gas (GHG) emissions relative to fossil-based and renewable technologies. Among the assessed technologies, coupling dark fermentation with anaerobic digestion and capturing CO2 for sequestration or later use is most efficient for GHGs, water, and energy, consuming 27% less energy and reducing GHGs by 98% compared to conventional ammonia. Water use is 38% lower than water electrolysis and GHGs are 94% below municipal waste incineration routes per kg NH3. Additionally, displacing conventional, high impact urea by integrating urea production from process CO2 decreases life cycle environmental impacts significantly despite increased energy demand. On a fertilizer-N basis, the ammonia + urea configuration without dark fermentation performs best on all categories included. Methane and ammonia leakage cause nearly all life cycle impacts, indicating that failing to prevent leakage undermines the effectiveness of new technologies such as these. Our results show that a green ammonia/ammonia + urea process family as designed here can reduce waste and prevent the release of additional CO2 from ammonia production while avoiding fossil-based alternatives and decreasing emissions from biogenic waste sources.}
}
@article{HERNANDEZRAMIREZ2024414,
title = {The Future End of Design Work: A Critical Overview of Managerialism, Generative AI, and the Nature of Knowledge Work, and Why Craft Remains Relevant},
journal = {She Ji: The Journal of Design, Economics, and Innovation},
volume = {10},
number = {4},
pages = {414-440},
year = {2024},
issn = {2405-8726},
doi = {https://doi.org/10.1016/j.sheji.2024.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S2405872624000960},
author = {Rodrigo Hernández-Ramírez and João Batalheiro Ferreira},
keywords = {creativity, design work, generative artificial intelligence (GenAI), knowledge work, managerialism},
abstract = {This article examines the transformation of design work under the influence of managerialism and the rise of Generative Artificial Intelligence (GenAI). Drawing on John Maynard Keynes’s projections of technological unemployment and the evolving nature of work, it argues that despite advancements in automation, work has not diminished but rather devalued. Design, understood as a type of knowledge work, faces an apparent existential crisis. GenAI grows adept at mimicking the output of creative processes. The article explores how the fear of the end of design work fueled by the rise of GenAI is rooted in a misunderstanding of design work. This misunderstanding is driven by managerialism—an ideology that prioritizes efficiency and quantifiable outcomes over the intrinsic value of work. Managerialism seeks to instrumentalize and automate design, turning it into a controllable procedure to generate quantifiable creative outputs. The article argues why design work cannot be turned into a procedure and automated using GenAI. Advocates of these systems claim they enhance productivity and open new opportunities. However, evidence so far shows that flawed GenAI models produce disappointing outcomes while operating at a significant environmental cost. The article concludes by arguing for a robust theory of design—one that acknowledges the unique ontological and epistemic boundaries of design work and underscores why design cannot be reduced to a procedural output.}
}
@article{TAMILVENDAN2024469,
title = {Parametric optimization in drilling of sisal–glass reinforced epoxy composites using Taguchi grey relational analysis method},
journal = {Transactions of the Canadian Society for Mechanical Engineering},
volume = {48},
number = {3},
pages = {469-476},
year = {2024},
issn = {0315-8977},
doi = {https://doi.org/10.1139/tcsme-2024-0018},
url = {https://www.sciencedirect.com/science/article/pii/S0315897724000570},
author = {D. Tamilvendan and A.R. Ravikumar and R. Thirumalai},
keywords = {Taguchi grey relational analysis, drlling, glass fiber, sisal fiber, composite},
abstract = {This research work intends to study the effect of hybridization of glass and sisal fiber, stacking sequence and tensile properties of the composite. The sisal-glass fiber hybrid composites laminates are prepared using reinforced plain woven sisal fabric (unidirectional) and plainwoven glass fabric. In this research study, 27 experiments are conducted as per L27 orthogonal array. Five process parameters are selected and three responses are considered in this work. The drilling of the composite specimen is considered and the drilling process parameters such as speed, feed rate, drill diameter, material thickness, and drill point angle are selected. The responses considered in this work are delamination factor, thrust force, and torque. Taguchi analysis is performed and the response table for means for the responses is determined, and the most influencing parameter in the drilling of the composite specimen is analyzed. The grey relational coefficients are computed and followed with the computation of the grey relational grade. The grey relational grades are calculated for determining the highest contributing parameter in the drilling of the sisal fiber and glass fiber reinforced hybrid composite specimen. The optimum drilling process parameters are ranked and the ranks presented represent the sequence of run resulting in optimum solutions.}
}
@article{HOIFODT2015,
title = {Predictors of Response to Web-Based Cognitive Behavioral Therapy With High-Intensity Face-to-Face Therapist Guidance for Depression: A Bayesian Analysis},
journal = {Journal of Medical Internet Research},
volume = {17},
number = {9},
year = {2015},
issn = {1438-8871},
doi = {https://doi.org/10.2196/jmir.4351},
url = {https://www.sciencedirect.com/science/article/pii/S1438887115002137},
author = {Ragnhild Sørensen Høifødt and Matthias Mittner and Kjersti Lillevoll and Susanne Kvam Katla and Nils Kolstrup and Martin Eisemann and Oddgeir Friborg and Knut Waterloo},
keywords = {treatment outcome, computer-assisted therapy, cognitive behavior therapy, depression, primary health care, Bayesian analysis},
abstract = {Background
Several studies have demonstrated the effect of guided Internet-based cognitive behavioral therapy (ICBT) for depression. However, ICBT is not suitable for all depressed patients and there is a considerable level of nonresponse. Research on predictors and moderators of outcome in ICBT is inconclusive.
Objective
This paper explored predictors of response to an intervention combining the Web-based program MoodGYM and face-to-face therapist guidance in a sample of primary care patients with mild to moderate depressive symptoms.
Methods
Participants (N=106) aged between 18 and 65 years were recruited from primary care and randomly allocated to a treatment condition or to a delayed treatment condition. The intervention included the Norwegian version of the MoodGYM program, face-to-face guidance from a psychologist, and reminder emails. In this paper, data from the treatment phase of the 2 groups was merged to increase the sample size (n=82). Outcome was improvement in depressive symptoms during treatment as assessed with the Beck Depression Inventory-II (BDI-II). Predictors included demographic variables, severity variables (eg, number of depressive episodes and pretreatment depression and anxiety severity), cognitive variables (eg, dysfunctional thinking), module completion, and treatment expectancy and motivation. Using Bayesian analysis, predictors of response were explored with a latent-class approach and by analyzing whether predictors affected the slope of response.
Results
A 2-class model distinguished well between responders (74%, 61/82) and nonresponders (26%, 21/82). Our results indicate that having had more depressive episodes, being married or cohabiting, and scoring higher on a measure of life satisfaction had high odds for positively affecting the probability of response. Higher levels of dysfunctional thinking had high odds for a negative effect on the probability of responding. Prediction of the slope of response yielded largely similar results. Bayes factors indicated substantial evidence that being married or cohabiting predicted a more positive treatment response. The effects of life satisfaction and number of depressive episodes were more uncertain. There was substantial evidence that several variables were unrelated to treatment response, including gender, age, and pretreatment symptoms of depression and anxiety.
Conclusions
Treatment response to ICBT with face-to-face guidance may be comparable across varying levels of depressive severity and irrespective of the presence and severity of comorbid anxiety. Being married or cohabiting, reporting higher life satisfaction, and having had more depressive episodes may predict a more favorable response, whereas higher levels of dysfunctional thinking may be a predictor of poorer response. More studies exploring predictors and moderators of Internet-based treatments are needed to inform for whom this treatment is most effective.
Trial Registration
Australian New Zealand Clinical Trials Registry number: ACTRN12610000257066; https://www.anzctr.org.au/trial_view.aspx?id=335255 (Archived by WebCite at http://www.webcitation.org/6GR48iZH4).}
}
@incollection{HARNAD2005817,
title = {Chapter 36 - A GROUNDED MIND IN A ROBOTIC BODY},
editor = {Henri Cohen and Claire Lefebvre},
booktitle = {Handbook of Categorization in Cognitive Science},
publisher = {Elsevier Science Ltd},
address = {Oxford},
pages = {817-820},
year = {2005},
isbn = {978-0-08-044612-7},
doi = {https://doi.org/10.1016/B978-008044612-7/50091-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780080446127500913},
author = {STEVAN HARNAD},
abstract = {Publisher Summary
This chapter presents the important themes of embodied cognition. In the chapter, Poirier and others first point out that minds (and brains) have bodies, and that this is not only unlikely to be incidental, but also most of the things that minds can do, they do with their bodies. Pure thinking, that is cognition, seems in and of itself to be a disembodied mental activity, conducted autonomously inside our heads without any signs of sensorimotor interaction with the world of objects, organisms, states, events, and properties that most of our thoughts are about. But surely whatever pure thinking does go on in our heads occurs in the service of our present and future doings in the world, and is grounded in our past doings. Both Proulx and Hélie, and Cangelosi are concerned with how to give a cognitive system the sensorimotor capacity, which is the capacity to detect, recognize and do the kinds of things that one is able to do with the kinds of things there are in the world. In other words, it is the capacity to categorize. The shapes that objects project on one's sensory surfaces can be processed by neural networks that do what is called unsupervised learning.}
}
@article{PUTICA2024105836,
title = {Reconceptualizing complex posttraumatic stress disorder: A predictive processing framework for mechanisms and intervention},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {164},
pages = {105836},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105836},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424003051},
author = {Andrea Putica and James Agathos},
keywords = {Complex Posttraumatic Stress Disorder (C-PTSD), Predictive processing, Trauma, Interoceptive inference, Active inference},
abstract = {In this article, we introduce a framework for interpreting Complex Posttraumatic Stress Disorder (C-PTSD) through predictive processing, a neuroscience concept explaining the brain’s interpretation and prediction of sensory information. While closely related to PTSD, C-PTSD encompasses additional symptom clusters marked by disturbances in self-organization (DSO), such as negative self-concept, affect dysregulation, and relational difficulties, typically resulting from prolonged traumatic stressors. Our model leverages advances in computational psychiatry and neuroscience, offering a mechanistic explanation for these symptoms by illustrating how prolonged trauma disrupts the brain's predictive processing. Specifically, altered predictive mechanisms contribute to C-PTSD's symptomatology, focusing on DSO: (1) Negative self-concept emerges from maladaptive priors that bias perception towards self-criticism, misaligning expected and actual interoceptive states; (2) Misalignment between predicted and actual interoceptive signals leads to affect dysregulation, with sensitivity to bodily cues; and (3) Relationship challenges arise from skewed social prediction errors, fostering mistrust and withdrawal. This precision-focused approach sheds light on the dynamics underpinning C-PTSD and highlights potential intervention targets aimed at recalibrating the predictive processing system.}
}
@article{DAI2024108354,
title = {Leveraging artificial intelligence (AI) in English as a foreign language (EFL) classes: Challenges and opportunities in the spotlight},
journal = {Computers in Human Behavior},
volume = {159},
pages = {108354},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108354},
url = {https://www.sciencedirect.com/science/article/pii/S074756322400222X},
author = {Kun Dai and Quanguo Liu},
keywords = {Artificial intelligence (AI), AI-Powered instruments, Challenges and opportunities, English as a foreign language (EFL) classes, EFL students},
abstract = {The widespread use of Artificial Intelligence (AI) in language education contexts has motivated several scholars around the world to uncover the advantages and disadvantages of AI and AI-powered instruments in different language classrooms. Yet, as the review of earlier investigations revealed, few inquiries have been carried out to divulge the pros and cons of leveraging AI in EFL classes. To narrow this gap, using the phenomenological approach, this inquiry investigated the opportunities and challenges of implementing AI in EFL classes from the perspective of Chinese EFL students. To do so, through the criterion sampling technique, a total of 45 EFL students was recruited from different educational institutions in China. To collect the dataset, participants were asked to complete an open-ended questionnaire. For the sake of triangulation, among the 45 participants, 15 were randomly selected to engage in a follow-up interview session. With the aid of MAXQDA software (version 2023), participants’ perceptions of AI opportunities and challenges were carefully analyzed. Overall, the analysis findings uncovered that leveraging AI in EFL classes can bring numerous opportunities for EFL students, including individualized learning, timely and immediate feedback, rich educational resources, and an interactive learning atmosphere. However, as demonstrated by the analysis outcomes, implementing AI in EFL courses may also face students with a range of challenges and problems. The research outcomes would be of great help to teachers and educational leaders in mitigating the challenges of leveraging AI in language classrooms.}
}
@incollection{PANDEY202563,
title = {Chapter 4 - Impact of quantum computing on healthcare data security},
editor = {Gayathri Nagasubramanian and S. Rakesh Kumar and Valentina {Emilia Balas}},
booktitle = {Quantum Computing for Healthcare Data},
publisher = {Academic Press},
pages = {63-90},
year = {2025},
series = {Advances in Biomedical Informatics},
isbn = {978-0-443-29297-2},
doi = {https://doi.org/10.1016/B978-0-443-29297-2.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780443292972000022},
author = {Manoj Kumar Pandey and Jyoti Upadhyay and Naresh Kumar Kar and Velliangiri Sarveshwaran},
keywords = {Quantum computing, security, cryptography, healthcare, challenges, sustainable development goals},
abstract = {With the potential to completely transform computation, quantum computing (QC) is a young topic at the vanguard of scientific inquiry and technological advancement. QC promises to bring about dramatic improvements in data security and processing capabilities when it is integrated into healthcare systems. Conventional encryption techniques like RSA and ECC are based on discrete logarithms and integer factorization, two cryptographic issues that are currently unsolvable but can be solved by QC. This trend, however, also makes it more likely that current cryptographic systems will be subject to quantum attacks, which will force the creation and use of encryption methods that are resistant to quantum attacks. Additionally, by employing quantum-resistant hashing techniques, QC enables improved data integrity verification, guaranteeing the veracity and validity of medical data. The applied application of quantum-resistant cryptography techniques and the integration of quantum secure protocols into the current healthcare infrastructure still facing some difficulties therefore anyhow these encouraging advancements in this technique. This chapter focuses on the effect of the QC on the security of healthcare data with particular importance on how it revolutionized encryption, data integrity, privacy protection, and other related issues.}
}
@article{CAGNAC2023,
title = {Codes and methods improvements for safety assessment and LTO: varied approaches},
journal = {EPJ - Nuclear Sciences & Technologies},
volume = {9},
year = {2023},
issn = {2491-9292},
doi = {https://doi.org/10.1051/epjn/2023001},
url = {https://www.sciencedirect.com/science/article/pii/S2491929223000109},
author = {Albannie Cagnac and Denis Verrier and Vladislav Pištora},
abstract = {Nuclear safety has always been at the heart of the concerns of nuclear power plant operators and developers, as well as of various nuclear research organizations and regulatory authorities. Over the last decades, all these nuclear actors have developed and integrated a large number of calculation codes and other tools into their safety work. From the system approach to the local understanding of a phenomenon on a given component, from neutronics to operation optimization for long-term operation, these methods and codes have been constantly evolving since their appearance, in order to be able to integrate new plant designs and components, to improve the results of modeling physical phenomena or quantify and thus reduce the uncertainties on these results. Currently, several H2020 Euratom projects are working on the improvement of these codes and methods. This article will focus on three of these projects: CAMIVVER (Codes And Methods Improvements for VVER comprehensive safety assessment), APAL (Advanced PTS Analysis for LTO), and sCO2-4-NPP (innovative SCO2-based heat removal technology for an increased level of safety of Nuclear Power Plants) in order to illustrate our thinking on the improvement of calculation frameworks. First, we will present the work and the approach adopted with regard to the different calculation codes and methods used in each of these three projects. We will then conclude with an overall analysis of these three approaches, highlighting the difficulties and successes of these three projects, and identifying areas of work for the general improvement of the calculation codes.}
}
@article{SALCEANU2014837,
title = {The Influence of Computer Games on Children's Development. Exploratory Study on the Attitudes of Parents},
journal = {Procedia - Social and Behavioral Sciences},
volume = {149},
pages = {837-841},
year = {2014},
note = {LUMEN 2014 - From Theory to Inquiry in Social Sciences, Iasi, Romania, 10-12 April 2014},
issn = {1877-0428},
doi = {https://doi.org/10.1016/j.sbspro.2014.08.323},
url = {https://www.sciencedirect.com/science/article/pii/S1877042814050368},
author = {Claudia Sălceanu},
keywords = {Computer games, influence on children, positive and negative effects of computer games, parents’ attitudes;},
abstract = {The current study aims to investigate the attitudes of parents (N=1087) regarding the influence of computer games on their children's development in the following aspects: time they spend at the computer to play, types of favourite games, ways of child supervision, benefits and disadvantages of computer games. The results of the research show: 30.47% of children may access the computer anytime they want; the computer is mostly used for games (36.28%); 42.87% of parents supervise their children's activities at the computer only when they have spare time; 50% of parents allow their children to spend 1-2hours at computer games every day, while 28.54% allow 3-4hours (and more) of computer games every day. The biggest benefits of computer games, according to parents, are thinking development (9.60%), observation capacity (8.27%), and creativity (8.01%). The biggest disadvantages of computer games are the lack of physical movement (13.37%), sight disorders (13.15%) and agitation (8.58%). Parents recognize that games can have powerful effects on children, and should therefore set limits on the amount and content of games their children play. In this way, we can realize the potential benefits while minimizing the potential harms.}
}
@article{PERIGNAT201931,
title = {STEAM in practice and research: An integrative literature review},
journal = {Thinking Skills and Creativity},
volume = {31},
pages = {31-43},
year = {2019},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1871187118302190},
author = {Elaine Perignat and Jen Katz-Buonincontro},
keywords = {STEAM education, Creativity, Arts-integration, Transdisciplinary, Interdisciplinary},
abstract = {This integrative review examines 44 published articles (empirical, descriptive, and pedagogical frameworks) on the topic of STEAM (Science, Technology, Engineering, Arts, Mathematics) education from 2007 to 2018. Despite the emergence of STEAM as a popular pedagogical approach for enhancing students’ creativity, problem-solving skills, and interest in STEM fields, the definitions and purposes of STEAM education remain ubiquitous. Therefore, the review examined descriptions of the overall purpose of STEAM education, definitions of the STEAM acronym and the ‘A’ in STEAM, creativity as a learning outcome, elements of arts education, and arts education learning outcomes. The review found a myriad of definitions of the STEAM concept in general, a variety of interpretations for the “A” in STEAM, and an overall lack of reported learning outcomes in the areas of creativity, problem-solving, and arts education. The articles also differentiate in methods for merging STEAM disciplines, described in one of five ways: transdisciplinary, interdisciplinary, multi-disciplinary, cross-disciplinary, and arts-integration. Recommendations are provided to advance both research and practice in STEAM education.}
}
@article{CUSHEN2011458,
title = {Aha! Voila! Eureka! Bilingualism and insightful problem solving},
journal = {Learning and Individual Differences},
volume = {21},
number = {4},
pages = {458-462},
year = {2011},
issn = {1041-6080},
doi = {https://doi.org/10.1016/j.lindif.2011.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1041608011000215},
author = {Patrick J. Cushen and Jennifer Wiley},
keywords = {Bilingualism, Creativity, Insight, Problem solving},
abstract = {What makes a person able to solve problems creatively? One interesting factor that may contribute is experience with multiple languages from an early age. Bilingual individuals who acquire two languages by the age of 6 have been shown to demonstrate superior performance on a number of thinking tasks that require flexibility. However, bilingual advantages have yet to be identified particularly on insight problems that are used as a model of creative problem solving following initial impasse. As such, the goal of the present study was to investigate the influence of language experience on problem solving performance on a matched set of insight and non-insight problems. Results demonstrate an interaction between type of problem (insight versus non-insight) and language status.}
}
@incollection{ZIEGLERRODRIGUEZ2025169,
title = {Chapter 6 - Life cycle assessment of constructed wetlands: measuring their contribution to sustainable development},
editor = {Asheesh Kumar Yadav and Jan Vymazal and Yaqian Zhao and Pratiksha Srivastava},
booktitle = {Emerging Developments in Constructed Wetlands},
publisher = {Elsevier},
pages = {169-193},
year = {2025},
isbn = {978-0-443-14078-5},
doi = {https://doi.org/10.1016/B978-0-443-14078-5.00006-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443140785000064},
author = {Kurt Ziegler-Rodriguez and Marianna Garfí},
keywords = {Sustainable development, life cycle assessment, constructed wetland, biological waste treatment, water management},
abstract = {Life cycle thinking has led to the development of a series of methodologies that evaluate the sustainability of any process, product, or activity, considering the three aspects of sustainable development: the environmental, economic, and social pillars. These methodologies called the (Environmental) Life Cycle Assessment, the Social Life Cycle Assessment and the Life Cycle Costing, have the peculiarity to consider the whole life cycle of a product or process, from the extraction of raw materials to their end of life. At the same time, sustainable development has led to the strengthening of disciplines and novel technologies such as circular bioeconomy, industrial ecology, and nature-based solutions. In this context, constructed wetlands have been gaining popularity since they are a low-cost alternative for urban and industrial wastewater treatment in small communities. The performed life cycle assessments of these technologies have shown that, regardless of the model, configuration, or type of waste treated, they have low environmental impacts compared with conventional solutions (e.g., activated sludge system) due to low energy requirements, no chemicals consumption, and avoidance of off-site management and transportation practices. In terms of costs, constructed wetlands can drastically reduce the costs associated with wastewater treatment and management. However, more efforts should be made in order to define the social benefits of this technology (e.g., local employment generation, landscape improvement) and the quality of the recovered resources (e.g., treated water, fertilizer).}
}
@article{KISAALITA201658,
title = {Perspectives on context, design teams and diffusion of technological innovations in low-resource settings: A practical approach based on sub-Saharan African projects},
journal = {Technology in Society},
volume = {46},
pages = {58-62},
year = {2016},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2016.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X16300495},
author = {William S. Kisaalita},
keywords = {Technological innovations, Sustainable development, Developing countries, Design teams, Poverty alleviation, Food and energy security},
abstract = {A human-centered design approach for creating science/engineering-driven solutions or innovations, referred to as “connect-the-dots,” is presented. Dots symbolize the best questions and the connections reveal the best order in which these questions should be answered. In this approach, the number of customer or user behavioral changes are critically analyzed, revealing the overall context in which the solution or innovation will operate; especially to undergraduate students creating solutions to problems from settings that are less familiar, from cultural, economic, and geopolitical viewpoints. Solutions or innovations that result in minimal user behavior changes are preferred. Additional benefits include better incorporation of systems theory thinking, ease with which team multidisciplinarity and diversity can be identified, and seamlessly integrating design and research.}
}
@article{YIN2022109800,
title = {Deep learning-accelerated optimization algorithm for controller parameters optimization of doubly-fed induction generators},
journal = {Applied Soft Computing},
volume = {131},
pages = {109800},
year = {2022},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2022.109800},
url = {https://www.sciencedirect.com/science/article/pii/S1568494622008493},
author = {Linfei Yin and Xinghui Cao and Senlin Wang},
keywords = {Deep fully connected models, Gray wolf optimizer, Adaptive differential evolution, Global search, Parameter optimization},
abstract = {In this work, a cooperative Gray wolf Optimizer with adaptive differential Evolution (GOE) is proposed for the multimodal controller parameters optimization of doubly-fed induction generators (DFIGs) based on maximum power point tracking (MPPT) strategies. Moreover, the optimization process of the GOE is accelerated by a deep fully connected model (DFCM). The GOE contains a cooperative gray wolf optimizer (GWO) and adaptive differential evolution (ADE). The cooperative GWO contains alpha, beta, delta, and omega wolves to explore and exploit optimization problems and achieves optimization tasks wider and deeper than GWO. The ADE cooperates with the cooperative GWO to solve global optimization over continuous spaces. The simulation results on seven uni-model benchmark functions show that the GOE accelerated by DFCM obtains acceptable fitness values with 39.99% lesser computation time than the symmetry adapted stochastic search (SASS) algorithm and 80.72% lesser computation time than the Lévy flights-success-history based adaptive differential evolution with constraint handling technique (COLSHADE) algorithm, which are the winners of the CEC2020 Competition on Real-World Single Objective Constrained Optimization. Furthermore, the simulation results on DFIG with MPPT strategies in three real-world cases verify that the GOE accelerated by DFCM can effectively obtain global optimization solutions for non-smooth problems with 99.51% lesser average computation time than the SASS algorithm, 99.63% less than the COLSHADE algorithm, and 89.52% less than other methods. In addition, the accelerated GOE algorithm by DFCM has the feature of faster convergence.}
}
@article{BERX2022107827,
title = {Identification and classification of risk factors for human-robot collaboration from a system-wide perspective},
journal = {Computers & Industrial Engineering},
volume = {163},
pages = {107827},
year = {2022},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2021.107827},
url = {https://www.sciencedirect.com/science/article/pii/S0360835221007312},
author = {Nicole Berx and Wilm Decré and Ido Morag and Peter Chemweno and Liliane Pintelon},
keywords = {Human-robot collaboration, Human factors, Industry 4.0, Safety, Risk factors, Socio-technical},
abstract = {Industry 4.0 systems in general and advanced manufacturing systems such as collaborative robots, in particular, are characterized by a high level of complexity leading to new safety concerns. Safety, specifically for collaborative robots, has been mainly addressed from a technical perspective, to safeguard the physical safety of the operator. Concerns have been raised regarding less focus in Industry 4.0 literature on how other factors, such as psychosocial can produce safety-related risks for the operator in human-robot collaboration. This paper identifies and classifies the risk factors in a human-robot collaboration that have been described in research papers in the last decade. The resulting five classes constitute dimensions that will be used as preliminary building blocks for a safety evaluation framework to be developed in the next step. By evaluating the resulting classes with the underlying dimensions of contemporary socio-technical thinking, this paper demonstrates that these five classes offer a comprehensive, system-wide perspective including risk factors beyond technological considerations. Topics emerging from new risks related to the impact of working with collaborative robots, such as psychosocial, ethical, and cyber risk factors will need to be taken into account in the risk factors that are important to identify, assess and mitigate before working with collaborative robots. Operator involvement and participation, especially throughout the risk assessment and mitigation cycle are recommended as new areas of attention in human-robot collaboration. Going forward, one challenge will be the agility and adaptability of legislation to at least keep track of risk factors emerging from continuously changing technologies and to translate them into practically applicable tools for enterprises and design engineers implementing collaborative applications. Another key challenge will be the measurement of the new emerging and sometimes less technological risks.}
}
@incollection{HE2013241,
title = {5.16 - Flood Inundation Dynamics and Socioeconomic Vulnerability under Environmental Change},
editor = {Roger A. Pielke},
booktitle = {Climate Vulnerability},
publisher = {Academic Press},
address = {Oxford},
pages = {241-255},
year = {2013},
isbn = {978-0-12-384704-1},
doi = {https://doi.org/10.1016/B978-0-12-384703-4.00508-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780123847034005086},
author = {Y. He and F. Pappenberger and D. Manful and H. Cloke and P. Bates and F. Wetterhall and B. Parkes},
keywords = {Flood inundation dynamics, Two-faced flood, Model cascade, Uncertainties, Flood vulnerability, Impact studies, Flood risk, Living with floods, Harnessing floods},
abstract = {Floods are a major threat to human existence and historically have both caused the collapse of civilizations and forced the emergence of new cultures. The physical processes of flooding are complex. Increased population, climate variability, change in catchment and channel management, modified landuse and land cover, and natural change of floodplains and river channels all lead to changes in flood dynamics, and as a direct or indirect consequence, social welfare of humans. Section 5.16.1 explores the risks and benefits brought about by floods and reviews the responses of floods and floodplains to climate and landuse change. Section 5.08.2 reviews the existing modeling tools, and the top–down and bottom–up modeling frameworks that are used to assess impacts on future floods. Section 5.08.3 discusses changing flood risk and socioeconomic vulnerability based on current trends in emerging or developing countries and presents an alternative paradigm as a pathway to resilience. Section 5.08.4 concludes the chapter by stating a portfolio of integrated concepts, measures, and avant-garde thinking that would be required to sustainably manage future flood risk.}
}
@article{SIEGELMANN2013117,
title = {Turing on Super-Turing and adaptivity},
journal = {Progress in Biophysics and Molecular Biology},
volume = {113},
number = {1},
pages = {117-126},
year = {2013},
note = {Can Biology Create a Profoundly New Mathematics and Computation?},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2013.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0079610713000278},
author = {Hava T. Siegelmann},
keywords = {Adaptive computation, Biological computation, Super-Turing computation},
abstract = {Biological processes are often compared to computation and modeled on the Universal Turing Machine. While many systems or aspects of systems can be well described in this manner, Turing computation can only compute what it has been programmed for. It has no ability to learn or adapt to new situations. Yet, adaptation, choice and learning are all hallmarks of living organisms. This suggests that there must be a different form of computation capable of this sort of calculation. It also suggests that there are current computational models of biological systems that may be fundamentally incorrect. We argue that the Super-Turing model is both capable of modeling adaptive computation, and furthermore, a possible answer to the computational model searched for by Turing himself.}
}
@article{LI2024124918,
title = {A method of dense point cloud SLAM based on improved YOLOV8 and fused with ORB-SLAM3 to cope with dynamic environments},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124918},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124918},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424017858},
author = {Yanke Li and Huabo Shen and Yaping Fu and Kai Wang},
keywords = {SLAM, VSLAM, Neural Network, Deep learning},
abstract = {With the development of society and the advancement of technology, intelligent robots have been widely used in various fields. At the same time, Simultaneous Localization and Mapping (SLAM) technology is a key technology in the research field of intelligent robots. However, in dynamic environments, achieving accurate and robust visual SLAM remains a major challenge. In this paper, we propose a method based on improved YOLOv8 fused with ORB-SLAM3 to address dense point cloud SLAM in dynamic environments. Our proposed method successfully integrates real-time object detection and image segmentation technologies of YOLOv8 into the ORB-SLAM3 framework, achieving high-precision and robust visual SLAM in dynamic environments. In the YOLOv8 framework, we use a balanced convolution method, GSConv, instead of some traditional convolution layers (Conv), which balances accuracy with computational load. Based on the GSConv convolution method, we adopt a new feature fusion module, VoVGSCSP, to replace traditional C2f feature fusion modules, thereby improving the Neck structure of YOLOv8 and achieving a lightweight network model. We compare our proposed method with ORB-SLAM3 and some computer vision algorithms on the TUM dataset. Experimental data confirms that our method outperforms existing visual SLAM algorithms in dynamic environments. In fast-moving dynamic environments, the RMSE of absolute pose estimation of our method is 96.28% lower than that of ORB-SLAM3, and the RMSE of relative pose estimation is 51.57% lower than that of ORB-SLAM3. The experimental results demonstrate that our method significantly improves the accuracy of pose estimation in dynamic environments and greatly enhances the performance compared to ORB-SLAM3.}
}
@article{TANG2014245,
title = {On the causes of early life experience effects: Evaluating the role of mom},
journal = {Frontiers in Neuroendocrinology},
volume = {35},
number = {2},
pages = {245-251},
year = {2014},
note = {CRH/Stress in Honor of Wylie Vale},
issn = {0091-3022},
doi = {https://doi.org/10.1016/j.yfrne.2013.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S009130221300068X},
author = {Akaysha C. Tang and Bethany C. Reeb-Sutherland and Russell D. Romeo and Bruce S. McEwen},
keywords = {Maternal care, Stress, CORT, HPA, Self-regulation, Novelty, Maternal mediation, Maternal modulation, Early experience, Cognitive development},
abstract = {Early life experiences are thought to have long-lasting effects on cognitive, emotional, and social function during adulthood. Changes in neuroendocrine function, particularly the hypothalamic–pituitary–adrenal (HPA) axis, contribute to these systems-level behavioral effects. In searching for causal mechanisms underlying these early experience effects, pioneering research has demonstrated an important role for maternal care in offspring development, and this has led to two persistent ideas that permeate current research and thinking: first, environmental impact on the developing infant is mediated through maternal care behavior; second, the more care that a mother provides, the better off her offspring. While a good beginning, the reality is likely more complex. In this review, we critically examine these ideas and propose a computationally-motivated theoretical framework, and within this framework, we consider evidence supporting a hypothesis of maternal modulation. These findings may inform policy decisions in the context of child health and development.}
}
@article{BARTOLOZZI2011163,
title = {eMorph: Towards Neuromorphic Robotic Vision},
journal = {Procedia Computer Science},
volume = {7},
pages = {163-165},
year = {2011},
note = {Proceedings of the 2nd European Future Technologies Conference and Exhibition 2011 (FET 11)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2011.09.027},
url = {https://www.sciencedirect.com/science/article/pii/S1877050911005874},
author = {Chiara Bartolozzi and Charles Clercq and Neeraj Mandloi and Francesco Rea and Giacomo Indiveri and Daniel Fasnacht and Giorgio Metta and Michael Hofstätter and Ryad Benosman},
keywords = {neuromorphic, humanoid robot, event-driven computation, vision},
abstract = {The eMorph project aims at introducing a new concept for vision in the field of humanoid robotics. The system that is currently being developed is inspired by the biology of mammalian visual systems, introducing concepts such as stimulus-driven signal acquisition and processing, together with space-variant sensor design coupled with active vision. This approach is leading to the realization of a system that goes beyond current thinking in robotic vision.}
}
@article{PUZANTIAN2021387,
title = {Redesigning a PhD measurement course for a new era in nursing science},
journal = {Journal of Professional Nursing},
volume = {37},
number = {2},
pages = {387-390},
year = {2021},
issn = {8755-7223},
doi = {https://doi.org/10.1016/j.profnurs.2020.04.019},
url = {https://www.sciencedirect.com/science/article/pii/S8755722320300983},
author = {Houry Puzantian and Hala Darwish},
keywords = {Measurement, Quantitative, Nursing research, PhD},
abstract = {Measurement is at the core of the research process. At the PhD level, students need to develop an in-depth understanding of measures relevant to their area of work and refine their knowledge of measurement issues. Traditionally, measurement coursework in Nursing focused on the psychometric evaluation of instruments measuring cognition and behavior. However, in the age of Big Data, precision medicine, and translational science, PhD students need to develop knowledge and skills relevant to these fields and to collaborate with experts from the different disciplines. Therefore, Nursing faculty need to recognize the state-of-the-science of nursing research and tend to a variety of measurement issues across a spectrum of operationalized concepts. Herein we present an overview of learning outcomes, instructional content and methods of delivery for a contemporary PhD-level course on measurement for Nursing Science. We also present our experience in the design, implementation, and evaluation of a novel PhD measurement course.}
}
@article{FIROOZI2025104593,
title = {Developing Urban Infrastructure: Strategic Integration of Solar-Heated Pavement Systems for Enhanced Resilience and Sustainability},
journal = {Results in Engineering},
pages = {104593},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.104593},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025006711},
author = {Ali Akbar Firoozi and Ali Asghar Firoozi and D.O. Oyejobi and Siva Avudaiappan and Erick Saavedra Flores},
keywords = {Solar-Heated Pavements, Urban Resilience, Sustainable Infrastructure, Smart City Technologies, Thermal Energy Storage, Green Urban Planning},
abstract = {This research examines the integration and optimization of solar-heated pavement systems in urban environments, emphasizing their potential to enhance urban resilience and sustainability. Utilizing advanced materials and smart technologies, these pavements maintain safe, ice-free surfaces during winter, reducing reliance on traditional snow removal methods and their environmental impacts. The methodology focuses on a combination of experimental setups and computational simulations to analyze the design features, material advancements, and strategic integration of these systems. Quantitative findings from case studies across diverse climates demonstrate a significant reduction in energy consumption by up to 40% and maintenance costs by 60%, highlighting the economic and environmental benefits. The manuscript advocates broader implementation and recommends further research to optimize system efficiency and applicability in urban planning initiatives.}
}
@article{KAFUKU2019192,
title = {Application of Fuzzy Logic in Selection of Remanufacturing Technology},
journal = {Procedia Manufacturing},
volume = {33},
pages = {192-199},
year = {2019},
note = {Sustainable Manufacturing for Global Circular Economy: Proceedings of the 16th Global Conference on Sustainable Manufacturing},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2019.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S2351978919305001},
author = {John Mbogo Kafuku and Muhamad Zameri {Mat Saman} and Sha’ri Mohd Yusof},
keywords = {Remanufacturing Operations, Technology Selection, Fuzzy Logic, Technology Selection Criteria, Fuzzy Decision Tool},
abstract = {Fuzzy approach is frequently used for selection of manufacturing technology. However, the application of the fuzzy tool for choosing the appropriate remanufacturing technology is seldom applied. This study applies the fuzzy logic approach for the selection of technology in order to minimize vagueness in decision making, thereby making results more similar to experts’ thinking. Through elicitation of experts’ inputs, six cleaning technologies were evaluated and ranked appropriately, using criteria of technology cost, operating cost, and disposal effect. Moreover, the technology selection was computed through experts’ opinion using the fuzzy logic inference system. The results show that when technical function of the technology is at the low level of 20%, the technology quality is as low as 15%, and the technology flexibility is rated as low at 25%; then the technical adequacy of the assessed technology will be as low as 10%. The fuzzy approach shows that technology performance is largely impacted by criteria far beyond the technology itself, including purchasing cost, disposal cost, operating cost, and other support functions to compliment experience of experts. Despite the fact that decision makers are appropriately selecting technology, the application of the fuzzy logic tool helps to accommodate vagueness, ambiguity, and subjective views of experts. Notwithstanding the robustness of the approach, application of software to help selection of technology is more reliable and accurate, reduce time of decision, and can be accessed worldwide.}
}
@article{KONOVALOV20213323,
title = {Dissecting functional contributions of the social brain to strategic behavior},
journal = {Neuron},
volume = {109},
number = {20},
pages = {3323-3337.e5},
year = {2021},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2021.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0896627321005699},
author = {Arkady Konovalov and Christopher Hill and Jean Daunizeau and Christian C. Ruff},
keywords = {fMRI, TPJ, dmPFC, social, decision making, strategic},
abstract = {Summary
Social interactions routinely lead to neural activity in a “social brain network” comprising, among other regions, the temporoparietal junction (TPJ) and the dorsomedial prefrontal cortex (dmPFC). But what is the function of these areas? Are they specialized for behavior in social contexts or do they implement computations required for dealing with any reactive process, even non-living entities? Here, we use fMRI and a game paradigm separating the need for these two aspects of cognition. We find that most social-brain areas respond to both social and non-social reactivity rather than just to human opponents. However, the TPJ shows a dissociation from the dmPFC: its activity and connectivity primarily reflect context-dependent outcome processing and reactivity detection, while dmPFC engagement is linked to implementation of a behavioral strategy. Our results characterize an overarching computational property of the social brain but also suggest specialized roles for subregions of this network.}
}
@article{BARFAR2019173,
title = {Cognitive and affective responses to political disinformation in Facebook},
journal = {Computers in Human Behavior},
volume = {101},
pages = {173-179},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.07.026},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219302699},
author = {Arash Barfar},
keywords = {Political disinformation, Polarization, Echo chamber, Text analysis, Social media, Facebook},
abstract = {The epidemic of political disinformation in social media has in part triggered the transition to the post-truth era in which emotional and ideological appeals are more influential in shaping public opinion than objective facts. In this study we examined the cognitive and affective responses that political disinformation prompted in Facebook, as the most popular social media platform. Through text analysis of user comments corpora on nearly 2,100 political posts from popular sources in Facebook, we found that compared to true news, political disinformation received significantly less analytic responses from Facebook followers. While the results indicated greater anxiety in responses to true news, responses to political disinformation were filled with greater anger and incivility. We also found similar (low) levels of cognitive thinking in responses to extreme conservative and extreme liberal disinformation. Contrary to prior research findings, our results indicated that responses to extreme liberal disinformation in Facebook were filled with greater anger and incivility. This suggests that the incivility and outrage in online political discourses should not be attributed to a specific political party without considering the concurrent political events.}
}
@article{HAMDI2019772,
title = {Fuzzy Approach for Locating Sensors in Industrial Internet of Things},
journal = {Procedia Computer Science},
volume = {160},
pages = {772-777},
year = {2019},
note = {The 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.11.012},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919317120},
author = {Sarah El Hamdi and Mustapha Oudani and Abdellah Abouabdellah and Anass Sebbar},
keywords = {I2oT, Architecture, Fuzzy Theory},
abstract = {Nowadays, in this era of a data driven thinking and reflection, data mining and data analysis are keys to any business survival in a competitive conjectural market. The internet of things is an emerging technology that manages to create a path for the new generation of industrial production system. This advanced technology is requirement to the proliferation of Smart factories, it represents the best tool to help this new concept of plants to organize themselves and optimize the available resources and their consumption. The purpose of this paper is two-pronged; a proposal for an architectural framework of the industrial internet of things, and a mathematical formulation based on fuzzy logic to determine the ideal location of sensors at the shop floor taking into consideration several restrictions.}
}
@article{STRATFORD2022115813,
title = {Exploring the potential neurotoxicity of vaping vitamin E or vitamin E acetate},
journal = {Toxicology and Applied Pharmacology},
volume = {434},
pages = {115813},
year = {2022},
issn = {0041-008X},
doi = {https://doi.org/10.1016/j.taap.2021.115813},
url = {https://www.sciencedirect.com/science/article/pii/S0041008X21004178},
author = {Kimberly Stratford and Prabha Kc and Susan Rudy and Anna-Sophie Weidner and Priscilla Callahan-Lyon and Luis G. Valerio},
keywords = {Pulmonary injury, Electronic Nicotine Delivery Systems (ENDS), Tobacco products, Electronic cigarettes, Vitamin E, Vitamin E acetate, E-Cigarette or Vaping Product Use-Associated Lung Injury (EVALI), Vaping, Neurotoxicity, Computational model},
abstract = {Serious adverse health effects have been reported with the use of vaping products, including neurologic disorders and e-cigarette or vaping product use-associated lung injury (EVALI). Vitamin E acetate, likely added as a diluent to cannabis-containing products, was linked to EVALI. Literature searches were performed on vitamin E and vitamin E acetate-associated neurotoxicity. Blood brain barrier (BBB) penetration potential of vitamin E and vitamin E acetate were evaluated using cheminformatic techniques. Review of the literature showed that the neurotoxic potential of inhalation exposures to these compounds in humans is unknown. Physico-chemical properties demonstrate these compounds are lipophilic, and molecular weights indicate vitamin E and vitamin E acetate have the potential for BBB permeability. Computational models also predict both compounds may cross the BBB via passive diffusion. Based on literature search, no experimental nonclinical studies and clinical information on the neurotoxic potential of vitamin E via inhalation. Neurotoxic effects from pyrolysis by-product, phenyl acetate, structurally analogous to vitamin E acetate, suggests vitamin E acetate has potential for central nervous system (CNS) impairment. Cheminformatic model predictions provide a theoretical basis for potential CNS permeability of these inhaled dietary ingredients suggesting prioritization to evaluate for potential hazard to the CNS.}
}
@article{ROOTESMURDY2024100987,
title = {Cortical similarities in psychiatric and mood disorders identified in federated VBM analysis via COINSTAC},
journal = {Patterns},
volume = {5},
number = {7},
pages = {100987},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.100987},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924001028},
author = {Kelly Rootes-Murdy and Sandeep Panta and Ross Kelly and Javier Romero and Yann Quidé and Murray J. Cairns and Carmel Loughland and Vaughan J. Carr and Stanley V. Catts and Assen Jablensky and Melissa J. Green and Frans Henskens and Dylan Kiltschewskij and Patricia T. Michie and Bryan Mowry and Christos Pantelis and Paul E. Rasser and William R. Reay and Ulrich Schall and Rodney J. Scott and Oliver J. Watkeys and Gloria Roberts and Philip B. Mitchell and Janice M. Fullerton and Bronwyn J. Overs and Masataka Kikuchi and Ryota Hashimoto and Junya Matsumoto and Masaki Fukunaga and Perminder S. Sachdev and Henry Brodaty and Wei Wen and Jiyang Jiang and Negar Fani and Timothy D. Ely and Adriana Lorio and Jennifer S. Stevens and Kerry Ressler and Tanja Jovanovic and Sanne J.H. {van Rooij} and Lydia M. Federmann and Christiane Jockwitz and Alexander Teumer and Andreas J. Forstner and Svenja Caspers and Sven Cichon and Sergey M. Plis and Anand D. Sarwate and Vince D. Calhoun},
keywords = {transdiagnostic, federated analysis, COINSTAC, psychiatric disorders, regression, mood disorders, decentralized, gray matter, PTSD, mild cognitive impairment},
abstract = {Summary
Structural neuroimaging studies have identified a combination of shared and disorder-specific patterns of gray matter (GM) deficits across psychiatric disorders. Pooling large data allows for examination of a possible common neuroanatomical basis that may identify a certain vulnerability for mental illness. Large-scale collaborative research is already facilitated by data repositories, institutionally supported databases, and data archives. However, these data-sharing methodologies can suffer from significant barriers. Federated approaches augment these approaches by enabling access or more sophisticated, shareable and scaled-up analyses of large-scale data. We examined GM alterations using Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation, an open-source, decentralized analysis application. Through federated analysis of eight sites, we identified significant overlap in the GM patterns (n = 4,102) of individuals with schizophrenia, major depressive disorder, and autism spectrum disorder. These results show cortical and subcortical regions that may indicate a shared vulnerability to psychiatric disorders.}
}
@article{BARTELS2008381,
title = {Principled moral sentiment and the flexibility of moral judgment and decision making},
journal = {Cognition},
volume = {108},
number = {2},
pages = {381-417},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2008.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010027708000607},
author = {Daniel M. Bartels},
keywords = {Morality, Judgment, Decision making, Values, Ethics, Intuition, Emotions, Reasoning, Moral rules, Moral dilemmas},
abstract = {Three studies test eight hypotheses about (1) how judgment differs between people who ascribe greater vs. less moral relevance to choices, (2) how moral judgment is subject to task constraints that shift evaluative focus (to moral rules vs. to consequences), and (3) how differences in the propensity to rely on intuitive reactions affect judgment. In Study 1, judgments were affected by rated agreement with moral rules proscribing harm, whether the dilemma under consideration made moral rules versus consequences of choice salient, and by thinking styles (intuitive vs. deliberative). In Studies 2 and 3, participants evaluated policy decisions to knowingly do harm to a resource to mitigate greater harm or to merely allow the greater harm to happen. When evaluated in isolation, approval for decisions to harm was affected by endorsement of moral rules and by thinking style. When both choices were evaluated simultaneously, total harm – but not the do/allow distinction – influenced rated approval. These studies suggest that moral rules play an important, but context-sensitive role in moral cognition, and offer an account of when emotional reactions to perceived moral violations receive less weight than consideration of costs and benefits in moral judgment and decision making.}
}
@incollection{BURATTINI20021315,
title = {37 - Hybrid Expert Systems: An Approach to Combining Neural Computation and Rule-Based Reasoning},
editor = {Cornelius T. Leondes},
booktitle = {Expert Systems},
publisher = {Academic Press},
address = {Burlington},
pages = {1315-1354},
year = {2002},
isbn = {978-0-12-443880-4},
doi = {https://doi.org/10.1016/B978-012443880-4/50081-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780124438804500818},
author = {Ernesto Burattini and Massimo {De Gregorio} and Guglielmo Tamburrini},
abstract = {Publisher Summary
This chapter examines an approach that integrates neural computation and rule-based reasoning, or the hybrid systems. This integration is actively applied in artificial intelligence and cognitive sciences, such as linguistic theory, natural language processing, and expert systems. The opportunity of employing neural techniques in expert systems is often suggested on the ground that the learning, generalization, fault, and noise tolerance capacities of neural networks can alleviate well-known shortcomings of symbolic problem solvers, such as brittleness in front of incomplete or noisy data, no increase in performance with experience, and time-consuming knowledge acquisition. This chapter explores neurosymbolic integration for rule-based expert systems in connection with automatic data acquisition, rule processing, and explanation. At the periphery of expert systems, sensory processing by neural nets is coupled to rule-based reasoning in order to perform a data acquisition task involving the deployment of expert knowledge and heuristic problem solving. The reaction times of rule-based systems are dramatically reduced by the use of a neurally inspired, parallel inference engine. Informative user interactions with expert systems are achieved by coupling symbolic and neurally supported, pictorial explanation. The relative significance of these aspects of neurosymbolic integration is enhanced by pointing to limitations of neural techniques for automatic knowledge acquisition and robust problem solving in expert systems. These uses of neural nets may often jeopardize an expert system's reliability and reduce its transparency to the user.}
}
@incollection{LEVY1989243,
title = {A Computational Approach to Hippocampal Function},
editor = {Robert D. Hawkins and Gordon H. Bower},
series = {Psychology of Learning and Motivation},
publisher = {Academic Press},
volume = {23},
pages = {243-305},
year = {1989},
booktitle = {Computational Models of Learning in Simple Neural Systems},
issn = {0079-7421},
doi = {https://doi.org/10.1016/S0079-7421(08)60113-9},
url = {https://www.sciencedirect.com/science/article/pii/S0079742108601139},
author = {William B Levy},
abstract = {Publisher Summary
This chapter describes the early, formative stages of a theory of hippocampal function. This theory has been stimulated by the psychological observations indicating a role for the hippocampus in short-term working memory and spatial behavior and develops mainly through the consideration of computational issues. These computational issues are related to the psychological viewpoint through physiological and anatomical observations. The hippocampus participates in the prediction of future representations based on past and present representations. All three classes of representations are derived from a multiplicity of sensory modalities, such as auditory, visual, and olfactory signals from neo- and piriform cortices. This fusion of sensory modalities requires recoding because of computational complexity problems. The CA1 region of the hippocampus is postulated to be a prediction-generating layer or tier. This region produces a prediction based on its input from hippocampal region CA3. The combined hippocampal dentate gyrus/CA3 (DG/CA3) system is postulated to be a preprocessor serving the CA1 prediction layer. The computational complexity problems arise from the combinatorial explosion of possible representations resulting when the hippocampus and supporting limbic structures mix representations from multiple sensory modalities.}
}
@article{AKANDA2025112329,
title = {Understanding comment practices in Scratch: A study of comments in a block-based visual programming language},
journal = {Journal of Systems and Software},
volume = {222},
pages = {112329},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112329},
url = {https://www.sciencedirect.com/science/article/pii/S016412122400373X},
author = {Wahiduzzaman Akanda and James Clause},
keywords = {Comment, Text-based programming, Visual programming, Scratch, Taxonomy},
abstract = {Comments are vital for software documentation. They provide necessary insights and assist developers in understanding and maintaining the software. Due to their importance, comments have been extensively studied, and much has been learned about them. These existing studies have predominantly focused on text-based languages. Conversely, block-based visual programming languages, particularly Scratch, are becoming increasingly popular. Some studies regarding comments related to the Scratch online community focus on topics such as fostering online community and engagement, sentiment analysis, etc. However, they overlook the visual aspects and the qualitative analysis of comments within code in Scratch projects. This is a meaningful limitation, and this research project studies comments and their pattern in Scratch projects from both textual and visual perspectives. We examined comments collected from different Scratch projects. Each comment was manually annotated based on textual and visual attributes, producing a taxonomy model of comments for a visual programming language. The classification results were analyzed to understand better the practice of commenting in Scratch. Our result revealed that Scratch projects produced noisier(i.e., less understandable) comments than text-based programming languages like Java. In addition, the study also revealed several limitations and shortcomings that could be addressed to improve the commenting experience in Scratch.}
}
@article{SHI2023926,
title = {Decoding Human Biology and Disease Using Single-cell Omics Technologies},
journal = {Genomics, Proteomics & Bioinformatics},
volume = {21},
number = {5},
pages = {926-949},
year = {2023},
issn = {1672-0229},
doi = {https://doi.org/10.1016/j.gpb.2023.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1672022923001043},
author = {Qiang Shi and Xueyan Chen and Zemin Zhang},
keywords = {Single-cell omics, Computational method, Cellular heterogeneity, Disease, Cancer research},
abstract = {Over the past decade, advances in single-cell omics (SCO) technologies have enabled the investigation of cellular heterogeneity at an unprecedented resolution and scale, opening a new avenue for understanding human biology and disease. In this review, we summarize the developments of sequencing-based SCO technologies and computational methods, and focus on considerable insights acquired from SCO sequencing studies to understand normal and diseased properties, with a particular emphasis on cancer research. We also discuss the technological improvements of SCO and its possible contribution to fundamental research of the human, as well as its great potential in clinical diagnoses and personalized therapies of human disease.}
}
@article{WANG19951,
title = {Peripheral dynamics of the Cl + CH4 → HCl + CH3 reaction. A classical trajectory computation},
journal = {Chemical Physics},
volume = {197},
number = {1},
pages = {1-17},
year = {1995},
issn = {0301-0104},
doi = {https://doi.org/10.1016/0301-0104(95)00134-A},
url = {https://www.sciencedirect.com/science/article/pii/030101049500134A},
author = {Xuebin Wang and M. Ben-Nun and R.D. Levine},
abstract = {The Cl + CH4 → HCl + CH3 reaction is expected to provide a prototype of a peripheral mechanism. This proposal is examined via a classical trajectory computation using a number of model potentials in which the degrees of freedom which do not take part in the net reaction are, or are not, frozen. The models include a full six-atom potential. The essential features of the dynamics are not sensitive to the level of detail with which the CH3 is described, showing that the intramolecular dynamics of the radical do not significantly affect the dynamics of the reactive event. The reaction is found to proceed by two distinct mechanisms: for trajectories with a large impact parameter, a very short lived complex is formed and dissociates to a rotationally cold HCl product, scattered into the forward direction. At smaller impact parameters, the reaction proceeds via a direct mechanism with a rotationally hot HCl which is scattered backward. The computed angular distribution is in agreement with the experiment, which detects HCl in the j = 1, 3 states and suggests that higher rotational states of HCl, which were not probed in the experiment, will also be scattered backward. The role of the initial vibrational excitation of CH4 is discussed.}
}
@incollection{KRAWCZYK2018101,
title = {Chapter 5 - Reasoning Origins: Human Development During Childhood},
editor = {Daniel C. Krawczyk},
booktitle = {Reasoning},
publisher = {Academic Press},
pages = {101-129},
year = {2018},
isbn = {978-0-12-809285-9},
doi = {https://doi.org/10.1016/B978-0-12-809285-9.00005-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128092859000053},
author = {Daniel C. Krawczyk},
keywords = {Analogies, Causal reasoning, Decision making, Development, Developmental stages, Moral reasoning, Relational reasoning},
abstract = {The developmental process is remarkably dynamic. The process is both a biological one and an environmental one with both factors frequently contributing to the output of increasingly sophisticated and abstract reasoning behavior. Children begin with a process of cortical thickening as large numbers of synaptic connections are formed. From age three onward, the cortex undergoes a tuning process as some synaptic connections strengthen and others weaken. The net result of this process is a decrease in cortical volume from age 5 through 20. Children's thinking is guided by a variety of factors. The context of a problem becomes a significant factor in determining how children will reason and developmental reasoning studies require sensitivity toward making the experimental stimuli understandable and interesting to the child. Children exhibit some competencies in causal reasoning and learning from a very young age. Children show increasing reasoning abilities as they develop. Skills such as relational and analogical reasoning grow during the elementary school years and are supported by increases in cognitive control and decreases in impulsivity. The child becomes less concrete in how he or she views and interacts with the world. This increasing abstraction ability encompasses semantic knowledge, deduction, and moral thinking.}
}
@article{FERRES2025,
title = {AI in the Era of GPT: Transforming the Future of Work and Discovery},
journal = {Journal of the American College of Radiology},
year = {2025},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2025.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S1546144025001097},
author = {Juan M.Lavista Ferres and Elliot K. Fishman and Linda C. Chu and Felipe Lopez-Ramirez and Charles K. Crawford and Steven P. Rowe}
}
@article{ALBALAWI201712033,
title = {Distributed Economic MPC with Safety-Based Constraints for Nonlinear Systems**Financial support from the National Science Foundation and the Department of Energy is gratefully acknowledged.},
journal = {IFAC-PapersOnLine},
volume = {50},
number = {1},
pages = {12033-12040},
year = {2017},
note = {20th IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2017.08.2098},
url = {https://www.sciencedirect.com/science/article/pii/S2405896317327581},
author = {Fahad Albalawi and Helen Durand and Panagiotis D. Christofides},
keywords = {Process safety, distributed model predictive control, computation time},
abstract = {Promoting process safety of chemical processes while operating them in an economically-optimal manner is a matter of great importance. In Albalawi et al. (2016), a safety-based economic model predictive control methodology (safety-EMPC) was developed to operate nonlinear processes in an economically-optimal manner while maintaining process safety and closed-loop stability. However, the safety-EMPC control strategy was developed with a centralized economic model predictive control (EMPC) structure; thus, computation time limitations within a sampling period may reduce the effectiveness of such a controller design for promoting process safety. Alternatively, we develop in this work sequential and iterative safety-based distributed EMPC schemes (safety-DEMPC) that may overcome the computation time limitations of the centralized safety-EMPC while maintaining similar closed-loop performance. Using a catalytic reactor example, the two proposed safety-DEMPC schemes were demonstrated to achieve similar closed-loop performance to the centralized safety-EMPC while reducing the on-line computation time requirements compared to the centralized safety-EMPC.}
}
@article{CRAGG1974315,
title = {Thinking about the future: A critique of the limits to growth: Edited by H. S. D. Cole, Christopher Freeman, Marie Jahoda & K. L. R. Pavitt. Chatto & Windus for Sussex University Press, London: 218 pp., £3.00, 1973},
journal = {Biological Conservation},
volume = {6},
number = {4},
pages = {315-316},
year = {1974},
issn = {0006-3207},
doi = {https://doi.org/10.1016/0006-3207(74)90014-7},
url = {https://www.sciencedirect.com/science/article/pii/0006320774900147},
author = {J.B. Cragg}
}
@article{SALEM2025141924,
title = {Novel eco-friendly nicotinonitrile derivative as a corrosion inhibitor for carbon steel: Synthesis, inhibitive efficiency, and DFT analysis},
journal = {Journal of Molecular Structure},
volume = {1335},
pages = {141924},
year = {2025},
issn = {0022-2860},
doi = {https://doi.org/10.1016/j.molstruc.2025.141924},
url = {https://www.sciencedirect.com/science/article/pii/S0022286025006106},
author = {Aya M. Salem and Ahmed Nassef and Ahmed M. Wahba and Samar M. Mohammed},
keywords = {Corrosion, Inhibition, C-steel, HCl, Nicotinonitrile derivatives, Langmuir isotherm},
abstract = {Two new variations of Nicotinonitrile were synthesized, namely: "4-(4-Chlorophenyl)-3-cyano-6-(thien-2-yl)-1H-pyridin-2-one (3A) and 4-(4-Chlorophenyl)-2-oxo-1-(prop‑2-yn-1-yl)-6-(thien-2-yl)-1,2-dihydropyridine-3-carbonitrile (4A). The chemical structures were examined and confirmed using IR and 1H NMR. This method's notable features include being solvent-free, catalyst-free, economical, and having great yields without the need for a catalyst. These compounds were then evaluated as corrosion inhibitors for carbon steel (CS) in 1 M HCl media. Both weight loss (WL) and electrochemical methods such as potentiodynamic polarization (PDP) and electrochemical impedance spectroscopy (EIS) were employed for the investigation. The synthesis and assessment of a novel series of organic compounds with related chemical structures as hydrochloric acid corrosion inhibitors of C-steel is a novel aspect of this study. The results showed that the Nicotinonitrile derivatives were effective corrosion inhibitors, with inhibition efficiencies ( %η) of 86.4 % and 90.7 % for 3A and 4A, respectively, at a concentration of 15×10−5 M. Theoretical computations are applied using the density functional theory. The experiments' findings show that these compounds are effective corrosion inhibitors, and that the concentration of the substances increases the inhibition efficiency. When compared to 3A, the 4A molecule has the maximum efficiency. Monte Carlo simulations and quantum chemical calculations were also performed to analyse and discuss the behaviour of these derivatives. Surface analysis using Scanning Electron Microscopy (SEM) and Energy Dispersive X-ray (EDX) was conducted to verify the results obtained from atomic force microscope measurements. Excellent agreement is found between the outcomes of theoretical computations and experimental measurements.}
}
@incollection{TANQUE202113,
title = {Chapter 2 - Knowledge Representation and Reasoning in AI-Based Solutions and IoT Applications},
editor = {Gurjit Kaur and Pradeep Tomar and Marcus Tanque},
booktitle = {Artificial Intelligence to Solve Pervasive Internet of Things Issues},
publisher = {Academic Press},
pages = {13-49},
year = {2021},
isbn = {978-0-12-818576-6},
doi = {https://doi.org/10.1016/B978-0-12-818576-6.00002-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128185766000022},
author = {Marcus Tanque},
keywords = {Artificial intelligence, machine learning, intelligent machine, artificial neural networks, cognitive science, deep learning, artificial general networks, knowledge representation, and reasoning, cognitive informatics, Internet of Things},
abstract = {Artificial intelligence (AI)-based solutions, knowledge representation and reasoning, and the Internet of Things applications have transformed how researchers and practitioners view the analytical and computational capabilities. The disruptive evolution of these technologies has encouraged researchers and practitioners to develop integrated AI-based analytical solutions needed for solving pervasive issues affecting computational applications. The capabilities include AI, knowledge Representation and Reasoning and Internet of Things. Such capabilities are designed to support AI-based solutions, knowledge representation and reasoning, and the Internet of Things (IoT) applications. These technology trends involve relevant computational areas, that is, intelligent devices, sensors, autonomous vehicles, robotics, virtual reality, augmented intelligence, and others. The study addresses and validates solutions on how researchers can solve issues that affect AI, knowledge representation and reasoning, and IoT applications.}
}
@article{AIROLDI2024101864,
title = {The nested relationality of perceived legitimacy: Mapping taste hierarchies with granular digital traces},
journal = {Poetics},
volume = {102},
pages = {101864},
year = {2024},
issn = {0304-422X},
doi = {https://doi.org/10.1016/j.poetic.2024.101864},
url = {https://www.sciencedirect.com/science/article/pii/S0304422X24000032},
author = {Massimo Airoldi},
keywords = {Taste, Cultural hierarchies, Music classification, Youtube, Digital traces},
abstract = {The article has a double purpose. On the one hand, it contributes to theories of cultural legitimacy and classification. Based on data about consumers’ music evaluations, it shows that taste hierarchies are configured as nested and relational classificatory systems. Nested, because rank systems of symbolic value are collectively recognized, reproduced, and negotiated by consumers not only at the level of genres, but also at lower, nested levels – e.g., sub-genre, artist, single artwork; relational, because the value attributed to music by consumers is ordinarily assessed and constructed through analogies and comparisons, and partly depends on the classifier's relative position in the social space. On the other hand, this paper makes a key methodological contribution: by analyzing large amounts of YouTube data through computational methods and in combination with survey data, it illustrates how the granularity of digital traces can advance sociological research on cultural categories, meaning structures and symbolic imaginaries.}
}
@article{YANG2025105265,
title = {Harmony in diversity: Digital literacy research in a multidisciplinary landscape},
journal = {Computers & Education},
volume = {230},
pages = {105265},
year = {2025},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2025.105265},
url = {https://www.sciencedirect.com/science/article/pii/S0360131525000338},
author = {Feng Yang and Ruiyang Yao and Yunyue Ren and Luxuan Guo},
keywords = {Information literacy, Interdisciplinary projects, Applications in subject areas, Bibliometrics},
abstract = {The advent of the digital era has significantly heightened interest in digital literacy across multidisciplinary backgrounds and has endowed these fields with interdisciplinary and integrative characteristics. In this study, we employed VOSviewer and Bibliometrix for bibliometric and descriptive analyses of digital literacy, and we analyzed 3005 records from the Social Science Citation Index and Science Citation Index. We constructed keyword co-occurrence time networks across five distinct research areas and supplemented them with keyword co-occurrence frequencies to examine similarities and differences between research themes from diverse disciplinary perspectives. The findings of this study indicate that although various fields recognize the significance of digital literacy, different fields prioritize different aspects. As the main field of research, Education & Educational Research focus primarily on the pedagogical practices of cultivating digital literacy, whereas Communication emphasizes the cultivation of digital literacy to address challenges in information dissemination. Information Science & Library Science typically view libraries as central to digital literacy. Moreover, Computer Science research emphasizes the leveraging of technology, whereas Psychology explores the connection between digital literacy and cognitive processes. Analyzing the differences between different disciplines and drawing new ideas from them is of great significance for Education & Educational Research regarding how to deepen digital literacy education content, construct digital literacy education contexts, integrate digital literacy education resources, narrow the digital divide, and promote educational equity in the future.}
}
@article{DEMSAR2007551,
title = {Investigating visual exploration of geospatial data: An exploratory usability experiment for visual data mining},
journal = {Computers, Environment and Urban Systems},
volume = {31},
number = {5},
pages = {551-571},
year = {2007},
note = {Geospatial Analysis and Modeling},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2007.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0198971507000579},
author = {Urška Demšar},
keywords = {Exploratory geovisualisation, Visual data mining, Exploratory usability},
abstract = {This study presents a small exploratory usability experiment with the goal to observe how people visually explore geospatial data. The well-known iris dataset from pattern recognition was put into geographical context for this experiment, in order to provide the participants with a dataset with easily observable spatial and other relationships. The participants were given free hand to explore this dataset with a visual data mining system in any way they liked. The protocols collected during the experiment with the thinking-aloud method were analysed with the aim to understand what types of hypotheses the participants formed, which visualisations they used to either derive, confirm or reject their hypotheses and what exploration strategies they adopted.}
}
@article{CONRAD1991316,
journal = {Bulletin of Mathematical Biology},
volume = {53},
number = {1},
pages = {316-318},
year = {1991},
issn = {0092-8240},
doi = {https://doi.org/10.1016/S0092-8240(05)80052-7},
url = {https://www.sciencedirect.com/science/article/pii/S0092824005800527},
author = {Michael Conrad}
}
@article{FISCHLER1987257,
title = {Parallel guessing: A strategy for high-speed computation},
journal = {Pattern Recognition},
volume = {20},
number = {2},
pages = {257-263},
year = {1987},
issn = {0031-3203},
doi = {https://doi.org/10.1016/0031-3203(87)90059-8},
url = {https://www.sciencedirect.com/science/article/pii/0031320387900598},
author = {M.A. Fischler and O. Firschein},
keywords = {Parallel processing, Image analysis algorithms, Image processing, Architectures},
abstract = {Conventional approaches to speeding up image understanding computation involving conventional serial algorithms attempt to decompose these algorithms into portions that can be computed in parallel. Because many classes of algorithms do not readily decompose, one seeks some other basis for parallelism. In this paper we argue that “parallel guessing” for image analysis is a useful approach, and that several recent scene analysis algorithms are based on this concept. Problems suitable for this approach have the characteristic that either “distance” from a true solution, or the correctness of a guess, can be readily checked. We review image analysis algorithms that have a parallel guessing or randomness flavor.}
}
@article{GIORGI2024119928,
title = {Embedding parametric resonance in a 2:1 wave energy converter to get a broader bandwidth},
journal = {Renewable Energy},
volume = {222},
pages = {119928},
year = {2024},
issn = {0960-1481},
doi = {https://doi.org/10.1016/j.renene.2023.119928},
url = {https://www.sciencedirect.com/science/article/pii/S0960148123018438},
author = {Giuseppe Giorgi},
keywords = {2:1 parametric resonance, Parametric instability, Wave energy converter, Nonlinear Froude–Krylov force},
abstract = {The effort to increase the converted power is a common challenge to players in the field of wave energy conversion, both academic and industrial. In the case devices are found to be prone to parametric resonance, it typically has a negative impact on power harvesting and may jeopardize the reliability of the device. This paper makes the case that parametric resonance is not a danger that should be avoided, but rather a chance to achieve a broader system response bandwidth and ultimately increase the amount of power available at the power take-off. Since a time-varying wetted surface causes the highly nonlinear phenomenon of parametric resonance, linear models are unable to fully capture this instability. As a result, nonlinear Froude–Krylov forces are herein implemented via a computationally effective method for prismatic floaters that is compatible with both exhaustive simulation methods and real-time computing, as the whole simulations runs up to 50 times faster than real-time. A novel pendulum-based device is intentionally defined to exhibit a 2:1 ratio between heave and pitch natural frequencies, causing parametric instability. Results demonstrate that linear models predict a single zone of meaningful potential power extraction around the pitch natural frequency, as expected; however, by using the designed attitude to develop parametric instability, a second additional region develops near the heave natural period. As a result, the free response bandwidth is in fact increased, making more energy available at the power take-off axis thanks to the nonlinear instability embedded in the wave energy converter.}
}
@article{REN2025109484,
title = {A multi-criteria decision-making method based on discrete Z-numbers and Aczel-Alsina aggregation operators and its application on early diagnosis of depression},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109484},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109484},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624016427},
author = {Dong Ren and Xiuqin Ma and Hongwu Qin and Siyue Lei and Xuli Niu},
keywords = {Multi-criteria decision-making, Fuzzy sets, Discrete Z-numbers, Aczel-alsina aggregation operator},
abstract = {In mental health diagnostics, the questionnaire is an effective and cost-effective method. However, the traditional questionnaire test methods for depression and anxiety have great ambiguity. The discrete Z-numbers (DZs) provide solutions for describing and resolving complex fuzzy issues in the intelligent multi-criteria decision-making (MCDM) process. However, large-scale datasets are not suited for the present MCDM techniques due to their extremely high computational cost. Additionally, these techniques are less stable and flexible. To address the above issues, a novel MCDM method is introduced, which is based on the DZs theory and the Aczel-Alsina (AA) aggregation operator (AO) for large-scale datasets. To begin with, centroid points are calculated for DZs, and a series of novel AOs are introduced. And then a score function with a parameter is introduced to balance the influence between the possibility restriction and the fuzzy restriction of DZs. Thirdly, a new MCDM method under DZs is presented based on the proposed AA AOs and score function. Finally, to support the early diagnosis of depression and anxiety, we apply our method to the real-life online Depression, Anxiety, and Stress Scale (DASS) which can be transformed into DZs by our proposed preprocessing method. According to experimental results, our method is applicable to large-scale datasets and has much lower complexity as well as higher flexibility and stability.}
}
@article{GROEGER1987295,
title = {Computation—The final metaphor? An interview with Philip Johnson-Laird},
journal = {New Ideas in Psychology},
volume = {5},
number = {2},
pages = {295-304},
year = {1987},
issn = {0732-118X},
doi = {https://doi.org/10.1016/0732-118X(87)90030-4},
url = {https://www.sciencedirect.com/science/article/pii/0732118X87900304},
author = {J.A. Groeger}
}
@article{ESCOUFLAIRE2024129,
title = {Automated text classification of opinion vs. news French press articles. A comparison of transformer and feature-based approaches},
journal = {Language & Communication},
volume = {99},
pages = {129-140},
year = {2024},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2024.09.004},
url = {https://www.sciencedirect.com/science/article/pii/S0271530924000624},
author = {Louis Escouflaire and Antonin Descampe and Cédrick Fairon},
keywords = {Subjectivity, Transformers, Feature-based model, Text classification, Discourse analysis, Explainability},
abstract = {This study explores Natural Language Processing (NLP) methods for distinguishing between press articles belonging to the journalistic genres of ‘objective’ news and ‘subjective’ opinion. Two classification models are compared: CamemBERT, a French transformer model fine-tuned for the task, and a machine learning model using 32 linguistic features. Trained on 8000 Belgian French articles, both models are evaluated on 1000 Canadian French articles. Results show CamemBERT’s superiority but highlight potential for hybrid approaches and emphasizes the need for robust and transparent methods in NLP. The research contributes to understanding NLP’s role in journalism by addressing challenges of point of view detection in press discourse.}
}
@article{BENARIE1992291,
title = {Air pollution modeling: P. Zannetti, Computational Mechanics Publications, Southampton, U.K. 1990, 444 pp. Price: £59.00},
journal = {Science of The Total Environment},
volume = {119},
pages = {291},
year = {1992},
issn = {0048-9697},
doi = {https://doi.org/10.1016/0048-9697(92)90273-U},
url = {https://www.sciencedirect.com/science/article/pii/004896979290273U},
author = {Michel Benarie}
}
@article{MUGHAL2020159,
title = {Goals of the national mathematics curriculum of Pakistan: educators’ perceptions and challenges toward achievement},
journal = {International Journal of Educational Management},
volume = {35},
number = {1},
pages = {159-172},
year = {2020},
issn = {0951-354X},
doi = {https://doi.org/10.1108/IJEM-04-2020-0203},
url = {https://www.sciencedirect.com/science/article/pii/S0951354X20000678},
author = {Shahid Hussain Mughal and Muhammad Mujtaba Asad and Donnie Adams},
keywords = {Mathematics, Curriculum design, Pedagogy, Content knowledge, National plan},
abstract = {Purpose
The national mathematics curriculum of Pakistan has emphasized on improving content knowledge, reasoning abilities and problem-solving skills of students about thinking, communicating and solving mathematics (national mathematics curriculum of Pakistan, 2006). Whereas, there is a need to understand the point of view of teachers about the challenges they face in achieving the goals of national mathematics curriculum. This will help leading teacher training institutions to revisit their math teacher continuous professional development (CPD) programs and facilitate school leadership in improving the quality of math education in rural schools of the province. However, the purpose of this research study is to figure out the challenges that teachers are facing while achieving the goals of the national curriculum by teaching mathematics at the primary level in educational institutes of Pakistan.
Design/methodology/approach
In this research study qualitative research approaches have been utilized, in which focus group discussions (FGDs) were used as data collection techniques. Furthermore, thematic analysis of the data led toward the development of four overarching themes such as teachers' knowledge about mathematics curriculum, challenges relating to mathematics content and pedagogy, difficulties in developing conceptual understanding and designing lesson plans to address students' diversity.
Findings
The overall findings of this research study suggested that the majority of teachers are facing difficulties in mathematics content teaching such as decimal fraction, unitary method, measurement principles, practical geometry and data handling. Moreover, teachers are also facing challenges and difficulties in developing hands-on and minds-on activities in the teaching of mathematical concepts to the students of primary level in educational institutes of Pakistan.
Practical implications
This research study will facilitate the teachers and stakeholders to address the problematic issues in the domain of content delivery of mathematics. Whereas, this study recommends educating teachers about national mathematics curriculum and to develop a CPD framework for mathematics teachers for the enhancement of their pedagogical content knowledge. The study also recommends orientating school heads about the different aspects of math curriculum so that they can mentor math teachers in achieving math curriculum goals.
Originality/value
This is the first research study of its nature, which targets and highlights the teacher's perceptions toward the achieving the goals of national mathematics curriculum of Pakistan and addressing the pedagogical challenges faced in mathematics teachers. There is a dearth of studies in mathematics education in Sindh province. The issue is of immense importance, the findings will help teachers to improve mathematics instructions at primary level.}
}
@article{NOST202223,
title = {Earth for AI: A Political Ecology of Data-Driven Climate Initiatives},
journal = {Geoforum},
volume = {130},
pages = {23-34},
year = {2022},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2022.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0016718522000240},
author = {Eric Nost and Emma Colven},
keywords = {Adaptation, Artificial intelligence, Climate change, Digital geographies, Environmental data justice, Knowledge production},
abstract = {Emerging narratives around artificial intelligence (AI) and machine learning place great faith in these technologies’ ability to ameliorate threats posed by climate change. They promise the capacity to analyze vast amounts of more precise and real-time data, improving how decision-makers predict, respond, and adapt. Yet scholars in political ecology have long observed that technocentric approaches typically reduce complex human-environment relationships in ways that fail to account for social relations and power dynamics. This paper charts the emerging political economy of “climate AI” – the philanthropies, NGOs, private consultancies, and tech giants investing in data-driven climate initiatives. Mapping out two case studies, we show that environmental and climate crises are grist for tech solutions and find that many climate AI actors are interested in it for surveillance, greenwashing, and commodifying algorithms. We pay special attention to how neocolonial and racialized power structures manifest in climate AI and outline three ways for political ecologists and digital geographers to research its socio-materiality: how computational resources are environmentally embedded, how disasters become “shocks” that the AI industry capitalizes on, and how climate AI shapes material investment flows and landscapes. Highlighting how data-driven approaches to climate crises reproduce injustices already faced by marginalized communities, our analysis contributes to research on environmental data justice.}
}
@incollection{LOEWER20012166,
title = {Cognitive Science: Philosophical Aspects},
editor = {Neil J. Smelser and Paul B. Baltes},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences},
publisher = {Pergamon},
address = {Oxford},
pages = {2166-2171},
year = {2001},
isbn = {978-0-08-043076-8},
doi = {https://doi.org/10.1016/B0-08-043076-7/01026-3},
url = {https://www.sciencedirect.com/science/article/pii/B0080430767010263},
author = {B. Loewer},
abstract = {Three questions have dominated the philosophy of mind in the analytic tradition since Descartes. They are: what are thoughts and thinking? How can the mind represent the world? What is consciousness? Most contemporary analytic philosophers attempt to answer these questions within a broadly materialistic framework since they think that there is overwhelming reason to believe that human beings are biological organisms entirely composed of ordinary matter. Recently the central questions in the philosophy of mind have been given some new twists and partial answers by developments within cognitive science. This article reviews some of the main ideas in cognitive science and its impact on these issues in the philosophy of mind.}
}
@article{B2021107538,
title = {A survey on genomic data by privacy-preserving techniques perspective},
journal = {Computational Biology and Chemistry},
volume = {93},
pages = {107538},
year = {2021},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2021.107538},
url = {https://www.sciencedirect.com/science/article/pii/S1476927121001055},
author = {Abinaya B. and Santhi S.},
keywords = {Data sharing, Data access and storage, Data computation, Outsourcing, Privacy-preserving techniques},
abstract = {Nowadays, the purpose of human genomics is widely emerging in health-related problems and also to achieve time and cost-efficient healthcare. Due to advancement in genomics and its research, development in privacy concerns is needed regarding querying, accessing and, storage and computation of the genomic data. While the genomic data is widely accessible, the privacy issues may emerge due to the untrusted third party (adversaries/researchers), they may reveal the information or strategy plans regarding the genome data of an individual when it is requested for research purposes. To mitigate this problem many privacy-preserving techniques are used along with cryptographic methods are briefly discussed. Furthermore, efficiency and accuracy in a secure and private genomic data computation are needed to be researched in future.}
}
@article{MOTANIETO2023103965,
title = {The Mexican Carbon Capture and Storage Platform: Construction of a boundary object for bridging the gaps between contexts, actors, and disciplines},
journal = {International Journal of Greenhouse Gas Control},
volume = {129},
pages = {103965},
year = {2023},
issn = {1750-5836},
doi = {https://doi.org/10.1016/j.ijggc.2023.103965},
url = {https://www.sciencedirect.com/science/article/pii/S1750583623001354},
author = {J. Mota-Nieto and J.A. Fernández-Reyes and P.M. García-Meneses},
keywords = {CCS/CCUS, Communication platform, Mexico, Boundary objects, Stakeholders},
abstract = {Carbon Capture and Storage (CCS) is a technology identified as a potential solution to mitigate climate change by reducing carbon emissions from large-scale emitters. If CCS is expected to be adopted globally, transparent and reliable data and information must be readily attainable to all stakeholders to support the technology choice and decision-making process. The implementation of CCS requires effective communication and collaboration strategies. Still, materials and communication platforms to inform stakeholders about the potential and contribution of CCS are predominantly accessible in English since ongoing projects are mainly located in English-speaking countries. The Mexican Carbon Capture and Storage platform (MeCCS) was developed as a digital sharing and learning space for national stakeholders to obtain and expand their knowledge about CCS technology in Spanish. It was constructed as a boundary object (BO) to bridge different communities and disciplines, facilitating communication, understanding, and cooperation. The platform includes diverse elements that combine science and art to produce dissemination materials for different audiences to help build critical thinking and inform them about CCS technology. The platform confirmed its capacity to transfer and translate knowledge one year after its launch. It also served to connect different audiences in Mexico and globally and identify further areas of research and CCS-related efforts.}
}
@article{CORTESE2024108397,
title = {Applications of genome-scale metabolic models to the study of human diseases: A systematic review},
journal = {Computer Methods and Programs in Biomedicine},
volume = {256},
pages = {108397},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108397},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724003900},
author = {Nicola Cortese and Anna Procopio and Alessio Merola and Paolo Zaffino and Carlo Cosentino},
keywords = {Genome-scale metabolic networks, Constraint-based modeling, Systems biology, Simulation, Systematic literature review},
abstract = {Background and Objectives:
Genome-scale metabolic networks (GEMs) represent a valuable modeling and computational tool in the broad field of systems biology. Their ability to integrate constraints and high-throughput biological data enables the study of intricate metabolic aspects and processes of different cell types and conditions. The past decade has witnessed an increasing number and variety of applications of GEMs for the study of human diseases, along with a huge effort aimed at the reconstruction, integration and analysis of a high number of organisms. This paper presents a systematic review of the scientific literature, to pursue several important questions about the application of constraint-based modeling in the investigation of human diseases. Hopefully, this paper will provide a useful reference for researchers interested in the application of modeling and computational tools for the investigation of metabolic-related human diseases.
Methods:
This systematic review was conducted according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. Elsevier Scopus®, National Library of Medicine PubMed® and Clarivate Web of Science™ databases were enquired, resulting in 566 scientific articles. After applying exclusion and eligibility criteria, a total of 169 papers were selected and individually examined.
Results:
The reviewed papers offer a thorough and up-to-date picture of the latest modeling and computational approaches, based on genome-scale metabolic models, that can be leveraged for the investigation of a large variety of human diseases. The numerous studies have been categorized according to the clinical research area involved in the examined disease. Furthermore, the paper discusses the most typical approaches employed to derive clinically-relevant information using the computational models.
Conclusions:
The number of scientific papers, utilizing GEM-based approaches for the investigation of human diseases, suggests an increasing interest in these types of approaches; hopefully, the present review will represent a useful reference for scientists interested in applying computational modeling approaches to investigate the aetiopathology of human diseases; we also hope that this work will foster the development of novel applications and methods for the discovery of clinically-relevant insights on metabolic-related diseases.}
}
@article{ZOU2025106959,
title = {LCFFNet: A Lightweight Cross-scale Feature Fusion Network for human pose estimation},
journal = {Neural Networks},
volume = {183},
pages = {106959},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106959},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024008888},
author = {Xuelian Zou and Xiaojun Bi},
keywords = {Human pose estimation, 2d dynamic multi-scale convolution, Contextual semantic information, Adaptive feature fusion},
abstract = {Human pose estimation is one of the most critical and challenging problems in computer vision. It is applied in many computer vision fields and has important research significance. However, it is still a difficult challenge to strike a balance between the number of parameters and computing load of the model and the accuracy of human pose estimation. In this study, we suggest a Lightweight Cross-scale Feature Fusion Network (LCFFNet) to strike a balance between accuracy and computational load and parameter volume. The Lightweight HRNet-Like (LHRNet) network, Cross-Resolution-Aware Semantics Module (CRASM), and Adapt Feature Fusion Module (AFFM) make up LCFFNet. To be more precise, first, we suggest a lightweight LHRNet network that includes Dynamic Multi-scale Convolution Basic (DMSC-Basic block) block, Basic block, and DMSC-Basic block submodules in the network’s three high-resolution subnetwork stages. The proposed dynamic multi-scale convolution in DMSC-Basic block can reduces the amount of model parameters and complexity of the LHRNet network, and has the ability to extract variable pose features. In order to maintain the model’s ability to express features, the Basic block is introduced. As a result, the LHRNet network not only makes the model more lightweight but also enhances its feature expression capabilities. Second, we propose a CRASM module to enhance contextual semantic information while reducing the semantic gap between different scales by fusing features from different scales. Finally, the augmented semantic feature map’s spatial resolution is finally restored from bottom to top using our suggested AFFM, and adaptive feature fusion is used to increase the positioning accuracy of important sites. Our method successfully predicts keypoints with 74.2 % AP, 89.9 % PCKh@0.5 and 66.9 % AP on the MSCOCO 2017, MPII and Crowdpose datasets, respectively. Our model reduces the number of parameters by 89.0 % and the computational complexity by 87.5 % compared with HRNet. The proposed network performs as well as current large-model human pose estimation networks while outperforming state-of the-art lightweight networks.}
}
@article{FERNANDEZ20181,
title = {Natural deep eutectic solvents-mediated extractions: The way forward for sustainable analytical developments},
journal = {Analytica Chimica Acta},
volume = {1038},
pages = {1-10},
year = {2018},
issn = {0003-2670},
doi = {https://doi.org/10.1016/j.aca.2018.07.059},
url = {https://www.sciencedirect.com/science/article/pii/S0003267018309231},
author = {María de los Ángeles Fernández and Joana Boiteux and Magdalena Espino and Federico J.V. Gomez and María Fernanda Silva},
keywords = {Natural deep eutectic solvents, Extraction, Green analytical chemistry, Sample prep, Microextractions},
abstract = {The concept of sustainable development has impacted in analytical chemistry changing the way of thinking processes and methods. It is important for analytical chemists to consider how sample preparation can integrate the basic concepts of Green Chemistry. In this sense, the replacement of traditional organic solvents is of utmost importance. Natural Deep Eutectic Solvents (NADES) have come to light as a green alternative. In the last few years, a growing number of contributions have applied these natural solvents proving their efficiency in terms of extraction ability, analyte stabilization capacity and detection compatibility. However, the arising question that has to be answered is: the use of NADES is enough to green an extraction process? This review presents an overview of knowledge regarding sustainability of NADES-based extraction procedures, focused on reported literature within the timeframe spanning from 2011 up to date. The contributions were analyzed from a green perspective in terms of energy, time, sample and solvent consumption. Moreover, we include a critical analysis to clarify whether the use of NADES as extraction media is enough for greening an analytical methodology; strategies to make them even greener are also presented. Finally, recent trends and future perspectives on how NADES-based extraction approaches in combination with computational methodologies can contribute are discussed.}
}
@article{BYLYA20172358,
title = {Modelling challenges for incremental bulk processes despite advances in simulation technology: example issues and approaches},
journal = {Procedia Engineering},
volume = {207},
pages = {2358-2363},
year = {2017},
note = {International Conference on the Technology of Plasticity, ICTP 2017, 17-22 September 2017, Cambridge, United Kingdom},
issn = {1877-7058},
doi = {https://doi.org/10.1016/j.proeng.2017.10.1008},
url = {https://www.sciencedirect.com/science/article/pii/S1877705817358010},
author = {O.I. Bylya and M. Ward and B. Krishnamurty and S. Tamang and R.A. Vasin},
keywords = {Flow forming, rotary forging, process modelling, simplification approaches. Introduction},
abstract = {Incremental bulk deformation processes have traditionally been difficult to simulate. This paper will argue that, despite advances in computation and software, they remain difficult to model. The main reason for this is the shortage of ideas on what is the real objective of FE modelling for such processes. Even a very detailed model and data obtained in simulation does not give answers to the main question - how to optimise the process parameters? High computational time and volume of information only aggravate the situation. All modern mathematical techniques of dimensionality reduction (such as POD/PGD) lose their power when the priorities and acceptable compromises of modelling are not clear. This paper tries to use a large volume of available experimental and modelling experience to illustrate this problem and look for possible break-through directions.}
}
@incollection{CUMMINS20171,
title = {Chapter 1 - The Agile Enterprise},
editor = {Fred A. Cummins},
booktitle = {Building the Agile Enterprise (Second Edition)},
publisher = {Morgan Kaufmann},
edition = {Second Edition},
address = {Boston},
pages = {1-34},
year = {2017},
series = {The MK/OMG Press},
isbn = {978-0-12-805160-3},
doi = {https://doi.org/10.1016/B978-0-12-805160-3.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128051603000016},
author = {Fred A. Cummins},
keywords = {Agile enterprise, Business impact of technology, Capability-based architecture, Business collaboration management, Value delivery management, Value delivery modeling language},
abstract = {This chapter begins with an introduction to the agile enterprise concept and provides a somewhat historical perspective on the evolution of information technology and its impact on business operations and management. It then introduces three new ways of thinking that are key to today's agile enterprise and are referenced in the subtitle of this book: (1) capability-based architecture, (2) business collaboration management (BCM), and (3) value delivery management (VDM). Finally, the impact of VDM is discussed related to the management of major business changes, along with some critical success factors for the journey to agility.}
}
@article{GOTTS2019100728,
title = {Agent-based modelling of socio-ecological systems: Models, projects and ontologies},
journal = {Ecological Complexity},
volume = {40},
pages = {100728},
year = {2019},
note = {Agent-based modelling to study resilience in socio-ecological systems},
issn = {1476-945X},
doi = {https://doi.org/10.1016/j.ecocom.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S1476945X18301272},
author = {Nicholas M. Gotts and George A.K. {van Voorn} and J. Gareth Polhill and Eline de Jong and Bruce Edmonds and Gert Jan Hofstede and Ruth Meyer},
keywords = {Socio-ecological system, Agent-based model, Complexity, Ontology},
abstract = {Socio-Ecological Systems (SESs) are the systems in which our everyday lives are embedded, so understanding them is important. The complex properties of such systems make modelling an indispensable tool for their description and analysis. Human actors play a pivotal role in SESs, but their interactions with each other and their environment are often underrepresented in SES modelling. We argue that more attention should be given to social aspects in models of SESs, but this entails additional kinds of complexity. Modelling choices need to be as transparent as possible, and to be based on analysis of the purposes and limitations of modelling. We recommend thinking in terms of modelling projects rather than single models. Such a project may involve multiple models adopting different modelling methods. We argue that agent-based models (ABMs) are an essential tool in an SES modelling project, but their expressivity, which is their major advantage, also produces problems with model transparency and validation. We propose the use of formal ontologies to make the structure and meaning of models as explicit as possible, facilitating model design, implementation, assessment, comparison and extension.}
}
@article{EVANS2008100,
title = {When can we say ‘if’?},
journal = {Cognition},
volume = {108},
number = {1},
pages = {100-116},
year = {2008},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2008.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0010027708000310},
author = {Jonathan St.B.T. Evans and Helen Neilens and Simon J. Handley and David E. Over},
keywords = {Conditionals, Reasoning, Decision making, Language comprehension},
abstract = {In this study, we focus on the conditions which permit people to assert a conditional statement of the form ‘if p then q’ with conversational relevance. In a broadly decision-theoretic approach, also drawing on hypothetical thinking theory [Evans, J. St. B. T. (2007). Hypothetical thinking: Dual processes in reasoning and judgement. Hove, UK: Psychology Press.], we predicted that conditional tips and promises would appear more useful and persuasive and be more likely to encourage an action p when (a) the conditional link from p to q was stronger, (b) the cost of the action p was lower and (c) the benefit of the consequence q was higher. Similarly, we predicted that conditional warnings and threats would be seen as more useful and persuasive and more likely to discourage an action p when (a) the conditional link from p to q was stronger, (b) the benefit of the action p was lower and (c) the cost of the consequence q was higher. All predictions were strongly confirmed, suggesting that such conditionals may best be asserted when they are of high relevance to the goals of the listener.}
}